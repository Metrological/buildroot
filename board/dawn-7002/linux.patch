diff -Naur kernel-3.3-3.0a-ref/arch/Kconfig kernel-current/arch/Kconfig
--- kernel-3.3-3.0a-ref/arch/Kconfig	2013-08-28 01:30:55.000000000 +0200
+++ kernel-current/arch/Kconfig	2015-06-12 16:27:20.008112063 +0200
@@ -199,4 +199,39 @@
 config HAVE_CMPXCHG_DOUBLE
 	bool
 
+config REBOOT_ON_PANIC
+	bool "Reboot on PANIC"
+	default n
+
+config REBOOT_ON_OOM
+	bool "Reboot on OOM"
+	default n
+
+config REBOOT_ON_OOPS
+	bool "Reboot on OOPS"
+	default n
+
+config REBOOT_ON_SIGNAL
+	bool "Reboot on signal"
+	default n
+
+config SIGNAL_TO_REBOOT_ON
+    string "Reboot on sent signal (user)"
+    depends on REBOOT_ON_SIGNAL
+	help
+		Add signal to the list.
+		Signal is a value enclosed between "()".
+		The value 0 means all signals and must be at the first position.	
+		Signals following 0 don't trigger the reboot.
+		
+
+config REBOOT_ON_FATAL_SIGNAL
+	bool "Reboot on received signal (kernel)"
+	depends on REBOOT_ON_SIGNAL
+	default n
+	help
+		In the kernel, if a signal is unknown or not handled at all 
+		Meaning without user handler or handle by default or ignore
+		The associated process is reboot (originally killed by the kernel)
+
 source "kernel/gcov/Kconfig"
diff -Naur kernel-3.3-3.0a-ref/arch/mips/brcmstb/Platform kernel-current/arch/mips/brcmstb/Platform
--- kernel-3.3-3.0a-ref/arch/mips/brcmstb/Platform	2013-08-28 01:30:56.000000000 +0200
+++ kernel-current/arch/mips/brcmstb/Platform	2015-06-12 16:27:19.928072066 +0200
@@ -3,6 +3,6 @@
 #
 platform-$(CONFIG_BRCMSTB)	+= brcmstb/
 cflags-$(CONFIG_BRCMSTB)	+= -I$(srctree)/arch/mips/include/asm/mach-brcmstb
-load-$(CONFIG_BRCMSTB)		+= 0x80001000
+load-$(CONFIG_BRCMSTB)		+= 0x80004000
 
 cflags-$(CONFIG_NO_INLINE)	+= -fno-inline
diff -Naur kernel-3.3-3.0a-ref/arch/mips/brcmstb/prom.c kernel-current/arch/mips/brcmstb/prom.c
--- kernel-3.3-3.0a-ref/arch/mips/brcmstb/prom.c	2013-08-28 01:30:56.000000000 +0200
+++ kernel-current/arch/mips/brcmstb/prom.c	2015-06-12 16:27:19.928072066 +0200
@@ -210,6 +210,7 @@
 	} while (0)
 
 	FETCH("ETH0_HWADDR", parse_eth0_hwaddr, brcm_primary_macaddr);
+	FETCH("MOCA_HWADDR", parse_eth0_hwaddr, brcm_moca_macaddr);
 	FETCH("ETH0_MDIO_MODE", parse_eth0_mdio_mode, &brcm_eth0_no_mdio);
 	FETCH("ETH0_PHY", parse_string, brcm_eth0_phy);
 	FETCH("ETH0_PHYADDR", parse_string, brcm_eth0_phyaddr);
diff -Naur kernel-3.3-3.0a-ref/arch/mips/Kconfig kernel-current/arch/mips/Kconfig
--- kernel-3.3-3.0a-ref/arch/mips/Kconfig	2013-08-28 01:30:56.000000000 +0200
+++ kernel-current/arch/mips/Kconfig	2015-06-12 16:27:20.008112063 +0200
@@ -8,12 +8,6 @@
 	select HAVE_PERF_EVENTS
 	select PERF_USE_VMALLOC
 	select HAVE_ARCH_KGDB
-	select HAVE_FUNCTION_TRACER
-	select HAVE_FUNCTION_TRACE_MCOUNT_TEST
-	select HAVE_DYNAMIC_FTRACE
-	select HAVE_FTRACE_MCOUNT_RECORD
-	select HAVE_C_RECORDMCOUNT
-	select HAVE_FUNCTION_GRAPH_TRACER
 	select HAVE_KPROBES
 	select HAVE_KRETPROBES
 	select ARCH_BINFMT_ELF_RANDOMIZE_PIE
@@ -2365,9 +2359,39 @@
 	default y
 
 config STACKTRACE_SUPPORT
-	bool
+	bool "Stack trace support"
 	default y
 
+menuconfig FTRACE_OPTIONS
+	bool "Ftrace options"
+	default y 
+
+if FTRACE_OPTIONS
+config HAVE_FUNCTION_TRACER
+	bool "Have function tracer"
+	default y
+	
+config HAVE_FUNCTION_TRACE_MCOUNT_TEST
+	bool "Have function trace mcount test"
+	default y
+	
+config HAVE_DYNAMIC_FTRACE
+	bool "have dynamic ftrace"
+	default y
+	
+config HAVE_FTRACE_MCOUNT_RECORD
+	bool "Have ftrace mcount record"
+	default y
+	
+config HAVE_C_RECORDMCOUNT
+	bool "Have C record mount"
+	default y
+	
+config HAVE_FUNCTION_GRAPH_TRACER
+	bool "Have function graph tracer"
+	default y
+endif
+	
 source "init/Kconfig"
 
 source "kernel/Kconfig.freezer"
diff -Naur kernel-3.3-3.0a-ref/arch/mips/Kconfig.debug kernel-current/arch/mips/Kconfig.debug
--- kernel-3.3-3.0a-ref/arch/mips/Kconfig.debug	2013-08-28 01:30:56.000000000 +0200
+++ kernel-current/arch/mips/Kconfig.debug	2015-06-12 16:27:20.008112063 +0200
@@ -1,7 +1,7 @@
 menu "Kernel hacking"
 
 config TRACE_IRQFLAGS_SUPPORT
-	bool
+	bool "Trace irq flags support"
 	default y
 
 source "lib/Kconfig.debug"
diff -Naur kernel-3.3-3.0a-ref/arch/mips/kernel/setup.c kernel-current/arch/mips/kernel/setup.c
--- kernel-3.3-3.0a-ref/arch/mips/kernel/setup.c	2013-08-28 01:30:57.000000000 +0200
+++ kernel-current/arch/mips/kernel/setup.c	2015-06-12 16:27:19.956086065 +0200
@@ -607,6 +607,15 @@
 		request_resource(res, &data_resource);
 	}
 }
+/* this is an awful patch on the kernel.
+the reason is that there is some gardening of the memory
+at address 0x80001000..
+so, we recopy the PK & CSC data to a new buffer
+*/
+char pPKdata[0x600];
+char pCSCdata[0x1000];
+EXPORT_SYMBOL(pPKdata);
+EXPORT_SYMBOL(pCSCdata);
 
 void __init setup_arch(char **cmdline_p)
 {
@@ -616,7 +625,26 @@
 #ifdef CONFIG_EARLY_PRINTK
 	setup_early_printk();
 #endif
-	cpu_report();
+        memcpy(pPKdata,(const void*)0x80001000,0x600);
+        memcpy(pCSCdata,(const void*)0x80001600,0x1000);
+	printk("pPKdata=0x%x\n",(int)pPKdata);
+	printk("pCSCdata=0x%x\n",(int)pCSCdata);
+	
+#if 0	
+        {
+	 printk("80001000:%2.2x%2.2x%2.2x%2.2x\n",
+	 *((unsigned char*)0x80001000),
+	 *((unsigned char*)0x80001001),
+	 *((unsigned char*)0x80001002),
+	 *((unsigned char*)0x80001003));
+	 printk("80001600:%2.2x%2.2x%2.2x%2.2x\n",
+	 *((unsigned char*)0x80001600),
+	 *((unsigned char*)0x80001601),
+	 *((unsigned char*)0x80001602),
+	 *((unsigned char*)0x80001603));	 
+	 }
+#endif	 
+	 	cpu_report();
 	check_bugs_early();
 
 #if defined(CONFIG_VT)
diff -Naur kernel-3.3-3.0a-ref/block/genhd.c kernel-current/block/genhd.c
--- kernel-3.3-3.0a-ref/block/genhd.c	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/block/genhd.c	2015-06-12 16:27:19.952084065 +0200
@@ -21,6 +21,10 @@
 
 #include "blk.h"
 
+#ifdef CONFIG_KDEV_DRIVER
+#include <linux/kdev.h>
+#endif
+
 static DEFINE_MUTEX(block_class_lock);
 struct kobject *block_depr;
 
@@ -263,6 +267,42 @@
 }
 #endif /* CONFIG_PROC_FS */
 
+
+#ifdef CONFIG_KDEV_DRIVER
+
+int blkdev_getList(kdev_ioc_getDevices_t * listOfBlkDev)
+{
+  unsigned int index;
+  unsigned int offset = 0;
+  struct blk_major_name * bd;
+  
+  mutex_lock(&block_class_lock);
+  index = listOfBlkDev->devs_nb;
+  
+  for(offset = 0; offset < BLKDEV_MAJOR_HASH_SIZE; offset++)
+  {
+    for (bd = major_names[offset]; bd; bd = bd->next)
+    {
+      listOfBlkDev->devs[index].device_type = KDEV_BLOCK_DEV;
+      strlcpy(listOfBlkDev->devs[index].device_name, bd->name, sizeof(bd->name));
+      listOfBlkDev->devs[index].major = bd->major;
+      listOfBlkDev->devs[index].min_minor = 0;
+      listOfBlkDev->devs[index].max_minor = 0;
+      
+      index++;
+      if(index == (sizeof(listOfBlkDev->devs)/sizeof(kdev_dev_t)))
+        return 1;
+    }
+  }
+  
+  listOfBlkDev->devs_nb = index;
+  mutex_unlock(&block_class_lock);
+  
+  return 0;
+}
+
+#endif /* CONFIG_KDEV_DRIVER */
+
 /**
  * register_blkdev - register a new block device
  *
diff -Naur kernel-3.3-3.0a-ref/drivers/brcmstb/bchip.c kernel-current/drivers/brcmstb/bchip.c
--- kernel-3.3-3.0a-ref/drivers/brcmstb/bchip.c	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/drivers/brcmstb/bchip.c	2015-06-12 16:27:19.928072066 +0200
@@ -55,6 +55,7 @@
 unsigned char brcm_eth0_phyaddr[CFE_STRING_SIZE];
 
 u8 brcm_primary_macaddr[IFHWADDRLEN] = { 0x00, 0x00, 0xde, 0xad, 0xbe, 0xef };
+u8 brcm_moca_macaddr[IFHWADDRLEN] = { 0x00, 0x00, 0xde, 0xad, 0xbf, 0xef };
 
 unsigned long brcm_base_baud0 = BRCM_BASE_BAUD_STB;	/* UPG UARTA */
 unsigned long brcm_base_baud = BRCM_BASE_BAUD_STB;	/* UPG_UART[BC] */
@@ -153,12 +154,21 @@
 /* SATA3 SSC per-port bitfield */
 static u32 sata3_enable_ssc;
 
+#define SATA3_MDIO_REG_BANK_SIZE	0x10
+#define SATA3_MDIO_BANK_SELECT(bank,port) \
+	((bank) + ((port) * SATA3_MDIO_REG_BANK_SIZE))
+
+#define SATA3_MDIO_TX_0_REG_BANK	0x60
 #define SATA3_MDIO_TXPMD_0_REG_BANK	0x1A0
 #define SATA3_MDIO_BRIDGE_BASE		(BCHP_SATA_GRB_REG_START + 0x100)
 #define SATA3_MDIO_BASE_REG_ADDR	(SATA3_MDIO_BRIDGE_BASE + 0x8F * 4)
 
 #define SATA_AHCI_GHC_PORTS_IMPLEMENTED	(BCHP_SATA_AHCI_GHC_REG_START + 0xC)
 
+/* SATA3_TX: TX Register Bank Registers */
+#define SATA3_TX_AFE_CTRL_2			0x82
+#define SATA3_TX_AFE_CTRL_3			0x83
+
 #define SATA3_TXPMD_CONTROL1			0x81
 #define SATA3_TXPMD_TX_FREQ_CTRL_CONTROL1	0x82
 #define SATA3_TXPMD_TX_FREQ_CTRL_CONTROL2	0x83
@@ -176,12 +186,12 @@
 	BDEV_WR(ofs * 4 + SATA3_MDIO_BRIDGE_BASE, tmp);
 }
 
-static void brcm_sata3_init_freq(int port, int ssc_enable)
+static void brcm_sata3_init_phy(int port, int ssc_enable)
 {
-	u32 bank = SATA3_MDIO_TXPMD_0_REG_BANK + port * 0x10;
+	u32 bank = SATA3_MDIO_BANK_SELECT(SATA3_MDIO_TXPMD_0_REG_BANK, port);
 
 	if (ssc_enable)
-		pr_info("SATA3: enabling SSC on port %d\n", port);
+		printk("SATA3: enabling SSC on port %d\n", port);
 
 	/* TXPMD_control1 - enable SSC force */
 	brcm_sata3_mdio_wr_reg(bank, SATA3_TXPMD_CONTROL1, 0xFFFFFFFC,
@@ -202,6 +212,18 @@
 	else
 		brcm_sata3_mdio_wr_reg(bank, SATA3_TXPMD_TX_FREQ_CTRL_CONTROL3,
 				0xFFFFFC00, 0x000003DF);
+
+	/*
+	 * (Derived from BBS document provided by Chanshine N.)
+	 * Set TX amplitude to -900mVppd, with pre-emphasis
+	 */
+	bank = SATA3_MDIO_BANK_SELECT(SATA3_MDIO_TX_0_REG_BANK, port);
+
+	brcm_sata3_mdio_wr_reg(bank, SATA3_TX_AFE_CTRL_2,
+			0xFFFF03FF, 0x00001000);
+
+	brcm_sata3_mdio_wr_reg(bank, SATA3_TX_AFE_CTRL_3,
+			0xFFFFF00F, 0x00000614);
 }
 
 /* Check up to 32 ports, although we typically only have 2 */
@@ -244,9 +266,10 @@
 
 	BDEV_WR(BCHP_SATA_TOP_CTRL_BUS_CTRL, (DATA_ENDIAN << 4) |
 			(DATA_ENDIAN << 2) | (MMIO_ENDIAN << 0));
-
+/* SB: Force ssc */
 	for (i = 0; i < ports; i++)
-		brcm_sata3_init_freq(i, sata3_enable_ssc & (1 << i));
+		/* brcm_sata3_init_freq(i, sata3_enable_ssc & (1 << i)); */
+		brcm_sata3_init_phy(i, 1);
 #endif
 }
 
@@ -484,7 +507,15 @@
 	brcm_primary_macaddr[4]++;
 	return 0;
 }
+
+int brcm_alloc_moca_macaddr(u8 *buf)
+{
+	memcpy(buf, brcm_moca_macaddr, ETH_ALEN);
+	return 0;
+}
+
 EXPORT_SYMBOL(brcm_alloc_macaddr);
+EXPORT_SYMBOL(brcm_alloc_moca_macaddr);
 
 /***********************************************************************
  * WKTMR utility functions (boot time only)
diff -Naur kernel-3.3-3.0a-ref/drivers/brcmstb/board.c kernel-current/drivers/brcmstb/board.c
--- kernel-3.3-3.0a-ref/drivers/brcmstb/board.c	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/drivers/brcmstb/board.c	2015-06-12 16:27:20.044130062 +0200
@@ -24,6 +24,7 @@
 #include <linux/bmoca.h>
 #include <linux/mtd/partitions.h>
 #include <linux/brcmstb/brcmstb.h>
+#include <linux/delay.h>
 
 /* board features */
 int brcm_docsis_platform;
@@ -49,6 +50,12 @@
 unsigned long brcm_moca_rf_band = MOCA_BAND_HIGHRF;
 #endif
 
+/*prototypes */
+static void board_pinux_setup_DMC7000KLG_CADB(void);
+static void board_cfe_environment_setup_DMC7000KLG_CADB(void);
+static void board_force_fan(void);
+void board_pinmux_setup_default(void);
+
 /***********************************************************************
  * PIN_MUX setup
  *
@@ -100,8 +107,959 @@
 				 (BCHP_SDIO_0_CFG_##y - \
 				  BCHP_SDIO_0_CFG_REG_START))
 
+#define IODIR(reg,shift,val) do{ \
+        BDEV_WR(BCHP_GIO_##reg, \
+        (BDEV_RD(BCHP_GIO_##reg) & ~(1<<shift)) | ((val) << shift)); \
+        } while(0)
+
+#define ODEN(reg,shift,val) do{ \
+        BDEV_WR(BCHP_GIO_##reg, \
+        (BDEV_RD(BCHP_GIO_##reg) & ~(1<<shift)) | ((val) << shift)); \
+        } while(0)
+
+#define DATA(reg,shift,val) do { \
+        BDEV_WR(BCHP_GIO_##reg, \
+                ((BDEV_RD(BCHP_GIO_##reg) & \
+                 ~(1 << shift)) | ((val) << shift)));\
+        } while (0)
+
+
+#define PAD_CTRL(reg, field, val) do { \
+        BDEV_WR(BCHP_SUN_TOP_CTRL_PIN_MUX_PAD_CTRL_##reg, \
+                (BDEV_RD(BCHP_SUN_TOP_CTRL_PIN_MUX_PAD_CTRL_##reg) & \
+                 ~BCHP_SUN_TOP_CTRL_PIN_MUX_PAD_CTRL_##reg##_##field##_pad_ctrl_MASK) | \
+                ((val) << \
+                 BCHP_SUN_TOP_CTRL_PIN_MUX_PAD_CTRL_##reg##_##field##_pad_ctrl_SHIFT)); \
+        } while (0)
+
 void board_pinmux_setup(void)
 {
+    printk (KERN_INFO " Board detected : ******* %s ******* . \n",brcm_cfe_boardname );
+    board_cfe_environment_setup_DMC7000KLG_CADB();
+    board_pinux_setup_DMC7000KLG_CADB ();
+    board_force_fan();
+}
+
+
+#define PULL_NONE   (0)
+#define PULL_DOWN   (1)
+#define PULL_UP     (2)
+#define IODIR_OUT   (0)
+#define IODIR_IN    (1)
+#define TOTEM_POLE  (0)
+#define OPEN_DRAIN  (1)
+
+void board_pinux_setup_DMC7000KLG_CADB(void)
+{
+    printk (KERN_INFO " Specific init for PACE DMC7000KLG CADB Board. \n");
+    printk (KERN_INFO " Based on D915_GPIO_MAP_CADB_d1-1_29-5.xls\n");
+
+    /* AON_GPIO_00  AON_GP0_AUD_SPDIF   O   AUD_SPDIF  N/A  PULL_NONE  totem-pole    N/A    SPDIF output + strapping for boot (strap_xcore_bias_sel_0) */
+    AON_PINMUX(0, aon_gpio_00, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_0_aon_gpio_00_AUD_SPDIF);
+    AON_PADCTRL(0, aon_gpio_00_pad_ctrl, PULL_NONE);
+    IODIR(AON_IODIR_LO, 0, IODIR_OUT);
+    ODEN(AON_ODEN_LO, 0, TOTEM_POLE);
+
+    /* AON_GPIO_01  Moca_powerdown_n    O   GPIO       LOW  PULL_HIGH   open-drain  HIGH    0 => MoCA 3V3 off + strapping for boot (strap_xcore_bias_sel_1) */
+    AON_PINMUX(0, aon_gpio_01, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_0_aon_gpio_01_AON_GPIO_01);
+    AON_PADCTRL(0, aon_gpio_01_pad_ctrl, PULL_UP);
+    IODIR(AON_IODIR_LO, 1, IODIR_OUT);
+    ODEN(AON_ODEN_LO, 1, TOTEM_POLE);
+    DATA(AON_DATA_LO, 1, 1);
+    brcm_moca_i2c_base = BPHYSADDR(BCHP_BSCD_REG_START);
+
+    /* AON_GPIO_02  CM_PWR_EN   O   GPIO    HIgh    PULL_HIGH   totem-pole  HIgh    cable modem power switch. 1=> cable modem power ON */
+    AON_PINMUX(0, aon_gpio_02, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_0_aon_gpio_02_AON_GPIO_02);
+    AON_PADCTRL(0, aon_gpio_02_pad_ctrl, PULL_UP);
+    IODIR(AON_IODIR_LO, 2, IODIR_OUT);
+    ODEN(AON_ODEN_LO, 2, TOTEM_POLE);
+    DATA(AON_DATA_LO, 2, 1);
+
+    /* AON_GPIO_03  wake_on_lan I   GPIO    LOW     PULL_HIGH   N/A    N/A    From ethernet switch BCM53125 */
+    AON_PINMUX(0, aon_gpio_03, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_0_aon_gpio_03_AON_IR_IN1); /* SB: switch wol to ir_in1 */
+    AON_PADCTRL(0, aon_gpio_03_pad_ctrl, PULL_UP);
+    IODIR(AON_IODIR_LO, 3, IODIR_IN);
+
+    /* AON_GPIO_04    led_cathode_0     I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915 - option to drive red power led with LDK to reduce power consumption in S3 mode. */
+    AON_PINMUX(0, aon_gpio_04, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_0_aon_gpio_04_AON_GPIO_04);
+    AON_PADCTRL(0, aon_gpio_04_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 4, IODIR_IN);
+
+    /* AON_GPIO_05    led_cathode_1     I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915 - option for wake-up of S3 mode managed by BCM3383. */
+    AON_PINMUX(0, aon_gpio_05, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_0_aon_gpio_05_AON_GPIO_05);
+    AON_PADCTRL(0, aon_gpio_05_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 5, IODIR_IN);
+
+    /* AON_GPIO_06    led_cathode_2     I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(1, aon_gpio_06, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_1_aon_gpio_06_AON_GPIO_06);
+    AON_PADCTRL(0, aon_gpio_06_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 6, IODIR_IN);
+
+    /* AON_GPIO_07    led_cathode_3     I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(1, aon_gpio_07, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_1_aon_gpio_07_AON_GPIO_07);
+    AON_PADCTRL(0, aon_gpio_07_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 7, IODIR_IN);
+
+    /* AON_GPIO_08    led_cathode_4     I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(1, aon_gpio_08, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_1_aon_gpio_08_AON_GPIO_08);
+    AON_PADCTRL(1, aon_gpio_08_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 8, IODIR_IN);
+
+    /* AON_GPIO_09    led_cathode_5     I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(1, aon_gpio_09, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_1_aon_gpio_09_AON_GPIO_09);
+    AON_PADCTRL(1, aon_gpio_09_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 9, IODIR_IN);
+
+    /* AON_GPIO_10    led_cathode_6     I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(1, aon_gpio_10, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_1_aon_gpio_10_AON_GPIO_10);
+    AON_PADCTRL(1, aon_gpio_10_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 10, IODIR_IN);
+
+    /* AON_GPIO_11    led_cathode_7     I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(1, aon_gpio_11, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_1_aon_gpio_11_AON_GPIO_11);
+    AON_PADCTRL(1, aon_gpio_11_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 11, IODIR_IN);
+
+    /* AON_GPIO_12    led_anode_0n      I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(1, aon_gpio_12, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_1_aon_gpio_12_AON_GPIO_12);
+    AON_PADCTRL(1, aon_gpio_12_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 12, IODIR_IN);
+
+    /* AON_GPIO_13    led_anode_1n      I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(1, aon_gpio_13, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_1_aon_gpio_13_AON_GPIO_13);
+    AON_PADCTRL(1, aon_gpio_13_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 13, IODIR_IN);
+
+    /* AON_GPIO_14    led_anode_2n      I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(2, aon_gpio_14, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_2_aon_gpio_14_AON_GPIO_14);
+    AON_PADCTRL(1, aon_gpio_14_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 14, IODIR_IN);
+
+    /* AON_GPIO_15    led_anode_3n      I   GPIO       n/a     Low    n/a    option for 7 segment display, not used on D915    */
+    AON_PINMUX(2, aon_gpio_15, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_2_aon_gpio_15_AON_GPIO_15);
+    AON_PADCTRL(1, aon_gpio_15_pad_ctrl, PULL_DOWN);
+    IODIR(AON_IODIR_LO, 15, IODIR_IN);
+
+    /* AON_GPIO_16        led_pwr_red    O    GPIO    HIgh    PULL_NONE    totem-pole    HIGH    "1 => red power LED ON init value to be confirmed, depending on standby LED behavior requested at boot" */
+    AON_PINMUX(2, aon_gpio_16, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_2_aon_gpio_16_AON_GPIO_16);
+    AON_PADCTRL(1, aon_gpio_16_pad_ctrl, PULL_NONE);
+    IODIR(AON_IODIR_LO, 16, IODIR_OUT);
+    ODEN(AON_ODEN_LO, 16, TOTEM_POLE);
+    DATA(AON_DATA_LO, 16, 0);
+
+    /* AON_GPIO_17        sw_standby_n    I    GPIO    HIgh    PULL_NONE    N/A    N/A    stand-by key input, 1 => key pressed */
+    AON_PINMUX(2, aon_gpio_17, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_2_aon_gpio_17_AON_GPIO_17);
+    AON_PADCTRL(1, aon_gpio_17_pad_ctrl, PULL_NONE);
+    IODIR(AON_IODIR_LO, 17, IODIR_IN);
+
+    /* AON_GPIO_18        sw_ch_up_n    I    GPIO    HIgh    PULL_NONE    N/A    N/A    channel up key input, 1 => key pressed */
+     AON_PINMUX(2, aon_gpio_18, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_2_aon_gpio_18_AON_GPIO_18);
+    AON_PADCTRL(1, aon_gpio_18_pad_ctrl, PULL_NONE);
+    IODIR(AON_IODIR_LO, 18, IODIR_IN);
+
+    /* AON_GPIO_19        sw_ch_dwn_n    I    GPIO    HIgh    PULL_NONE    N/A    N/A    channel down key input,  1 => key pressed */
+    AON_PINMUX(2, aon_gpio_19, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_2_aon_gpio_19_AON_GPIO_19);
+    AON_PADCTRL(1, aon_gpio_19_pad_ctrl, PULL_NONE);
+    IODIR(AON_IODIR_LO, 19, IODIR_IN);
+
+    /* AON_GPIO_20        PVR_POWER_EN    O    GPIO    HIgh    PULL_HIGH    totem-pole    HIgh    HDD supply switch, 1=> HDD power ON */
+    AON_PINMUX(2, aon_gpio_20, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_2_aon_gpio_20_AON_GPIO_20);
+    AON_PADCTRL(1, aon_gpio_20_pad_ctrl, PULL_UP);
+    IODIR(AON_IODIR_LO, 20, IODIR_OUT);
+    ODEN(AON_ODEN_LO, 20, TOTEM_POLE);
+    {
+		int i,j ; 
+		for ( i = 0 ; i < 100 ; i ++) /* 100 x ( 20us +20 us) = 4ms */
+		{
+			for ( j = 0 ; j < 17 ; j ++) { DATA(AON_DATA_LO, 20, 1); } /* Loop 20us  ( 17 * 1.2us ) high level */
+			
+			for ( j = 0 ; j < 17 ; j ++) { DATA(AON_DATA_LO, 20, 0); } /* Loop 20us  ( 17 * 1.2us ) low  level */
+			
+		}
+	}
+    DATA(AON_DATA_LO, 20, 1);
+
+    /* AON_SGPIO_00        rf4ce_irq_n    I    GPIO    LOW    N/A    N/A    N/A    */
+    AON_PINMUX(2, aon_sgpio_00, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_2_aon_sgpio_00_AON_SGPIO_00);
+    IODIR(AON_IODIR_EXT, 0, IODIR_IN);
+
+    /* AON_SGPIO_01        rf4ce_wkup    O    GPIO    LOW    N/A    open-drain    High */
+    AON_PINMUX(3, aon_sgpio_01, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_3_aon_sgpio_01_AON_SGPIO_01);
+    IODIR(AON_IODIR_EXT, 1, IODIR_OUT);
+    ODEN(AON_ODEN_EXT, 1, OPEN_DRAIN);
+    DATA(AON_DATA_EXT, 1, 1);
+
+    /* AON_SGPIO_02        RF4CE_SCL    O    AON_BSC_M1_SCL    LOW    N/A    open-drain    High    RF4CE_I2C */
+    AON_PINMUX(3, aon_sgpio_02, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_3_aon_sgpio_02_AON_BSC_M1_SCL);
+    IODIR(AON_IODIR_EXT, 2, IODIR_OUT);
+    ODEN(AON_ODEN_EXT, 2, OPEN_DRAIN);
+    DATA(AON_DATA_EXT, 2, 1);
+
+    /* AON_SGPIO_03        RF4CE_SDA    I/O    AON_BSC_M1_SDA    N/A    N/A    open-drain    High    RF4CE_I2C */
+    AON_PINMUX(3, aon_sgpio_03, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_3_aon_sgpio_03_AON_BSC_M1_SDA);
+    ODEN(AON_ODEN_EXT, 3, OPEN_DRAIN);
+    DATA(AON_DATA_EXT, 3, 1);
+
+    /* AON_SGPIO_04        HDMI_SCL    O    AON_BSC_M2_SCL    LOW    N/A    open-drain    High    HDMI I2C */
+    AON_PINMUX(3, aon_sgpio_04, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_3_aon_sgpio_04_AON_BSC_M2_SCL);
+    IODIR(AON_IODIR_EXT, 4, IODIR_OUT);
+    ODEN(AON_ODEN_EXT, 4, OPEN_DRAIN);
+    DATA(AON_DATA_EXT, 4, 1);
+
+    /* AON_SGPIO_05        HDMI_SDA    I/O    AON_BSC_M2_SDA    N/A    N/A    open-drain    High    HDMI I2C */
+    AON_PINMUX(3, aon_sgpio_05, BCHP_AON_PIN_CTRL_PIN_MUX_CTRL_3_aon_sgpio_05_AON_BSC_M2_SDA);
+    ODEN(AON_ODEN_EXT, 5, OPEN_DRAIN);
+    DATA(AON_DATA_EXT, 5, 1);
+
+    /* GPIO_000    sc_pwr_fail_n        I   GPIO    LOW     HIgh    N/A    detection of power fail to interrupt smart card dialog    */
+    PINMUX(0, gpio_000, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_0_gpio_000_GPIO_000);
+    PADCTRL(0, gpio_000_pad_ctrl, PULL_UP);
+    IODIR(IODIR_LO, 0, IODIR_IN);
+
+    /* GPIO_001    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(0, gpio_001_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 1, IODIR_IN);
+
+    /* GPIO_002    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(0, gpio_002_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 2, IODIR_IN);
+
+    /* GPIO_003    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(0, gpio_003_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 3, IODIR_IN);
+
+    /* GPIO_004    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(0, gpio_004_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 4, IODIR_IN);
+
+    /* GPIO_005    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(0, gpio_005_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 5, IODIR_IN);
+
+    /* GPIO_006    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_006_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 6, IODIR_IN);
+
+    /* GPIO_007    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_007_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 7, IODIR_IN);
+
+    /* GPIO_008    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_008_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 8, IODIR_IN);
+
+    /* GPIO_009    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_009_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 9, IODIR_IN);
+
+    /* GPIO_010    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_010_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 10, IODIR_IN);
+
+    /* GPIO_011    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_011_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 11, IODIR_IN);
+
+    /* GPIO_012    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_012_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 12, IODIR_IN);
+
+    /* GPIO_013    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_013_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 13, IODIR_IN);
+
+    /* GPIO_014    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_014_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 14, IODIR_IN);
+
+    /* GPIO_015    BCM7430_SPIM_SS1b    I   GPIO    n/a     Low    n/a    option for SPI bus to BCM53125 (not used on D915)    */
+    PINMUX(1, gpio_015, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_1_gpio_015_GPIO_015);
+    PADCTRL(1, gpio_015_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 15, IODIR_IN);
+
+    /* GPIO_016    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_016_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 16, IODIR_IN);
+
+    /* GPIO_017    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_017_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 17, IODIR_IN);
+
+    /* GPIO_018    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_018_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 18, IODIR_IN);
+
+    /* GPIO_019    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(1, gpio_019_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 19, IODIR_IN);
+
+    /* GPIO_020        7430_NOR_CS_N    O    EBI_CS0b    low    PULL_HIGH    totem-pole    HIGH   NAND FLASH INTERFACE */
+    PINMUX(2, gpio_020, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_2_gpio_020_EBI_CS0B);
+    PADCTRL(1, gpio_020_pad_ctrl, PULL_UP);
+    IODIR(IODIR_LO, 20, IODIR_OUT);
+    ODEN(ODEN_LO, 20, TOTEM_POLE);
+    DATA(DATA_LO, 20, 1);
+
+    /*  GPIO_021        7430_NAND_CE_NOT    O    EBI_CS1b    low    PULL_HIGH    totem-pole    HIGH */
+    PINMUX(2, gpio_021, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_2_gpio_021_EBI_CS1B);
+    PADCTRL(2, gpio_021_pad_ctrl, PULL_UP);
+    IODIR(IODIR_LO, 21, IODIR_OUT);
+    ODEN(ODEN_LO, 21, TOTEM_POLE);
+    DATA(DATA_LO, 21, 1);
+
+    /* GPIO_022    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(2, gpio_022_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 22, IODIR_IN);
+
+    /* GPIO_023    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(2, gpio_023_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 23, IODIR_IN);
+
+    /* GPIO_024    Unused               I   GPIO    n/a     Low    n/a    */
+    PADCTRL(2, gpio_024_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_LO, 24, IODIR_IN);
+
+    /* GPIO_025    7430_NAND_DATA0      I/O    NAND_DATA_0    */
+    PINMUX(3, gpio_025, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_3_gpio_025_EBI_DATA0);
+    PADCTRL(2, gpio_025_pad_ctrl, PULL_NONE);
+
+    /* GPIO_026    7430_NAND_DATA1      I/O    NAND_DATA_1    */
+    PINMUX(3, gpio_026, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_3_gpio_026_EBI_DATA1);
+    PADCTRL(2, gpio_026_pad_ctrl, PULL_NONE);
+
+    /* GPIO_027    7430_NAND_DATA2      I/O    NAND_DATA_2    */
+    PINMUX(3, gpio_027, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_3_gpio_027_EBI_DATA2);
+    PADCTRL(2, gpio_027_pad_ctrl, PULL_NONE);
+
+    /* GPIO_028    7430_NAND_DATA3      I/O    NAND_DATA_3    */
+    PINMUX(3, gpio_028, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_3_gpio_028_EBI_DATA3);
+    PADCTRL(2, gpio_028_pad_ctrl, PULL_NONE);
+
+    /* GPIO_029    7430_NAND_DATA4      I/O    NAND_DATA_4    */
+    PINMUX(3, gpio_029, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_3_gpio_029_EBI_DATA4);
+    PADCTRL(2, gpio_029_pad_ctrl, PULL_NONE);
+
+    /* GPIO_030    7430_NAND_DATA5      I/O    NAND_DATA_5    */
+    PINMUX(3, gpio_030, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_3_gpio_030_EBI_DATA5);
+    PADCTRL(2, gpio_030_pad_ctrl, PULL_NONE);
+
+    /* GPIO_031    7430_NAND_DATA6      I/O    NAND_DATA_6    */
+    PINMUX(3, gpio_031, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_3_gpio_031_EBI_DATA6);
+    PADCTRL(2, gpio_031_pad_ctrl, PULL_NONE);
+
+    /* GPIO_032    7430_NAND_DATA7      I/O    NAND_DATA_7    */
+    PINMUX(4, gpio_032, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_4_gpio_032_EBI_DATA7);
+    PADCTRL(2, gpio_032_pad_ctrl, PULL_NONE);
+
+    /* GPIO_033    Unused               I   GPIO    n/a    Low    n/a    */
+    PADCTRL(2, gpio_033_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 1, IODIR_IN);
+
+    /* GPIO_034        SCART_SBnot    O    GPIO    LOW    PULL_NONE    open-drain     LOW     1=> SB off */
+    /* PINMUX(4, gpio_034, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_4_gpio_034_GPIO_034);
+    PADCTRL(2, gpio_034_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 2, IODIR_OUT);
+    ODEN(ODEN_HI, 2, OPEN_DRAIN);
+    DATA(DATA_HI, 2, 0); */
+
+    /* GPIO_035        SCART_SB_6V    O    GPIO    HIGH    PULL_NONE    totem-pole    LOW     1=> SB=6V (if  SCART_SBnot=0) */
+    /*PINMUX(4, gpio_035, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_4_gpio_035_GPIO_035);
+    PADCTRL(2, gpio_035_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 3, IODIR_OUT);
+    ODEN(ODEN_HI, 3, TOTEM_POLE);
+    DATA(DATA_HI, 3, 0);*/
+
+    /* GPIO_036        SCART_FB    O    GPIO    HIGH    PULL_NONE    totem-pole    LOW     1=> FB on */
+    /*PINMUX(4, gpio_036, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_4_gpio_036_GPIO_036);
+    PADCTRL(3, gpio_036_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 4, IODIR_OUT);
+    ODEN(ODEN_HI, 4, TOTEM_POLE);
+    DATA(DATA_HI, 4, 0);*/
+
+    /* GPIO_037        AUDIO_MUTE    O    GPIO    LOW    PULL_NONE    totem-pole    LOW    shall remain low during the boot process until the DACs are properly initialized to avoid any plop. */
+    PINMUX(4, gpio_037, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_4_gpio_037_GPIO_037);
+    PADCTRL(3, gpio_037_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 5, IODIR_OUT);
+    ODEN(ODEN_HI, 5, TOTEM_POLE);
+    DATA(DATA_HI, 5, 0);
+
+    /* GPIO_038    BCM7430_SPIM_MOSI    I   GPIO    n/a    Low    n/a    option for SPI bus to BCM53125 (not used on D915)    */
+    PINMUX(4, gpio_038, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_4_gpio_038_GPIO_038);
+    PADCTRL(3, gpio_038_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 6, IODIR_IN);
+
+    /* GPIO_039    BCM7430_SPIM_MISO    I   GPIO    n/a    Low    n/a    option for SPI bus to BCM53125 (not used on D915)    */
+    PINMUX(4, gpio_039, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_4_gpio_039_GPIO_039);
+    PADCTRL(3, gpio_039_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 7, IODIR_IN);
+
+    /* GPIO_040    BCM7430_SPIM_SCK     I   GPIO    n/a    Low    n/a    option for SPI bus to BCM53125 (not used on D915)    */
+    PINMUX(5, gpio_040, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_5_gpio_040_GPIO_040);
+    PADCTRL(3, gpio_040_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 8, IODIR_IN);
+
+    /* GPIO_041        7430_NAND_READ_N    O    NAND_REb    N/A    PULL_NONE    N/A    N/A NAND FLASH INTERFACE*/
+    PINMUX(5, gpio_041, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_5_gpio_041_EBI_RDB);
+    PADCTRL(3, gpio_041_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 9, IODIR_OUT);
+
+    /* GPIO_042        7430_NAND_WE_N    O    NAND_WEb    N/A    PULL_NONE    N/A    N/A NAND FLASH INTERFACE*/
+    PINMUX(5, gpio_042, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_5_gpio_042_EBI_WE0B);
+    PADCTRL(3, gpio_042_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 10, IODIR_OUT);
+
+    /* GPIO_043        7430_NAND_WE_ALE    I    NAND_ALE    N/A    PULL_NONE    N/A    N/A NAND FLASH INTERFACE*/
+    PINMUX(5, gpio_043, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_5_gpio_043_EBI_DSB);
+    PADCTRL(3, gpio_043_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 11, IODIR_IN);
+
+    /* GPIO_044        7430_NAND_WE_CLE    I    NAND_CLE    N/A    PULL_NONE    N/A    N/A NAND FLASH INTERFACE*/
+    PINMUX(5, gpio_044, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_5_gpio_044_EBI_TSB);
+    PADCTRL(3, gpio_044_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 12, IODIR_IN);
+
+    /* GPIO_045        7430_NAND_RB_N    I    NAND_RBb    N/A    PULL_NONE    N/A    N/A NAND FLASH INTERFACE*/
+    PINMUX(5, gpio_045, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_5_gpio_045_EBI_NAND_RBB);
+    PADCTRL(3, gpio_045_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 13, IODIR_IN);
+
+    /* GPIO_046        HDMI_OFF    O    GPIO    HIgh    PULL_NONE    totem-pole    HIGH    HDMI 5V switch command. 1 => HDMI 5V ON */
+    PINMUX(5, gpio_046, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_5_gpio_046_GPIO_046);
+    PADCTRL(3, gpio_046_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 14, IODIR_OUT);
+    ODEN(ODEN_HI, 14, TOTEM_POLE);
+    DATA(DATA_HI, 14, 1);
+
+    /* GPIO_047    Unused               I   GPIO    n/a    Low    n/a    */
+    PADCTRL(3, gpio_047_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 15, IODIR_IN);
+
+    /* GPIO_048    Unused               I   GPIO    n/a    Low    n/a    */
+    PADCTRL(3, gpio_048_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 16, IODIR_IN);
+
+    /* GPIO_049     Scart_vid_buf_enable_n  I   GPIO    N/A PULL_LOW    N/A N/A option not used on D915 (if option included: 1 => Video buffer ON) */
+    PINMUX(6, gpio_049, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_6_gpio_049_GPIO_049);
+    PADCTRL(3, gpio_049_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 17, IODIR_IN);
+
+    /* GPIO_050    Unused               I   GPIO    n/a    Low    n/a    */
+    PADCTRL(3, gpio_050_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 18, IODIR_IN);
+
+    /* GPIO_051        led_pwr_grn    O    GPIO    HIgh    PULL_NONE    totem-pole    LOW    "1 => green power LED ON init value to be confirmed, depending on standby LED behavior requested at boot" */
+    PINMUX(6, gpio_051, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_6_gpio_051_GPIO_051);
+    PADCTRL(4, gpio_051_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_HI, 19, IODIR_OUT);
+    ODEN(ODEN_HI, 19, TOTEM_POLE);
+    DATA(DATA_HI, 19, 1);
+
+    /* GPIO_052    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_052_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 20, IODIR_IN);
+
+    /* GPIO_053    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_053_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 21, IODIR_IN);
+
+    /* GPIO_054    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_054_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 22, IODIR_IN);
+
+    /* GPIO_055    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_055_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 23, IODIR_IN);
+
+    /* GPIO_056    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_056_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 24, IODIR_IN);
+
+    /* GPIO_057    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_057_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 25, IODIR_IN);
+
+    /* GPIO_058    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_058_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 26, IODIR_IN);
+
+    /* GPIO_059    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_059_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 27, IODIR_IN);
+
+    /* GPIO_060    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_060_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 28, IODIR_IN);
+
+    /* GPIO_061    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_061_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 29, IODIR_IN);
+
+    /* GPIO_062    Unused               I    GPIO    n/a    Low    n/a    */
+    PINMUX(7, gpio_062, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_7_gpio_062_GPIO_062);
+    PADCTRL(4, gpio_062_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 30, IODIR_IN);
+
+    /* GPIO_063    Unused               I    GPIO    n/a    Low    n/a    */
+    PINMUX(7, gpio_063, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_7_gpio_063_GPIO_063);
+    PADCTRL(4, gpio_063_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_HI, 31, IODIR_IN);
+
+    /* GPIO_064    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(4, gpio_064_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 4, IODIR_IN);
+
+    /* GPIO_065     UART_TXD_1  O   UART_TX1    N/A PULL_NONE   N/A HIGH    TESTTASK    interface   */
+    PINMUX(8, gpio_065, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_8_gpio_065_UART_TX1);
+    PADCTRL(4, gpio_065_pad_ctrl, PULL_NONE);
+    DATA(DATA_EXT, 5, 1);
+
+    /* GPIO_066    UART_RXD_1    UART_RX1        TESTTASK interface    */
+    PINMUX(8, gpio_066, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_8_gpio_066_UART_RX1);
+    PADCTRL(5, gpio_066_pad_ctrl, PULL_NONE);
+
+    /* GPIO_067    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(5, gpio_067_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 7, IODIR_IN);
+
+    /* GPIO_068    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(5, gpio_068_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 8, IODIR_IN);
+
+    /* GPIO_069    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(5, gpio_069_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 9, IODIR_IN);
+
+    /* GPIO_070    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(5, gpio_070_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 10, IODIR_IN);
+
+    /* GPIO_071    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(5, gpio_071_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 11, IODIR_IN);
+
+    /* GPIO_072        RF4CE_resetn    O    GPIO    Low    PULL_NONE    totem-pole    LOW    to reset RF4CE (0 ==> GP510 resetted). GP510 has to be resetted at start-up. */
+    PINMUX(9, gpio_072, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_9_gpio_072_GPIO_072);
+    PADCTRL(5, gpio_072_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 12, IODIR_OUT);
+    ODEN(ODEN_EXT, 12, TOTEM_POLE);
+    DATA(DATA_EXT, 12, 0);
+
+    /* GPIO_073    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(5, gpio_073_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 13, IODIR_IN);
+
+    /* GPIO_074    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(5, gpio_074_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 14, IODIR_IN);
+
+    /* GPIO_075        led_rec    O    GPIO    HIGH    PULL_NONE    totem-pole    LOW    1=> record LED ON */
+    PINMUX(9, gpio_075, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_9_gpio_075_GPIO_075);
+    PADCTRL(5, gpio_075_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 15, IODIR_OUT);
+    ODEN(ODEN_EXT, 15, TOTEM_POLE);
+    DATA(DATA_EXT, 15, 0);
+
+    /* GPIO_076    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(5, gpio_076_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 16, IODIR_IN);
+
+    /* GPIO_077    not_sc_1v8           I    GPIO    */
+    PINMUX(9, gpio_077, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_9_gpio_077_GPIO_077);
+    PADCTRL(5, gpio_077_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 17, IODIR_IN);
+
+    /* GPIO_078    sc_5v_not_3v         O    GPIO    */
+    PINMUX(9, gpio_078, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_9_gpio_078_GPIO_078);
+    PADCTRL(5, gpio_078_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 18, IODIR_OUT);
+
+    /* GPIO_079    SC_VCC               O    SC0_VCC    */
+    PINMUX(9, gpio_079, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_9_gpio_079_SC0_VCC);
+    PADCTRL(5, gpio_079_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 19, IODIR_OUT);
+
+    /* GPIO_080    SC_CLK               O    SC0_CLK    */
+    PINMUX(10, gpio_080, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_10_gpio_080_SC0_CLK);
+    PADCTRL(5, gpio_080_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 20, IODIR_OUT);
+
+    /* GPIO_081    SC_RST               O    SC0_RST    */
+    PINMUX(10, gpio_081, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_10_gpio_081_SC0_RST);
+    PADCTRL(6, gpio_081_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 21, IODIR_OUT);
+
+    /* GPIO_082    SC_data              I/O    SC0_IO    */
+    PINMUX(10, gpio_082, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_10_gpio_082_SC0_IO);
+    PADCTRL(6, gpio_082_pad_ctrl, PULL_NONE);
+
+    /* GPIO_083    SC_PRES              I    SC0_PRES        */
+    PINMUX(10, gpio_083, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_10_gpio_083_SC0_PRES);
+    PADCTRL(6, gpio_083_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 23, IODIR_IN);
+
+    /* GPIO_084    SC_AUX0              I    GPIO    n/a    Low    n/a    not used on D915    */
+    PINMUX(10, gpio_084, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_10_gpio_084_GPIO_084);
+    PADCTRL(6, gpio_084_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 24, IODIR_IN);
+
+    /* GPIO_085    SC_AUX1              I    GPIO    n/a    Low    n/a    not used on D915    */
+    PINMUX(10, gpio_085, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_10_gpio_085_GPIO_085);
+    PADCTRL(6, gpio_085_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 25, IODIR_IN);
+
+    /* GPIO_086    Unused               I    GPIO    n/a    Low    n/a    */
+    PINMUX(10, gpio_086, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_10_gpio_086_GPIO_086);
+    PADCTRL(6, gpio_086_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 26, IODIR_IN);
+
+    /* GPIO_087    MTSIF_CLK            I    MTSIF0_CLK        Multiplex Transport Stream interface with BCM3383    */
+    PINMUX(10, gpio_087, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_10_gpio_087_MTSIF0_CLK);
+    PADCTRL(6, gpio_087_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 27, IODIR_IN);
+
+    /* GPIO_088    MTSIF_DATA0          I    MTSIF0_DATA0    */
+    PINMUX(11, gpio_088, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_11_gpio_088_MTSIF0_DATA0);
+    PADCTRL(6, gpio_088_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 28, IODIR_IN);
+
+    /* GPIO_089    MTSIF_SYNC           I    MTSIF0_SYNC        */
+    PINMUX(11, gpio_089, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_11_gpio_089_MTSIF0_SYNC);
+    PADCTRL(6, gpio_089_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 29, IODIR_IN);
+
+    /* GPIO_090    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(6, gpio_090_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT, 30, IODIR_IN);
+
+    /* GPIO_091    MTSIF_DATA1          I    MTSIF0_DATA1    */
+    PINMUX(11, gpio_091, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_11_gpio_091_MTSIF0_DATA1);
+    PADCTRL(6, gpio_091_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT, 31, IODIR_IN);
+
+    /* GPIO_092    UART_TXD_0           UART_TX0        CFE interface    */
+    PINMUX(11, gpio_092, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_11_gpio_092_UART_TX0);
+    PADCTRL(6, gpio_092_pad_ctrl, PULL_NONE);
+    DATA(DATA_EXT_HI, 0, 1);
+
+    /* GPIO_093    UART_RXD_0           UART_RX0        CFE interface    */
+    PINMUX(11, gpio_093, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_11_gpio_093_UART_RX0);
+    PADCTRL(6, gpio_093_pad_ctrl, PULL_NONE);
+
+    /* GPIO_094    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(6, gpio_094_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT_HI, 2, IODIR_IN);
+
+    /* GPIO_095    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(6, gpio_095_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT_HI, 3, IODIR_IN);
+
+    /* GPIO_096    FAN_CTRL             O    PWM0    N/A    HIgh    low    fan pwm, fan speed is increased when PWM duty cycle is decreasing    */
+    PINMUX(12, gpio_096, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_12_gpio_096_PWM0);
+    PADCTRL(7, gpio_096_pad_ctrl, PULL_UP);
+    IODIR(IODIR_EXT_HI, 4, IODIR_OUT);
+    DATA(DATA_EXT_HI, 4, 0);
+
+    /* GPIO_097    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(7, gpio_097_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT_HI, 5, IODIR_IN);
+
+    /* GPIO_098        fan_tacho    I    ????    N/A    PULL_NONE    N/A    N/A    This is a special GPIO. Check with BCM. */
+#if 0
+    PINMUX(12, gpio_098, 0);
+    PADCTRL(7, gpio_098_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT_HI, 6, IODIR_IN);
+#else
+    #warning "GPIO_098 fan_tacho => SPEC ISSUE TBC"
+#endif
+
+    /* GPIO_099    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(7, gpio_099_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT_HI, 7, IODIR_IN);
+
+    /* GPIO_100    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(7, gpio_100_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT_HI, 8, IODIR_IN);
+
+    /* GPIO_101    MTSIF_DATA2          I    MTSIF0_DATA2        Multiplex Transport Stream interface with BCM3383 */
+    PINMUX(12, gpio_101, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_12_gpio_101_MTSIF0_DATA2);
+    PADCTRL(7, gpio_101_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT_HI, 9, IODIR_IN);
+
+    /* GPIO_102    MTSIF_DATA3          I    MTSIF0_DATA3    */
+    PINMUX(12, gpio_102, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_12_gpio_102_MTSIF0_DATA3);
+    PADCTRL(7, gpio_102_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT_HI, 10, IODIR_IN);
+
+    /* GPIO_103    MTSIF_DATA4          I    MTSIF0_DATA4    */
+    PINMUX(12, gpio_103, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_12_gpio_103_MTSIF0_DATA4);
+    PADCTRL(7, gpio_103_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT_HI, 11, IODIR_IN);
+
+    /* GPIO_104        MTSIF_ATS_RST    I    MTSIF_ATS_RST    N/A        N/A    N/A */
+    PINMUX(12, gpio_104, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_12_gpio_104_MTSIF_ATS_RST);
+    IODIR(IODIR_EXT_HI, 12, IODIR_IN);
+
+    /* GPIO_105    MTSIF_DATA5          I    MTSIF0_DATA5    */
+    PINMUX(13, gpio_105, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_13_gpio_105_MTSIF0_DATA5);
+    PADCTRL(7, gpio_105_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT_HI, 13, IODIR_IN);
+
+    /* GPIO_0106 to 0113 are used for dedicated USB interface */
+    /* GPIO_106 ???? */
+    /* GPIO_107 ???? */
+    /* GPIO_108 ???? */
+    /* GPIO_109 ???? */
+    /* GPIO_110 ???? */
+    /* GPIO_111 ???? */
+    /* GPIO_112 ???? */
+    /* GPIO_113 ???? */
+
+    /* GPIO_114    "GP114_ENET0_ACTIVITY    (unused, but strapping resistor connected)"    I    GPIO    */
+    PINMUX(14, gpio_114, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_14_gpio_114_GPIO_114);
+    PADCTRL(8, gpio_114_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT_HI, 22, IODIR_IN);
+
+    /* GPIO_115 ???? */
+
+    /* GPIO_116        MTSIF_ATS_INC    I    MTSIF_ATS_INC    N/A        N/A    N/A */
+    PINMUX(14, gpio_116, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_14_gpio_116_MTSIF_ATS_INC);
+    IODIR(IODIR_EXT_HI, 24, IODIR_IN);
+
+    /* GPIO_117    MTSIF_DATA6          I    MTSIF0_DATA6    */
+    PINMUX(14, gpio_117, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_14_gpio_117_MTSIF0_DATA6);
+    PADCTRL(8, gpio_117_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT_HI, 25, IODIR_IN);
+
+    /* GPIO_118    MTSIF_DATA7          I    MTSIF0_DATA7    */
+    PINMUX(14, gpio_118, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_14_gpio_118_MTSIF0_DATA7);
+    PADCTRL(8, gpio_118_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT_HI, 26, IODIR_IN);
+
+    /* GPIO_119 ???? */
+    /* GPIO_120 ???? */
+    /* GPIO_121 ???? */
+
+    /* GPIO_122    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(8, gpio_122_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT_HI, 30, IODIR_IN);
+
+    /* GPIO_123    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(8, gpio_123_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT_HI, 31, IODIR_IN);
+
+    /* GPIO_124    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(8, gpio_124_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 0, IODIR_IN);
+
+    /* GPIO_125    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(8, gpio_125_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 1, IODIR_IN);
+
+    /* GPIO_126    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(8, gpio_126_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 2, IODIR_IN);
+
+    /* GPIO_127    Unused               I    GPIO    n/a    Low    n/a    */
+    /*PADCTRL(8, gpio_127_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 3, IODIR_IN);*/
+    PINMUX(15, gpio_127, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_15_gpio_127_GPIO_127);
+    PADCTRL(8, gpio_127_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 3, IODIR_OUT);
+    ODEN(ODEN_EXT2, 3, TOTEM_POLE);
+    DATA(DATA_EXT2, 3, 0);
+
+
+    /* GPIO_128    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(8, gpio_128_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 4, IODIR_IN);
+
+    /* GPIO_129    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(8, gpio_129_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 5, IODIR_IN);
+
+    /* GPIO_130    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(9, gpio_130_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 6, IODIR_IN);
+
+    /* GPIO_131    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(9, gpio_131_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 7, IODIR_IN);
+
+    /* GPIO_132    53125_7430_RGMII_RXDV    I    MII_RX_DV        EMAC0 interface with ethernet switch    */
+    PINMUX(15, gpio_132, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_15_gpio_132_MII_RX_DV);
+    PADCTRL(9, gpio_132_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 8, IODIR_IN);
+
+    /* GPIO_133    Unused               I    n/a    Low    n/a    */
+    PADCTRL(9, gpio_133_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 9, IODIR_IN);
+
+    /* GPIO_134    53125_7430_RGMII_RXCLK    I    MII_RX_CLK    */
+    PINMUX(16, gpio_134, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_16_gpio_134_MII_RX_CLK);
+    PADCTRL(9, gpio_134_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 10, IODIR_IN);
+
+    /* GPIO_135    Unused               I    n/a    Low    n/a    */
+    PADCTRL(9, gpio_135_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 11, IODIR_IN);
+
+    /* GPIO_136    Unused               I    n/a    Low    n/a    */
+    PADCTRL(9, gpio_136_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 12, IODIR_IN);
+
+    /* GPIO_137        7430_GP_137_MII_MDIO (option not used on D915)    I    GPIO    N/A    PULL_LOW    N/A    N/A */
+    PINMUX(16, gpio_137, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_16_gpio_137_GPIO_137);
+    PADCTRL(9, gpio_137_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 13, IODIR_IN);
+
+    /* GPIO_138    53125_7430_RMII_TXCLK    O    MII_TX_CLK    */
+    PINMUX(16, gpio_138, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_16_gpio_138_MII_TX_CLK);
+    PADCTRL(9, gpio_138_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 14, IODIR_OUT);
+
+    /* GPIO_139    53125_7430_RGMII_RXD3    I    MII_RXD_03    */
+    PINMUX(16, gpio_139, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_16_gpio_139_MII_RXD_03);
+    PADCTRL(9, gpio_139_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 15, IODIR_IN);
+
+    /* GPIO_140    53125_7430_RGMII_RXD2    I    MII_RXD_02    */
+    PINMUX(16, gpio_140, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_16_gpio_140_MII_RXD_02);
+    PADCTRL(9, gpio_140_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 16, IODIR_IN);
+
+    /* GPIO_141    53125_7430_RGMII_RXD1    I    MII_RXD_01    */
+    PINMUX(17, gpio_141, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_17_gpio_141_MII_RXD_01);
+    PADCTRL(9, gpio_141_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 17, IODIR_IN);
+
+    /* GPIO_142    53125_7430_RGMII_RXD0    i    MII_RXD_00    */
+    PINMUX(17, gpio_142, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_17_gpio_142_MII_RXD_00);
+    PADCTRL(9, gpio_142_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 18, IODIR_IN);
+
+    /* GPIO_143    53125_7430_RGMII_TXD3    O    MII_TXD_03    */
+    PINMUX(17, gpio_143, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_17_gpio_143_MII_TXD_03);
+    PADCTRL(9, gpio_143_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 19, IODIR_OUT);
+
+    /* GPIO_144    53125_7430_RGMII_TXD2    O    MII_TXD_02    */
+    PINMUX(17, gpio_144, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_17_gpio_144_MII_TXD_02);
+    PADCTRL(9, gpio_144_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 20, IODIR_OUT);
+
+    /* GPIO_145    53125_7430_RGMII_TXD1    O    MII_TXD_01    */
+    PINMUX(17, gpio_145, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_17_gpio_145_MII_TXD_01);
+    PADCTRL(10, gpio_145_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 21, IODIR_OUT);
+
+    /* GPIO_146    53125_7430_RGMII_TXD0    O    MII_TXD_00    */
+    PINMUX(17, gpio_146, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_17_gpio_146_MII_TXD_00);
+    PADCTRL(10, gpio_146_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 22, IODIR_OUT);
+
+    /* GPIO_147    53125_7430_RGMII_TXDV    O    MII_TXD_EN    */
+    PINMUX(17, gpio_147, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_17_gpio_147_MII_TX_EN);
+    PADCTRL(10, gpio_147_pad_ctrl, PULL_NONE);
+    IODIR(IODIR_EXT2, 23, IODIR_OUT);
+
+    /* GPIO_148    Unused               I    GPIO    n/a    Low    n/a    */
+    PADCTRL(10, gpio_148_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 24, IODIR_IN);
+
+    /* GPIO_149 53125_7430_MII_MDC  (option not used on D915)   +   spare strapping for boot    I   GPIO    N/A PULL_LOW    N/A N/A */
+    PINMUX(18, gpio_149, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_18_gpio_149_GPIO_149);
+    PADCTRL(10, gpio_149_pad_ctrl, PULL_DOWN);
+    IODIR(IODIR_EXT2, 25, IODIR_IN);
+
+    /* SGPIO_00        3450_BSC_SCL    O    BSC_M3_SCL    LOW    N/A    open-drain    HIGH    MOCA I2C Clock */
+    PINMUX(18, sgpio_00, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_18_sgpio_00_BSC_M3_SCL);
+    IODIR(IODIR_EXT, 0, IODIR_OUT);
+    ODEN(DATA_EXT, 0, OPEN_DRAIN);
+    DATA(DATA_EXT, 0, 1);
+
+    /* SGPIO_01        3450_BSC_SDA    I/O    BSC_M3_SDA    N/A    N/A    open-drain    HIGH    MOCA I2C Data */
+    PINMUX(18, sgpio_01, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_18_sgpio_01_BSC_M3_SDA);
+    ODEN(DATA_EXT, 1, OPEN_DRAIN);
+    DATA(DATA_EXT, 1, 1);
+
+    /* SGPIO_02    Unused               I    SGPIO    n/a    Low    n/a */
+    IODIR(IODIR_EXT, 2, IODIR_IN);
+
+    /* SGPIO_03    Unused               I    SGPIO    n/a    Low    n/a    */
+    IODIR(IODIR_EXT, 3, IODIR_IN);
+    
+    /* set RGMII lines to 2.5V */
+    /* Fix for Bug 175815 */
+    BDEV_WR_F(SUN_TOP_CTRL_GENERAL_CTRL_NO_SCAN_0, rgmii_0_pad_sel, 1);
+}
+static void board_cfe_environment_setup_DMC7000KLG_CADB(void)
+{
+
+    brcm_dram0_size_mb = 1024; /* Total memory(MEMC 0):1024MB */
+    brcm_mtd_flash_size_mb = 256; /* Total flash:256MB */
+    strcpy(brcm_mtd_flash_type,"NAND"); /* Boot Device:NAND */
+
+    /* Ethernet  Params */
+    strcpy(brcm_eth0_phyaddr,"30"); /* ETH0_PHYADDR:30 */
+    strcpy(brcm_eth0_phy,"RGMII_NO_ID"); /* ETH0_PHY:RGMII_NO_ID */
+    brcm_eth0_speed = 1000; /* ETH0_SPEED:1000 */
+    brcm_eth0_no_mdio = 1; /* ETH0_MDIO_MODE:boot */
+    /* Ethernet  Params End */
+
+    /* Specific USB init */
+    PINMUX(13, gpio_106, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_13_gpio_106_USB0_PWRON);
+    PINMUX(13, gpio_110, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_13_gpio_110_USB0_PWRFLT);
+    PADCTRL(7, gpio_110_pad_ctrl, PULL_UP);
+
+    PINMUX(13, gpio_107, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_13_gpio_107_USB1_PWRON);
+    PINMUX(13, gpio_111, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_13_gpio_111_USB1_PWRFLT);
+    PADCTRL(8, gpio_111_pad_ctrl, PULL_UP);
+
+    PINMUX(13, gpio_108, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_13_gpio_108_USB2_PWRON);
+    PINMUX(13, gpio_112, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_13_gpio_112_USB2_PWRFLT);
+    PADCTRL(8, gpio_112_pad_ctrl, PULL_UP);
+
+    PINMUX(13, gpio_109, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_13_gpio_109_USB3_PWRON);
+    PINMUX(14, gpio_113, BCHP_SUN_TOP_CTRL_PIN_MUX_CTRL_14_gpio_113_USB3_PWRFLT);
+    PADCTRL(8, gpio_113_pad_ctrl, PULL_UP);
+
+}
+static void board_force_fan(void)
+{
+#define DATA_REG(reg,shift,mask,val) do { \
+        BDEV_WR(reg, ((BDEV_RD(reg) & ~(mask << shift)) | ((val) << shift)));\
+        } while (0)
+
+/* Registers extracted from BBS...*/
+#define PWM_CTRL            (BCHP_PWM_REG_START + 0x00)
+#define PWM_CTRL2           (BCHP_PWM_REG_START + 0x04)
+#define PWM1_CWORD_MSB      (BCHP_PWM_REG_START + 0x08)
+#define PWM1_CWORD_LSB      (BCHP_PWM_REG_START + 0x0C)
+#define PWM1_ON             (BCHP_PWM_REG_START + 0x18)
+#define PWM1_PERIOD         (BCHP_PWM_REG_START + 0x1C)
+
+    /* Values were given by Vivian Aubry to set FAN on GPIO96 at 40% */
+
+    /* PWM_CTRL.PWM1_START */
+    DATA_REG(PWM_CTRL, 0, 1, 1);
+    /* PWM_CTRL.PWM1_OEB */
+    DATA_REG(PWM_CTRL, 1, 1, 0);
+    /* PWM_CTRL.FORCE_HIGH */
+    DATA_REG(PWM_CTRL, 2, 1, 0);
+    /* PWM_CTRL.FORCE_OPENDRAINB */
+    DATA_REG(PWM_CTRL, 3, 1, 1);
+
+    /* PWM_CTRL2.PWM1_OUT_SELECT */
+    DATA_REG(PWM_CTRL2, 0, 0xF, 1);
+
+    BDEV_WR(PWM1_CWORD_MSB, 0xFF);
+    BDEV_WR(PWM1_CWORD_LSB, 0x00);
+    BDEV_WR(PWM1_ON,        0x78); /* FAN SPEED 40% */
+    BDEV_WR(PWM1_PERIOD,    0xFF);
+}
+
+void board_pinmux_setup_default(void)
+{
 #if !defined(CONFIG_BRCM_IKOS)
 #if defined(CONFIG_BCM7231)
 
@@ -449,8 +1407,8 @@
 		PINMUX(15, gpio_129, 1);
 		PINMUX(15, gpio_131, 1);
 		/*
-		 * 7428 pinout uses GPIO_93 for SDIO0_PRES
-		 * 7429 pinout uses GPIO_130 for SDIO0_PRES
+		 * 7428a0 board uses GPIO_93 for SDIO0_PRES
+		 * 7429a0 board uses GPIO_130 for SDIO0_PRES
 		 */
 		if (BRCM_PROD_ID() == 0x7428) {
 			PINMUX(11, gpio_093, 5);
@@ -632,6 +1590,7 @@
  * FLASH configuration
  ***********************************************************************/
 
+#if !defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
 #if defined(CONFIG_BRCM_FIXED_MTD_PARTITIONS)
 
 static struct mtd_partition fixed_partition_map[] = {
@@ -664,7 +1623,7 @@
 int __init board_get_partition_map(struct mtd_partition **p)
 {
 	struct mtd_partition *ret;
-	int nr_parts;
+int nr_parts;
 
 	if (brcm_mtd_rootfs_len == 0)
 		return -ENODEV;
@@ -696,6 +1655,8 @@
 }
 #endif /* defined(CONFIG_BRCM_FIXED_MTD_PARTITIONS) */
 
+#endif
+
 void brcm_get_ocap_info(struct brcm_ocap_info *info)
 {
 	info->ocap_part_start = brcm_mtd_ocap_start;
diff -Naur kernel-3.3-3.0a-ref/drivers/brcmstb/Kconfig kernel-current/drivers/brcmstb/Kconfig
--- kernel-3.3-3.0a-ref/drivers/brcmstb/Kconfig	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/drivers/brcmstb/Kconfig	2015-06-12 16:27:20.008112063 +0200
@@ -398,7 +398,14 @@
 
 endchoice
 
+menu "Disclosed default options for BRCM MIPS chipset"
+  depends on BRCM_MIPS_DEFAULTS
+  
+  config SYS_HAS_EARLY_PRINTK
+    bool "SYS_HAS_EARLY_PRINTK"
+    default y 
 
+endmenu
 #####################################################################
 # User options: Memory configuration
 #####################################################################
@@ -1194,7 +1201,6 @@
 	select SYS_SUPPORTS_32BIT_KERNEL
 	select SYS_SUPPORTS_BIG_ENDIAN
 	select SYS_SUPPORTS_LITTLE_ENDIAN
-	select SYS_HAS_EARLY_PRINTK
 	select SERIAL
 	select SYS_SUPPORTS_KGDB
 	select CEVT_R4K
diff -Naur kernel-3.3-3.0a-ref/drivers/brcmstb/setup.c kernel-current/drivers/brcmstb/setup.c
--- kernel-3.3-3.0a-ref/drivers/brcmstb/setup.c	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/drivers/brcmstb/setup.c	2015-06-12 16:27:20.012114063 +0200
@@ -41,6 +41,9 @@
 #include "../drivers/mmc/host/sdhci-pltfm.h"
 
 #include <linux/brcmstb/brcmstb.h>
+#include <linux/mtd/nand_flash_mapping.h>
+#include <linux/mtd/pacenand.h>
+#include <linux/mtd/nor_flash_mapping.h>
 
 #ifndef CONFIG_MTD
 /* squash MTD warning on IKOS builds */
@@ -51,6 +54,10 @@
 #include <linux/mtd/physmap.h>
 #include <linux/mtd/map.h>
 
+#if defined(CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT) && defined(CFG_NAND_AUTO_DETECT_CONFIG)
+static void __init pace_nand_detect_configuration(void);
+#endif
+
 /* Default SPI flash chip selects to scan at boot time
    Can be overriden with spics=N kernel boot argument
 */
@@ -419,7 +426,7 @@
 	res[1].start = BRCM_IRQ_MOCA;
 	res[1].flags = IORESOURCE_IRQ;
 
-	brcm_alloc_macaddr(macaddr);
+	brcm_alloc_moca_macaddr(macaddr);
 	mac_to_u32(&pdata.macaddr_hi, &pdata.macaddr_lo, macaddr);
 
 	strcpy(pdata.enet_name, "bcmgenet");
@@ -545,7 +552,7 @@
 
 static struct ebi_cs_info cs_info[NUM_CS];
 
-#ifdef CONFIG_BRCM_HAS_SPI
+#if defined(CONFIG_BRCM_HAS_SPI) && defined(CONFIG_SPI_MASTER)
 static int __init brcm_setup_spi_flash(int cs, int bus_num, int nr_parts,
 	struct mtd_partition *parts)
 {
@@ -646,7 +653,7 @@
 #ifdef CONFIG_BRCM_HAS_NOR
 		struct physmap_flash_data pdata;
 		struct resource res;
-		static int nor_id;
+		static int nor_id = 0;
 
 		memset(&res, 0, sizeof(res));
 		memset(&pdata, 0, sizeof(pdata));
@@ -670,13 +677,13 @@
 	}
 	case TYPE_NAND: {
 		struct brcmnand_platform_data pdata;
-		static int nand_id;
+		static int nand_id = 0;
 
 		pdata.chip_select = cs;
 		pdata.nr_parts = nr_parts;
 		pdata.parts = parts;
 
-		pdev = platform_device_alloc("brcmnand", nand_id++);
+		pdev = platform_device_alloc("pacenand", nand_id++);
 		if (!pdev ||
 		    platform_device_add_data(pdev, &pdata, sizeof(pdata)) ||
 		    platform_device_add(pdev))
@@ -684,7 +691,7 @@
 		break;
 	}
 	case TYPE_SPI: {
-#ifdef CONFIG_BRCM_HAS_SPI
+#if defined(CONFIG_BRCM_HAS_SPI) && defined(CONFIG_SPI_MASTER)
 		const int bus_num = 0;
 		static int spi_master_registered;
 		int ret;
@@ -731,16 +738,23 @@
 #endif
 	}
 }
-
+#if !defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
 static struct map_info brcm_dummy_map = {
 	.name			= "DUMMY",
 };
+#endif
 
 static int __init brcmstb_mtd_setup(void)
 {
+#if defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
+	struct brcm_mtd_partition_map *parts_array;     /* Array of parts for multiple devices */
+    int    nr_entries = 0;
+    int i;
+#else
 	struct mtd_partition *parts;
 	int nr_parts;
 	int i, first = -1, primary = -1, primary_type = TYPE_NAND;
+#endif
 
 #ifdef CONFIG_OF
 	return 0;
@@ -748,6 +762,30 @@
 	if (noflash)
 		return 0;
 
+#if defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
+	nr_entries = board_get_partition_map_pace(&parts_array);
+	printk("number of entries in new partiton map = %d\n", nr_entries);
+    for (i = 0; i < nr_entries; i++) {
+        struct brcm_mtd_partition_map * part_map = &parts_array[i];
+
+        printk("Entry %d has %d partitions\n", i, part_map->num_parts);
+        if(part_map->num_parts) {
+            int j;
+            struct mtd_partition * entry = part_map->partition_map;
+
+            for (j = 0; j < part_map->num_parts; j++) {
+                printk("Partition %d has size=0x%X, offset=0x%X, name=%s\n",
+                                  j,
+                                  (unsigned int)entry[j].size,
+                                  (unsigned int)entry[j].offset,
+                                  entry[j].name);
+            }
+        }
+    }
+#else
+/* RT171011
+   we don't want to create a dummy MTD0, as there is usually a
+   command-line MTD partition definition that we prefer to use */
 	nr_parts = board_get_partition_map(&parts);
 	if (nr_parts <= 0) {
 		struct mtd_info *mtd;
@@ -778,7 +816,7 @@
 	for (i = TYPE_NOR; i <= TYPE_MAX; i++)
 		if (strcmp(brcm_mtd_flash_type, type_names[i]) == 0)
 			primary_type = i;
-
+#endif
 	/* scan each chip select to see what (if anything) lives there */
 	for (i = 0; i < NUM_CS; i++) {
 		u32 base, size, config __maybe_unused;
@@ -820,7 +858,7 @@
 		if (BDEV_RD(BCHP_NAND_CS_NAND_SELECT) & (0x100 << i))
 			cs_info[i].type = TYPE_NAND;
 #endif
-
+#if !defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
 		if (cs_info[i].type != TYPE_NAND && nandcs[i] != 0) {
 			cs_info[i].type = TYPE_NAND;
 		} else {
@@ -835,8 +873,10 @@
 		}
 		if (first == -1 && cs_info[i].type != TYPE_NONE)
 			first = i;
+#endif  /* !defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT */
 	}
 
+#if !defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
 	if (primary == -1) {
 		if (first == -1) {
 			printk(KERN_INFO "EBI: No flash devices detected\n");
@@ -845,7 +885,34 @@
 		primary = first;
 		primary_type = cs_info[primary].type;
 	}
+#endif
 
+#if defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
+    /* Set up each active CS of a particular type with it's own MTD partition(s) */
+	for (i = 0; i < NUM_CS; i++) {
+        int type = cs_info[i].type;
+
+		if ((type != FLASH_TYPE_NONE) && (type <= FLASH_TYPE_MAX )) {
+            /* Find entries for this memory type */
+            int j;
+            struct brcm_mtd_partition_map * part_map = &parts_array[type - 1];
+            struct mtd_partition          * entry    = part_map->partition_map;
+
+			printk("EBI CS%d: Setting up %s flash\n", i, type_names[type]);
+			printk("EBI CS%d: Number of partitions=%d\n", i, part_map->num_parts);
+			for (j = 0; j < part_map->num_parts; j++) {
+
+			    printk("EBI CS%d: Partition %d has size=0x%X, offset=0x%X, name=%s\n",
+			                      i,
+			                      j,
+			                      (unsigned int)entry[j].size,
+			                      (unsigned int)entry[j].offset,
+			                      entry[j].name);
+			}
+			brcm_setup_cs(i, part_map->num_parts, part_map->partition_map);
+		}
+	}
+#else
 	/* set up primary first, so that it owns mtd0/mtd1/(mtd2) */
 	printk(KERN_INFO "EBI CS%d: setting up %s flash (primary)\n", primary,
 		type_names[primary_type]);
@@ -858,6 +925,7 @@
 			brcm_setup_cs(i, 0, NULL);
 		}
 	}
+#endif
 
 	return 0;
 }
@@ -956,3 +1024,179 @@
 	}
 	return str;
 }
+
+#if defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
+
+static struct mtd_partition fixed_partition_map_nand[] = {
+	{
+		.name = NAND_FLASH_LINUX_SCHNG_NAME,
+		.size = NAND_FLASH_LINUX_SCHNG_SIZE,
+		.offset = NAND_FLASH_LINUX_SCHNG_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_AXIROS_NAME,
+		.size = NAND_FLASH_LINUX_AXIROS_SIZE,
+		.offset = NAND_FLASH_LINUX_AXIROS_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_EPG_NAME,
+		.size = NAND_FLASH_LINUX_EPG_SIZE,
+		.offset = NAND_FLASH_LINUX_EPG_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_UI_NAME,
+		.size = NAND_FLASH_LINUX_UI_SIZE,
+		.offset = NAND_FLASH_LINUX_UI_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_BROWSER_NAME,
+		.size = NAND_FLASH_LINUX_BROWSER_SIZE,
+		.offset = NAND_FLASH_LINUX_BROWSER_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_VFS_NAME,
+		.size = NAND_FLASH_LINUX_VFS_SIZE,
+		.offset = NAND_FLASH_LINUX_VFS_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_IRDETO_NAME,
+		.size = NAND_FLASH_LINUX_IRDETO_SIZE,
+		.offset = NAND_FLASH_LINUX_IRDETO_ADDRESS
+	}
+};
+static struct mtd_partition fixed_partition_map_512mb_nand[] = {
+	{
+		.name = NAND_FLASH_LINUX_SCHNG_NAME,
+		.size = NAND_FLASH_LINUX_SCHNG_512MB_SIZE,
+		.offset = NAND_FLASH_LINUX_SCHNG_512MB_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_AXIROS_NAME,
+		.size = NAND_FLASH_LINUX_AXIROS_512MB_SIZE,
+		.offset = NAND_FLASH_LINUX_AXIROS_512MB_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_EPG_NAME,
+		.size = NAND_FLASH_LINUX_EPG_512MB_SIZE,
+		.offset = NAND_FLASH_LINUX_EPG_512MB_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_UI_NAME,
+		.size = NAND_FLASH_LINUX_UI_512MB_SIZE,
+		.offset = NAND_FLASH_LINUX_UI_512MB_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_APPS_NAME,
+		.size = NAND_FLASH_LINUX_APPS_512MB_SIZE,
+		.offset = NAND_FLASH_LINUX_APPS_512MB_ADDRESS
+	},
+	{
+		.name = NAND_FLASH_LINUX_VFS_NAME,
+		.size = NAND_FLASH_LINUX_VFS_512MB_SIZE,
+		.offset = NAND_FLASH_LINUX_VFS_512MB_ADDRESS
+	}
+    ,
+	{
+		.name = NAND_FLASH_LINUX_IRDETO_NAME,
+		.size = NAND_FLASH_LINUX_IRDETO_512MB_SIZE,
+		.offset = NAND_FLASH_LINUX_IRDETO_512MB_ADDRESS
+	}
+};
+
+static struct mtd_partition fixed_partition_map_spi[] = {
+   {
+	  .name   = NOR_FLASH_FTSBL_NAME,
+	  .size   = NOR_FLASH_FTSBL_SIZE,
+	  .offset = NOR_FLASH_FTSBL_ADDRESS,
+   },
+   {
+	  .name   = NOR_FLASH_FRDNL_NAME,
+	  .size   = NOR_FLASH_FRDNL_SIZE,
+	  .offset = NOR_FLASH_FRDNL_ADDRESS,
+   },
+   {
+      .name   = NOR_FLASH_SDIF_NAME,
+      .size   = NOR_FLASH_SDIF_SIZE,
+      .offset = NOR_FLASH_SDIF_ADDRESS,
+   },
+   {
+      .name   = NOR_FLASH_UTSBL_NAME,
+      .size   = NOR_FLASH_UTSBL_SIZE,
+      .offset = NOR_FLASH_UTSBL_ADDRESS,
+   },
+   {
+      .name   = NOR_FLASH_TBX_NAME,
+      .size   = NOR_FLASH_TBX_SIZE,
+      .offset = NOR_FLASH_TBX_ADDRESS,
+   },
+   {
+      .name   = NOR_FLASH_OSY_NAME,
+      .size   = NOR_FLASH_OSY_SIZE,
+      .offset = NOR_FLASH_OSY_ADDRESS,
+   },
+   {
+      .name   = NOR_FLASH_FUT_NAME,
+      .size   = NOR_FLASH_FUT_SIZE,
+      .offset = NOR_FLASH_FUT_ADDRESS,
+   },
+   {
+      .name   = NOR_FLASH_BSECK_RELOAD_NAME,
+      .size   = NOR_FLASH_BSECK_RELOAD_SIZE,
+      .offset = NOR_FLASH_BSECK_RELOAD_ADDRESS,
+   },
+};
+
+static struct brcm_mtd_partition_map fixed_partition_map[FLASH_TYPE_MAX] = {
+   /* NORFLASH partitions */
+   {
+      0,        /* No NORFLASH partitions */
+      NULL
+   },
+   /* NANDFLASH partitions */
+   {
+      7,
+      fixed_partition_map_512mb_nand
+   },
+   /* SPIFLASH partitions */
+   /*{             Has been removed. We use now command line for that
+      8,
+      fixed_partition_map_spi
+   }       */
+};
+
+#if defined(CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT) && defined(CFG_NAND_AUTO_DETECT_CONFIG)
+static void __init pace_nand_detect_configuration(void)
+{
+    NAND_DEV_INFO *nand_info;
+    int status = NDR_SUCCESS;
+	status = nand_dev_init();
+	if ((status != NDR_SUCCESS) && (status != NDR_ALREADY_INITIALISED ))
+	{
+		return;
+	}
+	nand_dev_get_info(&nand_info);
+	if(nand_info->Block_Size == NAND_FLASH_512MB_BLOCK_SIZE)
+	{
+        printk("512MB/4K NAND chip Detected, Switching to 7 partitions map\r\n");
+	    fixed_partition_map[1].num_parts = 7;
+		fixed_partition_map[1].partition_map = fixed_partition_map_512mb_nand;
+	}
+	else
+	{
+		printk("256MB/2K NAND chip Detected, Switching to 6 partitions map\r\n");
+	    fixed_partition_map[1].num_parts = 7;
+		fixed_partition_map[1].partition_map = fixed_partition_map_nand;
+	}
+}
+#endif
+int __init board_get_partition_map_pace(struct brcm_mtd_partition_map  **p)
+{
+#if defined(CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT) && defined(CFG_NAND_AUTO_DETECT_CONFIG)
+   pace_nand_detect_configuration();
+#endif
+   *p = fixed_partition_map;
+   return 3;
+}
+
+
+#endif
diff -Naur kernel-3.3-3.0a-ref/drivers/char/bmoca.c kernel-current/drivers/char/bmoca.c
--- kernel-3.3-3.0a-ref/drivers/char/bmoca.c	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/drivers/char/bmoca.c	2015-06-12 16:27:20.000108063 +0200
@@ -13,9 +13,11 @@
  * You should have received a copy of the GNU General Public License
  * along with this program; if not, write to the Free Software
  * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
- */
 
-#define pr_fmt(fmt)		KBUILD_MODNAME ": " fmt
+ <:label-BRCM::GPL:standard
+ :>
+
+ */
 
 #include <linux/module.h>
 #include <linux/kernel.h>
@@ -36,28 +38,41 @@
 #include <linux/scatterlist.h>
 #include <linux/clk.h>
 #include <linux/io.h>
-#include <linux/bitops.h>
-#include <linux/printk.h>
 
 #define DRV_VERSION		0x00040000
 #define DRV_BUILD_NUMBER	0x20110831
 
+
 #if defined(CONFIG_BRCMSTB)
+
 #define MOCA6816		0
 #include <linux/bmoca.h>
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 3, 0)
+#include <linux/brcmstb/brcmstb.h>
+#else
+#include <asm/brcmstb/brcmstb.h>
+#endif
+
 #elif defined(DSL_MOCA)
+
 #define MOCA6816		1
 #include "bmoca.h"
 #include <boardparms.h>
 #include <bcm3450.h>
+/* board.h cannot declare spinlock, so do it here */
+extern spinlock_t bcm_gpio_spinlock;
 #include <linux/netdevice.h>
+
+#if defined(CONFIG_BCM_6802_MoCA)
+#include <board.h>
+#endif
+
 #else
+
 #define MOCA6816		1
 #include <linux/bmoca.h>
-#endif
 
-#if defined(CONFIG_BRCMSTB)
-#include <linux/brcmstb/brcmstb.h>
 #endif
 
 #define MOCA_ENABLE		1
@@ -109,11 +124,11 @@
 #define MAX_LAB_PRINTF		104
 
 #ifdef CONFIG_CPU_LITTLE_ENDIAN
-#define M2M_WRITE		(BIT(31) | BIT(27) | BIT(28))
-#define M2M_READ		(BIT(30) | BIT(27) | BIT(28))
+#define M2M_WRITE		((1 << 31) | (1 << 27) | (1 << 28))
+#define M2M_READ		((1 << 30) | (1 << 27) | (1 << 28))
 #else
-#define M2M_WRITE		(BIT(31) | BIT(27))
-#define M2M_READ		(BIT(30) | BIT(27))
+#define M2M_WRITE		((1 << 31) | (1 << 27))
+#define M2M_READ		((1 << 30) | (1 << 27))
 #endif
 
 #define M2M_TIMEOUT_MS		10
@@ -123,7 +138,8 @@
 #define FLUSH_DMA_ONLY		2
 #define FLUSH_REQRESP_ONLY	3
 
-#define DEFAULT_PHY_CLOCK	(300 * 1000000)
+#define DEFAULT_PHY_CLOCK       300000000
+
 
 /* DMA buffers may not share a cache line with anything else */
 #define __DMA_ALIGN__		__attribute__((__aligned__(L1_CACHE_BYTES)))
@@ -141,29 +157,35 @@
 };
 
 struct moca_regs {
-	unsigned int		data_mem_offset;
-	unsigned int		data_mem_size;
-	unsigned int		cntl_mem_size;
-	unsigned int		cntl_mem_offset;
-	unsigned int		gp0_offset;
-	unsigned int		gp1_offset;
-	unsigned int		ringbell_offset;
-	unsigned int		l2_status_offset;
-	unsigned int		l2_clear_offset;
-	unsigned int		l2_mask_set_offset;
-	unsigned int		l2_mask_clear_offset;
-	unsigned int		sw_reset_offset;
-	unsigned int		led_ctrl_offset;
-	unsigned int		m2m_src_offset;
-	unsigned int		m2m_dst_offset;
-	unsigned int		m2m_cmd_offset;
-	unsigned int		m2m_status_offset;
-	unsigned int		moca2host_mmp_inbox_0_offset;
-	unsigned int		moca2host_mmp_inbox_1_offset;
-	unsigned int		moca2host_mmp_inbox_2_offset;
-	unsigned int		h2m_resp_bit[2]; /* indexed by cpu */
-	unsigned int		h2m_req_bit[2]; /* indexed by cpu */
-	unsigned int		sideband_gmii_fc_offset;
+	unsigned int	data_mem_offset;
+	unsigned int	data_mem_size;
+	unsigned int	cntl_mem_size;
+	unsigned int	cntl_mem_offset;
+	unsigned int	gp0_offset;
+	unsigned int	gp1_offset;
+	unsigned int	ringbell_offset;
+	unsigned int	l2_status_offset;
+	unsigned int	l2_clear_offset;
+	unsigned int	l2_mask_set_offset;
+	unsigned int	l2_mask_clear_offset;
+	unsigned int	sw_reset_offset;
+	unsigned int	led_ctrl_offset;
+	unsigned int	m2m_src_offset;
+	unsigned int	m2m_dst_offset;
+	unsigned int	m2m_cmd_offset;
+	unsigned int	m2m_status_offset;
+	unsigned int	host2moca_mmp_outbox_0_offset;
+	unsigned int	moca2host_mmp_inbox_0_offset;
+	unsigned int	moca2host_mmp_inbox_1_offset;
+	unsigned int	moca2host_mmp_inbox_2_offset;
+	unsigned int	h2m_resp_bit[2]; /* indexed by cpu */
+	unsigned int	h2m_req_bit[2]; /* indexed by cpu */
+	unsigned int	sideband_gmii_fc_offset;
+#if MOCA6816
+	unsigned int	pmb_master_wdata_offset;
+	unsigned int	pmb_master_cmd_offset;
+	unsigned int	pmb_master_status;
+#endif
 };
 
 struct moca_priv_data {
@@ -196,7 +218,7 @@
 
 	spinlock_t		list_lock;
 	spinlock_t		clock_lock;
-	spinlock_t		irq_status_lock;
+	struct mutex		irq_status_mutex;
 	struct mutex		dev_mutex;
 	struct mutex		copy_mutex;
 	struct mutex		moca_i2c_mutex;
@@ -221,120 +243,181 @@
 	unsigned int		phy_freq;
 
 	unsigned int		hw_rev;
-
-	const struct moca_regs	*regs;
+	struct moca_regs	*regs;
 
 	/* MMP Parameters */
-	unsigned int		mmp_20;
-	unsigned int		host_req_size;
-	unsigned int		host_resp_size;
-	unsigned int		core_req_size;
-	unsigned int		core_resp_size;
-	unsigned int		host_req_offset;
-	unsigned int		host_resp_offset;
-	unsigned int		core_req_offset;
-	unsigned int		core_resp_offset;
+	unsigned int	mmp_20;
+	unsigned int	host_req_size;
+	unsigned int	host_resp_size;
+	unsigned int	core_req_size;
+	unsigned int	core_resp_size;
+	unsigned int	host_req_offset;
+	unsigned int	host_resp_offset;
+	unsigned int	core_req_offset;
+	unsigned int	core_resp_offset;
+
 };
 
-static const struct moca_regs regs_11_plus = {
-	.data_mem_offset		= 0,
-	.data_mem_size			= (256 * 1024),
-	.cntl_mem_offset		= 0x00040000,
-	.cntl_mem_size			= (128 * 1024),
-	.gp0_offset			= 0x000a2050,
-	.gp1_offset			= 0x000a2054,
-	.ringbell_offset		= 0x000a2060,
-	.l2_status_offset		= 0x000a2080,
-	.l2_clear_offset		= 0x000a2088,
-	.l2_mask_set_offset		= 0x000a2090,
-	.l2_mask_clear_offset		= 0x000a2094,
-	.sw_reset_offset		= 0x000a2040,
-	.led_ctrl_offset		= 0x000a204c,
-	.led_ctrl_offset		= 0x000a204c,
-	.m2m_src_offset			= 0x000a2000,
-	.m2m_dst_offset			= 0x000a2004,
-	.m2m_cmd_offset			= 0x000a2008,
-	.m2m_status_offset		= 0x000a200c,
-	.h2m_resp_bit[1]		= 0x1,
-	.h2m_req_bit[1]			= 0x2,
-	.sideband_gmii_fc_offset	= 0x000a1420
+#if MOCA6816
+struct moca_regs regs_6802 = {
+	.data_mem_offset = 0,
+	.data_mem_size = (640 * 1024),
+	.cntl_mem_offset = 0x00108000,
+	.cntl_mem_size = (384 * 1024),
+	.gp0_offset = 0,
+	.gp1_offset = 0,
+	.ringbell_offset = 0x001ffd0c,
+	.l2_status_offset = 0x001ffc40,
+	.l2_clear_offset = 0x001ffc48,
+	.l2_mask_set_offset = 0x001ffc50,
+	.l2_mask_clear_offset = 0x001ffc54,
+	.sw_reset_offset = 0x001ffd00,
+	.led_ctrl_offset = 0,
+	.m2m_src_offset = 0x001ffc00,
+	.m2m_dst_offset = 0x001ffc04,
+	.m2m_cmd_offset = 0x001ffc08,
+	.m2m_status_offset = 0x001ffc0c,
+	.host2moca_mmp_outbox_0_offset = 0x001ffd18,
+	.moca2host_mmp_inbox_0_offset = 0x001ffd58,
+	.moca2host_mmp_inbox_1_offset = 0x001ffd5c,
+	.moca2host_mmp_inbox_2_offset = 0x001ffd60,
+	.h2m_resp_bit[1] = 0x10,
+	.h2m_req_bit[1] = 0x20,
+	.h2m_resp_bit[0] = 0x1,
+	.h2m_req_bit[0] = 0x2,
+	.sideband_gmii_fc_offset = 0x001fec18,
+	.pmb_master_status       = 0x001ffcc0,
+	.pmb_master_wdata_offset = 0x001ffcc8,
+	.pmb_master_cmd_offset   = 0x001ffccc
 };
 
-static const struct moca_regs regs_11_lite = {
-	.data_mem_offset		= 0,
-	.data_mem_size			= (96 * 1024),
-	.cntl_mem_offset		= 0x0004c000,
-	.cntl_mem_size			= (80 * 1024),
-	.gp0_offset			= 0x000a2050,
-	.gp1_offset			= 0x000a2054,
-	.ringbell_offset		= 0x000a2060,
-	.l2_status_offset		= 0x000a2080,
-	.l2_clear_offset		= 0x000a2088,
-	.l2_mask_set_offset		= 0x000a2090,
-	.l2_mask_clear_offset		= 0x000a2094,
-	.sw_reset_offset		= 0x000a2040,
-	.led_ctrl_offset		= 0x000a204c,
-	.led_ctrl_offset		= 0x000a204c,
-	.m2m_src_offset			= 0x000a2000,
-	.m2m_dst_offset			= 0x000a2004,
-	.m2m_cmd_offset			= 0x000a2008,
-	.m2m_status_offset		= 0x000a200c,
-	.h2m_resp_bit[1]		= 0x1,
-	.h2m_req_bit[1]			= 0x2,
-	.sideband_gmii_fc_offset	= 0x000a1420
+struct moca_regs regs_6816 = {
+	.data_mem_offset = 0,
+	.data_mem_size = (256 * 1024),
+	.cntl_mem_offset = 0x0004c000,
+	.cntl_mem_size = (80 * 1024),
+	.gp0_offset = 0x000a1418,
+	.gp1_offset = 0x000a141c,
+	.ringbell_offset = 0x000a1404,
+	.l2_status_offset = 0x000a2080,
+	.l2_clear_offset = 0x000a2088,
+	.l2_mask_set_offset = 0x000a2090,
+	.l2_mask_clear_offset = 0x000a2094,
+	.sw_reset_offset = 0x000a2040,
+	.led_ctrl_offset = 0x000a204c,
+	.m2m_src_offset = 0x000a2000,
+	.m2m_dst_offset = 0x000a2004,
+	.m2m_cmd_offset = 0x000a2008,
+	.m2m_status_offset = 0x000a200c,
+	.h2m_resp_bit[1] = 0x1,
+	.h2m_req_bit[1] = 0x2,
+	.sideband_gmii_fc_offset = 0x000a1420
 };
 
-static const struct moca_regs regs_11 = {
-	.data_mem_offset		= 0,
-	.data_mem_size			= (256 * 1024),
-	.cntl_mem_offset		= 0x0004c000,
-	.cntl_mem_size			= (80 * 1024),
-	.gp0_offset			= 0x000a2050,
-	.gp1_offset			= 0x000a2054,
-	.ringbell_offset		= 0x000a2060,
-	.l2_status_offset		= 0x000a2080,
-	.l2_clear_offset		= 0x000a2088,
-	.l2_mask_set_offset		= 0x000a2090,
-	.l2_mask_clear_offset		= 0x000a2094,
-	.sw_reset_offset		= 0x000a2040,
-	.led_ctrl_offset		= 0x000a204c,
-	.m2m_src_offset			= 0x000a2000,
-	.m2m_dst_offset			= 0x000a2004,
-	.m2m_cmd_offset			= 0x000a2008,
-	.m2m_status_offset		= 0x000a200c,
-	.h2m_resp_bit[1]		= 0x1,
-	.h2m_req_bit[1]			= 0x2,
-	.sideband_gmii_fc_offset	= 0x000a1420
+#else
+
+struct moca_regs regs_11_plus = {
+	.data_mem_offset = 0,
+	.data_mem_size = (256 * 1024),
+	.cntl_mem_offset = 0x00040000,
+	.cntl_mem_size = (128 * 1024),
+	.gp0_offset = 0x000a2050,
+	.gp1_offset = 0x000a2054,
+	.ringbell_offset = 0x000a2060,
+	.l2_status_offset = 0x000a2080,
+	.l2_clear_offset = 0x000a2088,
+	.l2_mask_set_offset = 0x000a2090,
+	.l2_mask_clear_offset = 0x000a2094,
+	.sw_reset_offset = 0x000a2040,
+	.led_ctrl_offset = 0x000a204c,
+	.led_ctrl_offset = 0x000a204c,
+	.m2m_src_offset = 0x000a2000,
+	.m2m_dst_offset = 0x000a2004,
+	.m2m_cmd_offset = 0x000a2008,
+	.m2m_status_offset = 0x000a200c,
+	.h2m_resp_bit[1] = 0x1,
+	.h2m_req_bit[1] = 0x2,
+	.sideband_gmii_fc_offset = 0x000a1420
 };
 
-static const struct moca_regs regs_20 = {
-	.data_mem_offset		= 0,
-	.data_mem_size			= (288 * 1024),
-	.cntl_mem_offset		= 0x00120000,
-	.cntl_mem_size			= (384 * 1024),
-	.gp0_offset			= 0,
-	.gp1_offset			= 0,
-	.ringbell_offset		= 0x001ffd0c,
-	.l2_status_offset		= 0x001ffc40,
-	.l2_clear_offset		= 0x001ffc48,
-	.l2_mask_set_offset		= 0x001ffc50,
-	.l2_mask_clear_offset		= 0x001ffc54,
-	.sw_reset_offset		= 0x001ffd00,
-	.led_ctrl_offset		= 0,
-	.m2m_src_offset			= 0x001ffc00,
-	.m2m_dst_offset			= 0x001ffc04,
-	.m2m_cmd_offset			= 0x001ffc08,
-	.m2m_status_offset		= 0x001ffc0c,
-	.moca2host_mmp_inbox_0_offset	= 0x001ffd58,
-	.moca2host_mmp_inbox_1_offset	= 0x001ffd5c,
-	.moca2host_mmp_inbox_2_offset	= 0x001ffd60,
-	.h2m_resp_bit[1]		= 0x10,
-	.h2m_req_bit[1]			= 0x20,
-	.h2m_resp_bit[0]		= 0x1,
-	.h2m_req_bit[0]			= 0x2,
-	.sideband_gmii_fc_offset	= 0x001fec18
+struct moca_regs regs_11_lite = {
+	.data_mem_offset = 0,
+	.data_mem_size = (96 * 1024),
+	.cntl_mem_offset = 0x0004c000,
+	.cntl_mem_size = (80 * 1024),
+	.gp0_offset = 0x000a2050,
+	.gp1_offset = 0x000a2054,
+	.ringbell_offset = 0x000a2060,
+	.l2_status_offset = 0x000a2080,
+	.l2_clear_offset = 0x000a2088,
+	.l2_mask_set_offset = 0x000a2090,
+	.l2_mask_clear_offset = 0x000a2094,
+	.sw_reset_offset = 0x000a2040,
+	.led_ctrl_offset = 0x000a204c,
+	.led_ctrl_offset = 0x000a204c,
+	.m2m_src_offset = 0x000a2000,
+	.m2m_dst_offset = 0x000a2004,
+	.m2m_cmd_offset = 0x000a2008,
+	.m2m_status_offset = 0x000a200c,
+	.h2m_resp_bit[1] = 0x1,
+	.h2m_req_bit[1] = 0x2,
+	.sideband_gmii_fc_offset = 0x000a1420
 };
 
+struct moca_regs regs_11 = {
+	.data_mem_offset = 0,
+	.data_mem_size = (256 * 1024),
+	.cntl_mem_offset = 0x0004c000,
+	.cntl_mem_size = (80 * 1024),
+	.gp0_offset = 0x000a2050,
+	.gp1_offset = 0x000a2054,
+	.ringbell_offset = 0x000a2060,
+	.l2_status_offset = 0x000a2080,
+	.l2_clear_offset = 0x000a2088,
+	.l2_mask_set_offset = 0x000a2090,
+	.l2_mask_clear_offset = 0x000a2094,
+	.sw_reset_offset = 0x000a2040,
+	.led_ctrl_offset = 0x000a204c,
+	.m2m_src_offset = 0x000a2000,
+	.m2m_dst_offset = 0x000a2004,
+	.m2m_cmd_offset = 0x000a2008,
+	.m2m_status_offset = 0x000a200c,
+	.h2m_resp_bit[1] = 0x1,
+	.h2m_req_bit[1] = 0x2,
+	.sideband_gmii_fc_offset = 0x000a1420
+};
+
+struct moca_regs regs_20 = {
+	.data_mem_offset = 0,
+	.data_mem_size = (288 * 1024),
+	.cntl_mem_offset = 0x00120000,
+	.cntl_mem_size = (384 * 1024),
+	.gp0_offset = 0,
+	.gp1_offset = 0,
+	.ringbell_offset = 0x001ffd0c,
+	.l2_status_offset = 0x001ffc40,
+	.l2_clear_offset = 0x001ffc48,
+	.l2_mask_set_offset = 0x001ffc50,
+	.l2_mask_clear_offset = 0x001ffc54,
+	.sw_reset_offset = 0x001ffd00,
+	.led_ctrl_offset = 0,
+	.m2m_src_offset = 0x001ffc00,
+	.m2m_dst_offset = 0x001ffc04,
+	.m2m_cmd_offset = 0x001ffc08,
+	.m2m_status_offset = 0x001ffc0c,
+	.host2moca_mmp_outbox_0_offset = 0x001ffd18,
+	.moca2host_mmp_inbox_0_offset = 0x001ffd58,
+	.moca2host_mmp_inbox_1_offset = 0x001ffd5c,
+	.moca2host_mmp_inbox_2_offset = 0x001ffd60,
+	.h2m_resp_bit[1] = 0x10,
+	.h2m_req_bit[1] = 0x20,
+	.h2m_resp_bit[0] = 0x1,
+	.h2m_req_bit[0] = 0x2,
+	.sideband_gmii_fc_offset = 0x001fec18
+};
+
+#endif
+
 #define MOCA_FW_MAGIC		0x4d6f4341
 
 struct moca_fw_hdr {
@@ -358,6 +441,7 @@
 	u32			scl_param;
 };
 
+
 /* support for multiple MoCA devices */
 #define NUM_MINORS		8
 static struct moca_priv_data *minor_tbl[NUM_MINORS];
@@ -367,18 +451,18 @@
 #define MOCA_MAJOR		234
 #define MOCA_CLASS		"bmoca"
 
-#define M2H_RESP		BIT(0)
-#define M2H_REQ			BIT(1)
-#define M2H_ASSERT		BIT(2)
-#define M2H_NEXTCHUNK		BIT(3)
-#define M2H_NEXTCHUNK_CPU0	BIT(4)
-#define M2H_WDT_CPU0		BIT(6)
-#define M2H_WDT_CPU1		BIT(10)
-#define M2H_DMA			BIT(11)
-
-#define M2H_RESP_CPU0		BIT(13)
-#define M2H_REQ_CPU0		BIT(14)
-#define M2H_ASSERT_CPU0		BIT(15)
+#define M2H_RESP		(1 << 0)
+#define M2H_REQ			(1 << 1)
+#define M2H_ASSERT		(1 << 2)
+#define M2H_NEXTCHUNK		(1 << 3)
+#define M2H_NEXTCHUNK_CPU0		(1<<4)
+#define M2H_WDT_CPU1			(1 << 10)
+#define M2H_WDT_CPU0			(1 << 6)
+#define M2H_DMA			(1 << 11)
+
+#define M2H_RESP_CPU0	(1 << 13)
+#define M2H_REQ_CPU0		(1 << 14)
+#define M2H_ASSERT_CPU0	(1 << 15)
 
 /* does this word contain a NIL byte (i.e. end of string)? */
 #define HAS0(x)			((((x) & 0xff) == 0) || \
@@ -396,32 +480,32 @@
 static void moca_3450_write_i2c(struct moca_priv_data *priv, u8 addr, u32 data);
 static u32 moca_3450_read_i2c(struct moca_priv_data *priv, u8 addr);
 static int moca_get_mbx_offset(struct moca_priv_data *priv);
+static u32 moca_irq_status(struct moca_priv_data *priv, int flush);
 
 #define INRANGE(x, a, b)	(((x) >= (a)) && ((x) < (b)))
 
 static inline int moca_range_ok(struct moca_priv_data *priv,
 	unsigned long offset, unsigned long len)
 {
-	const struct moca_regs *r = priv->regs;
 	unsigned long lastad = offset + len - 1;
 
 	if (lastad < offset)
 		return -EINVAL;
 
-	if (INRANGE(offset, r->cntl_mem_offset,
-		    r->cntl_mem_offset + r->cntl_mem_size) &&
-	    INRANGE(lastad, r->cntl_mem_offset,
-		    r->cntl_mem_offset + r->cntl_mem_size))
+	if (INRANGE(offset, priv->regs->cntl_mem_offset,
+		priv->regs->cntl_mem_offset+priv->regs->cntl_mem_size) &&
+		INRANGE(lastad, priv->regs->cntl_mem_offset,
+		priv->regs->cntl_mem_offset+priv->regs->cntl_mem_size))
 		return 0;
 
-	if (INRANGE(offset, r->data_mem_offset,
-		    r->data_mem_offset + r->data_mem_size) &&
-	    INRANGE(lastad, r->data_mem_offset,
-		    r->data_mem_offset + r->data_mem_size))
+	if (INRANGE(offset, priv->regs->data_mem_offset,
+		priv->regs->data_mem_offset + priv->regs->data_mem_size) &&
+		INRANGE(lastad, priv->regs->data_mem_offset,
+		priv->regs->data_mem_offset + priv->regs->data_mem_size))
 		return 0;
 
 	if (INRANGE(offset, OFF_PKT_REINIT_MEM, PKT_REINIT_MEM_END) &&
-	    INRANGE(lastad, OFF_PKT_REINIT_MEM, PKT_REINIT_MEM_END))
+		INRANGE(lastad, OFF_PKT_REINIT_MEM, PKT_REINIT_MEM_END))
 		return 0;
 
 	return -EINVAL;
@@ -454,7 +538,7 @@
 
 static int moca_is_20(struct moca_priv_data *priv)
 {
-	return (priv->hw_rev & MOCA_PROTVER_MASK) == MOCA_PROTVER_20;
+	return ((priv->hw_rev & MOCA_PROTVER_MASK) == MOCA_PROTVER_20);
 }
 
 #ifdef CONFIG_BRCM_MOCA_BUILTIN_FW
@@ -463,6 +547,14 @@
 static const char *bmoca_fw_image;
 #endif
 
+#if MOCA6816
+#if defined(CONFIG_BCM_6802_MoCA)
+#include "bmoca-6802.c"
+#else
+#include "bmoca-6816.c"
+#endif
+#else
+
 /*
  * LOW-LEVEL DEVICE OPERATIONS
  */
@@ -473,49 +565,52 @@
 #define I2C_RD(x)		MOCA_RD(x)
 #define I2C_WR(x, y)		MOCA_WR(x, y)
 
+#define moca_clk_enable   clk_enable
+#define moca_clk_disable  clk_disable
+#define moca_clk_set_rate clk_set_rate
+#define moca_clk_put      clk_put
+#define moca_clk_get      clk_get
+
 static void moca_hw_reset(struct moca_priv_data *priv)
 {
-	const struct moca_regs *r = priv->regs;
-
 	/* disable and clear all interrupts */
-	MOCA_WR(priv->base + r->l2_mask_set_offset, 0xffffffff);
-	MOCA_RD(priv->base + r->l2_mask_set_offset);
+	MOCA_WR(priv->base + priv->regs->l2_mask_set_offset, 0xffffffff);
+	MOCA_RD(priv->base + priv->regs->l2_mask_set_offset);
 
 	/* assert resets */
 
 	/* reset CPU first, both CPUs for MoCA 20 HW */
 	if (moca_is_20(priv))
-		MOCA_SET(priv->base + r->sw_reset_offset, 5);
+		MOCA_SET(priv->base + priv->regs->sw_reset_offset, 5);
 	else
-		MOCA_SET(priv->base + r->sw_reset_offset, 1);
+		MOCA_SET(priv->base + priv->regs->sw_reset_offset, 1);
 
-	MOCA_RD(priv->base + r->sw_reset_offset);
+	MOCA_RD(priv->base + priv->regs->sw_reset_offset);
 
 	udelay(20);
 
 	/* reset everything else except clocks */
-	MOCA_SET(priv->base + r->sw_reset_offset, ~(BIT(3) | BIT(7)));
-	MOCA_RD(priv->base + r->sw_reset_offset);
+	MOCA_SET(priv->base + priv->regs->sw_reset_offset,
+		~((1 << 3) | (1 << 7)));
+	MOCA_RD(priv->base + priv->regs->sw_reset_offset);
 
 	udelay(20);
 
 	/* disable clocks */
-	MOCA_SET(priv->base + r->sw_reset_offset, ~BIT(3));
-	MOCA_RD(priv->base + r->sw_reset_offset);
+	MOCA_SET(priv->base + priv->regs->sw_reset_offset, ~(1 << 3));
+	MOCA_RD(priv->base + priv->regs->sw_reset_offset);
 
-	MOCA_WR(priv->base + r->l2_clear_offset, 0xffffffff);
-	MOCA_RD(priv->base + r->l2_clear_offset);
+	MOCA_WR(priv->base + priv->regs->l2_clear_offset, 0xffffffff);
+	MOCA_RD(priv->base + priv->regs->l2_clear_offset);
 }
 
 /* called any time we start/restart/stop MoCA */
 static void moca_hw_init(struct moca_priv_data *priv, int action)
 {
-	const struct moca_regs *r = priv->regs;
-
 	if (action == MOCA_ENABLE && !priv->enabled) {
-		clk_enable(priv->clk);
-		clk_enable(priv->phy_clk);
-		clk_enable(priv->cpu_clk);
+		moca_clk_enable(priv->clk);
+		moca_clk_enable(priv->phy_clk);
+		moca_clk_enable(priv->cpu_clk);
 		priv->enabled = 1;
 	}
 
@@ -528,89 +623,55 @@
 
 	if (action == MOCA_ENABLE) {
 		/* deassert moca_sys_reset and clock */
-		MOCA_UNSET(priv->base + r->sw_reset_offset, BIT(1) | BIT(7));
+		MOCA_UNSET(priv->base + priv->regs->sw_reset_offset,
+			(1 << 1) | (1 << 7));
 
 		if (priv->hw_rev >= HWREV_MOCA_20_GEN22) {
 			/* Take PHY0 out of reset and enable clock */
-			MOCA_UNSET(priv->base + r->sw_reset_offset,
-				   BIT(4) | BIT(8));
+			MOCA_UNSET(priv->base + priv->regs->sw_reset_offset,
+				(1<<4) | (1<<8));
 
 			if (priv->bonded_mode) {
 				/* Take PHY1 out of reset and enable clock */
-				MOCA_UNSET(priv->base + r->sw_reset_offset,
-					   BIT(5) | BIT(9));
+				MOCA_UNSET(priv->base +
+					priv->regs->sw_reset_offset,
+					(1<<5) | (1<<9));
 			}
 		}
-		MOCA_RD(priv->base + r->sw_reset_offset);
+		MOCA_RD(priv->base + priv->regs->sw_reset_offset);
 	}
 
+
 	if (!moca_is_20(priv)) {
 		/* clear junk out of GP0/GP1 */
-		MOCA_WR(priv->base + r->gp0_offset, 0xffffffff);
-		MOCA_WR(priv->base + r->gp1_offset, 0x0);
+		MOCA_WR(priv->base + priv->regs->gp0_offset, 0xffffffff);
+		MOCA_WR(priv->base + priv->regs->gp1_offset, 0x0);
 		/* set up activity LED for 50% duty cycle */
-		MOCA_WR(priv->base + r->led_ctrl_offset, 0x40004000);
+		MOCA_WR(priv->base + priv->regs->led_ctrl_offset,
+			0x40004000);
 	}
 
 	/* enable DMA completion interrupts */
-	MOCA_WR(priv->base + r->ringbell_offset, 0);
-	MOCA_WR(priv->base + r->l2_mask_clear_offset, M2H_DMA);
-	MOCA_RD(priv->base + r->l2_mask_clear_offset);
+	MOCA_WR(priv->base + priv->regs->ringbell_offset, 0);
+	MOCA_WR(priv->base + priv->regs->l2_mask_clear_offset, M2H_DMA);
+	MOCA_RD(priv->base + priv->regs->l2_mask_clear_offset);
 
 	if (action == MOCA_DISABLE && priv->enabled) {
 		priv->enabled = 0;
-		clk_disable(priv->cpu_clk);
-		clk_disable(priv->phy_clk);
-		clk_disable(priv->clk);
+		moca_clk_disable(priv->clk);
+		moca_clk_disable(priv->phy_clk);
+		moca_clk_disable(priv->cpu_clk);
 	}
 }
 
 static void moca_ringbell(struct moca_priv_data *priv, u32 mask)
 {
-	const struct moca_regs *r = priv->regs;
-
-	MOCA_WR(priv->base + r->ringbell_offset, mask);
-	MOCA_RD(priv->base + r->ringbell_offset);
-}
-
-static u32 moca_irq_status(struct moca_priv_data *priv, int flush)
-{
-	const struct moca_regs *r = priv->regs;
-	u32 stat, dma_mask = M2H_DMA | M2H_NEXTCHUNK;
-	unsigned long flags;
-
-	if (moca_is_20(priv))
-		dma_mask |= M2H_NEXTCHUNK_CPU0;
-
-	spin_lock_irqsave(&priv->irq_status_lock, flags);
-
-	stat = MOCA_RD(priv->base + priv->regs->l2_status_offset);
-
-	if (flush == FLUSH_IRQ) {
-		MOCA_WR(priv->base + r->l2_clear_offset, stat);
-		MOCA_RD(priv->base + r->l2_clear_offset);
-	}
-	if (flush == FLUSH_DMA_ONLY) {
-		MOCA_WR(priv->base + r->l2_clear_offset,
-			stat & dma_mask);
-		MOCA_RD(priv->base + r->l2_clear_offset);
-	}
-	if (flush == FLUSH_REQRESP_ONLY) {
-		MOCA_WR(priv->base + r->l2_clear_offset,
-			stat & (M2H_RESP | M2H_REQ |
-			M2H_RESP_CPU0 | M2H_REQ_CPU0));
-		MOCA_RD(priv->base + r->l2_clear_offset);
-	}
-
-	spin_unlock_irqrestore(&priv->irq_status_lock, flags);
-
-	return stat;
+	MOCA_WR(priv->base + priv->regs->ringbell_offset, mask);
+	MOCA_RD(priv->base + priv->regs->ringbell_offset);
 }
 
 static void moca_enable_irq(struct moca_priv_data *priv)
 {
-	const struct moca_regs *r = priv->regs;
-
 	/* unmask everything */
 	u32 mask = M2H_REQ | M2H_RESP | M2H_ASSERT | M2H_WDT_CPU1 |
 		M2H_NEXTCHUNK | M2H_DMA;
@@ -619,14 +680,12 @@
 		mask |= M2H_WDT_CPU0 | M2H_NEXTCHUNK_CPU0 |
 			M2H_REQ_CPU0 | M2H_RESP_CPU0 | M2H_ASSERT_CPU0;
 
-	MOCA_WR(priv->base + r->l2_mask_clear_offset, mask);
-	MOCA_RD(priv->base + r->l2_mask_clear_offset);
+	MOCA_WR(priv->base + priv->regs->l2_mask_clear_offset, mask);
+	MOCA_RD(priv->base + priv->regs->l2_mask_clear_offset);
 }
 
 static void moca_disable_irq(struct moca_priv_data *priv)
 {
-	const struct moca_regs *r = priv->regs;
-
 	/* mask everything except DMA completions */
 	u32 mask = M2H_REQ | M2H_RESP | M2H_ASSERT | M2H_WDT_CPU1 |
 		M2H_NEXTCHUNK;
@@ -635,50 +694,50 @@
 		mask |= M2H_WDT_CPU0 | M2H_NEXTCHUNK_CPU0 |
 			M2H_REQ_CPU0 | M2H_RESP_CPU0 | M2H_ASSERT_CPU0;
 
-	MOCA_WR(priv->base + r->l2_mask_set_offset, mask);
-	MOCA_RD(priv->base + r->l2_mask_set_offset);
+	MOCA_WR(priv->base + priv->regs->l2_mask_set_offset, mask);
+	MOCA_RD(priv->base + priv->regs->l2_mask_set_offset);
 }
 
 static u32 moca_start_mips(struct moca_priv_data *priv, u32 cpu)
 {
-	const struct moca_regs *r = priv->regs;
-
 	if (moca_is_20(priv)) {
 		if (cpu == 1)
-			MOCA_UNSET(priv->base + r->sw_reset_offset, BIT(0));
+			MOCA_UNSET(priv->base + priv->regs->sw_reset_offset,
+				(1 << 0));
 		else {
 			moca_mmp_init(priv, 1);
-			MOCA_UNSET(priv->base + r->sw_reset_offset, BIT(2));
+			MOCA_UNSET(priv->base + priv->regs->sw_reset_offset,
+				(1 << 2));
 		}
 	} else
-		MOCA_UNSET(priv->base + r->sw_reset_offset, BIT(0));
-	MOCA_RD(priv->base + r->sw_reset_offset);
+		MOCA_UNSET(priv->base + priv->regs->sw_reset_offset, (1 << 0));
+	MOCA_RD(priv->base + priv->regs->sw_reset_offset);
 	return 0;
 }
 
 static void moca_m2m_xfer(struct moca_priv_data *priv,
 	u32 dst, u32 src, u32 ctl)
 {
-	const struct moca_regs *r = priv->regs;
 	u32 status;
 
-	MOCA_WR(priv->base + r->m2m_src_offset, src);
-	MOCA_WR(priv->base + r->m2m_dst_offset, dst);
-	MOCA_WR(priv->base + r->m2m_status_offset, 0);
-	MOCA_RD(priv->base + r->m2m_status_offset);
-	MOCA_WR(priv->base + r->m2m_cmd_offset, ctl);
+	MOCA_WR(priv->base + priv->regs->m2m_src_offset, src);
+	MOCA_WR(priv->base + priv->regs->m2m_dst_offset, dst);
+	MOCA_WR(priv->base + priv->regs->m2m_status_offset, 0);
+	MOCA_RD(priv->base + priv->regs->m2m_status_offset);
+	MOCA_WR(priv->base + priv->regs->m2m_cmd_offset, ctl);
 
 	if (wait_for_completion_timeout(&priv->copy_complete,
 		1000 * M2M_TIMEOUT_MS) <= 0) {
-		dev_warn(priv->dev, "DMA interrupt timed out, status %x\n",
-			 moca_irq_status(priv, NO_FLUSH_IRQ));
+		printk(KERN_WARNING "%s: DMA interrupt timed out, status %x\n",
+			__func__, moca_irq_status(priv, NO_FLUSH_IRQ));
 	}
 
-	status = MOCA_RD(priv->base + r->m2m_status_offset);
+	status = MOCA_RD(priv->base + priv->regs->m2m_status_offset);
 
 	if (status & (3 << 29))
-		dev_warn(priv->dev, "bad status %08x (s/d/c %08x %08x %08x)\n",
-			 status, src, dst, ctl);
+		printk(KERN_WARNING "%s: bad status %08x "
+			"(s/d/c %08x %08x %08x)\n", __func__,
+			status, src, dst, ctl);
 }
 
 static void moca_write_mem(struct moca_priv_data *priv,
@@ -687,8 +746,8 @@
 	dma_addr_t pa;
 
 	if (moca_range_ok(priv, dst_offset, len) < 0) {
-		dev_warn(priv->dev, "copy past end of cntl memory: %08x\n",
-			 dst_offset);
+		printk(KERN_WARNING "%s: copy past end of cntl memory: %08x\n",
+			__func__, dst_offset);
 		return;
 	}
 
@@ -704,8 +763,8 @@
 	int i;
 
 	if (moca_range_ok(priv, src_offset, len) < 0) {
-		dev_warn(priv->dev, "copy past end of cntl memory: %08x\n",
-			 src_offset);
+		printk(KERN_WARNING "%s: copy past end of cntl memory: %08x\n",
+			__func__, src_offset);
 		return;
 	}
 
@@ -754,6 +813,51 @@
 
 #define moca_3450_write moca_3450_write_i2c
 #define moca_3450_read moca_3450_read_i2c
+#endif
+
+// Can be called from MoCA ISR
+static u32 moca_irq_status_no_lock(struct moca_priv_data *priv, int flush)
+{
+	u32 stat;
+	u32 dma_mask = M2H_DMA | M2H_NEXTCHUNK;
+
+	if (moca_is_20(priv))
+		dma_mask |= M2H_NEXTCHUNK_CPU0;
+
+	stat = MOCA_RD(priv->base + priv->regs->l2_status_offset);
+
+	if (flush == FLUSH_IRQ) {
+		MOCA_WR(priv->base + priv->regs->l2_clear_offset, stat);
+		MOCA_RD(priv->base + priv->regs->l2_clear_offset);
+	}
+	if (flush == FLUSH_DMA_ONLY) {
+		MOCA_WR(priv->base + priv->regs->l2_clear_offset,
+			stat & dma_mask);
+		MOCA_RD(priv->base + priv->regs->l2_clear_offset);
+	}
+	if (flush == FLUSH_REQRESP_ONLY) {
+		MOCA_WR(priv->base + priv->regs->l2_clear_offset,
+			stat & (M2H_RESP | M2H_REQ |
+			M2H_RESP_CPU0 | M2H_REQ_CPU0));
+		MOCA_RD(priv->base + priv->regs->l2_clear_offset);
+	}
+
+	return stat;
+}
+
+// Must have MoCA ISR disabled (moca_disable_irq) to call
+static u32 moca_irq_status(struct moca_priv_data *priv, int flush)
+{
+	u32 stat;
+
+	mutex_lock(&priv->irq_status_mutex);
+
+	stat = moca_irq_status_no_lock(priv, flush);
+
+	mutex_unlock(&priv->irq_status_mutex);
+
+	return stat;
+}
 
 static void moca_put_pages(struct moca_priv_data *priv, int pages)
 {
@@ -786,8 +890,8 @@
 	BUG_ON((ret > MAX_FW_PAGES) || (pages == 0));
 
 	if (ret < pages) {
-		dev_warn(priv->dev, "get_user_pages returned %d, expecting %d\n",
-			 ret, pages);
+		printk(KERN_WARNING "%s: get_user_pages returned %d, "
+			"expecting %d\n", __func__, ret, pages);
 		moca_put_pages(priv, ret);
 		return -EFAULT;
 	}
@@ -833,29 +937,51 @@
 
 	/* write the first two chunks, then start the MIPS */
 	moca_write_sg(priv, 0, &priv->fw_sg[0], bl_chunks + 1);
-	moca_enable_irq(priv);
+
+#if defined(CONFIG_BCM_6802_MoCA)
+	/* 6802 doesn't need a handshake between blocks, the timing
+		is guaranteed.  Eliminating the handshake cuts the time
+		required to load firmware */
 	moca_start_mips(priv, be32_to_cpu(hdr.cpuid));
-	ret = 0;
+	udelay(5);
+
+	for (i = bl_chunks + 1; i < pages; i++) {
+		moca_write_sg(priv,
+			priv->regs->data_mem_offset + FW_CHUNK_SIZE * bl_chunks,
+			&priv->fw_sg[i], 1);
+	}
+
+	moca_enable_irq(priv);
+
+#else
 
+	moca_enable_irq(priv);
+	moca_start_mips(priv, be32_to_cpu(hdr.cpuid));
 	/* wait for an ACK, then write each successive chunk */
 	for (i = bl_chunks + 1; i < pages; i++) {
 		if (wait_for_completion_timeout(&priv->chunk_complete,
-				1000 * M2M_TIMEOUT_MS) <= 0) {
+			1000 * M2M_TIMEOUT_MS) <= 0) {
 			moca_disable_irq(priv);
-			dev_warn(priv->dev, "chunk ack timed out\n");
+			printk(KERN_WARNING "%s: chunk ack timed out\n",
+				__func__);
 			ret = -EIO;
-			break;
+			goto out;
 		}
+
 		moca_write_sg(priv,
 			priv->regs->data_mem_offset + FW_CHUNK_SIZE * bl_chunks,
 			&priv->fw_sg[i], 1);
 	}
 
-  /* wait for ACK of last block.  Older firmware images didn't
-     ACK the last block, so don't return an error */
+	/* wait for ACK of last block.  Older firmware images didn't
+	   ACK the last block, so don't return an error */
 	wait_for_completion_timeout(&priv->chunk_complete,
 			1000 * M2M_TIMEOUT_MS / 10);
 
+#endif
+
+	ret = 0;
+
 out:
 	moca_put_pages(priv, pages);
 	return ret;
@@ -961,18 +1087,23 @@
 	struct list_head *ml = NULL;
 	struct moca_core_msg *m;
 	unsigned int w, rw, num_ies;
-	u32 data, size;
+	u32 data;
 	char *msg;
 	int err = -ENOMEM;
 	u32 *reply = priv->core_resp_buf;
 	int attach = 1;
-
+	u32 size;
 	m = &priv->core_msg_temp;
 
 	BUG_ON((uintptr_t)m->data & (L1_CACHE_BYTES - 1));
 
 	/* make sure we have the mailbox offset before using it */
-	moca_get_mbx_offset(priv);
+	if (moca_get_mbx_offset(priv))
+	{
+		err = -EIO;
+		msg = "no mailbox";
+		goto bad;
+	}
 
 	/* read only as much as is necessary.
 	   The second word is the length for mmp_20 */
@@ -1033,7 +1164,8 @@
 			 * return code is always 0
 			 */
 			if ((rw << 2) >= priv->core_resp_size)
-				dev_warn(priv->dev, "Core ack buffer overflowed\n");
+				printk(KERN_WARNING "%s: Core ack buffer "
+					"overflowed\n", __func__);
 			else {
 				reply[rw] = cpu_to_be32((data & ~0xffff) | 4);
 				rw++;
@@ -1138,6 +1270,7 @@
 			msg = "core_req overwritten by assertion";
 			goto bad;
 		}
+
 		moca_write_mem(priv, reply_offset + priv->mbx_offset[cpuid],
 			reply, rw << 2);
 		moca_ringbell(priv, priv->regs->h2m_resp_bit[cpuid]);
@@ -1151,7 +1284,7 @@
 	return 0;
 
 bad:
-	dev_warn(priv->dev, "%s\n", msg);
+	printk(KERN_WARNING "%s: %s\n", __func__, msg);
 
 	if (ml)
 		moca_attach_tail(priv, ml, &priv->core_msg_free_list);
@@ -1193,6 +1326,7 @@
 	}
 }
 
+
 /* Must have dev_mutex when calling this function */
 static int moca_sendmsg(struct moca_priv_data *priv, u32 cpuid)
 {
@@ -1225,7 +1359,9 @@
 
 	ml = moca_detach_head(priv, &priv->core_msg_free_list);
 	if (ml == NULL) {
-		dev_warn(priv->dev, "no entries left on core_msg_free_list\n");
+		printk(KERN_WARNING
+			"%s: no entries left on core_msg_free_list\n",
+			__func__);
 		return -ENOMEM;
 	}
 
@@ -1261,37 +1397,40 @@
 
 static int moca_get_mbx_offset(struct moca_priv_data *priv)
 {
-	const struct moca_regs *r = priv->regs;
 	uintptr_t base;
 
 	if (priv->mbx_offset[1] == -1) {
 		if (moca_is_20(priv))
 			base = MOCA_RD(priv->base +
-				r->moca2host_mmp_inbox_0_offset) &
+				priv->regs->moca2host_mmp_inbox_0_offset) &
 				0x1fffffff;
 		else
-			base = MOCA_RD(priv->base + r->gp0_offset) &
+			base = MOCA_RD(priv->base + priv->regs->gp0_offset) &
 				0x1fffffff;
 
 		if ((base == 0) ||
-			(base >= r->cntl_mem_size + r->cntl_mem_offset) ||
+			(base >= priv->regs->cntl_mem_size +
+			 priv->regs->cntl_mem_offset) ||
 			(base & 0x07)) {
-			dev_warn(priv->dev, "can't get mailbox base CPU 1 (%X)\n",
-				 (int)base);
+			printk(KERN_WARNING "%s: can't get mailbox base CPU 1 (%X)\n",
+				__func__, (int)base);
 			return -1;
 		}
 		priv->mbx_offset[1] = base;
 	}
 
-	if ((priv->mbx_offset[0] == -1) && moca_is_20(priv) && priv->mmp_20) {
+	if ((priv->mbx_offset[0] == -1) &&
+		(moca_is_20(priv)) &&
+		(priv->mmp_20)) {
 		base = MOCA_RD(priv->base +
-			r->moca2host_mmp_inbox_2_offset) &
+			priv->regs->moca2host_mmp_inbox_2_offset) &
 			0x1fffffff;
 		if ((base == 0) ||
-			(base >= r->cntl_mem_size + r->cntl_mem_offset) ||
+			(base >= priv->regs->cntl_mem_size +
+			 priv->regs->cntl_mem_offset) ||
 			(base & 0x07)) {
-			dev_warn(priv->dev, "can't get mailbox base CPU 0 (%X)\n",
-				 (int)base);
+			printk(KERN_WARNING "%s: can't get mailbox base CPU 0 (%X)\n",
+				__func__, (int)base);
 			return -1;
 		}
 
@@ -1312,6 +1451,8 @@
 	u32 mask = 0;
 	int ret, stopped = 0;
 
+	mutex_lock(&priv->dev_mutex);
+
 	if (priv->enabled) {
 		mask = moca_irq_status(priv, FLUSH_IRQ);
 		if (mask & M2H_DMA) {
@@ -1324,12 +1465,14 @@
 			complete(&priv->chunk_complete);
 		}
 
-		if (moca_is_20(priv) && mask & M2H_NEXTCHUNK_CPU0) {
+		if (moca_is_20(priv) &&
+			(mask & M2H_NEXTCHUNK_CPU0)) {
 			mask &= ~M2H_NEXTCHUNK_CPU0;
 			complete(&priv->chunk_complete);
 		}
 
 		if (mask == 0) {
+			mutex_unlock(&priv->dev_mutex);
 			moca_enable_irq(priv);
 			return;
 		}
@@ -1338,14 +1481,13 @@
 			M2H_REQ_CPU0 | M2H_RESP_CPU0)) {
 			if (moca_get_mbx_offset(priv)) {
 				/* mbx interrupt but mbx_offset is bogus?? */
+				mutex_unlock(&priv->dev_mutex);
 				moca_enable_irq(priv);
 				return;
 			}
 		}
 	}
 
-	mutex_lock(&priv->dev_mutex);
-
 	if (!priv->running) {
 		stopped = 1;
 	} else {
@@ -1354,25 +1496,26 @@
 			ret = moca_recvmsg(priv, priv->core_req_offset,
 				priv->core_req_size, 0, 1);
 			if (ret == -ENOMEM)
-				priv->assert_pending = 2;
+				priv->assert_pending |= 2;
 		}
 		if (mask & M2H_ASSERT_CPU0) {
 			ret = moca_recvmsg(priv, priv->core_req_offset,
 				priv->core_req_size, 0, 0);
 			if (ret == -ENOMEM)
-				priv->assert_pending = 1;
+				priv->assert_pending |= 1;
 		}
 		/* M2H_WDT_CPU1 is mapped to the only CPU for MoCA11 HW */
 		if (mask & M2H_WDT_CPU1) {
 			ret = moca_wdt(priv, 2);
 			if (ret == -ENOMEM)
-				priv->wdt_pending |= BIT(1);
+				priv->wdt_pending |= (1 << 1);
 			stopped = 1;
 		}
-		if (moca_is_20(priv) && mask & M2H_WDT_CPU0) {
+		if (moca_is_20(priv) &&
+			(mask & M2H_WDT_CPU0)) {
 			ret = moca_wdt(priv, 1);
 			if (ret == -ENOMEM)
-				priv->wdt_pending |= BIT(0);
+				priv->wdt_pending |= (1 << 0);
 			stopped = 1;
 		}
 	}
@@ -1391,13 +1534,13 @@
 		ret = moca_recvmsg(priv, priv->core_req_offset,
 			priv->core_req_size, priv->core_resp_offset, 1);
 		if (ret == -ENOMEM)
-			priv->core_req_pending = 2;
+			priv->core_req_pending |= 2;
 	}
 	if (mask & M2H_RESP) {
 		ret = moca_recvmsg(priv, priv->host_resp_offset,
 			priv->host_resp_size, 0, 1);
 		if (ret == -ENOMEM)
-			priv->host_resp_pending = 2;
+			priv->host_resp_pending |= 2;
 		if (ret == 0) {
 			priv->host_mbx_busy = 0;
 			moca_sendmsg(priv, 1);
@@ -1408,13 +1551,13 @@
 		ret = moca_recvmsg(priv, priv->core_req_offset,
 			priv->core_req_size, priv->core_resp_offset, 0);
 		if (ret == -ENOMEM)
-			priv->core_req_pending = 1;
+			priv->core_req_pending |= 1;
 	}
 	if (mask & M2H_RESP_CPU0) {
 		ret = moca_recvmsg(priv, priv->host_resp_offset,
 			priv->host_resp_size, 0, 0);
 		if (ret == -ENOMEM)
-			priv->host_resp_pending = 1;
+			priv->host_resp_pending |= 1;
 		if (ret == 0) {
 			priv->host_mbx_busy = 0;
 			moca_sendmsg(priv, 0);
@@ -1429,8 +1572,23 @@
 {
 	struct moca_priv_data *priv = arg;
 
+#if MOCA6816
+	struct moca_platform_data *pd =
+		(struct moca_platform_data *)priv->pdev->dev.platform_data;
+
+	/*
+	 * If the driver is for an external chip then the work function needs
+	 * to run, otherwise a few interrupts can be handled here
+	 */
+	if (0 == pd->use_spi) {
+#else
 	if (1) {
-		u32 mask = moca_irq_status(priv, FLUSH_DMA_ONLY);
+#endif
+		/* Calling the "no_lock" version of this function. This is ok
+		   because no other function processes the DMA INT so there
+		   should be no contention issues. If more than the DMA
+		   INTs are checked here, the locking should be reconsidered. */
+		u32 mask = moca_irq_status_no_lock(priv, FLUSH_DMA_ONLY);
 
 		/* need to handle DMA completions ASAP */
 		if (mask & M2H_DMA) {
@@ -1458,7 +1616,7 @@
 static int moca_3450_wait(struct moca_priv_data *priv)
 {
 	struct bsc_regs *bsc = priv->i2c_base;
-	long timeout = HZ / 1000;	/* 1ms */
+	long timeout = HZ / 1000; /* 1 ms */
 	DECLARE_WAIT_QUEUE_HEAD_ONSTACK(wait);
 	int i = 0;
 
@@ -1469,7 +1627,8 @@
 		}
 		if (i++ > 50) {
 			I2C_WR(&bsc->iic_enable, 0);
-			dev_warn(priv->dev, "3450 I2C timed out\n");
+			printk(KERN_WARNING "%s: 3450 I2C timed out\n",
+				__func__);
 			return -1;
 		}
 		sleep_on_timeout(&wait, timeout ? timeout : 1);
@@ -1512,12 +1671,58 @@
 		return 0xffffffff;
 }
 
+
 #define BCM3450_CHIP_ID		0x00
 #define BCM3450_CHIP_REV	0x04
 #define BCM3450_LNACNTL		0x14
 #define BCM3450_PACNTL		0x18
 #define BCM3450_MISC		0x1c
 
+static int moca_3450_get_reg(struct moca_priv_data *priv, unsigned int  *arg)
+{
+	struct moca_xfer x;
+	u32 *dst;
+	u32 val;
+
+	if (!priv->i2c_base)
+		return -ENODEV;
+
+	if (copy_from_user(&x, (void __user *)arg, sizeof(x)))
+		return -EFAULT;
+
+	dst = (u32 *)(unsigned long)x.buf;
+
+	mutex_lock(&priv->moca_i2c_mutex);
+	val = moca_3450_read(priv, x.moca_addr);
+	mutex_unlock(&priv->moca_i2c_mutex);
+
+	if (put_user(val, dst))
+		return -EFAULT;
+
+	return 0;
+}
+
+static int moca_3450_set_reg(struct moca_priv_data *priv, unsigned int  *arg)
+{
+	struct moca_xfer x;
+	u32 val;
+
+	if (!priv->i2c_base)
+		return -ENODEV;
+
+	if (copy_from_user(&x, (void __user *)arg, sizeof(x)))
+		return -EFAULT;
+
+	mutex_lock(&priv->moca_i2c_mutex);
+	if (get_user(val, (u32 *)(unsigned long)x.buf))
+		return -EFAULT;
+
+	moca_3450_write(priv, x.moca_addr, val);
+	mutex_unlock(&priv->moca_i2c_mutex);
+
+	return 0;
+}
+
 static void moca_3450_init(struct moca_priv_data *priv, int action)
 {
 	u32 data;
@@ -1532,8 +1737,8 @@
 		/* verify chip ID */
 		data = moca_3450_read(priv, BCM3450_CHIP_ID);
 		if (data != 0x3450)
-			dev_warn(priv->dev, "invalid 3450 chip ID 0x%08x\n",
-				 data);
+			printk(KERN_WARNING "%s: invalid 3450 chip ID 0x%08x\n",
+				__func__, data);
 
 		/* reset the 3450's deserializer */
 		data = moca_3450_read(priv, BCM3450_MISC);
@@ -1541,6 +1746,10 @@
 		moca_3450_write(priv, BCM3450_MISC, data | 2);
 		moca_3450_write(priv, BCM3450_MISC, data & ~2);
 
+		/*enable the serial interface*/
+		data = moca_3450_read(priv, BCM3450_MISC);
+		moca_3450_write(priv, BCM3450_MISC, data | (1<<29) );
+		
 		/* set new PA gain */
 		data = moca_3450_read(priv, BCM3450_PACNTL);
 
@@ -1553,14 +1762,19 @@
 		moca_3450_write(priv, BCM3450_LNACNTL, 0x4924);
 
 	} else {
+		
+		/*disable the serial interface*/
+		data = moca_3450_read(priv, BCM3450_MISC);
+		moca_3450_write(priv, BCM3450_MISC, data & (~(1<<29)) );
+
 		/* power down the PA/LNA */
 		data = moca_3450_read(priv, BCM3450_MISC);
 		moca_3450_write(priv, BCM3450_MISC, data | 0x8000);
 
 		data = moca_3450_read(priv, BCM3450_PACNTL);
 		moca_3450_write(priv, BCM3450_PACNTL, data |
-			BIT(0) |	/* PA_PWRDWN */
-			BIT(25));	/* PA_SELECT_PWRUP_BSC */
+			(0x01 << 0) | /* PA_PWRDWN */
+			(0x01 << 25)); /* PA_SELECT_PWRUP_BSC */
 
 		data = moca_3450_read(priv, BCM3450_LNACNTL);
 		/* LNA_INBIAS=0, LNA_PWRUP_IIC=0: */
@@ -1630,6 +1844,7 @@
 	return 0;
 }
 
+
 static int moca_ioctl_writemem(struct moca_priv_data *priv,
 	unsigned long xfer_uaddr)
 {
@@ -1657,6 +1872,13 @@
 	return 0;
 }
 
+#if !MOCA6816
+static unsigned int moca_get_phy_freq(struct moca_priv_data *priv)
+{
+	return priv->phy_freq;
+}
+#endif
+
 /* legacy ioctl - DEPRECATED */
 static int moca_ioctl_get_drv_info_v2(struct moca_priv_data *priv,
 	unsigned long arg)
@@ -1712,6 +1934,15 @@
 		info.gp1 = priv->running ?
 			MOCA_RD(priv->base + priv->regs->gp1_offset) : 0;
 
+	info.phy_freq = moca_get_phy_freq(priv);
+
+#if MOCA6816
+	info.device_id = (((struct moca_platform_data *)
+		priv->pdev->dev.platform_data)->devId);
+	moca_read_mac_addr(priv, &pd->macaddr_hi,
+		&pd->macaddr_lo);
+#endif
+
 	memcpy(info.enet_name, pd->enet_name, MOCA_IFNAMSIZ);
 
 	info.enet_id = pd->enet_id;
@@ -1720,7 +1951,6 @@
 	info.chip_id = pd->chip_id;
 	info.hw_rev = pd->hw_rev;
 	info.rf_band = pd->rf_band;
-	info.phy_freq = priv->phy_freq;
 
 	if (copy_to_user((void *)arg, &info, sizeof(info)))
 		return -EFAULT;
@@ -1737,7 +1967,11 @@
 
 	moca_disable_irq(priv);
 
-	moca_get_mbx_offset(priv);
+	if (moca_get_mbx_offset(priv))
+	{
+		moca_enable_irq(priv);
+		return -EIO;
+	}
 
 	/* If an IRQ is pending, process it here rather than waiting for it to
 	   ensure the results are ready. Clear the ones we are currently
@@ -1748,13 +1982,13 @@
 		ret = moca_recvmsg(priv, priv->core_req_offset,
 			priv->core_req_size, priv->core_resp_offset, 1);
 		if (ret == -ENOMEM)
-			priv->core_req_pending = 2;
+			priv->core_req_pending |= 2;
 	}
 	if (mask & M2H_RESP) {
 		ret = moca_recvmsg(priv, priv->host_resp_offset,
 			priv->host_resp_size, 0, 1);
 		if (ret == -ENOMEM)
-			priv->host_resp_pending = 2;
+			priv->host_resp_pending |= 2;
 		if (ret == 0) {
 			priv->host_mbx_busy = 0;
 			moca_sendmsg(priv, 1);
@@ -1765,13 +1999,13 @@
 		ret = moca_recvmsg(priv, priv->core_req_offset,
 			priv->core_req_size, priv->core_resp_offset, 0);
 		if (ret == -ENOMEM)
-			priv->core_req_pending = 1;
+			priv->core_req_pending |= 1;
 	}
 	if (mask & M2H_RESP_CPU0) {
 		ret = moca_recvmsg(priv, priv->host_resp_offset,
 			priv->host_resp_size, 0, 0);
 		if (ret == -ENOMEM)
-			priv->host_resp_pending = 1;
+			priv->host_resp_pending |= 1;
 		if (ret == 0) {
 			priv->host_mbx_busy = 0;
 			moca_sendmsg(priv, 0);
@@ -1790,27 +2024,67 @@
 	return 0;
 }
 
+static int moca_clk_ssc(struct moca_priv_data *priv,
+	unsigned int *arg)
+{
+
+#if defined(BCHP_CLKGEN_PLL_MOCA_PLL_SSC_MODE_CONTROL_HIGH)
+
+	unsigned int enable;
+
+	get_user(enable, arg);
+	if (enable)
+	{
+		BDEV_WR(BCHP_CLKGEN_PLL_MOCA_PLL_SSC_MODE_CONTROL_HIGH, 0x00005B06);
+		BDEV_WR_F(CLKGEN_PLL_MOCA_PLL_SSC_MODE_CONTROL_LOW, SSC_LIMIT, 0x10000);
+		BDEV_WR_F(CLKGEN_PLL_MOCA_PLL_SSC_MODE_CONTROL_LOW, SSC_MODE, 0x1);
+	}
+	else
+	{
+		BDEV_WR(BCHP_CLKGEN_PLL_MOCA_PLL_SSC_MODE_CONTROL_HIGH, 0x00005B06);
+		BDEV_WR_F(CLKGEN_PLL_MOCA_PLL_SSC_MODE_CONTROL_LOW, SSC_LIMIT, 0x10000);
+		BDEV_WR_F(CLKGEN_PLL_MOCA_PLL_SSC_MODE_CONTROL_LOW, SSC_MODE, 0x0);
+	}
+
+#endif
+
+	return 0;
+}
+
 static long moca_file_ioctl(struct file *file, unsigned int cmd,
 	unsigned long arg)
 {
 	struct moca_priv_data *priv = file->private_data;
-	struct moca_start start;
+	struct moca_start	  start;
 	long ret = -ENOTTY;
+#if MOCA6816
+	struct moca_platform_data *pd = priv->pdev->dev.platform_data;
+#endif
 
 	mutex_lock(&priv->dev_mutex);
 
 	switch (cmd) {
 	case MOCA_IOCTL_START:
-		ret = clk_set_rate(priv->phy_clk, DEFAULT_PHY_CLOCK);
-		/* FIXME: this fails on some platforms, so ignore the value */
 		ret = 0;
-		if (ret < 0)
-			break;
+
+#if MOCA6816
+		/*
+		 * When MoCA is configured as WAN interface it will
+		 * get a new MAC address
+		 */
+		moca_read_mac_addr(priv, &pd->macaddr_hi,
+			&pd->macaddr_lo);
+#endif
+
+		moca_clk_set_rate(priv->phy_clk, DEFAULT_PHY_CLOCK);
 
 		if (copy_from_user(&start, (void __user *)arg, sizeof(start)))
 			ret = -EFAULT;
 
 		if (ret >= 0) {
+			priv->bonded_mode =
+				(start.boot_flags & MOCA_BOOT_FLAGS_BONDED);
+
 			if (!priv->enabled) {
 				moca_msg_reset(priv);
 				moca_hw_init(priv, MOCA_ENABLE);
@@ -1818,8 +2092,7 @@
 				moca_irq_status(priv, FLUSH_IRQ);
 				moca_mmp_init(priv, 0);
 			}
-			priv->bonded_mode =
-				(start.boot_flags & MOCA_BOOT_FLAGS_BONDED);
+
 			ret = moca_write_img(priv, &start.x);
 			if (ret >= 0)
 				priv->running = 1;
@@ -1861,14 +2134,24 @@
 		if (!priv->cpu_clk)
 			ret = -EIO;
 		else
-			ret = clk_set_rate(priv->cpu_clk, (unsigned int)arg);
+			ret = moca_clk_set_rate(priv->cpu_clk, (unsigned int)arg);
 		break;
 	case MOCA_IOCTL_SET_PHY_RATE:
 		if (!priv->phy_clk)
 			ret = -EIO;
 		else
-			ret = clk_set_rate(priv->phy_clk, (unsigned int)arg);
+			ret = moca_clk_set_rate(priv->phy_clk, (unsigned int)arg);
 		break;
+	case MOCA_IOCTL_GET_3450_REG:
+		ret = moca_3450_get_reg(priv, (unsigned int *)arg);
+		break;
+	case MOCA_IOCTL_SET_3450_REG:
+		ret = moca_3450_set_reg(priv, (unsigned int *)arg);
+		break;
+	case MOCA_IOCTL_CLK_SSC:
+		ret = moca_clk_ssc(priv, (unsigned int *)arg);
+		break;
+
 	}
 	mutex_unlock(&priv->dev_mutex);
 
@@ -1942,14 +2225,16 @@
 				priv->core_req_size, 0, 1) != -ENOMEM)
 				priv->assert_pending &= ~2;
 			else
-				dev_warn(priv->dev, "moca_recvmsg assert failed\n");
+				printk(KERN_WARNING "%s: moca_recvmsg "
+					"assert failed\n", __func__);
 		}
 		if (priv->assert_pending & 1) {
 			if (moca_recvmsg(priv, priv->core_req_offset,
 				priv->core_req_size, 0, 0) != -ENOMEM)
 				priv->assert_pending &= ~1;
 			else
-				dev_warn(priv->dev, "moca_recvmsg assert failed\n");
+				printk(KERN_WARNING "%s: moca_recvmsg "
+					"assert failed\n", __func__);
 		}
 		if (priv->wdt_pending)
 			if (moca_wdt(priv, priv->wdt_pending) != -ENOMEM)
@@ -1961,7 +2246,8 @@
 				!= -ENOMEM)
 				priv->core_req_pending &= ~1;
 			else
-				dev_warn(priv->dev, "moca_recvmsg core_req failed\n");
+				printk(KERN_WARNING "%s: moca_recvmsg "
+					"core_req failed\n", __func__);
 		}
 		if (priv->core_req_pending & 2) {
 			if (moca_recvmsg(priv, priv->core_req_offset,
@@ -1969,21 +2255,24 @@
 				!= -ENOMEM)
 				priv->core_req_pending &= ~2;
 			else
-				dev_warn(priv->dev, "moca_recvmsg core_req failed\n");
+				printk(KERN_WARNING "%s: moca_recvmsg "
+					"core_req failed\n", __func__);
 		}
 		if (priv->host_resp_pending & 1) {
 			if (moca_recvmsg(priv, priv->host_resp_offset,
 				priv->host_resp_size, 0, 0) != -ENOMEM)
 				priv->host_resp_pending &= ~1;
 			else
-				dev_warn(priv->dev, "moca_recvmsg host_resp failed\n");
+				printk(KERN_WARNING "%s: moca_recvmsg "
+					"host_resp failed\n", __func__);
 		}
 		if (priv->host_resp_pending & 2) {
 			if (moca_recvmsg(priv, priv->host_resp_offset,
 				priv->host_resp_size, 0, 1) != -ENOMEM)
 				priv->host_resp_pending &= ~2;
 			else
-				dev_warn(priv->dev, "moca_recvmsg host_resp failed\n");
+				printk(KERN_WARNING "%s: moca_recvmsg "
+					"host_resp failed\n", __func__);
 		}
 		mutex_unlock(&priv->dev_mutex);
 	}
@@ -2106,38 +2395,48 @@
 static int moca_probe(struct platform_device *pdev)
 {
 	struct moca_priv_data *priv;
-	struct resource *mres, *ires;
-	int minor, err;
+	struct resource *mres, *ires = NULL;
+	int minor, err = 0;
 	struct moca_platform_data *pd = pdev->dev.platform_data;
 
 	priv = kzalloc(sizeof(*priv), GFP_KERNEL);
 	if (!priv) {
-		pr_err("out of memory\n");
+		printk(KERN_ERR "%s: out of memory\n", __func__);
 		return -ENOMEM;
 	}
 	dev_set_drvdata(&pdev->dev, priv);
 	priv->pdev = pdev;
 	priv->start_time = jiffies;
 
-	priv->clk = clk_get(&pdev->dev, "moca");
-	priv->cpu_clk = clk_get(&pdev->dev, "moca-cpu");
-	priv->phy_clk = clk_get(&pdev->dev, "moca-phy");
+	priv->clk = moca_clk_get(&pdev->dev, "moca");
+
+	priv->cpu_clk = moca_clk_get(&pdev->dev, "moca-cpu");
+	priv->phy_clk = moca_clk_get(&pdev->dev, "moca-phy");
 
 	priv->hw_rev = pd->hw_rev;
+
+#if MOCA6816
+	if ((pd->hw_rev == HWREV_MOCA_20_ALT) ||
+	    (pd->hw_rev == HWREV_MOCA_20_GEN21) ||
+	    (pd->hw_rev == HWREV_MOCA_20_GEN22) ||
+	    (pd->hw_rev == HWREV_MOCA_20_GEN23))
+		priv->regs = &regs_6802;
+	else
+		priv->regs = &regs_6816;
+#else
 	if (pd->hw_rev == HWREV_MOCA_11_PLUS)
 		priv->regs = &regs_11_plus;
 	else if (pd->hw_rev == HWREV_MOCA_11_LITE)
 		priv->regs = &regs_11_lite;
 	else if (pd->hw_rev == HWREV_MOCA_11)
 		priv->regs = &regs_11;
-	else if ((pd->hw_rev == HWREV_MOCA_20_GEN21) ||
+	else if ((pd->hw_rev == HWREV_MOCA_20_ALT) ||
+		(pd->hw_rev == HWREV_MOCA_20_GEN21) ||
 		(pd->hw_rev == HWREV_MOCA_20_GEN22))
 		priv->regs = &regs_20;
-	else {
-		pr_err("unsupported MoCA HWREV: %x\n", pd->hw_rev);
-		err = -EINVAL;
-		goto bad;
-	}
+	else
+		priv->regs = &regs_11_plus;
+#endif
 
 	init_waitqueue_head(&priv->host_msg_wq);
 	init_waitqueue_head(&priv->core_msg_wq);
@@ -2146,8 +2445,7 @@
 
 	spin_lock_init(&priv->list_lock);
 	spin_lock_init(&priv->clock_lock);
-	spin_lock_init(&priv->irq_status_lock);
-
+	mutex_init(&priv->irq_status_mutex);
 	mutex_init(&priv->dev_mutex);
 	mutex_init(&priv->copy_mutex);
 	mutex_init(&priv->moca_i2c_mutex);
@@ -2165,37 +2463,60 @@
 	}
 
 	if (priv->minor == -1) {
-		pr_err("can't allocate minor device\n");
+		printk(KERN_ERR "%s: can't allocate minor device\n",
+			__func__);
 		err = -EIO;
 		goto bad;
 	}
 
 	mres = platform_get_resource(pdev, IORESOURCE_MEM, 0);
 	ires = platform_get_resource(pdev, IORESOURCE_IRQ, 0);
+
 	if (!mres || !ires) {
-		pr_err("can't get resources\n");
+		printk(KERN_ERR "%s: can't get resources\n", __func__);
 		err = -EIO;
 		goto bad;
 	}
+
+
+#if defined(CONFIG_BCM_6802_MoCA)
+	priv->base = (void *)mres->start;
+	priv->irq = ires->start;
+	priv->i2c_base = (void *)pd->bcm3450_i2c_base;
+#else
 	priv->base = ioremap(mres->start, mres->end - mres->start + 1);
 	priv->irq = ires->start;
 	priv->i2c_base = ioremap(pd->bcm3450_i2c_base, sizeof(struct bsc_regs));
+#endif
 
-	/* leave core in reset until we get an ioctl */
+#if MOCA6816
+	moca_read_mac_addr(priv, &pd->macaddr_hi, &pd->macaddr_lo);
+	if (hw_specific_init(priv))
+		goto bad;
+#endif
 
+	/* leave core in reset until we get an ioctl */
 	moca_hw_reset(priv);
 
+#if defined(CONFIG_BCM_6802_MoCA)
+	kerSysRegisterMocaHostIntrCallback(
+		(MocaHostIntrCallback) moca_interrupt,
+		(void *)priv, pd->devId);
+#else
 	if (request_irq(priv->irq, moca_interrupt, 0, "moca", priv) < 0) {
-		pr_err("can't request interrupt\n");
+		printk(KERN_WARNING  "%s: can't request interrupt\n",
+			__func__);
 		err = -EIO;
 		goto bad2;
 	}
+#endif
+
 	moca_hw_init(priv, MOCA_ENABLE);
 	moca_disable_irq(priv);
 	moca_msg_reset(priv);
 	moca_hw_init(priv, MOCA_DISABLE);
 
-	pr_info("adding minor #%d at base 0x%08llx, IRQ %d, "
+	printk(KERN_INFO "bmoca: adding minor #%d at base 0x%08llx, IRQ %d, "
 		"I2C 0x%08llx/0x%02x\n", priv->minor,
 		(unsigned long long)mres->start, ires->start,
 		(unsigned long long)pd->bcm3450_i2c_base, pd->bcm3450_i2c_addr);
@@ -2204,10 +2525,13 @@
 	priv->dev = device_create(moca_class, NULL,
 		MKDEV(MOCA_MAJOR, priv->minor), NULL, "bmoca%d", priv->minor);
 	if (IS_ERR(priv->dev)) {
-		pr_warn("can't register class device\n");
+		printk(KERN_WARNING "bmoca: can't register class device\n");
 		priv->dev = NULL;
 	}
 
+	if (err)
+		goto bad2;
+
 	return 0;
 
 bad2:
@@ -2231,14 +2555,17 @@
 		device_destroy(moca_class, MKDEV(MOCA_MAJOR, priv->minor));
 	minor_tbl[priv->minor] = NULL;
 
-	free_irq(priv->irq, priv);
+	/* free irq if it is used (not used on 6802) */
+	if (priv->irq)
+		free_irq(priv->irq, priv);
+
 	iounmap(priv->i2c_base);
 	iounmap(priv->base);
 	kfree(priv);
 
-	clk_put(cpu_clk);
-	clk_put(phy_clk);
-	clk_put(clk);
+	moca_clk_put(clk);
+	moca_clk_put(phy_clk);
+	moca_clk_put(cpu_clk);
 
 	return 0;
 }
@@ -2248,7 +2575,6 @@
 {
 	/* do not do anything on suspend.
 	MoCA core is not necessarily stopped */
-
 	return 0;
 }
 
@@ -2282,26 +2608,38 @@
 	memset(minor_tbl, 0, sizeof(minor_tbl));
 	ret = register_chrdev(MOCA_MAJOR, MOCA_CLASS, &moca_fops);
 	if (ret < 0) {
-		pr_err("can't register major %d\n", MOCA_MAJOR);
+		printk(KERN_ERR "bmoca: can't register major %d\n", MOCA_MAJOR);
 		goto bad;
 	}
 
 	moca_class = class_create(THIS_MODULE, MOCA_CLASS);
 	if (IS_ERR(moca_class)) {
-		pr_err("can't create device class\n");
+		printk(KERN_ERR "bmoca: can't create device class\n");
 		ret = PTR_ERR(moca_class);
 		goto bad2;
 	}
 
+#if MOCA6816
+	ret = moca_platform_dev_register();
+
+	if (ret < 0) {
+		printk(KERN_ERR "bmoca: can't register platform_device\n");
+		goto bad3;
+	}
+#endif
+
 	ret = platform_driver_register(&moca_plat_drv);
 	if (ret < 0) {
-		pr_err("can't register platform_driver\n");
+		printk(KERN_ERR "bmoca: can't register platform_driver\n");
 		goto bad3;
 	}
 
 	return 0;
 
 bad3:
+#if MOCA6816
+	moca_platform_dev_unregister();
+#endif
 	class_destroy(moca_class);
 bad2:
 	unregister_chrdev(MOCA_MAJOR, MOCA_CLASS);
@@ -2314,6 +2652,9 @@
 	class_destroy(moca_class);
 	unregister_chrdev(MOCA_MAJOR, MOCA_CLASS);
 	platform_driver_unregister(&moca_plat_drv);
+#if MOCA6816
+	moca_platform_dev_unregister();
+#endif
 
 }
 
@@ -2323,4 +2664,3 @@
 MODULE_LICENSE("GPL");
 MODULE_AUTHOR("Broadcom Corporation");
 MODULE_DESCRIPTION("MoCA messaging driver");
-
diff -Naur kernel-3.3-3.0a-ref/drivers/char/mem.c kernel-current/drivers/char/mem.c
--- kernel-3.3-3.0a-ref/drivers/char/mem.c	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/drivers/char/mem.c	2015-06-12 16:27:19.960088064 +0200
@@ -741,12 +741,6 @@
 #define open_oldmem	open_mem
 
 static const struct file_operations mem_fops = {
-	.llseek		= memory_lseek,
-	.read		= read_mem,
-	.write		= write_mem,
-	.mmap		= mmap_mem,
-	.open		= open_mem,
-	.get_unmapped_area = get_unmapped_area_mem,
 };
 
 #ifdef CONFIG_DEVKMEM
@@ -851,7 +845,7 @@
 	const struct file_operations *fops;
 	struct backing_dev_info *dev_info;
 } devlist[] = {
-	 [1] = { "mem", 0, &mem_fops, &directly_mappable_cdev_bdi },
+	/* [1] = { "mem", 0, &mem_fops, &directly_mappable_cdev_bdi },*/
 #ifdef CONFIG_DEVKMEM
 	 [2] = { "kmem", 0, &kmem_fops, &directly_mappable_cdev_bdi },
 #endif
diff -Naur kernel-3.3-3.0a-ref/drivers/genid/genid_driver.c kernel-current/drivers/genid/genid_driver.c
--- kernel-3.3-3.0a-ref/drivers/genid/genid_driver.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/genid/genid_driver.c	2015-06-12 16:27:19.932074066 +0200
@@ -0,0 +1,177 @@
+#include <linux/module.h>
+#include <linux/kernel.h>
+#include <asm/uaccess.h>
+#include <linux/fs.h>
+#include <linux/ioctl.h>
+#include <linux/security.h>
+#include <linux/genid_driver.h>
+
+MODULE_LICENSE("GPL");
+MODULE_DESCRIPTION("genid interface");
+MODULE_AUTHOR("");
+ 
+DEFINE_MUTEX(genid_mutex);
+
+static int GENID_Open = 0;
+static int Major;
+
+extern void sh_reset (void) __attribute__ ((noreturn));
+
+static int genid_open(struct inode *inode, struct file *file);
+
+#if defined(HAVE_UNLOCKED_IOCTL)
+static long genid_ioctl(struct inode *inode, struct file *filp, unsigned int cmd, 
+                     unsigned long genid_data);
+#else
+static int genid_ioctl(struct inode *inode, struct file *filp, unsigned int cmd, 
+                     unsigned long genid_data);
+#endif
+
+static int genid_release(struct inode *inode, struct file *file);
+
+static struct file_operations genid_fops = {
+ .owner   = THIS_MODULE,
+ .open    = genid_open,
+#if defined(HAVE_UNLOCKED_IOCTL)
+ .unlocked_ioctl   = genid_ioctl,
+#else
+ .ioctl   = genid_ioctl,
+#endif
+ .release = genid_release,
+};
+
+
+#define MAX_PID 100
+#define MAX_LEN 256
+
+struct pmw_task {
+  char name[MAX_LEN];
+  unsigned int pid;
+};
+
+static struct pmw_task pmw_tasks[MAX_PID];
+static unsigned int pmw_count = 1;
+
+#if defined(HAVE_UNLOCKED_IOCTL)
+static long genid_ioctl(struct inode *inode, struct file *filp, 
+                     unsigned int cmd, unsigned long genid_data) 
+#else
+static int genid_ioctl(struct inode *inode, struct file *filp, 
+                     unsigned int cmd, unsigned long genid_data) 
+#endif
+{
+  int err=0;
+  unsigned int i = 0; 
+  unsigned int pid;
+  unsigned int res;
+  
+  if (_IOC_DIR(cmd) & _IOC_READ)
+  {
+      printk ("%s:%d ERROR access _IOC_READ\n", __FUNCTION__,__LINE__);
+      err = !access_ok(VERIFY_WRITE, (void *)genid_data, _IOC_SIZE(cmd));
+  }
+  else if (_IOC_DIR(cmd) & _IOC_WRITE)
+  {
+      printk ("%s:%d ERROR access _IOC_WRITE\n", __FUNCTION__,__LINE__);
+      err = !access_ok(VERIFY_READ, (void *)genid_data, _IOC_SIZE(cmd)); 
+  }
+  
+  if (err) 
+  {
+      printk ("%s:%d ERROR access return:%d\n", __FUNCTION__,__LINE__,-EFAULT);
+      return -EFAULT; 
+  }
+  
+  switch(cmd)
+  {
+    case GENID_GETID:
+        //printk("From kernel ===> looking for pid of %s\n", current->comm);
+        
+        while (i < MAX_PID)
+        {                         
+            res = strncmp(pmw_tasks[i].name, current->comm, strlen(current->comm));
+            if (res != 0)
+            {
+                if (strlen(pmw_tasks[i].name) == 0)
+                {
+                    //printk ("adding %s at %d pid %d!!!!!!!!!!!!!!!!\n", current->comm, i, pmw_count);
+                    strncpy(pmw_tasks[i].name, current->comm, strlen(current->comm));
+                    pmw_tasks[i].pid = pmw_count;
+                    pmw_count++;
+                    pid = pmw_tasks[i].pid;
+                    return pid;
+                }
+            }
+            else
+            {
+                pid = pmw_tasks[i].pid;
+                return pid;
+            }
+            i++;
+        }//end while
+        if  (i == MAX_PID)
+        {
+            printk ("%s:%d ERROR too much tasks return:%d\n", __FUNCTION__,__LINE__,-EFAULT);
+            return -EFAULT;
+        }
+        break;
+    default:
+      printk ("%s:%d ERROR unknown ioctl return:%d\n", __FUNCTION__,__LINE__,-ENOTTY);
+      return -ENOTTY;
+  }//end switch
+  
+  //should never be reached
+  printk ("%s:%d ERROR return:%d\n", __FUNCTION__,__LINE__,-EFAULT);
+  return -EFAULT;
+}
+
+static int genid_open(struct inode *inode, struct file *file)
+{
+  if (GENID_Open > 1)
+  {
+      printk ("%s:%d return -EBUSY=%d\n", __FUNCTION__,__LINE__,-EBUSY);
+      return -EBUSY;
+  }
+  
+  GENID_Open++;
+  try_module_get(THIS_MODULE);
+  return 0;
+}
+
+static int genid_release(struct inode *inode, struct file *file)
+{
+  GENID_Open--;/* We're now ready for our next caller */
+  module_put(THIS_MODULE);
+  return 0;
+}
+
+/* Initialization routine */ 
+static int __init genid_init(void) 
+{
+  int j = 0; 
+  
+  Major = register_chrdev(0, DEVICE_NAME, &genid_fops);
+  
+  if (Major < 0)
+  {
+      printk("registering char device failed with %d\n", Major);
+      return Major;
+  }
+  
+  printk("genid module loaded major %d \n", Major);
+  return 0;
+}
+
+
+/* Cleanup routine */
+static void __exit genid_cleanup(void) 
+{
+  int j = 0;
+  
+  unregister_chrdev(Major, DEVICE_NAME);
+ 
+  printk(" module unloaded.\n");
+}
+
+module_init(genid_init);
+module_exit(genid_cleanup);
diff -Naur kernel-3.3-3.0a-ref/drivers/genid/Kconfig kernel-current/drivers/genid/Kconfig
--- kernel-3.3-3.0a-ref/drivers/genid/Kconfig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/genid/Kconfig	2015-06-12 16:27:19.932074066 +0200
@@ -0,0 +1,8 @@
+menu "Genid device support"
+     config GENID_DRIVER
+     bool "activate the genid driver for pseudo pid management"
+     default y 
+     help
+     activate the genid driver for pseudo pid management
+
+endmenu
diff -Naur kernel-3.3-3.0a-ref/drivers/genid/Makefile kernel-current/drivers/genid/Makefile
--- kernel-3.3-3.0a-ref/drivers/genid/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/genid/Makefile	2015-06-12 16:27:19.932074066 +0200
@@ -0,0 +1,6 @@
+#
+# Makefile for the GPL Pace GENID driver
+#
+
+
+obj-$(CONFIG_GENID_DRIVER)		+= genid_driver.o
diff -Naur kernel-3.3-3.0a-ref/drivers/Kconfig kernel-current/drivers/Kconfig
--- kernel-3.3-3.0a-ref/drivers/Kconfig	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/drivers/Kconfig	2015-06-12 16:27:19.960088064 +0200
@@ -2,6 +2,14 @@
 
 source "drivers/base/Kconfig"
 
+source "drivers/genid/Kconfig"
+
+source "drivers/kdev/Kconfig"
+
+source "drivers/kstorman/Kconfig"
+
+source "drivers/kextstats/Kconfig"
+
 source "drivers/connector/Kconfig"
 
 source "drivers/mtd/Kconfig"
@@ -136,4 +144,7 @@
 
 source "drivers/devfreq/Kconfig"
 
+source "drivers/sysinfo/Kconfig"
+
+
 endmenu
diff -Naur kernel-3.3-3.0a-ref/drivers/kdev/Kconfig kernel-current/drivers/kdev/Kconfig
--- kernel-3.3-3.0a-ref/drivers/kdev/Kconfig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kdev/Kconfig	2015-06-12 16:27:19.952084065 +0200
@@ -0,0 +1,5 @@
+ config KDEV_DRIVER
+ bool "kdev driver"
+ help
+ activate the kdev driver for devices list
+
diff -Naur kernel-3.3-3.0a-ref/drivers/kdev/kdev.c kernel-current/drivers/kdev/kdev.c
--- kernel-3.3-3.0a-ref/drivers/kdev/kdev.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kdev/kdev.c	2015-06-12 16:27:19.952084065 +0200
@@ -0,0 +1,109 @@
+/*
+ *  kdev.c
+ *
+ *  This file contains the implementation of the kdev
+ *  core functions.
+ *
+ *  Created by Pace on 05/09/13.
+ *
+ */
+ 
+#include "kdev_priv.h"
+
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/genhd.h>
+#include <linux/kdev_t.h>
+#include <linux/kernel.h>
+#include <linux/blkdev.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/slab.h>
+#include <linux/kmod.h>
+#include <linux/kobj_map.h>
+#include <linux/mutex.h>
+#include <linux/idr.h>
+#include <linux/log2.h>
+#include <linux/sched.h>
+#include <linux/nsproxy.h>
+#include <linux/security.h>
+#include <linux/fs_struct.h>
+#include <linux/device-mapper.h>
+
+/*#define KDEV_CORE_PRINT_DBG*/
+
+extern int chardev_getList(kdev_ioc_getDevices_t* listOfCharDev);
+extern int blkdev_getList(kdev_ioc_getDevices_t* listOfBlkDev);
+
+/***********************************************************************************************
+ *
+ *  static functions
+ *
+ ***********************************************************************************************/
+
+
+/***********************************************************************************************
+ *
+ *  core functions
+ *
+ ***********************************************************************************************/
+
+/*
+ * kdev_core_init
+ */
+int kdev_core_init ( void )
+{
+    return 0;
+}
+
+/*
+ * kdev_core_cleanup
+ */
+void kdev_core_cleanup ( void )
+{
+    return;
+}
+
+
+/*
+ * kdev_core_getDevices
+ */
+int kdev_core_getDevices ( kdev_ioc_getDevices_t *devicesList )
+{
+  int ret = 0;
+  
+  logkdev("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  
+  devicesList->devs_nb = 0;
+  
+  /* Collect char devices */
+  ret = chardev_getList(devicesList);
+  if(ret) printk("\t-> ERROR !!! Not able to store all devices. Increase KDEV_DEVLIST_MAXSIZE !!!");
+  
+  ret = blkdev_getList(devicesList);
+  if(ret) printk("\t-> ERROR !!! Not able to store all devices. Increase KDEV_DEVLIST_MAXSIZE !!!");
+
+#ifdef KDEV_CORE_PRINT_DBG
+  {
+    int index;
+    printk("\n----------------------------------------\n");
+    printk("\n Devices list registered in the kernel:\n");
+    printk("\n----------------------------------------\n\n");
+    for(index = 0; index < devicesList->devs_nb; index++)
+    {
+      printk("\t- type: %s   name: %s\tmajor: %03d   min_minor: %03d   max_minor: %03d\n",
+             (devicesList->devs[index].device_type == KDEV_CHAR_DEV) ? "c" : "b",
+             devicesList->devs[index].device_name,
+             devicesList->devs[index].major,
+             devicesList->devs[index].min_minor,
+             devicesList->devs[index].max_minor);
+    }
+    printk("\n\n----------------------------------------\n\n");
+  }
+#endif
+  
+  return ret;
+}
+
diff -Naur kernel-3.3-3.0a-ref/drivers/kdev/kdev_driver.c kernel-current/drivers/kdev/kdev_driver.c
--- kernel-3.3-3.0a-ref/drivers/kdev/kdev_driver.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kdev/kdev_driver.c	2015-06-12 16:27:19.952084065 +0200
@@ -0,0 +1,307 @@
+/*
+ *  kdev_driver.c
+ *
+ *  This file contains the implementation of the kdev
+ *  interface module with the user space.
+ *
+ *  Created by Pace on 05/09/13.
+ *
+ */
+
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/ioctl.h>
+#include <linux/wait.h>
+#include <linux/sched.h>
+#include <linux/poll.h>
+#include <linux/spinlock.h>
+#include <asm/uaccess.h>
+
+#include <linux/kdev.h>
+
+#include "kdev_priv.h"
+
+MODULE_AUTHOR ("Pace");
+MODULE_DESCRIPTION ("kdev interface");
+MODULE_SUPPORTED_DEVICE ("");
+MODULE_LICENSE ("GPL");
+
+
+/*
+ *
+ *  Module param
+ *
+ */
+static int kdev_major = 144;
+
+module_param (kdev_major,  int, 0644);
+MODULE_PARM_DESC (kdev_major,  "Device major number");
+
+
+/*
+ *
+ *  Module data
+ *
+ */
+static kdev_info_t kdev_info;
+static char connected_id[KDEV_MAX_CONNECT];
+
+/***********************************************************************************************
+ *
+ *  ioctl functions
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  kdev_getblocks_ioc
+ *
+ */
+int kdev_getDevices_ioc (kdev_ioc_getDevices_t *devicesList)
+{
+  int ret;
+
+  logkdev("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+  ret = kdev_core_getDevices(devicesList);
+
+  return ret;
+}
+
+
+
+/***********************************************************************************************
+ *
+ *  Char device functions
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  kdev_open
+ *
+ */
+int kdev_open(struct inode *inode, struct file *filp)
+{
+  int i;
+  kdev_data_t *priv_data;
+  
+  logkdev("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  logkdev("opened = %i\n", (int) kdev_info.opened);
+  if(!kdev_info.opened) /* If first open */
+  {
+    logkdev("opening kdev\n");
+    
+    kdev_info.opened = 1;
+  }
+
+  if ( kdev_info.connected < KDEV_MAX_CONNECT )
+  {
+    kdev_info.connected++;
+    
+    /* Alloc priv_data */
+    priv_data = (kdev_data_t *) kmalloc(sizeof(kdev_data_t), GFP_ATOMIC);
+    if ( priv_data == NULL )
+    {
+      logkdev("kmalloc error\n");
+      return -ENOMEM;
+    }
+    
+    priv_data->infos = &kdev_info;
+    
+    for (i = 0; i < KDEV_MAX_CONNECT; i++)
+    {
+      if (connected_id[i] == 0)
+      {
+        priv_data->id = i;
+        connected_id[i] = 1;
+        break;
+      }
+    }
+    
+    if (!filp->private_data)
+      filp->private_data = priv_data;
+  }
+  else
+  {
+    logkdev("kdev already opened\n");
+    return -EBUSY;
+  }
+
+  logkdev("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  return 0;   /* success */
+}
+
+
+/*
+ *
+ *  kdev_release
+ *
+ */
+int kdev_release(struct inode *inode, struct file *filp)
+{
+  kdev_data_t *priv_data;
+
+  logkdev("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  
+  priv_data = (kdev_data_t *)filp->private_data;
+  
+  connected_id[priv_data->id] = 0;
+  
+  if( kdev_info.connected ) kdev_info.connected--;
+  
+  kfree (priv_data);
+  
+  if (filp->private_data)
+    filp->private_data = NULL;
+  
+  if (!kdev_info.connected)
+    kdev_info.opened = 0;
+  
+  logkdev("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  return 0;
+}
+
+
+/*
+ *
+ *  kdev_ioctl
+ *
+ */
+long kdev_ioctl (struct file *filp, unsigned int cmd, unsigned long arg)
+{
+  int err = 0;
+  kdev_data_t *priv_data;
+  
+  logkdev("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  
+  priv_data = (kdev_data_t *)filp->private_data;
+  
+  /*
+   *  Check IOC
+   */
+  if (_IOC_TYPE(cmd) != KDEV_IOC_MAGIC) return -ENOTTY;
+  if (_IOC_NR(cmd) > KDEV_IOC_MAXNR) return -ENOTTY;
+  
+  if (_IOC_DIR(cmd) & _IOC_READ)
+    err = !access_ok(VERIFY_WRITE, (void *)arg, _IOC_SIZE(cmd));
+  else if (_IOC_DIR(cmd) & _IOC_WRITE)
+    err = !access_ok(VERIFY_READ, (void *)arg, _IOC_SIZE(cmd));
+  if (err) return -EFAULT;
+  
+  switch(cmd)
+  {
+    case KDEV_IOC_GET_ALL_DEVICES:
+      err = kdev_getDevices_ioc (&priv_data->devicesList);
+      if (!err)
+      {
+        copy_to_user( (kdev_ioc_getDevices_t __user *)arg, &priv_data->devicesList, sizeof(kdev_ioc_getDevices_t));
+      }
+      break;
+    default:
+      return -ENOTTY;
+  }
+  
+  logkdev("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  
+  if (err) return -EFAULT;
+  
+  return err;
+}
+
+
+struct file_operations kdev_fops =
+{
+  open:  kdev_open,
+  release: kdev_release,
+  unlocked_ioctl: kdev_ioctl,
+  owner: THIS_MODULE,
+};
+
+
+
+
+/***********************************************************************************************
+ *
+ *  init and exit functions
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  kdev_init
+ *
+ */
+static int __init kdev_init(void)
+{
+  int result;
+  int i;
+  
+  logkdev("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  
+  /*
+   *  Register char kdev device
+   */
+  result = register_chrdev(kdev_major, KDEV_NAME, &kdev_fops);
+  if (result < 0)
+  {
+    logkdev(KERN_WARNING "kdev: can't get major %d\n", kdev_major);
+    return result;
+  }
+  
+  if (kdev_major == 0) kdev_major = result; /* dynamic */
+  
+  logkdev("kdev device created with %i major number\n", kdev_major);
+  
+  /*
+   *  Init kdev_info
+   */
+  kdev_info.opened = 0;
+  kdev_info.connected = 0;
+  
+  for (i = 0; i < KDEV_MAX_CONNECT; i++)
+    connected_id[i] = 0;
+  
+  /*
+   *  Init kdev core
+   */
+  if (kdev_core_init ())
+    return ENOMEM;
+  
+  logkdev("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  
+  return 0;
+}
+
+
+/*
+ *
+ *  kdev_cleanup
+ *
+ */
+static void __exit kdev_cleanup(void)
+{
+  logkdev("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  
+  /*
+   *  Init kdev core
+   */
+  kdev_core_cleanup ();
+  
+  /*
+   *  Uninit kdev_info
+   */
+  
+  
+  /*
+   *  Unregister char kdev device 
+   */
+  unregister_chrdev(kdev_major, KDEV_NAME);
+  
+  logkdev("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+}
+
+module_init(kdev_init);
+module_exit(kdev_cleanup);
+
diff -Naur kernel-3.3-3.0a-ref/drivers/kdev/kdev_priv.h kernel-current/drivers/kdev/kdev_priv.h
--- kernel-3.3-3.0a-ref/drivers/kdev/kdev_priv.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kdev/kdev_priv.h	2015-06-12 16:27:19.952084065 +0200
@@ -0,0 +1,47 @@
+/*
+ *  kdev_priv.h
+ *
+ *  This file contains the implementation of the storman
+ *  interface module with the user space.
+ *
+ *  Created by Pace on 05/09/13.
+ *
+ */
+
+#ifndef KDEV_PRIV_H
+#define KDEV_PRIV_H
+
+#include <linux/kdev.h>
+
+/*#define KDEVDEBUG*/
+
+#ifdef KDEVDEBUG
+#define logkdev(...) \
+    printk("[KDEV] "__VA_ARGS__);
+#else
+#define logkdev(...)
+#endif
+
+#define KDEV_NAME "kdev"
+
+#define KDEV_MAX_CONNECT 10
+
+typedef struct
+{
+	char opened;
+	char connected;
+} kdev_info_t;
+
+typedef struct
+{
+    int id;
+    kdev_ioc_getDevices_t devicesList;
+    kdev_info_t* infos;
+} kdev_data_t;
+
+int kdev_core_init ( void );
+void kdev_core_cleanup ( void );
+int kdev_core_getDevices ( kdev_ioc_getDevices_t *devicesList );
+
+
+#endif /* KDEV_PRIV_H */
diff -Naur kernel-3.3-3.0a-ref/drivers/kdev/Makefile kernel-current/drivers/kdev/Makefile
--- kernel-3.3-3.0a-ref/drivers/kdev/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kdev/Makefile	2015-06-12 16:27:19.952084065 +0200
@@ -0,0 +1 @@
+obj-$(CONFIG_KDEV_DRIVER)		+= kdev.o kdev_driver.o
diff -Naur kernel-3.3-3.0a-ref/drivers/kextstats/Kconfig kernel-current/drivers/kextstats/Kconfig
--- kernel-3.3-3.0a-ref/drivers/kextstats/Kconfig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kextstats/Kconfig	2015-06-12 16:27:19.960088064 +0200
@@ -0,0 +1,5 @@
+ config KEXTSTATS_DRIVER
+ bool "kextstats driver"
+ help
+ activate the kextstats driver for extended statistics on network devices
+
diff -Naur kernel-3.3-3.0a-ref/drivers/kextstats/kextstats.c kernel-current/drivers/kextstats/kextstats.c
--- kernel-3.3-3.0a-ref/drivers/kextstats/kextstats.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kextstats/kextstats.c	2015-06-12 16:27:19.964090064 +0200
@@ -0,0 +1,142 @@
+/*
+ *  kextstats.c
+ *
+ *  This file contains the implementation of the extstats
+ *  core functions.
+ *
+ *  Created by Pace on 19/07/13.
+ *
+ */
+
+#include "kextstats_priv.h"
+
+#include <linux/module.h>
+#include <linux/slab.h>
+#include <linux/netdevice.h>
+
+/*#define KEXTSTATS_CORE_PRINT_DBG*/
+
+/***********************************************************************************************
+ *
+ *  static functions
+ *
+ ***********************************************************************************************/
+
+
+/***********************************************************************************************
+ *
+ *  core functions
+ *
+ ***********************************************************************************************/
+
+/*
+ * kextstats_core_init
+ */
+int kextstats_core_init (void)
+{
+  return 0;
+}
+
+/*
+ * kextstats_core_cleanup
+ */
+void kextstats_core_cleanup (void)
+{
+  return;
+}
+
+/*
+ * kextstats_core_getstats
+ */
+int kextstats_core_getstats (kextstats_ioc_getstats_t *statlist)
+{
+  struct net_device *dev;
+  struct rtnl_link_stats64 temp;
+  struct rtnl_link_stats64 *stats;
+  unsigned long long rx_unicast_packets = 0;
+  unsigned long long tx_unicast_packets = 0;
+  int ret = 0;
+
+  logkextstats("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+  statlist->stats_nb = 0;
+
+  read_lock(&dev_base_lock);
+  dev = first_net_device(&init_net);
+  while (dev)
+  {
+    statlist->stats_nb++;
+    stats = dev_get_stats(dev, &temp);
+
+    /* Calculated unicast packets */
+    /*
+      Calculate unicast packet counts as total packets less broadcast and multicast.
+      Normalize to zero in case an error sum of multicast and broadcast packets is reported
+    */
+    if ((stats->multicast + stats->rx_broadcast_packets) < stats->rx_packets)
+      rx_unicast_packets = stats->rx_packets - (stats->multicast + stats->rx_broadcast_packets);
+    else
+      rx_unicast_packets = 0;
+
+    if ((stats->tx_multicast_packets + stats->tx_broadcast_packets) < stats->tx_packets)
+      tx_unicast_packets = stats->tx_packets - (stats->tx_multicast_packets + stats->tx_broadcast_packets);
+    else
+      tx_unicast_packets = 0;
+
+    if (dev->features & NETIF_F_EXTSTATS)
+    {
+      snprintf (statlist->stats[statlist->stats_nb - 1].stat, KEXTSTATS_STR_MAXSIZE - 1, "%6s %8llu %7llu %4llu %4llu %4llu %5llu %5llu %5llu %8llu %7llu %4llu %4llu %4llu %4llu %4llu %5llu %6llu %6llu %6llu %6llu %5llu %5llu %5llu %5llu %5llu",
+	       dev->name,
+	       stats->rx_bytes,
+	       stats->rx_packets,
+	       stats->rx_errors,
+	       stats->rx_dropped + stats->rx_missed_errors,
+	       stats->rx_fifo_errors,
+	       stats->rx_length_errors + stats->rx_over_errors + stats->rx_crc_errors + stats->rx_frame_errors,
+	       stats->rx_compressed,
+	       stats->multicast,
+	       stats->tx_bytes,
+	       stats->tx_packets,
+	       stats->tx_errors,
+	       stats->tx_dropped,
+	       stats->tx_fifo_errors,
+	       stats->collisions,
+	       stats->tx_carrier_errors + stats->tx_aborted_errors + stats->tx_window_errors + stats->tx_heartbeat_errors,
+	       stats->tx_compressed,
+	       stats->rx_multicast_packets,
+	       stats->tx_multicast_packets,
+	       stats->rx_multicast_bytes,
+	       stats->tx_multicast_bytes,
+	       rx_unicast_packets,
+	       tx_unicast_packets,
+	       stats->rx_broadcast_packets,
+	       stats->tx_broadcast_packets,
+	       stats->rx_unknown_packets);
+    }
+    else
+    {
+      snprintf (statlist->stats[statlist->stats_nb - 1].stat, KEXTSTATS_STR_MAXSIZE - 1,"%6s %8llu %7llu %4llu %4llu %4llu %5llu %5llu %5llu %8llu %7llu %4llu %4llu %4llu %4llu %4llu %5llu",
+	       dev->name,
+	       stats->rx_bytes,
+	       stats->rx_packets,
+	       stats->rx_errors,
+	       stats->rx_dropped + stats->rx_missed_errors,
+	       stats->rx_fifo_errors,
+	       stats->rx_length_errors + stats->rx_over_errors + stats->rx_crc_errors + stats->rx_frame_errors,
+	       stats->rx_compressed,
+	       stats->multicast,
+	       stats->tx_bytes,
+	       stats->tx_packets,
+	       stats->tx_errors,
+	       stats->tx_dropped,
+	       stats->tx_fifo_errors,
+	       stats->collisions,
+	       stats->tx_carrier_errors + stats->tx_aborted_errors + stats->tx_window_errors + stats->tx_heartbeat_errors,
+	       stats->tx_compressed);
+    }
+    dev = next_net_device(dev);
+  }
+  read_unlock(&dev_base_lock);
+
+  return ret;
+}
diff -Naur kernel-3.3-3.0a-ref/drivers/kextstats/kextstats_driver.c kernel-current/drivers/kextstats/kextstats_driver.c
--- kernel-3.3-3.0a-ref/drivers/kextstats/kextstats_driver.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kextstats/kextstats_driver.c	2015-06-12 16:27:19.964090064 +0200
@@ -0,0 +1,300 @@
+/*
+ *  kextstats_driver.c
+ *
+ *  This file contains the implementation of the extstats
+ *  interface module with the user space.
+ *
+ *  Created by Pace on 19/07/13.
+ *
+ */
+
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/ioctl.h>
+
+#include <linux/kextstats.h>
+
+#include "kextstats_priv.h"
+
+MODULE_AUTHOR ("Pace");
+MODULE_DESCRIPTION ("kextstats interface");
+MODULE_SUPPORTED_DEVICE ("");
+MODULE_LICENSE ("GPL");
+
+
+/*
+ *
+ *  Module param
+ *
+ */
+static int kextstats_major = 0;
+module_param (kextstats_major,  int, 0644);
+MODULE_PARM_DESC (kextstats_major,  "Device major number");
+
+
+/*
+ *
+ *  Module data
+ *
+ */
+static kextstats_info_t kextstats_info;
+char extstats_connected_id[KEXTSTATS_MAX_CONNECT];
+
+/***********************************************************************************************
+ *
+ *  ioctl functions
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  kextstats_getstats_ioc
+ *
+ */
+int kextstats_getstats_ioc (kextstats_ioc_getstats_t *statlist)
+{
+  int ret;
+
+  logkextstats("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+  ret = kextstats_core_getstats (statlist);
+
+  return ret;
+}
+
+/***********************************************************************************************
+ *
+ *  Char device functions
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  kextstats_open
+ *
+ */
+int kextstats_open(struct inode *inode, struct file *filp)
+{
+  int i;
+
+  kextstats_data_t *priv_data;
+
+  logkextstats("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  logkextstats("opened = %i\n", (int) kextstats_info.opened);
+
+  if(!kextstats_info.opened) /* If first open */
+  {
+    logkextstats("opening kextstats\n");
+
+    kextstats_info.opened = 1;
+  }
+
+  if ( kextstats_info.connected < KEXTSTATS_MAX_CONNECT )
+  {
+    kextstats_info.connected++;
+
+    /* Alloc priv_data */
+    priv_data = (kextstats_data_t *) kmalloc(sizeof(kextstats_data_t), GFP_ATOMIC);
+    if ( priv_data == NULL )
+    {
+      logkextstats("kmalloc error\n");
+      return -ENOMEM;
+    }
+
+    priv_data->infos = &kextstats_info;
+
+    for (i = 0; i < KEXTSTATS_MAX_CONNECT; i++)
+    {
+      if (extstats_connected_id[i] == 0)
+      {
+	priv_data->id = i;
+	extstats_connected_id[i] = 1;
+	break;
+      }
+    }
+
+    if (!filp->private_data)
+      filp->private_data = priv_data;
+  }
+  else
+  {
+    logkextstats("kextstats already opened\n");
+    return -EBUSY;
+  }
+
+  logkextstats("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  return 0;   /* success */
+}
+
+
+/*
+ *
+ *  kextstats_release
+ *
+ */
+int kextstats_release(struct inode *inode, struct file *filp)
+{
+  kextstats_data_t *priv_data;
+
+  logkextstats("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+  priv_data = (kextstats_data_t *)filp->private_data;
+
+  extstats_connected_id[priv_data->id] = 0;
+
+  if( kextstats_info.connected ) kextstats_info.connected--;
+
+  kfree (priv_data);
+
+  if (filp->private_data)
+    filp->private_data = NULL;
+
+  if (!kextstats_info.connected)
+    kextstats_info.opened = 0;
+
+  logkextstats("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  return 0;
+}
+
+
+/*
+ *
+ *  kextstats_ioctl
+ *
+ */
+long kextstats_ioctl (struct file *filp, unsigned int cmd, unsigned long arg)
+{
+  int err = 0;
+
+  kextstats_data_t *priv_data;
+
+  logkextstats("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+  priv_data = (kextstats_data_t *)filp->private_data;
+
+  /*
+   *  Check IOC
+   */
+  if (_IOC_TYPE(cmd) != KEXTSTATS_IOC_MAGIC) return -ENOTTY;
+  if (_IOC_NR(cmd) > KEXTSTATS_IOC_MAXNR) return -ENOTTY;
+
+  if (_IOC_DIR(cmd) & _IOC_READ)
+    err = !access_ok(VERIFY_WRITE, (void *)arg, _IOC_SIZE(cmd));
+  else if (_IOC_DIR(cmd) & _IOC_WRITE)
+    err = !access_ok(VERIFY_READ, (void *)arg, _IOC_SIZE(cmd));
+  if (err) return -EFAULT;
+
+  switch(cmd)
+  {
+    case KEXTSTATS_IOC_GETSTATS:
+      err = kextstats_getstats_ioc (&priv_data->statlist);
+
+      if (!err)
+      {
+	copy_to_user( (kextstats_ioc_getstats_t __user *)arg, &priv_data->statlist, sizeof(kextstats_ioc_getstats_t));
+      }
+      break;
+    default:
+      return -ENOTTY;
+  }
+
+  logkextstats("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+  
+  if (err) return -EFAULT;
+
+  return err;
+}
+
+struct file_operations kextstats_fops = {
+  open:  kextstats_open,
+  release: kextstats_release,
+  unlocked_ioctl: kextstats_ioctl,
+  owner: THIS_MODULE,
+};
+
+
+
+
+/***********************************************************************************************
+ *
+ *  init and exit functions
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  kextstats_init
+ *
+ */
+static int __init kextstats_init(void)
+{
+  int result;
+  int i;
+
+  logkextstats("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+  /*
+   *  Register char kextstats device
+   */
+  result = register_chrdev(kextstats_major, KEXTSTATS_NAME, &kextstats_fops);
+  if (result < 0)
+  {
+    logkextstats(KERN_WARNING "kextstats: can't get major %d\n",kextstats_major);
+    return result;
+  }
+
+  if (kextstats_major == 0) kextstats_major = result; /* dynamic */
+
+  logkextstats("kextstats device created with %i major number\n", kextstats_major);
+
+  /*
+   *  Init kextstats_info
+   */
+  kextstats_info.opened = 0;
+  kextstats_info.connected = 0;
+
+  for (i = 0; i < KEXTSTATS_MAX_CONNECT; i++)
+    extstats_connected_id[i] = 0;
+
+  /*
+   *  Init kextstats core
+   */
+  if (kextstats_core_init ())
+    return ENOMEM;
+
+  logkextstats("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+  return 0;
+}
+
+
+/*
+ *
+ *  kextstats_cleanup
+ *
+ */
+static void __exit kextstats_cleanup(void)
+{
+  logkextstats("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+  /*
+   *  Init kextstats core
+   */
+  kextstats_core_cleanup ();
+
+  /*
+   *  Uninit kextstats_info
+   */
+
+
+  /*
+   *  Unregister char kextstats device
+   */
+  unregister_chrdev(kextstats_major, KEXTSTATS_NAME);
+
+  logkextstats("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+}
+
+module_init(kextstats_init);
+module_exit(kextstats_cleanup);
diff -Naur kernel-3.3-3.0a-ref/drivers/kextstats/kextstats_priv.h kernel-current/drivers/kextstats/kextstats_priv.h
--- kernel-3.3-3.0a-ref/drivers/kextstats/kextstats_priv.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kextstats/kextstats_priv.h	2015-06-12 16:27:19.964090064 +0200
@@ -0,0 +1,47 @@
+/*
+ *  kextstats_priv.h
+ *
+ *  This file contains the implementation of the extstats
+ *  interface module with the user space.
+ *
+ *  Created by Pace on 19/07/13.
+ *
+ */
+
+#ifndef KEXTSTATS_PRIV_H
+#define KEXTSTATS_PRIV_H
+
+#include <linux/kextstats.h>
+
+//#define KEXTSTATSDEBUG
+
+#ifdef KEXTSTATSDEBUG
+#define logkextstats(...)			\
+  printk("[KEXTSTATS] "__VA_ARGS__);
+#else
+#define logkextstats(...)
+#endif
+
+#define KEXTSTATS_NAME "kextstats"
+
+#define KEXTSTATS_MAX_CONNECT 1
+
+typedef struct
+{
+  char opened;
+  char connected;
+} kextstats_info_t;
+
+typedef struct
+{
+  int id;
+  kextstats_ioc_getstats_t statlist;
+  kextstats_info_t* infos;
+} kextstats_data_t;
+
+int kextstats_core_init (void);
+void kextstats_core_cleanup (void);
+int kextstats_core_getstats (kextstats_ioc_getstats_t *statlist);
+
+
+#endif /* KEXTSTATS_PRIV_H */
diff -Naur kernel-3.3-3.0a-ref/drivers/kextstats/Makefile kernel-current/drivers/kextstats/Makefile
--- kernel-3.3-3.0a-ref/drivers/kextstats/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kextstats/Makefile	2015-06-12 16:27:19.964090064 +0200
@@ -0,0 +1 @@
+obj-$(CONFIG_KEXTSTATS_DRIVER)		+= kextstats.o kextstats_driver.o
diff -Naur kernel-3.3-3.0a-ref/drivers/kstorman/Kconfig kernel-current/drivers/kstorman/Kconfig
--- kernel-3.3-3.0a-ref/drivers/kstorman/Kconfig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kstorman/Kconfig	2015-06-12 16:27:19.944080065 +0200
@@ -0,0 +1,6 @@
+ config KSTORMAN_DRIVER
+ bool "kstorman driver"
+     depends on BLK_DEV_DM
+ help
+ activate the kstorman driver for device infos
+
diff -Naur kernel-3.3-3.0a-ref/drivers/kstorman/kstorman.c kernel-current/drivers/kstorman/kstorman.c
--- kernel-3.3-3.0a-ref/drivers/kstorman/kstorman.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kstorman/kstorman.c	2015-06-12 16:27:19.944080065 +0200
@@ -0,0 +1,475 @@
+/*
+ *  kstorman.c
+ *
+ *  This file contains the implementation of the storman 
+ *  core functions.
+ *
+ *  Created by Pace on 19/07/13.
+ *
+ */
+ 
+#include "kstorman_priv.h"
+
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/genhd.h>
+#include <linux/kdev_t.h>
+#include <linux/kernel.h>
+#include <linux/blkdev.h>
+#include <linux/init.h>
+#include <linux/spinlock.h>
+#include <linux/proc_fs.h>
+#include <linux/seq_file.h>
+#include <linux/slab.h>
+#include <linux/kmod.h>
+#include <linux/kobj_map.h>
+#include <linux/mutex.h>
+#include <linux/idr.h>
+#include <linux/log2.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mount.h>
+#include <linux/mnt_namespace.h>
+#include <linux/sched.h>
+#include <linux/nsproxy.h>
+#include <linux/security.h>
+#include <linux/fs_struct.h>
+#include <linux/device-mapper.h>
+#include <linux/libata.h>
+#include <linux/dm-ioctl.h>
+#include <scsi/scsi_device.h>
+#include <scsi/scsi_host.h>
+#include "../../fs/mount.h"
+#include "../usb/storage/usb.h"
+#include "../md/dm.h"
+
+/*#define KSTORMAN_CORE_PRINT_DBG*/
+
+/***********************************************************************************************
+ *
+ *  static functions
+ *
+ ***********************************************************************************************/
+ 
+/*
+ * Copied from fs/namespace.c
+ */
+static struct mount *next_mnt(struct mount *p, struct mount *root)
+{
+    struct list_head *next = p->mnt_mounts.next;
+    if (next == &p->mnt_mounts) {
+        while (1) {
+            if (p == root)
+                return NULL;
+            next = p->mnt_child.next;
+            if (next != &p->mnt_parent->mnt_mounts)
+                break;
+            p = p->mnt_parent;
+        }
+    }
+    return list_entry(next, struct mount, mnt_child);
+}
+
+
+static int set_mount_infos ( kstorman_ioc_getmounts_t *mountlist, struct mount *s )
+{
+    struct path mnt_path = { .dentry = s->mnt.mnt_root, .mnt = &s->mnt };
+    char *pathname;
+    char *tmp;
+    
+    if ((mountlist->mounts_nb + 1) == KSTORMAN_MOUNTLIST_MAXSIZE)
+        return 1;
+    
+    tmp = (char *)__get_free_page(GFP_TEMPORARY);
+
+    if (!tmp) {
+        return -ENOMEM;
+    }
+
+    pathname = d_path(&mnt_path, tmp, PAGE_SIZE);
+
+    if (IS_ERR(pathname)) {
+        free_page((unsigned long)tmp);
+        return PTR_ERR(pathname);
+    }
+
+    /* 
+     * fill mount list
+     */
+    strncpy (mountlist->mounts[mountlist->mounts_nb].device, s->mnt_devname, KSTORMAN_STR_MAXSIZE);
+    strncpy (mountlist->mounts[mountlist->mounts_nb].dir, pathname, KSTORMAN_STR_MAXSIZE);
+    strncpy (mountlist->mounts[mountlist->mounts_nb].type, s->mnt.mnt_sb->s_type->name, KSTORMAN_STR_MAXSIZE);
+    mountlist->mounts[mountlist->mounts_nb].flags = s->mnt.mnt_flags;
+    
+    
+    /* 
+     * Print for debug
+     */
+#ifdef KSTORMAN_CORE_PRINT_DBG
+    printk ("%s on %s", mountlist->mounts[mountlist->mounts_nb].device, mountlist->mounts[mountlist->mounts_nb].dir);
+    
+    printk (" type %s", mountlist->mounts[mountlist->mounts_nb].type);
+    
+    printk (mountlist->mounts[mountlist->mounts_nb].flags & MNT_READONLY ? " (ro" : " (rw");
+    if (mountlist->mounts[mountlist->mounts_nb].flags & MNT_NOSUID) printk (",nosuid");
+    if (mountlist->mounts[mountlist->mounts_nb].flags & MNT_NODEV) printk (",nodev");
+    if (mountlist->mounts[mountlist->mounts_nb].flags & MNT_NOEXEC) printk (",noexec");
+    if (mountlist->mounts[mountlist->mounts_nb].flags & MNT_NOATIME) printk (",noatime");
+    if (mountlist->mounts[mountlist->mounts_nb].flags & MNT_NODIRATIME) printk (",nodiratime");
+    if (mountlist->mounts[mountlist->mounts_nb].flags & MNT_RELATIME) printk (",relatime");
+
+    printk (")\n");
+#endif
+
+    free_page((unsigned long)tmp);
+    
+    mountlist->mounts_nb++;
+    
+    return 0;
+}
+
+
+static struct ata_device *ata_find_dev(struct ata_port *ap, int devno)
+{
+    if (!sata_pmp_attached(ap)) {
+        if (likely(devno < ata_link_max_devices(&ap->link)))
+            return &ap->link.device[devno];
+    } else {
+        if (likely(devno < ap->nr_pmp_links))
+            return &ap->pmp_link[devno].device[0];
+    }
+
+    return NULL;
+}
+
+static struct ata_device *__ata_scsi_find_dev(struct ata_port *ap,
+                          const struct scsi_device *scsidev)
+{
+    int devno;
+
+    /* skip commands not addressed to targets we simulate */
+    if (!sata_pmp_attached(ap)) {
+        if (unlikely(scsidev->channel || scsidev->lun))
+            return NULL;
+        devno = scsidev->id;
+    } else {
+        if (unlikely(scsidev->id || scsidev->lun))
+            return NULL;
+        devno = scsidev->channel;
+    }
+
+    return ata_find_dev(ap, devno);
+}
+
+/**
+ *	ata_scsi_find_dev - lookup ata_device from scsi_cmnd
+ *	@ap: ATA port to which the device is attached
+ *	@scsidev: SCSI device from which we derive the ATA device
+ *
+ *	Given various information provided in struct scsi_cmnd,
+ *	map that onto an ATA bus, and using that mapping
+ *	determine which ata_device is associated with the
+ *	SCSI command to be sent.
+ *
+ *	LOCKING:
+ *	spin_lock_irqsave(host lock)
+ *
+ *	RETURNS:
+ *	Associated ATA device, or %NULL if not found.
+ */
+static struct ata_device *
+ata_scsi_find_dev(struct ata_port *ap, const struct scsi_device *scsidev)
+{
+    struct ata_device *dev = __ata_scsi_find_dev(ap, scsidev);
+
+    if (unlikely(!dev || !ata_dev_enabled(dev)))
+        return NULL;
+
+    return dev;
+}
+
+static int set_block_infos ( kstorman_ioc_getblocks_t *blocklist, struct gendisk *disk )
+{
+    struct mapped_device *mp;
+    struct dm_table *map;
+    struct dm_dev_internal *dd;
+    struct device *device = disk_to_dev (disk);
+    struct device *dev = NULL;
+    struct scsi_device *scsi_dev = NULL;
+    struct Scsi_Host *scsi_host = NULL;
+    struct scsi_target *scsi_targ = NULL;
+    struct ata_port *ap;
+    struct ata_device *atadev;
+    struct us_data *usb_data;
+    struct list_head *devices;
+    
+    if ((blocklist->blkdevs_nb + 1) == KSTORMAN_BLKDEVLIST_MAXSIZE)
+        return 1;
+
+    strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].name, disk->disk_name, KSTORMAN_STR_MAXSIZE);
+    blocklist->blkdevs[blocklist->blkdevs_nb].major = disk->major;
+    blocklist->blkdevs[blocklist->blkdevs_nb].minor = disk->first_minor;
+
+    strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].bus, "unknown", KSTORMAN_STR_MAXSIZE);
+    strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].type, "unknown", KSTORMAN_STR_MAXSIZE);
+
+    
+    if ( disk->driverfs_dev != NULL && disk->driverfs_dev->type != NULL
+         && ( !strcmp (disk->driverfs_dev->type->name, "scsi_device")
+            || !strcmp (disk->driverfs_dev->type->name, "mtd")))
+    {
+        if (device)
+        {
+            dev = device;
+
+            while (dev != NULL)
+            {
+                if (dev->type)
+                {
+                    if (!strcmp(dev->type->name, "scsi_device"))
+                    {
+                        scsi_dev = to_scsi_device (dev);
+                        if (scsi_dev)
+                        {
+                            scsi_host = scsi_dev->host;
+                            scsi_targ = scsi_dev->sdev_target;
+
+                            if (!strcmp(scsi_host->hostt->name, "ahci_platform"))
+                            {
+                                ap = ata_shost_to_port(scsi_dev->host);
+                                if (ap)
+                                {
+                                    atadev = ata_scsi_find_dev(ap, scsi_dev);
+                                    if (atadev)
+                                    {
+                                        snprintf (  blocklist->blkdevs[blocklist->blkdevs_nb].bus, KSTORMAN_STR_MAXSIZE, 
+                                                    "ata%u.%02u", atadev->link->ap->print_id, atadev->link->pmp + atadev->devno);
+                                        strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].type, "ata", KSTORMAN_STR_MAXSIZE);
+                                    }
+                                }
+                            }   
+                            else if (!strcmp(scsi_host->hostt->name, "usb-storage"))
+                            {
+                                usb_data = (struct us_data *) scsi_host->hostdata;
+
+                                snprintf (  blocklist->blkdevs[blocklist->blkdevs_nb].bus, KSTORMAN_STR_MAXSIZE, 
+                                            "%s %s", dev_driver_string (&(usb_data->pusb_dev->dev)), 
+                                                     dev_name(&(usb_data->pusb_dev->dev)));
+                                strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].type, "usb", KSTORMAN_STR_MAXSIZE);
+                                
+                            }
+                        }
+                        break;
+                    }
+                    else if (!strcmp(dev->type->name, "mtd"))
+                    {
+                        strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].bus, "mtd", KSTORMAN_STR_MAXSIZE);
+                        strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].type, "mtd", KSTORMAN_STR_MAXSIZE);
+                        break;
+                    }
+                }
+                
+                dev = dev->parent;
+            }
+        }
+    }
+    else
+    {
+        mp = dm_get_md(disk_to_dev(disk)->devt);
+        
+        if (mp)
+        {
+            strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].bus, "dev-mapper", KSTORMAN_STR_MAXSIZE);
+            strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].type, "dev-mapper", KSTORMAN_STR_MAXSIZE);
+
+            map = dm_get_live_table(mp);
+            
+            if (map) {
+                struct list_head *tmp, *next;
+                devices = dm_table_get_devices(map);
+
+                list_for_each_safe(tmp, next, devices) {
+                    dd = list_entry(tmp, struct dm_dev_internal, list);
+                    strncpy (blocklist->blkdevs[blocklist->blkdevs_nb].mapped_to, dd->dm_dev.name, KSTORMAN_STR_MAXSIZE);
+                }
+
+                dm_table_put(map);
+            }
+
+            dm_put (mp);
+        }
+    }
+    
+    
+    /* 
+     * Print for debug
+     */
+#ifdef KSTORMAN_CORE_PRINT_DBG
+    printk ("disk_name=%s\n", blocklist->blkdevs[blocklist->blkdevs_nb].name);
+    printk ("major=%i\n", blocklist->blkdevs[blocklist->blkdevs_nb].major);
+    printk ("first minor=%i\n", blocklist->blkdevs[blocklist->blkdevs_nb].minor);
+    printk ("type=%s\n", blocklist->blkdevs[blocklist->blkdevs_nb].type);
+    printk ("bus=%s\n", blocklist->blkdevs[blocklist->blkdevs_nb].bus);
+#endif
+    
+    blocklist->blkdevs_nb++;
+    
+    return 0;
+}
+
+/***********************************************************************************************
+ *
+ *  core functions
+ *
+ ***********************************************************************************************/
+
+/*
+ * kstorman_core_init
+ */
+int kstorman_core_init ( void )
+{        
+    return 0;
+}
+
+/*
+ * kstorman_core_cleanup
+ */
+void kstorman_core_cleanup ( void )
+{
+    return;
+}
+
+/*
+ * kstorman_core_getmounts
+ */
+int kstorman_core_getmounts ( kstorman_ioc_getmounts_t *mountlist )
+{
+    struct nsproxy *nsproxy;
+    struct mnt_namespace *namespace = NULL;
+    struct mount *r = NULL;
+    int ret = 0;
+        
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    memset (mountlist, 0, sizeof (kstorman_ioc_getmounts_t));
+    mountlist->mounts_nb = 0;
+    
+    rcu_read_lock();
+    nsproxy = task_nsproxy(current);
+    if (nsproxy != NULL) {
+
+        namespace = rcu_dereference(nsproxy->mnt_ns);
+         get_mnt_ns(namespace);
+
+    }
+
+    rcu_read_unlock();
+
+    if (namespace != NULL)
+    {
+        if ((ret = set_mount_infos (mountlist, namespace->root)))
+        {
+            put_mnt_ns(namespace);
+            return ret;
+        }
+
+        list_for_each_entry(r, &namespace->root->mnt_mounts, mnt_child)
+        {
+            struct mount *s;
+
+            for (s = r; s; s = next_mnt(s, r)) {
+                if (s != NULL)
+                {
+                    if ((ret = set_mount_infos (mountlist, s)))
+                    {
+                        put_mnt_ns(namespace);
+                        return ret;
+                    }
+                }
+            }
+        }
+        
+    }
+    else
+        ret = 1;
+
+    put_mnt_ns(namespace);
+    return ret;
+}
+
+/*src/Broadcom/kernel/kernel-current/Documentation/RCU/lockdep.txt
+ * kstorman_core_getblocks
+ */
+int kstorman_core_getblocks ( kstorman_ioc_getblocks_t *blocklist )
+{
+    struct class_dev_iter iter;
+    struct device *dev;
+    int ret = 0;
+    
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    
+    blocklist->blkdevs_nb = 0;
+    
+    class_dev_iter_init(&iter, &block_class, NULL, NULL);
+    while ((dev = class_dev_iter_next(&iter))) {
+        
+        struct gendisk *disk;
+        
+        if (strcmp(dev->type->name, "disk"))
+            continue;
+            
+        disk = dev_to_disk(dev);
+
+        if (get_capacity(disk) == 0 ||
+            (disk->flags & GENHD_FL_SUPPRESS_PARTITION_INFO))
+            continue;
+            
+        if ( (ret = set_block_infos ( blocklist, disk ))) break;
+
+    }
+    class_dev_iter_exit(&iter);
+    
+    return ret;
+}
+
+
+/*
+ * kstorman_core_getmmtd
+ */
+int kstorman_core_getmtd ( kstorman_ioc_getmtd_t *mtdlist )
+{
+    struct mtd_info *mtd_info = NULL;
+    int num;
+    
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    
+    mtdlist->mtd_nb = 0;
+    
+    for(num = 0; num < 64; num++) {
+        if ((mtdlist->mtd_nb + 1) == KSTORMAN_MTDLIST_MAXSIZE)
+            return 1;
+    
+        mtd_info = get_mtd_device(NULL, num);
+        if(IS_ERR(mtd_info)) {
+            continue;
+        }
+        
+        strncpy (mtdlist->mtd[mtdlist->mtd_nb].name, mtd_info->name, KSTORMAN_STR_MAXSIZE);
+        mtdlist->mtd[mtdlist->mtd_nb].index = mtd_info->index;
+        mtdlist->mtd[mtdlist->mtd_nb].type = mtd_info->type;
+
+        /* 
+         * Print for debug
+         */
+#ifdef KSTORMAN_CORE_PRINT_DBG
+        printk("MTD name: %s\n", mtdlist->mtd[mtdlist->mtd_nb].name);
+        printk("MTD index: mtd%i\n", mtdlist->mtd[mtdlist->mtd_nb].index);
+        printk("MTD type: %u\n", mtdlist->mtd[mtdlist->mtd_nb].type);
+#endif
+        
+        mtdlist->mtd_nb++;
+    }
+    
+    logkstorman("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    
+    return 0;
+}
+
diff -Naur kernel-3.3-3.0a-ref/drivers/kstorman/kstorman_driver.c kernel-current/drivers/kstorman/kstorman_driver.c
--- kernel-3.3-3.0a-ref/drivers/kstorman/kstorman_driver.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kstorman/kstorman_driver.c	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1,359 @@
+/*
+ *  kstorman_driver.c
+ *
+ *  This file contains the implementation of the storman 
+ *  interface module with the user space.  
+ *
+ *  Created by Pace on 19/07/13.
+ *
+ */
+
+#include <linux/slab.h>
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/ioctl.h>
+#include <linux/wait.h>
+#include <linux/sched.h>
+#include <linux/poll.h>
+#include <linux/spinlock.h>
+#include <asm/uaccess.h>
+
+#include <linux/kstorman.h>
+
+#include "kstorman_priv.h"
+
+MODULE_AUTHOR ("Pace");
+MODULE_DESCRIPTION ("kstorman interface");
+MODULE_SUPPORTED_DEVICE ("");
+MODULE_LICENSE ("GPL");
+
+
+/*
+ * 
+ *  Module param
+ *
+ */
+static int kstorman_major = 0;
+
+module_param (kstorman_major,  int, 0644);
+MODULE_PARM_DESC (kstorman_major,  "Device major number");
+
+
+/*
+ * 
+ *  Module data
+ *
+ */
+static kstorman_info_t kstorman_info;
+char connected_id[KSTORMAN_MAX_CONNECT];
+
+/***********************************************************************************************
+ *
+ *  ioctl functions
+ *
+ ***********************************************************************************************/
+
+/*
+ * 
+ *  kstorman_getmounts_ioc
+ *
+ */
+int kstorman_getmounts_ioc (kstorman_ioc_getmounts_t *mountlist)
+{
+    int ret;
+
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+    ret = kstorman_core_getmounts (mountlist);
+
+    return ret;
+}
+
+
+/*
+ * 
+ *  kstorman_getblocks_ioc
+ *
+ */
+int kstorman_getblocks_ioc (kstorman_ioc_getblocks_t *blocklist)
+{
+    int ret;
+
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+    ret = kstorman_core_getblocks (blocklist);
+
+    return ret;
+}
+
+/*
+ * 
+ *  kstorman_getmtd_ioc
+ *
+ */
+int kstorman_getmtd_ioc (kstorman_ioc_getmtd_t *mtdlist)
+{
+    int ret;
+
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+    ret = kstorman_core_getmtd(mtdlist);
+
+    return ret;
+}
+
+
+
+
+/***********************************************************************************************
+ *
+ *  Char device functions
+ *
+ ***********************************************************************************************/
+
+/*
+ * 
+ *  kstorman_open
+ *
+ */
+int kstorman_open(struct inode *inode, struct file *filp)
+{
+    int i;
+    
+    kstorman_data_t *priv_data;
+    
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    logkstorman("opened = %i\n", (int) kstorman_info.opened);
+
+    if(!kstorman_info.opened) /* If first open */
+    {
+        logkstorman("opening kstorman\n");
+
+        kstorman_info.opened = 1;
+    }
+
+    if ( kstorman_info.connected < KSTORMAN_MAX_CONNECT )
+    {
+        kstorman_info.connected++;
+        
+        /* Alloc priv_data */
+        priv_data = (kstorman_data_t *) kmalloc(sizeof(kstorman_data_t), GFP_ATOMIC);
+        if ( priv_data == NULL )
+        {
+            logkstorman("kmalloc error\n");
+            return -ENOMEM;
+        }
+        
+        priv_data->infos = &kstorman_info;
+        
+        for (i = 0; i < KSTORMAN_MAX_CONNECT; i++)
+        {
+            if (connected_id[i] == 0)
+            {
+                priv_data->id = i;
+                connected_id[i] = 1;
+                break;
+            }
+        }
+        
+        if (!filp->private_data)
+            filp->private_data = priv_data;
+    }
+    else
+    {
+        logkstorman("kstorman already opened\n");
+        return -EBUSY;
+    }
+
+    logkstorman("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    return 0;   /* success */
+}
+
+
+/*
+ * 
+ *  kstorman_release
+ *
+ */
+int kstorman_release(struct inode *inode, struct file *filp)
+{
+    kstorman_data_t *priv_data;
+
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    
+    priv_data = (kstorman_data_t *)filp->private_data;
+    
+    connected_id[priv_data->id] = 0;
+
+    if( kstorman_info.connected ) kstorman_info.connected--;
+    
+    kfree (priv_data);
+    
+    if (filp->private_data)
+        filp->private_data = NULL;
+        
+    if (!kstorman_info.connected)
+        kstorman_info.opened = 0;
+
+    logkstorman("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    return 0;
+}
+
+
+/*
+ * 
+ *  kstorman_ioctl
+ *
+ */
+long kstorman_ioctl (struct file *filp, unsigned int cmd, unsigned long arg)
+{
+    int err = 0;
+
+    kstorman_data_t *priv_data;
+
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    
+    priv_data = (kstorman_data_t *)filp->private_data;
+
+    /*
+     *  Check IOC
+     */
+    if (_IOC_TYPE(cmd) != KSTORMAN_IOC_MAGIC) return -ENOTTY;
+    if (_IOC_NR(cmd) > KSTORMAN_IOC_MAXNR) return -ENOTTY;
+
+    if (_IOC_DIR(cmd) & _IOC_READ)
+        err = !access_ok(VERIFY_WRITE, (void *)arg, _IOC_SIZE(cmd));
+    else if (_IOC_DIR(cmd) & _IOC_WRITE)
+        err = !access_ok(VERIFY_READ, (void *)arg, _IOC_SIZE(cmd));
+    if (err) return -EFAULT;
+
+    switch(cmd)
+    {
+        case KSTORMAN_IOC_GETMOUNTS:
+            err = kstorman_getmounts_ioc (&priv_data->mountlist);
+            
+            if (!err)
+            {
+                copy_to_user( (kstorman_ioc_getmounts_t __user *)arg, &priv_data->mountlist, sizeof(kstorman_ioc_getmounts_t));
+            }
+            break;
+        case KSTORMAN_IOC_GETBLOCKS:
+            err = kstorman_getblocks_ioc (&priv_data->blocklist);
+            
+            if (!err)
+            {
+                copy_to_user( (kstorman_ioc_getblocks_t __user *)arg, &priv_data->blocklist, sizeof(kstorman_ioc_getblocks_t));
+            }
+            break;
+        case KSTORMAN_IOC_GETMTD:
+            err = kstorman_getmtd_ioc (&priv_data->mtdlist);
+            
+            if (!err)
+            {
+                copy_to_user( (kstorman_ioc_getmtd_t __user *)arg, &priv_data->mtdlist, sizeof(kstorman_ioc_getmtd_t));
+            }
+            break;
+        default:
+            return -ENOTTY;
+    }
+    
+    logkstorman("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    
+    if (err) return -EFAULT;
+
+    return err;
+}
+
+struct file_operations kstorman_fops = {
+    open:  kstorman_open,
+    release: kstorman_release,
+    unlocked_ioctl: kstorman_ioctl,
+    owner: THIS_MODULE,
+};
+
+
+
+
+/***********************************************************************************************
+ *
+ *  init and exit functions
+ *
+ ***********************************************************************************************/
+
+/*
+ * 
+ *  kstorman_init
+ *
+ */
+static int __init kstorman_init(void)
+{
+    int result;
+    int i;
+
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    
+    /*
+     *  Register char kstorman device 
+     */
+    result = register_chrdev(kstorman_major, KSTORMAN_NAME, &kstorman_fops);
+    if (result < 0) 
+    {
+        logkstorman(KERN_WARNING "kstorman: can't get major %d\n",kstorman_major);
+        return result;
+    }
+
+    if (kstorman_major == 0) kstorman_major = result; /* dynamic */
+
+    logkstorman("kstorman device created with %i major number\n", kstorman_major);
+
+    /*
+     *  Init kstorman_info
+     */
+    kstorman_info.opened = 0;
+    kstorman_info.connected = 0;
+    
+    for (i = 0; i < KSTORMAN_MAX_CONNECT; i++)
+        connected_id[i] = 0;
+        
+    /*
+     *  Init kstorman core
+     */
+    if (kstorman_core_init ())
+        return ENOMEM;
+
+    logkstorman("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+
+    return 0;
+}
+
+
+/*
+ * 
+ *  kstorman_cleanup
+ *
+ */
+static void __exit kstorman_cleanup(void)
+{
+    logkstorman("enter %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+    
+    /*
+     *  Init kstorman core
+     */
+     kstorman_core_cleanup ();
+
+    /*
+     *  Uninit kstorman_info
+     */
+
+
+    /*
+     *  Unregister char kstorman device 
+     */
+    unregister_chrdev(kstorman_major, KSTORMAN_NAME);
+
+    logkstorman("exit %s  [%s:%d]\n", __FUNCTION__, __FILE__, __LINE__);
+}
+
+module_init(kstorman_init);
+module_exit(kstorman_cleanup);
+
diff -Naur kernel-3.3-3.0a-ref/drivers/kstorman/kstorman_priv.h kernel-current/drivers/kstorman/kstorman_priv.h
--- kernel-3.3-3.0a-ref/drivers/kstorman/kstorman_priv.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kstorman/kstorman_priv.h	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1,51 @@
+/*
+ *  kstorman_priv.h
+ *
+ *  This file contains the implementation of the storman 
+ *  interface module with the user space.  
+ *
+ *  Created by Pace on 19/07/13.
+ *
+ */
+
+#ifndef KSTORMAN_PRIV_H
+#define KSTORMAN_PRIV_H
+
+#include <linux/kstorman.h>
+
+/*#define KSTORMANDEBUG*/
+
+#ifdef KSTORMANDEBUG
+#define logkstorman(...) \
+        printk("[KSTORMAN] "__VA_ARGS__);
+#else
+#define logkstorman(...)
+#endif
+
+#define KSTORMAN_NAME "kstorman"
+
+#define KSTORMAN_MAX_CONNECT 10
+
+typedef struct
+{
+    char opened;
+    char connected;
+} kstorman_info_t;
+
+typedef struct
+{
+    int id;
+    kstorman_ioc_getmounts_t mountlist;
+    kstorman_ioc_getblocks_t blocklist;
+    kstorman_ioc_getmtd_t mtdlist;
+    kstorman_info_t* infos;
+} kstorman_data_t;
+
+int kstorman_core_init ( void );
+void kstorman_core_cleanup ( void );
+int kstorman_core_getmounts ( kstorman_ioc_getmounts_t *mountlist );
+int kstorman_core_getblocks ( kstorman_ioc_getblocks_t *blocklist );
+int kstorman_core_getmtd ( kstorman_ioc_getmtd_t *mtdlist );
+
+
+#endif /* KSTORMAN_PRIV_H */
diff -Naur kernel-3.3-3.0a-ref/drivers/kstorman/Makefile kernel-current/drivers/kstorman/Makefile
--- kernel-3.3-3.0a-ref/drivers/kstorman/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/kstorman/Makefile	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1 @@
+obj-$(CONFIG_KSTORMAN_DRIVER)		+= kstorman.o kstorman_driver.o
diff -Naur kernel-3.3-3.0a-ref/drivers/Makefile kernel-current/drivers/Makefile
--- kernel-3.3-3.0a-ref/drivers/Makefile	2013-08-28 01:30:58.000000000 +0200
+++ kernel-current/drivers/Makefile	2015-06-12 16:27:19.960088064 +0200
@@ -9,6 +9,10 @@
 # GPIO must come after pinctrl as gpios may need to mux pins etc
 obj-y				+= pinctrl/
 obj-y				+= gpio/
++obj-$(CONFIG_GENID_DRIVER)	+= genid/
+obj-$(CONFIG_KDEV_DRIVER)	+= kdev/
+obj-$(CONFIG_KSTORMAN_DRIVER)	+= kstorman/
+obj-$(CONFIG_KEXTSTATS_DRIVER)	+= kextstats/
 obj-$(CONFIG_PCI)		+= pci/
 obj-$(CONFIG_PARISC)		+= parisc/
 obj-$(CONFIG_RAPIDIO)		+= rapidio/
@@ -127,6 +131,7 @@
 obj-$(CONFIG_HWSPINLOCK)	+= hwspinlock/
 obj-$(CONFIG_NFC)		+= nfc/
 obj-$(CONFIG_IOMMU_SUPPORT)	+= iommu/
+obj-$(CONFIG_SYSINFO_SUPPORT)   += sysinfo/
 
 # Virtualization drivers
 obj-$(CONFIG_VIRT_DRIVERS)	+= virt/
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/devices/m25p80.c kernel-current/drivers/mtd/devices/m25p80.c
--- kernel-3.3-3.0a-ref/drivers/mtd/devices/m25p80.c	2013-08-28 01:30:59.000000000 +0200
+++ kernel-current/drivers/mtd/devices/m25p80.c	2015-06-12 16:27:19.916066066 +0200
@@ -644,6 +644,14 @@
 	{ "320s33b",  INFO(0x898912, 0, 64 * 1024,  64, 0) },
 	{ "640s33b",  INFO(0x898913, 0, 64 * 1024, 128, 0) },
 
+	/* Pace change start */
+	{ "MX25L3255D",  INFO(0xc29e16, 0, 64 * 1024,  64, 0) },
+	/* Pace change end */
+
+	/* Pace change start */
+	{ "MX25L3255E",  INFO(0xc29e16, 0, 64 * 1024,  64, 0) },
+	/* Pace change end */
+
 	/* Macronix */
 	{ "mx25l4005a",  INFO(0xc22013, 0, 64 * 1024,   8, SECT_4K) },
 	{ "mx25l8005",   INFO(0xc22014, 0, 64 * 1024,  16, 0) },
@@ -658,6 +666,7 @@
 	/* Spansion -- single (large) sector size only, at least
 	 * for the chips listed here (without boot sectors).
 	 */
+	{ "s25fl132k",  INFO(0x014016, 0, 64 * 1024,  64, 0) },	
 	{ "s25sl004a",  INFO(0x010212,      0,  64 * 1024,   8, 0) },
 	{ "s25sl008a",  INFO(0x010213,      0,  64 * 1024,  16, 0) },
 	{ "s25sl016a",  INFO(0x010214,      0,  64 * 1024,  32, 0) },
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/Kconfig kernel-current/drivers/mtd/Kconfig
--- kernel-3.3-3.0a-ref/drivers/mtd/Kconfig	2013-08-28 01:30:59.000000000 +0200
+++ kernel-current/drivers/mtd/Kconfig	2015-06-12 16:27:19.920068066 +0200
@@ -322,6 +322,8 @@
 
 source "drivers/mtd/nand/Kconfig"
 
+source "drivers/mtd/pacenand/Kconfig"
+
 source "drivers/mtd/onenand/Kconfig"
 
 source "drivers/mtd/lpddr/Kconfig"
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/Makefile kernel-current/drivers/mtd/Makefile
--- kernel-3.3-3.0a-ref/drivers/mtd/Makefile	2013-08-28 01:30:59.000000000 +0200
+++ kernel-current/drivers/mtd/Makefile	2015-06-12 16:27:19.920068066 +0200
@@ -33,3 +33,5 @@
 obj-y		+= chips/ lpddr/ maps/ devices/ nand/ onenand/ tests/
 
 obj-$(CONFIG_MTD_UBI)		+= ubi/
+
+obj-$(CONFIG_MTD_PACENAND)		+= pacenand/
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/mtdpart.c kernel-current/drivers/mtd/mtdpart.c
--- kernel-3.3-3.0a-ref/drivers/mtd/mtdpart.c	2013-08-28 01:30:59.000000000 +0200
+++ kernel-current/drivers/mtd/mtdpart.c	2015-06-12 16:27:20.016116063 +0200
@@ -72,6 +72,9 @@
 		if (mtd_is_eccerr(res))
 			mtd->ecc_stats.failed += part->master->ecc_stats.failed - stats.failed;
 	}
+	mtd->ecc_stats.writtenpages = part->master->ecc_stats.writtenpages;
+	mtd->ecc_stats.erasedblocks = part->master->ecc_stats.erasedblocks;
+	mtd->ecc_stats.writtenblocks = part->master->ecc_stats.writtenblocks;
 	return res;
 }
 
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/pacenand/Kconfig kernel-current/drivers/mtd/pacenand/Kconfig
--- kernel-3.3-3.0a-ref/drivers/mtd/pacenand/Kconfig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/mtd/pacenand/Kconfig	2015-06-12 16:27:19.920068066 +0200
@@ -0,0 +1,51 @@
+#
+# linux/drivers/mtd/pacenand/Kconfig
+#
+
+config MTD_PACENAND
+        tristate "Pace NAND device support using Broadcom NAND controller"
+        default n
+        depends on MTD && MTD_BRCMNAND = n
+        select BRCM_SKIP_CHECK_BOOTROM
+        select LONG_LONG_SUPPORT
+        ---help---
+          This enables support for accessing selected types of NAND flash
+          devices through the Broadcom NAND controller using the Pace driver
+
+config MTD_PACENAND_VERIFY_WRITE
+        bool "Verify Pace NAND page writes"
+        default y
+        depends on MTD_PACENAND
+        ---help---
+          This adds an extra check when data is written to the flash. The
+          Broadcom NAND flash device internally checks only bits transitioning
+          from 1 to 0. There is a rare possibility that even though the
+          device thinks the write was successful, a bit could have been
+          flipped accidentaly due to device wear or something else.
+
+config PACE_SYSTEM_IS_NAND_ONLY
+	bool "Select System as Nand Only"
+        default n
+        depends on MTD_PACENAND
+        ---help---
+          Turn this flag on for nand only solution.
+
+config PACE_NAND_FORCE_HAMMING_FOR_LEGACY_CHIP
+	bool "Force Legacy 1-bit chip to use Hamming ECC"
+        default n
+        depends on MTD_PACENAND
+        ---help---
+          Force Legacy 1-bit chip to use Hamming ECC for NOR+NAND solution.
+
+config MTD_PACENAND_DEBUG
+   bool "Turn on Pace NAND driver debug"
+   default n
+   depends on MTD_PACENAND
+   ---help---
+      Turn this flag on to enable extra debug output from the Pace NAND driver.
+
+
+      
+
+      
+   
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/pacenand/Makefile kernel-current/drivers/mtd/pacenand/Makefile
--- kernel-3.3-3.0a-ref/drivers/mtd/pacenand/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/mtd/pacenand/Makefile	2015-06-12 16:27:19.920068066 +0200
@@ -0,0 +1,7 @@
+#
+# Makefile for the Pace NAND MTD
+#
+#-include include/config/auto.conf
+
+obj-$(CONFIG_MTD_PACENAND)		+=  pacenand.o
+pacenand-objs = pacenand_base.o nand_dev_new_73xx.o
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/pacenand/nand_dev_new_73xx.c kernel-current/drivers/mtd/pacenand/nand_dev_new_73xx.c
--- kernel-3.3-3.0a-ref/drivers/mtd/pacenand/nand_dev_new_73xx.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/mtd/pacenand/nand_dev_new_73xx.c	2015-06-12 16:27:19.920068066 +0200
@@ -0,0 +1,4218 @@
+
+/****************************************************************************
+ *                                                                          *
+ * File        : nand_dev_new.c                                             *
+ *                                                                          *
+ * Description : Low level read/write functions for NAND flash using the    *
+ *               NEW Broadcom NAND flash controller                         *
+ *                                                                          *
+ * Author      : Neil Crossley (crossln1)/Sumil Patel                       *
+ *                                                                          *
+ * Copyright   : (c) Pace PLC 2007/2013                                     *
+ *                                                                          *
+ *               The copyright in this material is owned by                 *
+ *               Pace Microtechnology PLC ("Pace"). This                    *
+ *               material is regarded as a highly confidential              *
+ *               trade secret of Pace. It may not be reproduced,            *
+ *               used, sold or in any other way exploited or                *
+ *               transferred to any third party without the prior           *
+ *               written permission of Pace.                                *
+ *                                                                          *
+ * Notes       : Thanks to Simon Hemming for the previous driver (and also  *
+ *               figuring out how the hardware works) as well as John Smith *
+ *               for additional help                                        *
+ *                                                                          *
+ * History     : Initial Version by Neil                                    *
+ *             : Updated by Sumil for ONFI Support and 4K Page Chip Support *
+ *               Read Notes for further details                             *
+ *                                                                          *
+ ****************************************************************************/
+
+/* Notes ...
+
+   - Delay timing calculations ...
+
+     Any reads of the NAND controller registers lock the CPU to approx 100Mhz
+     so to delay for one second we simply read the status register 100 million
+     times. Note that due to the overhead of the loop logic this will actually
+     wait for slightly longer (though this should not cause any problems).
+
+   - OS Dependance ...
+
+     This module does not rely on any paticular operating system.
+
+   - Object file size ...
+
+     Currently the stripped version of the .o file this produces is approx 10K
+     If anyone needs a smaller version then please let me know (though the code
+     may not be as readable afterwards!)
+
+   - Broadcom Controller Specific ...
+
+     The controller always writes the ECC data for the block using the offsets
+     defined in the 'small page' spare area format even for devices with large
+     pages.  Also the controller does NOT calc the ECC data for the 'logical
+     sector number' bytes.
+
+     There is now an option to calculate/check an additional CRC32 in addition
+     to the controllers ECC checks, this is guaranteed to spot uncorrectable
+     errors correctly however this decreases the reading speed significantly
+     (especially if you build this driver with no optimizations!)
+
+   - Changes for Multibit ECC
+
+     We no longer support small page devices.
+
+   - Style notes
+
+        Can whoever keeps removing the padding lines after comments PLEASE STOP
+        DOING THIS, it makes things less readable (and before anyone mentions
+        things fitting in an 80x25 terminal window in VI then please dont, it's
+     2013 for heavens sake!)
+
+   Update on Intial Version...
+   ---------------------------
+
+   - ONFI support with FIX_BROKEN_BCM_NAND_AUTODETECT flag
+   - 4k page chip support
+   - FIX_BROKEN_BCM_NAND_AUTODETECT enbaled forcefully for NOR+NAND solution
+     to achieve diversity to all nand chips
+   - FORCE_2K_PAGEWRITES enabled by enbaled forcefully for NOR+NAND solution
+     to improve read/write performance
+   - optimize NAND_DEV_INFO and SPARE_MAP structures by reducing not-used variables.
+   - removed UNC error caused by clean marker(written by nand_dev_write_spare()) in read_nand()
+     it will be handled by filesystem driver(pacenand_base.c)
+   - CACHE Program Mode for speedy write operation
+
+*/
+
+/****************************************************************************/
+
+
+/************
+ * Includes *
+ ************/
+
+#include <linux/version.h>
+#include <linux/types.h>
+#include <stdbool.h>
+#include <linux/mtd/pacenand.h>
+#include <linux/module.h>
+#include <linux/delay.h>
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,31)
+#include <generated/autoconf.h>
+#else
+#include <linux/autoconf.h>
+#endif
+
+#if defined(LINUX) || defined(__linux__)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
+#include "linux/brcmstb/brcmstb.h"
+#else
+#include "asm/brcmstb/brcmstb.h"
+#endif
+#else
+#include "bchp_nand.h"
+#include "bchp_ebi.h"
+#endif
+
+/***********
+ * Defines *
+ ***********/
+#if defined(CONFIG_PACE_SYSTEM_IS_NAND_ONLY)
+#define SYSTEM_IS_NAND_ONLY
+#endif
+
+#if defined(CONFIG_FORCE_ECC_SPARE_AREA_LAYOUT)
+#define FORCE_ECC_SPARE_AREA_LAYOUT CONFIG_FORCE_ECC_SPARE_AREA_LAYOUT
+#endif
+
+#if defined(CONFIG_READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE)
+#define READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE CONFIG_READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE
+#endif
+
+#if defined(CONFIG_PACE_NAND_FORCE_HAMMING_FOR_LEGACY_CHIP)
+#define FORCE_HAMMING_FOR_LEGACY_CHIP
+#endif
+
+#if defined(CONFIG_PACE_NAND_ENABLE_HIGHSPEED)
+#define PACE_NAND_ENABLE_HIGHSPEED
+#endif
+
+#define FIX_BROKEN_BCM_NAND_AUTODETECT
+#define FORCE_2K_PAGEWRITES
+
+/*************
+ * DataTypes *
+ *************/
+
+/* Lets just fix this here then the source still looks nice */
+
+#ifndef __BLI_TYPES_DEFINED__
+#define __BLI_TYPES_DEFINED__
+#define BLI_INT8    int8_t
+#define BLI_UINT8   uint8_t
+#define BLI_INT16   int16_t
+#define BLI_UINT16  uint16_t
+#define BLI_INT32   int32_t
+#define BLI_UINT32  uint32_t
+#define BLI_INT64   int64_t
+#define BLI_UINT64  uint64_t
+#define BLI_VOID    void
+#define BLI_BOOL    uint32_t
+#define TRUE        true
+#define FALSE       false
+#endif
+
+
+/***********
+ * Defines *
+ ***********/
+
+/* Enable parameter checking
+
+   - Only disable if you REALLY need the extra few cycles! */
+
+#define PARAM_CHECK                     1
+
+/* Polynomial for CRC table generator */
+
+#define CRC32_POLY                      0x04c11db7
+
+/* Hardware Access*/
+
+#define BCHP_HARDWARE_BASE              0x10000000
+
+#define NAND_CACHE_BASE                 (BCHP_HARDWARE_BASE + BCHP_NAND_FLASH_CACHEi_ARRAY_BASE)
+#define NAND_CACHE_SIZE                 512
+
+/* Delay constants */
+
+#define DELAY_ONE_USEC                  100
+#define DELAY_ONE_MSEC                  100000
+#define DELAY_ONE_SECOND                100000000
+
+/* Sizes */
+
+#ifndef KILO
+
+#define KILO                            1024
+#define MEGA                            (1024 * 1024)
+#define GIGA                            (1024 * 1024 * 1024)
+
+#endif
+
+/* Bits from the status register of the flash device
+   These bits are fairly common, but newer devices may have other bits */
+
+#define DEVICE_STATUS_NOT_WRITE_PROTECT (1 << 7)
+#define DEVICE_STATUS_CONTROLLER_READY  (1 << 6)
+#define DEVICE_STATUS_ERROR             (1 << 0)
+#define DEVICE_STATUS_CACHE_ERROR       (1 << 1)
+
+/* Sort out the stupid new chip select nonsense on later controllers
+   New NAND controller has different registers for CS0 and CS1 */
+
+#ifdef BCHP_NAND_ACC_CONTROL_CS1
+  #ifdef SYSTEM_IS_NAND_ONLY
+    #ifdef BCHP_NAND_ACC_CONTROL_CS0
+      #define REG_ACC_CONTROL    BCHP_NAND_ACC_CONTROL_CS0
+      #define REG_CONFIG         BCHP_NAND_CONFIG_CS0
+    #else
+      #define REG_ACC_CONTROL    BCHP_NAND_ACC_CONTROL
+      #define REG_CONFIG         BCHP_NAND_CONFIG
+    #endif
+  #else
+    #define REG_ACC_CONTROL    BCHP_NAND_ACC_CONTROL_CS1
+    #define REG_CONFIG         BCHP_NAND_CONFIG_CS1
+  #endif
+#else
+  #define REG_ACC_CONTROL    BCHP_NAND_ACC_CONTROL
+  #define REG_CONFIG         BCHP_NAND_CONFIG
+#endif
+
+/* The headers for the latest NAND controllers break compatibility with the old ones
+   for a few registers, rather than have this code turn into even more of a mess of
+   #ifdef's we'll fix that here (this is really getting silly now!)                  */
+
+#ifdef BCHP_NAND_ACC_CONTROL_CS0
+#define BCHP_NAND_ACC_CONTROL_RD_ECC_EN_MASK          BCHP_NAND_ACC_CONTROL_CS0_RD_ECC_EN_MASK
+#define BCHP_NAND_ACC_CONTROL_WR_ECC_EN_MASK          BCHP_NAND_ACC_CONTROL_CS0_WR_ECC_EN_MASK
+#define BCHP_NAND_ACC_CONTROL_RD_ERASED_ECC_EN_MASK   BCHP_NAND_ACC_CONTROL_CS0_RD_ERASED_ECC_EN_MASK
+#define BCHP_NAND_ACC_CONTROL_ECC_LEVEL_MASK          BCHP_NAND_ACC_CONTROL_CS0_ECC_LEVEL_MASK
+#define BCHP_NAND_ACC_CONTROL_ECC_LEVEL_SHIFT         BCHP_NAND_ACC_CONTROL_CS0_ECC_LEVEL_SHIFT
+#define BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_MASK    BCHP_NAND_ACC_CONTROL_CS0_SPARE_AREA_SIZE_MASK
+#define BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_SHIFT   BCHP_NAND_ACC_CONTROL_CS0_SPARE_AREA_SIZE_SHIFT
+#define BCHP_NAND_ACC_CONTROL_WR_PREEMPT_EN_MASK      BCHP_NAND_ACC_CONTROL_CS0_WR_PREEMPT_EN_MASK
+#define BCHP_NAND_ACC_CONTROL_PAGE_HIT_EN_MASK        BCHP_NAND_ACC_CONTROL_CS0_PAGE_HIT_EN_MASK
+#define BCHP_NAND_ACC_CONTROL_PARTIAL_PAGE_EN_MASK    BCHP_NAND_ACC_CONTROL_CS0_PARTIAL_PAGE_EN_MASK
+#define BCHP_NAND_ACC_CONTROL_FAST_PGM_RDIN_MASK      BCHP_NAND_ACC_CONTROL_CS0_FAST_PGM_RDIN_MASK
+#define BCHP_NAND_ACC_CONTROL_PREFETCH_EN_MASK		  BCHP_NAND_ACC_CONTROL_CS0_PREFETCH_EN_MASK
+#define BCHP_NAND_CONFIG_DEVICE_SIZE_DVC_SIZE_512MB   BCHP_NAND_CONFIG_CS0_DEVICE_SIZE_DVC_SIZE_512MB
+#define BCHP_NAND_CONFIG_DEVICE_SIZE_DVC_SIZE_256MB   BCHP_NAND_CONFIG_CS0_DEVICE_SIZE_DVC_SIZE_256MB
+#define BCHP_NAND_CONFIG_DEVICE_SIZE_DVC_SIZE_128MB   BCHP_NAND_CONFIG_CS0_DEVICE_SIZE_DVC_SIZE_128MB
+#define BCHP_NAND_CONFIG_DEVICE_SIZE_MASK             BCHP_NAND_CONFIG_CS0_DEVICE_SIZE_MASK
+#define BCHP_NAND_CONFIG_DEVICE_SIZE_SHIFT            BCHP_NAND_CONFIG_CS0_DEVICE_SIZE_SHIFT
+#define BCHP_NAND_CONFIG_BLOCK_SIZE_MASK              BCHP_NAND_CONFIG_CS0_BLOCK_SIZE_MASK
+#define BCHP_NAND_CONFIG_BLOCK_SIZE_SHIFT             BCHP_NAND_CONFIG_CS0_BLOCK_SIZE_SHIFT
+#define BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_512KB     BCHP_NAND_CONFIG_CS0_BLOCK_SIZE_BK_SIZE_512KB
+#define BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_256KB     BCHP_NAND_CONFIG_CS0_BLOCK_SIZE_BK_SIZE_256KB
+#define BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_128KB     BCHP_NAND_CONFIG_CS0_BLOCK_SIZE_BK_SIZE_128KB
+#define BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_16KB      BCHP_NAND_CONFIG_CS0_BLOCK_SIZE_BK_SIZE_16KB
+#define BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_8KB       BCHP_NAND_CONFIG_CS0_BLOCK_SIZE_BK_SIZE_8KB
+#define BCHP_NAND_CONFIG_PAGE_SIZE_MASK               BCHP_NAND_CONFIG_CS0_PAGE_SIZE_MASK
+#define BCHP_NAND_CONFIG_PAGE_SIZE_SHIFT              BCHP_NAND_CONFIG_CS0_PAGE_SIZE_SHIFT
+#define BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_512        BCHP_NAND_CONFIG_CS0_PAGE_SIZE_PG_SIZE_512
+#define BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_2KB        BCHP_NAND_CONFIG_CS0_PAGE_SIZE_PG_SIZE_2KB
+#define BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_4KB        BCHP_NAND_CONFIG_CS0_PAGE_SIZE_PG_SIZE_4KB
+#define BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_8KB        BCHP_NAND_CONFIG_CS0_PAGE_SIZE_PG_SIZE_8KB
+#define BCHP_NAND_ACC_CONTROL_CACHE_MODE_EN_MASK         BCHP_NAND_ACC_CONTROL_CS0_CACHE_MODE_EN_MASK
+#define BCHP_NAND_ACC_CONTROL_CACHE_MODE_LAST_PAGE_MASK  BCHP_NAND_ACC_CONTROL_CS0_CACHE_MODE_LAST_PAGE_MASK
+#endif
+
+/**********
+ * Macros *
+ **********/
+
+/* RT050711 Pace change */
+
+/* Temporarily changing the KSEG1 */
+
+/* CROSSLN1 - How come these both OR with 0xa0000000, surely we should
+   be using 0x90000000 if CONFIG_BRCM_UPPER_MEMORY is defined????      */
+
+#ifdef CONFIG_BRCM_UPPER_MEMORY
+#define PHYS_TO_KSEG1(v)  ((v) | 0x90000000)
+#else
+#define PHYS_TO_KSEG1(v)  ((v) | 0xa0000000)
+#endif
+#define BCHP_REG(r)       *((volatile uint32_t*) PHYS_TO_KSEG1(BCHP_HARDWARE_BASE | r))
+
+
+#if defined(BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK)
+#define ECC_ENABLE() do { \
+	BLI_UINT32 reg; \
+    reg  = BCHP_REG(REG_ACC_CONTROL); \
+    reg  |= (BCHP_NAND_ACC_CONTROL_RD_ECC_EN_MASK | BCHP_NAND_ACC_CONTROL_WR_ECC_EN_MASK | BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK) ; \
+    BCHP_REG(REG_ACC_CONTROL) = reg; \
+    } while (0)
+#define ECC_DISABLE() do { \
+	BLI_UINT32 reg; \
+    reg  = BCHP_REG(REG_ACC_CONTROL); \
+    reg  &= ~(BCHP_NAND_ACC_CONTROL_RD_ECC_EN_MASK | BCHP_NAND_ACC_CONTROL_WR_ECC_EN_MASK | BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK) ; \
+	BCHP_REG(REG_ACC_CONTROL) = reg; \
+    } while (0)
+#else
+#define ECC_ENABLE() do { \
+	BLI_UINT32 reg; \
+    reg  = BCHP_REG(REG_ACC_CONTROL); \
+    reg  |= (BCHP_NAND_ACC_CONTROL_RD_ECC_EN_MASK | BCHP_NAND_ACC_CONTROL_WR_ECC_EN_MASK) ; \
+    BCHP_REG(REG_ACC_CONTROL) = reg; \
+    } while (0)
+#define ECC_DISABLE() do { \
+	BLI_UINT32 reg; \
+    reg  = BCHP_REG(REG_ACC_CONTROL); \
+    reg  &= ~(BCHP_NAND_ACC_CONTROL_RD_ECC_EN_MASK | BCHP_NAND_ACC_CONTROL_WR_ECC_EN_MASK); \
+    BCHP_REG(REG_ACC_CONTROL) = reg; \
+	} while (0)
+#endif
+/**************
+ * Prototypes *
+ *************/
+static NDR_ERROR  is_vpage_erased(BLI_UINT32 vpage);
+static NDR_ERROR  read_spare(BLI_UINT32 vpage, BLI_VOID* data);
+static NDR_ERROR  write_spare(BLI_UINT32 vpage, BLI_VOID* data);
+static NDR_ERROR  read_nand(BLI_UINT64 unit_size, BLI_UINT32 unit_count, BLI_UINT32 unit, BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags, BLI_BOOL *pageused);
+static NDR_ERROR  write_nand(BLI_UINT64 unit_size, BLI_UINT32 unit_count, BLI_UINT32 unit, BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags);
+static void nand_write_oob(BLI_UINT32 *buffer, BLI_INT32 oob_size);
+static void nand_read_oob(BLI_UINT32 *buffer, BLI_INT32 oob_size);
+static BLI_BOOL   initialise_hardware(BLI_UINT32 *config);
+static NDR_ERROR  wait_ready(BLI_VOID);
+static BLI_UINT64 get_device_size(BLI_UINT32 nand_config);
+static BLI_INT32  get_block_size(BLI_UINT32 nand_config);
+static BLI_INT32  get_page_size(BLI_UINT32 nand_config);
+static BLI_UINT32 force_native_endian(BLI_UINT32 value);
+static BLI_VOID   memset08(BLI_VOID *dest, BLI_UINT8 source, BLI_UINT32 len);
+static BLI_VOID   memcopy08(BLI_VOID *dest, BLI_VOID *source, BLI_UINT32 len);
+static BLI_VOID   memcopy32(BLI_VOID *dest, BLI_VOID *source, BLI_UINT32 len);
+static BLI_BOOL   memcompare08(BLI_VOID *source1, BLI_VOID *source2, BLI_UINT32 len);
+static BLI_BOOL   memcompare32(BLI_VOID *source1, BLI_VOID *source2, BLI_UINT32 len);
+static BLI_VOID   generate_crc_table(BLI_VOID);
+static BLI_UINT32 calc_crc32(BLI_VOID *source, BLI_UINT32 crc, BLI_UINT32 *crctable, BLI_UINT32 count);
+static BLI_UINT64 lrshift64(BLI_UINT64 arg, BLI_UINT8 shift);
+static BLI_INT32 countsetbits(BLI_UINT8 * ptr, BLI_INT32 nbytes);
+#ifdef BCHP_NAND_ACC_CONTROL_CS0
+static NDR_ERROR write_nandblock_cached(BLI_UINT64 unit_size, BLI_UINT32 unit_count, BLI_UINT32 unit, BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags);
+#endif
+
+/**************
+ * Structures *
+ **************/
+
+typedef struct nand_ids_t
+{
+	BLI_UINT8  id;
+	BLI_UINT32 msize;
+}nand_ids_s;
+
+typedef struct nand_device_t
+{
+  BLI_UINT32  spare_size;
+  BLI_UINT32  page_size;
+  BLI_UINT32  block_size;
+  BLI_UINT32  device_size;
+} nand_device_s;
+
+
+/* Spare area layout */
+
+typedef struct
+{
+  BLI_UINT32  sparemask;
+  BLI_UINT32  badblock_pos;
+  BLI_UINT32  usedmarker_pos;
+  BLI_UINT32  crc_pos;
+  BLI_UINT32  crc_bytes;
+  BLI_UINT32  ecc_pos;
+  BLI_UINT32  ecc_bytes;
+  BLI_UINT32  bytes_free;
+  BLI_UINT32  corr_stat_threshold;
+} SPARE_MAP;
+
+
+/**********
+ * Tables *
+ **********/
+
+/* Device information structure */
+
+static NAND_DEV_INFO nd_info =
+{
+  {0xDE,0xAD,0xBE,0xEF},        /* See Notes Above                                          */
+  0,                            /* Device size in bytes                                     */
+  0,                            /* Block size in bytes                                      */
+  0,                            /* Number of blocks on device                               */
+  0,                            /* Page size in bytes                                       */
+  0,                            /* Original Spare Area Size of chip                         */
+  0,                            /* Number of pages on device                                */
+  0,                            /* Virtual page size in bytes                               */
+  0,                            /* Number of virtual pages on device                        */
+  0,                            /* Number of pages per block                                */
+  0,                            /* Number of virtual pages per page                         */
+  0,                            /* Number of virtual pages per block                        */
+  0,                            /* ECC Type + spare area layout                             */
+  0,                            /* Type of ECC used                                         */
+  0,                            /* Number of bits ECC can handle                            */
+  0,                            /* ECC Enabled readback                                     */
+  0,                            /* Size of the spare area                                   */
+  0,                            /* Number of free bytes in spare area                       */
+  0,                            /* Number of bytes used to store ECC data                   */
+  {0},                          /* Spare area free bytes                                    */
+
+};
+
+
+/* Table of flash devices and geometries
+
+   Needed to fix the 40nm autodetect issue
+
+   *NOTE* if a new 8 bit ECC chip we may have to
+          check the entire 4 byte device code!     */
+
+#ifdef FIX_BROKEN_BCM_NAND_AUTODETECT
+
+#define MAN_TOSHIBA_ID					0x98
+#define MAN_SPANSION_ID					0x01
+#define MAN_MICRON_ID					0x2C
+#define MAN_MACRONIX_ID					0xC2
+#define MAN_SAMSUNG_ID					0xEC
+#define MAN_NUMONYX_ID					0x20
+#define MAN_HYNIX_ID					0xAD
+#define MAN_CI_CELLTYPE_MSK    			0x0C
+#define MAX_NAND_IDS                    4
+
+#define ONFI_CRC_BASE   				0x4F4E
+#define ONFI_PAGE_SIZE_OFFSET 			80
+#define ONFI_SPARE_SIZE_OFFSET 			84
+#define ONFI_NO_PAGE_PER_BLOCK_OFFSET 	92
+#define ONFI_NO_BLOCK_PER_LUN  			96
+#define ONFI_NO_LUN            			100
+#define ONFI_CRC_OFFSET 				254
+
+static nand_device_s nand_device;
+static nand_ids_s nand_ids[MAX_NAND_IDS] =
+{
+	{0xF1,128*MEGA},
+	{0xD1,128*MEGA},
+	{0xDA,256*MEGA},
+	{0xDC,512*MEGA},
+};
+#ifdef BCHP_NAND_CMD_START_OPCODE_PARAMETER_READ
+static BLI_UINT16 nand_onfi_crc16(BLI_UINT16 crc, BLI_UINT8 *p, BLI_INT32 len);
+static BLI_BOOL nand_onfi_detect(void);
+#endif
+static BLI_INT32 nand_id_has_period(BLI_UINT8 *id_data, BLI_INT32 arrlen, BLI_INT32 period);
+static BLI_INT32 nand_id_len(BLI_UINT8 *id_data, BLI_INT32 arrlen);
+static BLI_BOOL  nand_decode_ext_id(BLI_UINT8 *id_data);
+#endif // #ifdef FIX_BROKEN_BCM_NAND_AUTODETECT
+
+
+/* Spare area usage maps
+
+   Usage type ...
+
+   B = Badblock marker
+   s = Spare
+   E = ECC data
+   U = Page Used
+   C = CRC32
+
+   NOTE - For efficiency the page used marker and CRC MUST
+          be placed in the first 16 bytes
+*/
+
+static SPARE_MAP sparemaps[7] =
+{
+  /* Hamming / 16 byte spare area
+
+     Byte   0123456789ABCDEF
+     Usage  BsssssEEEssUCCCC
+
+     12 Bytes unused (spare)   */
+
+  {
+    0x0000fe3e,         /* sparemask           */
+    0,                  /* badblock_pos        */
+    11,                 /* usedmarker_pos      */
+    12,                 /* crc_pos             */
+    4,                  /* crc_bytes           */
+    6,                  /* ecc_pos             */
+    3,                  /* ecc_bytes           */
+    12,                 /* bytes_free          */
+    1,                  /* CORR_STAT_THRESHOLD */
+  },
+
+  /* BCH4 / 16 byte spare area
+
+     Byte   0123456789ABCDEF
+     Usage  BsssCCCCUEEEEEEE
+
+     8 Bytes unused (spare)   */
+
+  {
+    0x000001fe,         /* sparemask           */
+    0,                  /* badblock_pos        */
+    8,                  /* usedmarker_pos      */
+    4,                  /* crc_pos             */
+    4,                  /* crc_bytes           */
+    9,                  /* ecc_pos             */
+    7,                  /* ecc_bytes           */
+    8,                  /* bytes_free          */
+    2,                  /* CORR_STAT_THRESHOLD */
+  },
+
+  /* BCH8 / 27 byte spare area
+
+     Byte   0123456789ABCDEF 0123456789A
+     Usage  BsssssssCCCCUEEE EEEEEEEEEEE
+
+     12 Bytes unused (spare)   */
+
+  {
+    0x00001ffe,         /* sparemask           */
+    0,                  /* badblock_pos        */
+    12,                 /* usedmarker_pos      */
+    8,                  /* crc_pos             */
+    4,                  /* crc_bytes           */
+    13,                 /* ecc_pos             */
+    14,                 /* ecc_bytes           */
+    12,                 /* bytes_free          */
+    6,                  /* CORR_STAT_THRESHOLD */
+  },
+
+  /* BCH8 / 32 byte spare area
+
+     Byte   0123456789ABCDEF 0123456789ABCDEF
+     Usage  BUssssssssssCCCC ssEEEEEEEEEEEEEE
+
+     17 Bytes unused (spare)   */
+
+  {
+    0x0002fffe,         /* sparemask           */
+    0,                  /* badblock_pos        */
+    1,                  /* usedmarker_pos      */
+    12,                 /* crc_pos             */
+    4,                  /* crc_bytes           */
+    18,                 /* ecc_pos             */
+    14,                 /* ecc_bytes           */
+    17,                 /* bytes_free          */
+    6,                  /* CORR_STAT_THRESHOLD */
+  },
+
+  /* BCH12 / 27 byte spare area
+
+     Byte   0123456789ABCDEF 0123456789A
+     Usage  BUCCCCEEEEEEEEEE EEEEEEEEEEE
+
+     5 Bytes unused (spare)   */
+
+  {
+    0x0000003e,         /* sparemask           */
+    0,                  /* badblock_pos        */
+    1,                  /* usedmarker_pos      */
+    2,                  /* crc_pos             */
+    4,                  /* crc_bytes           */
+    6,                  /* ecc_pos             */
+    21,                 /* ecc_bytes           */
+    5,                  /* bytes_free          */
+    9,                  /* CORR_STAT_THRESHOLD */
+  },
+
+  /* BCH12 / 32 byte spare area
+
+     Byte   0123456789ABCDEF 0123456789ABCDEF
+     Usage  BsssssUCCCCEEEEE EEEEEEEEEEEEEEEE
+
+     10 Bytes unused (spare)   */
+  {
+    0x000007fe,         /* sparemask           */
+    0,                  /* badblock_pos        */
+    6,                  /* usedmarker_pos      */
+    7,                  /* crc_pos             */
+    4,                  /* crc_bytes           */
+    11,                 /* ecc_pos             */
+    21,                 /* ecc_bytes           */
+    10,                 /* bytes_free          */
+    9,                  /* CORR_STAT_THRESHOLD */
+  },
+
+  /* BCH12 / 28 byte spare area
+
+     Byte   0123456789ABCDEF 0123456789AB
+     Usage  BsUCCCCEEEEEEEEE EEEEEEEEEEEE
+
+     6 Bytes unused (spare)   */
+
+  {
+    0x0000007e,         /* sparemask           */
+    0,                  /* badblock_pos        */
+    2,                  /* usedmarker_pos      */
+    3,                  /* crc_pos             */
+    4,                  /* crc_bytes           */
+    7,                  /* ecc_pos             */
+    21,                 /* ecc_bytes           */
+    6,                  /* bytes_free          */
+    9,                  /* CORR_STAT_THRESHOLD */
+  },
+};
+
+
+/***********
+ * Buffers *
+ ***********/
+
+/* Page Buffer */
+
+static BLI_UINT8  pagebuffer_r[512];
+static BLI_UINT8  pagebuffer_w[512];
+static BLI_UINT8  pagecopybuffer[4096];
+
+/* 'Spare' Area buffer */
+
+static BLI_UINT8  sparebuffer[256];
+
+/* CRC Table */
+
+static BLI_UINT32 nand_crc_table[256];
+
+
+/***************
+ * Global Data *
+ ***************/
+
+static BLI_BOOL   nand_driver_initialised = FALSE;
+static BLI_UINT32 nand_bad_block_offset;
+static BLI_UINT32 nand_data_crc32_offset;
+static BLI_UINT32 nand_data_valid_offset;
+static BLI_BOOL   little_endian;
+static BLI_UINT32 cs_ext_select;
+static BLI_UINT32 ecctype;
+static BLI_UINT32 ecc_spare_area_layout;
+static BLI_UINT32 errorbits;
+static BLI_UINT32 spare_area_size;
+static BLI_UINT32 chip_spare_area_size;
+static BLI_UINT32 sub_pages_per_page;
+static BLI_UINT32 virt_page_size;
+static BLI_UINT32 virt_page_mask;
+static BLI_UINT32 virt_page_shift;
+static struct semaphore nand_dev_sema;
+
+
+/****************************************************************************
+ *                                 Exported Routines                        *
+ ****************************************************************************/
+
+/*********************
+ * Initialise Driver *
+ *********************/
+
+/* Entry   : NO PARAMETERS
+
+   Returns : NDR error code (see header file)  */
+
+NDR_ERROR nand_dev_init(BLI_VOID)
+{
+  /* Locals */
+
+  BLI_UINT32            nand_config;
+  BLI_UINT64            device_size;
+  BLI_UINT32            block_size, page_size;
+  BLI_UINT32            device_size_kilo, block_size_kilo;
+  BLI_UINT32            vpages_per_page;
+  BLI_UINT32            dev_id;
+  volatile BLI_UINT32   endlong;
+  volatile BLI_UINT8    *endptr08;
+  BLI_INT32             i,j;
+  BLI_UINT32            sm,smp,mask;
+
+  /* If driver already initialised return an error */
+
+  if (nand_driver_initialised)
+  {
+    return(NDR_ALREADY_INITIALISED);
+  }
+
+  /* Initialise Mutex */
+
+  sema_init(&nand_dev_sema, 0);
+
+  /* Determian endian mode */
+
+  endlong  = 0xDEADBEEF;
+  endptr08 = (BLI_UINT8*) &endlong;
+  little_endian = FALSE;
+
+  if ((endptr08[0] == 0xEF) && (endptr08[1] == 0xBE) && (endptr08[2] == 0xAD) && (endptr08[3] == 0xDE))
+  {
+    little_endian = TRUE;
+  }
+
+  /* Initialise hardware registers */
+
+  if (!(initialise_hardware(&nand_config)))
+  {
+	up(&nand_dev_sema);
+    return(NDR_UNSUPPORTED_DEVICE);
+  }
+
+  /* Sanity check, need the extended registers if >16 byte spare area */
+
+  if (spare_area_size > 16)
+  {
+    #if !defined(BCHP_NAND_SPARE_AREA_READ_OFS_10) || !defined(BCHP_NAND_SPARE_AREA_WRITE_OFS_10)
+    up(&nand_dev_sema);
+    return(NDR_FATAL_ERROR);
+    #endif
+  }
+
+
+  if (spare_area_size > 32)
+  {
+    up(&nand_dev_sema);
+   	return(NDR_UNSUPPORTED_DEVICE);
+  }
+
+  /* Get the device ID, bail if no NAND found */
+
+  dev_id = BCHP_REG(BCHP_NAND_FLASH_DEVICE_ID);
+
+  if (dev_id == 0)
+  {
+	up(&nand_dev_sema);
+    return(NDR_NO_NAND_PRESENT);
+  }
+
+  /* Get the device, block and page size from the config register */
+
+  device_size = get_device_size(nand_config);
+  block_size  = get_block_size(nand_config);
+  page_size   = get_page_size(nand_config);
+
+  /* Bail out now if the device, block or page sizes were invalid */
+
+  if ((device_size == -1) || (block_size == -1) || (page_size == -1))
+  {
+	up(&nand_dev_sema);
+    return(NDR_UNSUPPORTED_DEVICE);
+  }
+
+  /* The page size *MUST* be 2k/4k
+
+     Yet another nasty fix for later :( */
+
+  if((page_size != 2048) && (page_size != 4096))
+  {
+	up(&nand_dev_sema);
+    return(NDR_UNSUPPORTED_DEVICE);
+  }
+
+  if((spare_area_size != 16) &&
+  	(spare_area_size != 32) &&
+  	(spare_area_size != 27) &&
+  	(spare_area_size != 28))
+  {
+	up(&nand_dev_sema);
+	return(NDR_UNSUPPORTED_DEVICE);
+  }
+
+  /* Build the information structure */
+
+  #ifdef FORCE_2K_PAGEWRITES
+
+  virt_page_size = 2048;
+  virt_page_mask = 0x7ff;
+  virt_page_shift = 11;
+  sub_pages_per_page = 4;
+
+  #else
+
+  virt_page_size = NAND_CACHE_SIZE;
+  virt_page_mask = 0x1ff;
+  virt_page_shift = 9;
+  sub_pages_per_page = 1;
+
+  #endif
+
+
+  if(page_size == 4096)
+  {
+	virt_page_size = 4096;
+  	virt_page_mask = 0xFFF;
+  	virt_page_shift = 12;
+  	sub_pages_per_page = 8;
+  }
+
+  if(errorbits == 1)
+  {
+	virt_page_size = NAND_CACHE_SIZE;
+	virt_page_mask = 0x1ff;
+	virt_page_shift = 9;
+  	sub_pages_per_page = 1;
+  }
+
+  nand_data_valid_offset = sparemaps[ecc_spare_area_layout].usedmarker_pos;
+  nand_data_crc32_offset = sparemaps[ecc_spare_area_layout].crc_pos;
+  nand_bad_block_offset  = sparemaps[ecc_spare_area_layout].badblock_pos;
+
+  vpages_per_page = page_size / virt_page_size;
+
+  device_size_kilo = device_size >> 10;
+  block_size_kilo  = block_size >> 10;
+
+  nd_info.Device_ID[0]                = (BLI_UINT8)(dev_id >> 24);
+  nd_info.Device_ID[1]                = (BLI_UINT8)(dev_id >> 16);
+  nd_info.Device_ID[2]                = (BLI_UINT8)(dev_id >> 8);
+  nd_info.Device_ID[3]                = (BLI_UINT8)(dev_id);
+  nd_info.Device_Size                 = device_size;
+  nd_info.Block_Size                  = block_size;
+  nd_info.Block_Count                 = device_size_kilo / block_size_kilo;
+  nd_info.Page_Size                   = page_size;
+  nd_info.Page_Count                  = nd_info.Block_Count * (block_size / page_size);
+  nd_info.Virt_Page_Size              = virt_page_size;
+  nd_info.Virt_Page_Count             = nd_info.Page_Count * vpages_per_page;
+  nd_info.Pages_Per_Block             = block_size / page_size;
+  nd_info.Virt_Pages_Per_Page         = vpages_per_page;
+  nd_info.Virt_Pages_Per_Block        = block_size / virt_page_size;
+  nd_info.ECC_Spare_Area_Layout       = ecc_spare_area_layout;
+  nd_info.ECC_Type                    = ecctype;
+  nd_info.ECC_Bits                    = errorbits;
+  nd_info.ECC_Enabled                 = TRUE;
+  nd_info.Spare_Area_Size             = spare_area_size * sub_pages_per_page;
+  nd_info.Spare_Size                  = (chip_spare_area_size < nd_info.Spare_Area_Size)? nd_info.Spare_Area_Size: chip_spare_area_size;
+  nd_info.Spare_Area_Free             = sparemaps[ecc_spare_area_layout].bytes_free * sub_pages_per_page;
+  nd_info.Spare_Area_ECC_Bytes        = sparemaps[ecc_spare_area_layout].ecc_bytes  * sub_pages_per_page;
+  /* Build the spare area usage data */
+
+  smp = 0;
+
+  for (i = 0; i < sub_pages_per_page; i++)
+  {
+    sm  = sparemaps[ecc_spare_area_layout].sparemask;
+    mask = 1;
+    for (j = 0; j < spare_area_size; j++)
+    {
+      if (sm & mask)
+      {
+        nd_info.Spare_Area_Bytes[smp] = j + (i * spare_area_size);
+        smp++;
+      }
+      mask <<= 1;
+    }
+  }
+
+  smp = 0;
+
+  for (i = 0; i < sub_pages_per_page; i++)
+  {
+    for (j = 0; j < sparemaps[ecc_spare_area_layout].ecc_bytes; j++)
+    {
+      nd_info.Spare_Area_ECC_bytes[smp] = (sparemaps[ecc_spare_area_layout].ecc_pos + j) + (i * spare_area_size);
+      smp++;
+    }
+  }
+
+  /* Build the CRC table */
+
+  generate_crc_table();
+
+  /* Driver is now initialised */
+
+  nand_driver_initialised = TRUE;
+
+  up(&nand_dev_sema);
+
+  /* Return success */
+  return(NDR_SUCCESS);
+}
+
+
+/********************
+ * Shut Down Driver *
+ ********************/
+
+/* Entry   : NO PARAMETERS
+
+   Returns : NDR error code (see header file)  */
+
+NDR_ERROR nand_dev_shutdown(BLI_VOID)
+{
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  /* Clear initialised flag */
+
+  nand_driver_initialised = FALSE;
+
+  up(&nand_dev_sema);
+  /* Return success */
+
+  return(NDR_SUCCESS);
+}
+
+
+/*****************************
+ * Return Device Information *
+ *****************************/
+
+/* Entry   : Pointer to pointer to information block
+
+   Returns : NDR error code (see header file)
+
+   Notes   : The returned pointer will point to a blank
+             information structure if this function is
+             called before the driver is inialised, this
+             avoids any nasty NULL pointer issues!       */
+
+NDR_ERROR nand_dev_get_info(NAND_DEV_INFO **info)
+{
+  /* Return pointer to information block */
+
+  *info = &nd_info;
+
+  /* Return an error if the driver has not initialised */
+
+  if (!nand_driver_initialised)
+  {
+    return(NDR_NOT_INITIALISED);
+  }
+
+  /* Return success */
+
+  return(NDR_SUCCESS);
+}
+
+
+/**************
+ * Enable ECC *
+ **************/
+
+/* Entry   : Pass FALSE to DISABLE ECC
+             Pass TRUE  to ENABLE  ECC
+
+   Returns : NDR error code (see header file)  */
+
+NDR_ERROR nand_dev_enable_ecc(BLI_BOOL enable)
+{
+  /* Locals */
+
+  BLI_UINT32 reg;
+
+  /* Bail if the driver is not initialised */
+
+  if (!nand_driver_initialised)
+  {
+    return(NDR_NOT_INITIALISED);
+  }
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+
+  /* Enable or Disable ECC */
+
+  reg  = BCHP_REG(REG_ACC_CONTROL);
+
+  if (enable)
+  {
+    reg |= BCHP_NAND_ACC_CONTROL_RD_ECC_EN_MASK;        /* Enable Read ECC for blocks 1-?  */
+    reg |= BCHP_NAND_ACC_CONTROL_WR_ECC_EN_MASK;        /* Enable write ECC for all blocks */
+    #if defined(BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK)
+    reg |= BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK;   /* Enable Read ECC for block 0     */
+    #endif
+  }
+  else
+  {
+    reg &= ~BCHP_NAND_ACC_CONTROL_RD_ECC_EN_MASK;        /* Enable Read ECC for blocks 1-?  */
+    reg &= ~BCHP_NAND_ACC_CONTROL_WR_ECC_EN_MASK;        /* Enable write ECC for all blocks */
+    #if defined(BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK)
+    reg &= ~BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK;   /* Enable Read ECC for block 0     */
+    #endif
+  }
+
+  BCHP_REG(REG_ACC_CONTROL) = reg;
+
+  /* Update the info structure */
+
+  nd_info.ECC_Enabled = enable;
+
+  up(&nand_dev_sema);
+  /* Return Success */
+
+  return(NDR_SUCCESS);
+}
+
+
+/****************
+ * Read a block *
+ ****************/
+
+/* Entry   : block  - The block number to start at
+             data   - Destination address for data
+             offset - Offset within the block to begin reading at
+             length - The number of bytes to read
+
+   Returns : NDR error code (see header file)
+
+   Notes   : The maximum read length is one block
+           : If the destination address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_read_block(BLI_UINT32 block, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = read_nand((BLI_UINT64)nd_info.Block_Size, nd_info.Block_Count, block, data, (BLI_UINT64)offset, length, flags, NULL);
+  up(&nand_dev_sema);
+  return(result);
+}
+
+
+/***************
+ * Read a page *
+ ***************/
+
+/* Entry   : page   - The page number to start at
+             data   - Destination address for data
+             offset - Offset within the page to begin reading at
+             length - The number of bytes to read
+
+   Returns : NDR error code (see header file)
+
+   Notes   : The maximum read length is one page
+           : If the destination address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_read_page(BLI_UINT32 page, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = read_nand((BLI_UINT64)nd_info.Page_Size, nd_info.Page_Count, page, data, (BLI_UINT64)offset, length, flags, NULL);
+  up(&nand_dev_sema);
+  return(result);
+}
+
+
+/***********************
+ * Read a virtual page *
+ ***********************/
+
+/* Entry   : page   - The virtual page number to start at
+             data   - Destination address for data
+             offset - Offset within the page to begin reading at
+             length - The number of bytes to read
+
+   Returns : NDR error code (see header file)
+
+   Notes   : The maximum read length is one page
+           : If the destination address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_read_vpage(BLI_UINT32 vpage, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = read_nand((BLI_UINT64)nd_info.Virt_Page_Size, nd_info.Virt_Page_Count, vpage, data, (BLI_UINT64)offset, length, flags, NULL);
+  up(&nand_dev_sema);
+  return(result);
+}
+
+
+/******************
+ * Read anywhere *
+ ******************/
+
+/* Entry   : data   - Source address of data
+             offset - Offset within the page to begin writing to
+             length - The number of bytes to write
+
+   Returns : NDR error code (see header file)
+
+   Notes   : If the source address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_read_anywhere(BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = read_nand((BLI_UINT64)nd_info.Device_Size, 1, 0, data, (BLI_UINT64)offset, length, flags, NULL);
+  up(&nand_dev_sema);
+  return(result);
+}
+
+/*******************************************
+ * Read anywhere in raw mode(ECC disabled) *
+ *******************************************/
+
+/* Entry   : data   - Source address of data
+             offset - Offset within the page to begin writing to
+             length - The number of bytes to write
+
+   Returns : NDR error code (see header file)
+
+   Notes   : If the source address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_read_anywhere_raw(BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  if(nd_info.ECC_Enabled)
+  	ECC_DISABLE();
+  result = read_nand((BLI_UINT64)nd_info.Device_Size, 1, 0, data, (BLI_UINT64)offset, length, flags, NULL);
+  if(nd_info.ECC_Enabled)
+  	ECC_ENABLE();
+  up(&nand_dev_sema);
+  return result;
+}
+
+
+/*****************
+ * Write a block *
+ *****************/
+
+/* Entry   : block  - The block number to start at
+             data   - Source address of data
+             offset - Offset within the block to begin writing to
+             length - The number of bytes to write
+
+   Returns : NDR error code (see header file)
+
+   Notes   : The maximum read length is one block
+           : If the source address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_write_block(BLI_UINT32 block, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length,BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  if((flags & NDR_FLAGS_CACHEBLOCKWRITE) && (length == nd_info.Block_Size))
+ #ifdef BCHP_NAND_ACC_CONTROL_CS0
+    result = write_nandblock_cached((BLI_UINT64)nd_info.Block_Size, nd_info.Block_Count, block, data, (BLI_UINT64)offset, length, flags);
+ #else
+    result = write_nand((BLI_UINT64)nd_info.Block_Size, nd_info.Block_Count, block, data, (BLI_UINT64)offset, length, flags);
+ #endif
+  else
+  	result = write_nand((BLI_UINT64)nd_info.Block_Size, nd_info.Block_Count, block, data, (BLI_UINT64)offset, length, flags);
+  up(&nand_dev_sema);
+  return(result);
+
+}
+
+
+/****************
+ * Write a page *
+ ****************/
+
+/* Entry   : block  - The page number to start at
+             data   - Source address of data
+             offset - Offset within the page to begin writing to
+             length - The number of bytes to write
+
+   Returns : NDR error code (see header file)
+
+   Notes   : The maximum read length is one block
+           : If the source address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_write_page(BLI_UINT32 page, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = write_nand((BLI_UINT64)nd_info.Page_Size, nd_info.Page_Count, page, data, (BLI_UINT64)offset, length, flags);
+  up(&nand_dev_sema);
+  return(result);
+}
+
+
+/************************
+ * Write a virtual page *
+ ************************/
+
+/* Entry   : block  - The page number to start at
+             data   - Source address of data
+             offset - Offset within the page to begin writing to
+             length - The number of bytes to write
+
+   Returns : NDR error code (see header file)
+
+   Notes   : The maximum read length is one block
+           : If the source address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_write_vpage(BLI_UINT32 vpage, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = write_nand((BLI_UINT64)nd_info.Virt_Page_Size, nd_info.Virt_Page_Count, vpage, data, (BLI_UINT64)offset, length, flags);
+  up(&nand_dev_sema);
+  return(result);
+}
+
+
+/******************
+ * Write anywhere *
+ ******************/
+
+/* Entry   : data   - Source address of data
+             offset - Offset within the page to begin writing to
+             length - The number of bytes to write
+
+   Returns : NDR error code (see header file)
+
+   Notes   : If the source address is misaligned then performance will suffer. */
+
+NDR_ERROR nand_dev_write_anywhere(BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = write_nand((BLI_UINT64)nd_info.Device_Size, 1, 0, data, (BLI_UINT64)offset, length, flags);
+  up(&nand_dev_sema);
+  return(result);
+}
+
+
+/*****************
+ * Erase a block *
+ *****************/
+
+/* Entry   : block - The block number erase
+
+   Returns : NDR error code (see header file)  */
+
+NDR_ERROR nand_dev_erase_block(BLI_UINT32 block)
+{
+  /* Locals */
+
+  BLI_INT32   result;
+  BLI_UINT64  block_address;
+  BLI_UINT32  status;
+
+  /* Bail if the driver is not initialised */
+
+  if (!nand_driver_initialised)
+  {
+    return(NDR_NOT_INITIALISED);
+  }
+
+  /* Check block in range */
+
+  #if PARAM_CHECK
+  if (block >= nd_info.Block_Count)
+  {
+    return(NDR_ILLEGAL_BLOCK_OR_PAGE);
+  }
+  #endif
+
+  /* Take Mutex */
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+
+  /* Calculate address of block to be erased */
+
+  block_address = (block * nd_info.Block_Size);
+
+  /* Ensure controller is ready before we start */
+
+  result = wait_ready();
+
+  if (result != NDR_SUCCESS)
+  {
+	up(&nand_dev_sema);
+    return(result);
+  }
+
+  /* Set Base Address */
+
+  BCHP_REG(BCHP_NAND_CMD_ADDRESS)     = block_address & 0xffffffff;
+  BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = lrshift64(block_address, 32) | cs_ext_select;
+
+  /* Tell the controller to erase the block */
+
+  BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_BLOCK_ERASE << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+
+  /* Wait for controller ready */
+
+  result = wait_ready();
+  if (result != NDR_SUCCESS)
+  {
+	up(&nand_dev_sema);
+	return(result);
+  }
+
+  /* Check for error */
+
+  status = BCHP_REG(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_FLASH_STATUS_MASK;
+
+  if (status & DEVICE_STATUS_ERROR)
+  {
+	up(&nand_dev_sema);
+    return(NDR_DEVICE_ERASE_ERROR);
+  }
+
+  #ifdef CHECK_WRITEPROTECT
+  if (!(status & DEVICE_STATUS_NOT_WRITE_PROTECT))
+  {
+	up(&nand_dev_sema);
+    return(NDR_WRITE_PROTECTED);
+  }
+  #endif
+
+  up(&nand_dev_sema);
+
+  /* Return Success */
+
+  return(NDR_SUCCESS);
+}
+
+
+/****************
+ * Copy a block *
+ ****************/
+
+/* Entry   : destblock   - The block to copy TO
+             sourceblock - The block to copy FROM
+             vpignore    - The virtual page not to copy (set to 0xffffffff to disable)
+             flags       - Flags for Verify/CRC/UsedMarker
+
+   Returns : NDR error code (see header file)
+
+   Notes   : Normal people (ie the people who think that the C memcopy has the
+             source and destination parameters the wrong may around) will probably
+             overwrite a block by accident the first time they use this!!!         */
+
+NDR_ERROR nand_dev_copy_block(BLI_UINT32 destblock, BLI_UINT32 sourceblock, BLI_UINT32 vpignore, BLI_UINT32 flags)
+{
+  /* Locals */
+
+  NDR_ERROR   result = NDR_SUCCESS;
+  BLI_UINT32  vppb;
+  BLI_INT32   i;
+  BLI_BOOL    pageused;
+
+  /* Bail if the driver is not initialised */
+
+  if (!nand_driver_initialised)
+  {
+    return(NDR_NOT_INITIALISED);
+  }
+
+  /* Check source and dest blocks in range and not the same */
+
+  #if PARAM_CHECK
+  if (sourceblock == destblock) return(NDR_ERROR_COPY_TO_SAME_BLOCK);
+  if (sourceblock >= nd_info.Block_Count) return(NDR_ILLEGAL_BLOCK_OR_PAGE);
+  if (destblock >= nd_info.Block_Count) return(NDR_ILLEGAL_BLOCK_OR_PAGE);
+  #endif
+
+  /* Take Mutex */
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+
+  /* Copy all the vpages in the block, exit if error */
+
+  vppb = nd_info.Virt_Pages_Per_Block;
+
+  for (i = 0; i < vppb; i++)
+  {
+    /* Check we're not skipping this vpage */
+
+    if (i != vpignore)
+    {
+      /* Read the vpage (also reads the spare area) */
+
+      result = read_nand((BLI_UINT64)nd_info.Virt_Page_Size, nd_info.Virt_Page_Count,
+                         (sourceblock * vppb) + i, &pagecopybuffer[0], (BLI_UINT64) 0, nd_info.Virt_Page_Size, flags, &pageused);
+
+      /* If we're only copying used vpages then do the check
+         skip over the write if the vpage has not been written */
+      pageused = true;
+      if (flags & NDR_FLAGS_USEDMARKER)
+      {
+        if (!pageused) continue;
+      }
+
+      /* abort the copy if we got an error during the read */
+
+      if (result < NDR_SUCCESS) break;
+
+      /* Write the vpage, any error here aborts the copy */
+
+      result = nand_dev_write_vpage((destblock * vppb) + i, &pagecopybuffer[0], 0, nd_info.Virt_Page_Size, (flags | NDR_FLAGS_VERIFY));
+
+      if (result != NDR_SUCCESS) break;
+    }
+  }
+
+  up(&nand_dev_sema);
+
+  /* Return Success */
+
+  return(result);
+}
+
+
+/*****************
+ * Is Vpage Used *
+ *****************/
+
+NDR_ERROR nand_dev_is_vpage_used(BLI_UINT32 vpage)
+{
+  /* Locals */
+
+  BLI_INT32   pageused,result;
+
+  /* Take Mutex */
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+
+  pageused = is_vpage_erased(vpage);
+
+   if (pageused != NDR_IS_ERASED)
+      result = NDR_VPAGE_IS_USED;
+  else
+  	  result = NDR_VPAGE_NOT_USED;
+
+
+  up(&nand_dev_sema);
+  return result;
+}
+
+
+/*******************
+ * Read spare area *
+ *******************/
+
+/* Entry   : vpage - The virtual page who's spare bytes you want to read
+             data  - Destination Address for data
+
+   Returns : NDR error code (see header file)
+
+   Notes   : This function will probably only be of use if you are
+             implementing your own error correction (or detection)
+             routines.                                             */
+
+NDR_ERROR nand_dev_read_spare(BLI_UINT32 vpage, BLI_VOID* data)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = read_spare(vpage,data);
+  up(&nand_dev_sema);
+  return result;
+}
+
+
+/********************
+ * Write spare area *
+ ********************/
+
+/* Entry   : vpage - The virtual page who's spare bytes you want to write
+             data  - Source Address for data
+
+   Returns : NDR error code (see header file)
+
+   Notes   : This function will probably only be of use if you are
+             implementing your own error correction (or detection)
+             routines.
+
+             We have to re-enable PARTIAL_PAGE_EN here as there seems
+             to be a bug in the controller which corrupts the data
+             if this is disabled :(                                         */
+
+NDR_ERROR nand_dev_write_spare(BLI_UINT32 vpage, BLI_VOID* data)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = write_spare(vpage,data);
+  up(&nand_dev_sema);
+  return result;
+}
+
+
+/**********************
+ * Is a block erased? *
+ **********************/
+
+/* block   : block - The block to check
+
+   Returns : NDR error code (see header file)
+
+   Notes   : Returns
+             the pages in the block to determine if it is erased.     */
+
+NDR_ERROR nand_dev_is_block_erased(BLI_UINT32 block)
+{
+  /* Locals */
+
+  BLI_INT32   result;
+  BLI_UINT32  vppb;
+  BLI_UINT32  i;
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+
+  /* Check all virtial pages in this block */
+
+  vppb = nd_info.Virt_Pages_Per_Block;
+
+  for (i = 0; i < vppb; i++)
+  {
+    result = is_vpage_erased((block * vppb) + i);
+
+    if (result != NDR_IS_ERASED)
+    {
+	  up(&nand_dev_sema);
+      return(result);
+    }
+  }
+  /* return block erased */
+  up(&nand_dev_sema);
+  return(NDR_IS_ERASED);
+}
+
+
+/*******************
+ * Is page erased? *
+ *******************/
+
+/* block   : page - The Page to check
+
+   Returns : NDR error code (see header file)
+
+   Notes   : Returns
+             the pages in the block to determine if it is erased.     */
+
+NDR_ERROR nand_dev_is_page_erased(BLI_UINT32 page)
+{
+  /* Locals */
+
+  BLI_INT32   result;
+  BLI_UINT32  vppp;
+  BLI_UINT32  i;
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  /* Check all virtial pages in this page */
+
+  vppp = nd_info.Virt_Pages_Per_Page;
+
+  for (i = 0; i < vppp; i++)
+  {
+    result = is_vpage_erased((page * vppp) + i);
+
+    if (result != NDR_IS_ERASED)
+    {
+	  up(&nand_dev_sema);
+      return(result);
+    }
+  }
+  /* return block erased */
+  up(&nand_dev_sema);
+  return(NDR_IS_ERASED);
+}
+
+
+/*****************************
+ * Is a virtual page erased? *
+ *****************************/
+
+/* Entry   : page - The page to check
+
+   Returns : NDR error code (see header file)
+
+   Notes   :
+*/
+NDR_ERROR nand_dev_is_vpage_erased(BLI_UINT32 vpage)
+{
+  NDR_ERROR result;
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  result = is_vpage_erased(vpage);
+  up(&nand_dev_sema);
+  return result;
+}
+/*******************
+ * Is a block bad? *
+ *******************/
+
+/* Entry   : block - The block to check
+
+   Returns : NDR error code (see header file)
+
+   Notes   : This reads the bad block information byte located in the spare
+             area of the first or second page in the block.                  */
+
+NDR_ERROR nand_dev_is_block_bad(BLI_UINT32 block)
+{
+  /* Locals */
+
+  BLI_INT32   result;
+  BLI_UINT32  vpage;
+  BLI_UINT32  page_address;
+  BLI_UINT8  *sparebuff8;
+  BLI_UINT32  i;
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+  /* Setup destination buffer */
+  sparebuff8 = (BLI_UINT8*)&pagebuffer_r[0];
+  for (i = 0; i < nd_info.Spare_Area_Size; i++)
+    sparebuff8[i] = 0xFF;
+
+  /* Calculate address of page */
+  page_address = block * nd_info.Block_Size;
+
+  for (i = 0; i < 2; i++)
+  {
+
+    /* Calclulate number of page */
+    vpage = page_address/nd_info.Page_Size;
+	result = read_spare(vpage,sparebuff8);
+	if (result != NDR_SUCCESS)
+    {
+      goto end;
+    }
+	if (sparebuff8[nand_bad_block_offset] != 0xFF)
+	{
+	  result = NDR_BLOCK_IS_BAD;
+	  goto end;
+	}
+    /* Advance to next page */
+    page_address += nd_info.Page_Size;
+  }
+  result = NDR_BLOCK_IS_GOOD;
+
+  /* Return result */
+  end:
+  up(&nand_dev_sema);
+  return(result);
+}
+
+
+/*********************
+ * Mark Block as bad *
+ *********************/
+
+/* Entry   : block - The block to mark as bad
+
+   Returns : NDR error code (see header file)
+
+   Notes   : This writes the bad block information bytes located in the spare
+             area of the first and second page in the block. */
+
+NDR_ERROR nand_dev_mark_block_bad(BLI_UINT32 block)
+{
+  /* Locals */
+
+  BLI_INT32   result;
+  BLI_UINT32  vpage;
+  BLI_UINT32  page_address;
+  BLI_UINT8  *sparebuff8;
+  BLI_UINT32  i;
+
+  if (down_interruptible(&nand_dev_sema)) return(NDR_SYS_ERROR);
+
+  /* Setup destination buffer */
+  sparebuff8 = (BLI_UINT8*)&pagebuffer_r[0];
+  for (i = 0; i < nd_info.Spare_Area_Size; i++)
+    sparebuff8[i] = 0xFF;
+
+  sparebuff8[nand_bad_block_offset] = 0xF0;
+
+  /* Calculate address of page */
+  page_address = block * nd_info.Block_Size;
+
+  /* We need to mark bad in the first two pages of the block */
+
+  for (i = 0; i < 2; i++)
+  {
+    /* Calclulate number of page */
+    vpage = page_address/nd_info.Page_Size;
+	result = write_spare(vpage,sparebuff8);
+	if (result != NDR_SUCCESS)
+    {
+      goto end;
+    }
+	/* Advance to next page */
+    page_address += nd_info.Page_Size;
+  }
+  result = NDR_SUCCESS;
+
+  /* Return result */
+  end:
+  up(&nand_dev_sema);
+  return(result);
+}
+
+
+/****************
+ * Return CRC32 *
+ ****************/
+
+/* We may as well export this so higher levels can do their own CRC checks */
+
+BLI_UINT32 nand_dev_calc_crc32(BLI_VOID* data, BLI_UINT32 crc, BLI_UINT32 count)
+{
+  return(calc_crc32(data, crc, nand_crc_table,count));
+}
+
+
+/************************************************************************
+ *                     Internal -  Read and Write                       *
+ ************************************************************************/
+ /*****************************
+  * Is a virtual page erased? *
+  *****************************/
+
+ /* Entry   : page - The page to check
+
+    Returns : NDR error code (see header file)
+
+    Notes   :
+ */
+ static NDR_ERROR  is_vpage_erased(BLI_UINT32 vpage)
+ {
+
+  /* Locals */
+   BLI_INT32   result;
+   BLI_UINT8  *pagebuffer;
+   BLI_UINT32  i;
+   BLI_INT32   used;
+
+   /* Setup destination buffer */
+   pagebuffer = (BLI_UINT8*)&pagecopybuffer[0];
+   for (i = 0; i < nd_info.Virt_Page_Size; i++)
+     pagebuffer[i] = 0xFF;
+
+   result = read_nand((BLI_UINT64)nd_info.Virt_Page_Size, nd_info.Virt_Page_Count,vpage,&pagebuffer[0],0,nd_info.Virt_Page_Size,0,NULL);
+   if (result != NDR_SUCCESS)
+   {
+     goto end;
+   }
+   used = 0;
+   for (i = 0; i < nd_info.Virt_Page_Size; i++)
+         used |= (pagebuffer[i] != 0xFF);
+
+   if (used) result = NDR_NOT_ERASED;
+   else result = NDR_IS_ERASED;
+
+   end:
+   return(result);
+
+}
+/*******************
+ * Read spare area *
+ *******************/
+
+/* Entry   : vpage - The virtual page who's spare bytes you want to read
+				 data  - Destination Address for data
+
+   Returns : NDR error code (see header file)
+
+   Notes   : This function will probably only be of use if you are
+			 implementing your own error correction (or detection)
+			 routines.											   */
+
+static NDR_ERROR read_spare(BLI_UINT32 vpage, BLI_VOID* data)
+{
+  /* Locals */
+
+  NDR_ERROR   result;
+  BLI_UINT64  vpage_address;
+  BLI_UINT8   *d;
+  BLI_UINT32  *sparebuff;
+  BLI_INT32   i;
+  BLI_UINT32  copy;
+
+  /* Bail if the driver is not initialised */
+
+  if (!nand_driver_initialised)
+  {
+    return(NDR_NOT_INITIALISED);
+  }
+
+  /* Check page in range */
+
+ #if PARAM_CHECK
+  if (vpage >= nd_info.Virt_Page_Count)
+  {
+    return(NDR_ILLEGAL_BLOCK_OR_PAGE);
+  }
+  #endif
+
+  /* Calculate address of virtual page */
+
+  vpage_address = (vpage * nd_info.Virt_Page_Size);
+
+  /* Setup destination buffer */
+
+  sparebuff = (BLI_UINT32*)&sparebuffer[0];
+  copy = (spare_area_size + 0xF) & 0x30;
+
+/* Clear the correctable / unncorrectable error registers */
+  BCHP_REG(BCHP_NAND_ECC_CORR_ADDR)     = 0;
+  BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_ADDR)      = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR)  = 0;
+  /* Ensure controller is ready before we start */
+
+  result = wait_ready();
+
+  if (result != NDR_SUCCESS)
+  {
+    goto end;
+  }
+
+  /* Read all the spares */
+
+  for (i = 0; i < sub_pages_per_page; i++)
+  {
+	/* Set Base Address */
+
+	BCHP_REG(BCHP_NAND_CMD_ADDRESS) 	= vpage_address & 0xffffffff;
+	BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = lrshift64(vpage_address, 32) | cs_ext_select;
+
+	vpage_address += NAND_CACHE_SIZE;
+
+	/* Tell the controller to read the spares */
+
+	BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_PAGE_READ << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+
+	/* Wait for controller ready */
+
+	result = wait_ready();
+
+	if (result != NDR_SUCCESS)
+	{
+	  goto end;
+	}
+
+	/* Transfer the data to the buffer */
+	nand_read_oob(sparebuff,copy);
+	sparebuff += (copy/4);
+
+	/* Clear the correctable / unncorrectable error registers */
+	BCHP_REG(BCHP_NAND_ECC_CORR_ADDR)     = 0;
+	BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+	BCHP_REG(BCHP_NAND_ECC_UNC_ADDR)      = 0;
+  	BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR)  = 0;
+
+  }
+  result = NDR_SUCCESS;
+
+  /* Copy data back to caller ... */
+  d = (BLI_UINT8*)data;
+  for (i = 0; i < sub_pages_per_page; i++)
+  {
+	memcopy08(d, &sparebuffer[i*copy], spare_area_size);
+	d += spare_area_size;
+  }
+
+  end:
+
+  /* Return Success */
+  return(result);
+}
+
+
+/********************
+ * Write spare area *
+ ********************/
+
+/* Entry   : vpage - The virtual page who's spare bytes you want to write
+			 data  - Source Address for data
+
+   Returns : NDR error code (see header file)
+
+   Notes   : This function will probably only be of use if you are
+			 implementing your own error correction (or detection)
+			 routines.
+
+			 We have to re-enable PARTIAL_PAGE_EN here as there seems
+			 to be a bug in the controller which corrupts the data
+			 if this is disabled :( 										*/
+
+static NDR_ERROR write_spare(BLI_UINT32 vpage, BLI_VOID* data)
+{
+  /* Locals */
+
+  NDR_ERROR   result;
+  BLI_UINT64  vpage_address;
+  BLI_UINT8   *d;
+  BLI_UINT32  *sparebuff;
+  BLI_UINT32  status;
+  BLI_UINT32  copy;
+  BLI_INT32   i,j;
+  volatile BLI_UINT32 *nand_flash_cache = (BLI_UINT32*)PHYS_TO_KSEG1(NAND_CACHE_BASE);
+
+  /* Bail if the driver is not initialised */
+
+  if (!nand_driver_initialised)
+  {
+	return(NDR_NOT_INITIALISED);
+  }
+
+  /* Check page in range */
+
+ #if PARAM_CHECK
+  if (vpage >= nd_info.Virt_Page_Count)
+  {
+	return(NDR_ILLEGAL_BLOCK_OR_PAGE);
+  }
+  #endif
+
+  /* Copy data from  caller to aligned buffer */
+  copy = (spare_area_size + 0xF) & 0x30;
+  d = (BLI_UINT8*)data;
+  for (i = 0; i < sub_pages_per_page; i++)
+  {
+	  memcopy08(&sparebuffer[i*copy],d,spare_area_size);
+	  d += spare_area_size;
+  }
+
+  /* Disable ECC to write spare Area in Raw Mode*/
+  if(nd_info.ECC_Enabled)
+  	ECC_DISABLE();
+  /* Ensure controller is ready before we start */
+  result = wait_ready();
+
+  if (result != NDR_SUCCESS)
+  {
+	goto end;
+  }
+
+
+  /* Calculate address of virtual page */
+  vpage_address = (vpage * nd_info.Virt_Page_Size);
+  sparebuff = (BLI_UINT32*)&sparebuffer[0];
+
+  for (i = 0; i < sub_pages_per_page; i++)
+  {
+	/* Set Base Address */
+
+	BCHP_REG(BCHP_NAND_CMD_ADDRESS) 	= vpage_address & 0xffffffff;
+	BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = lrshift64(vpage_address, 32) | cs_ext_select;
+
+	vpage_address += NAND_CACHE_SIZE;
+
+	/* Transfer the data to the spare holding registers */
+	nand_write_oob(sparebuff,copy);
+	sparebuff += (copy/4);
+
+	for (j = 0; j < NAND_CACHE_SIZE/4; j++ )
+		 nand_flash_cache[j] = 0xFFFFFFFF;
+
+	/* Tell the controller to write the spares */
+
+	BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_PROGRAM_PAGE << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+
+	/* Wait for controller ready */
+
+	result = wait_ready();
+
+	if (result != NDR_SUCCESS)
+	{
+	  goto end;
+	}
+  }
+
+  result = NDR_SUCCESS;
+  /* Check for error */
+
+  status = BCHP_REG(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_FLASH_STATUS_MASK;
+
+  if (status & DEVICE_STATUS_ERROR)
+  {
+	result = NDR_DEVICE_PROGRAM_ERROR;
+	goto end;
+  }
+
+  #ifdef CHECK_WRITEPROTECT
+  if (!(status & DEVICE_STATUS_NOT_WRITE_PROTECT))
+  {
+	result = NDR_WRITE_PROTECTED;
+  }
+  #endif
+
+  /* Return Result */
+  end:
+  /* Enable ECC */
+  if(nd_info.ECC_Enabled)
+  	ECC_ENABLE();
+
+  return(result);
+}
+
+/*************************
+ * Read a block or page  *
+ *************************/
+
+/* Entry   : unit_size - Size of a block or page
+             num_units - The number of blocks or pages on the device
+             unit      - The block or page number to start at
+             data      - Destination address
+             offset    - Offset within the block or page to begin reading at
+             length    - The number of bytes to read
+
+   Returns : NDR error code (see header file)
+
+   Notes   : If the destination address is misaligned then performance will suffer. */
+
+static NDR_ERROR read_nand(BLI_UINT64 unit_size, BLI_UINT32 unit_count, BLI_UINT32 unit, BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags, BLI_BOOL *pageused)
+{
+  /* Locals */
+
+  BLI_UINT64  source_address;
+  BLI_UINT32  dest_address;
+  BLI_UINT8   *crc_source;
+  BLI_UINT8   b;
+  BLI_UINT64  start_offs;
+  BLI_UINT64  slice;
+  BLI_UINT32  slices;
+  BLI_UINT32  offs;
+  BLI_UINT32  len;
+  BLI_UINT32  crc;
+  BLI_UINT32  crc_calc;
+  BLI_BOOL    uncorr_error;
+  BLI_BOOL    corr_error;
+  BLI_BOOL    crc_error;
+  BLI_BOOL    page_used;
+  BLI_UINT32  *sparebuff;
+  BLI_INT32   result,copy;
+  BLI_UINT32  i;
+  BLI_INT32 oob_bitflips, data_bitflips, total_bitflips, oob_nbits, data_nbits;
+
+  /* Bail if the driver is not initialised */
+
+  if (!nand_driver_initialised)
+  {
+    return(NDR_NOT_INITIALISED);
+  }
+
+  /* Check the unit number, offset and length are legal */
+
+  #if PARAM_CHECK
+  if (unit >= unit_count)
+  {
+    return(NDR_ILLEGAL_BLOCK_OR_PAGE);
+  }
+
+  if (offset >= unit_size)
+  {
+    return(NDR_ILLEGAL_OFFSET);
+  }
+
+  if ((length == 0) || (length > unit_size))
+  {
+    return(NDR_ILLEGAL_LENGTH);
+  }
+
+  if ((offset + length) > unit_size)
+  {
+    return(NDR_CANT_CROSS_BOUNDARY);
+  }
+
+  #endif
+
+  /* Calculate the start address and offset in NAND */
+
+  start_offs     = (unit * unit_size) + offset;
+  slice          = start_offs / NAND_CACHE_SIZE;
+  offs           = start_offs % NAND_CACHE_SIZE;
+  source_address = (slice * NAND_CACHE_SIZE);
+
+  /* Ensure controller is ready before we start */
+
+  result = wait_ready();
+
+  if (result != NDR_SUCCESS)
+  {
+    return(result);
+  }
+
+  /* Set the destination address */
+
+  dest_address = (BLI_UINT32) data;
+
+  /* Calculate the number of slices we need to read */
+
+  slices = length / NAND_CACHE_SIZE;
+  slices += ((length % NAND_CACHE_SIZE) + offs + (NAND_CACHE_SIZE - 1)) / NAND_CACHE_SIZE;
+
+  /* Clear the correctable / unncorrectable error registers */
+
+  BCHP_REG(BCHP_NAND_ECC_CORR_ADDR)     = 0;
+  BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_ADDR)      = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR)  = 0;
+
+  /* Clear the last two extended spare area read words (in case 27bye spare area) */
+
+  BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_18) = 0xffffffff;
+  BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_1C) = 0xffffffff;
+
+  /* Pointer to spare buffer (dwords) */
+
+  sparebuff = (BLI_UINT32*)&sparebuffer[0];
+  copy      = (spare_area_size + 0xF) & 0x30;
+
+  /* Read the slices */
+
+  uncorr_error = FALSE;
+  corr_error   = FALSE;
+  crc_error    = FALSE;
+
+  for (i = 0; i < slices; i++)
+  {
+
+    /* Calculate the length for this slice */
+
+    if (length > (NAND_CACHE_SIZE - offs))
+    {
+      len = (NAND_CACHE_SIZE - offs);
+    }
+    else
+    {
+      len = length;
+    }
+
+    /* Set Base Address */
+
+    BCHP_REG(BCHP_NAND_CMD_ADDRESS)     = source_address & 0xffffffff;
+    BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = lrshift64(source_address, 32) | cs_ext_select;
+
+    /* Tell the controller to read the data */
+
+    BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_PAGE_READ << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+
+    /* Wait for controller ready */
+
+    result = wait_ready();
+
+    if (result != NDR_SUCCESS)
+    {
+      return(result);
+    }
+
+    /* Now we copy the data from the slice cache ...
+
+       - We leave crcsource set up for the CRC routine
+
+       - We clear offs after the transfer as it is only needed for
+         the first slice
+
+       - If the destination is mislaigned OR we're doing a partial
+         slice then we have to use a slow byte transfer!              */
+
+    if ((dest_address & 3) || (offs) || (len != NAND_CACHE_SIZE))
+    {
+      /* Transfer to aligned buffer for the CRC routine as we don't
+         want to read the controller cache twice as it's much slower
+         than normal memory!!                                        */
+
+      crc_source = (BLI_UINT8*)&pagebuffer_r[0];
+      memcopy32(crc_source, (BLI_UINT8*)PHYS_TO_KSEG1(NAND_CACHE_BASE), NAND_CACHE_SIZE);
+
+      /* Copy from the pagebuffer back to the user */
+
+      memcopy08((BLI_UINT8*)dest_address, (BLI_UINT8*)&pagebuffer_r[offs], len);
+    }
+    else
+    {
+      crc_source = (BLI_UINT8*)dest_address;
+      memcopy32(crc_source, (BLI_UINT8*)PHYS_TO_KSEG1(NAND_CACHE_BASE), NAND_CACHE_SIZE);
+    }
+
+    /* Transfer the data from the spare holding registers */
+
+    nand_read_oob(sparebuff,copy);
+
+    /* Was the page used marker set? */
+
+    page_used = false;
+
+    if (flags & NDR_FLAGS_USEDMARKER)
+    {
+      b = sparebuffer[nand_data_valid_offset];
+      if ((b >= 0xf0) && (b <= 0xf3)) page_used = true;
+    }
+    else
+    {
+      page_used = true;
+    }
+
+    if (pageused) *pageused = page_used;
+
+    /* Check the CRC */
+
+    if ((flags & NDR_FLAGS_CRC) && (page_used))
+    {
+      crc  = sparebuffer[nand_data_crc32_offset + 0];
+      crc <<= 8;
+      crc |= sparebuffer[nand_data_crc32_offset + 1];
+      crc <<= 8;
+      crc |= sparebuffer[nand_data_crc32_offset + 2];
+      crc <<= 8;
+      crc |= sparebuffer[nand_data_crc32_offset + 3];
+
+      crc_calc = calc_crc32(crc_source, 0, nand_crc_table, NAND_CACHE_SIZE);
+
+      if (crc != crc_calc)
+      {
+        crc_error = TRUE;
+      }
+    }
+
+    if (nd_info.ECC_Enabled)
+    {
+      /* Check for correctable error */
+
+      if ((BCHP_REG(BCHP_NAND_ECC_CORR_ADDR) != 0) || (BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) != 0))
+      {
+        BCHP_REG(BCHP_NAND_ECC_CORR_ADDR) = 0;
+        BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+        corr_error = TRUE;
+      }
+
+      /* Check for uncorrectable error */
+
+      if ((BCHP_REG(BCHP_NAND_ECC_UNC_ADDR) != 0) || (BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR) != 0))
+      {
+        BCHP_REG(BCHP_NAND_ECC_UNC_ADDR) = 0;
+        BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR) = 0;
+        oob_nbits = spare_area_size << 3;
+        data_nbits = NAND_CACHE_SIZE << 3;
+        oob_bitflips = oob_nbits - countsetbits((BLI_UINT8*)sparebuff,spare_area_size);
+        crc_source = (BLI_UINT8*)&pagebuffer_r[0];
+        memcopy32(crc_source, (BLI_UINT8*)PHYS_TO_KSEG1(NAND_CACHE_BASE), NAND_CACHE_SIZE);
+        data_bitflips = data_nbits - countsetbits((BLI_UINT8*)crc_source,NAND_CACHE_SIZE);
+        total_bitflips = data_bitflips + oob_bitflips;
+        if (total_bitflips < sparemaps[ecc_spare_area_layout].corr_stat_threshold)
+        {
+		   total_bitflips = 0;
+		   crc_error = FALSE;
+		   corr_error = TRUE;
+		   crc_source = (BLI_UINT8*)dest_address;
+		   memset08(crc_source,0xFF,len);
+	 	}
+	 	else
+	 	{
+		   uncorr_error = TRUE;
+		}
+
+      } /* if ((BCHP_REG(BCHP_NAND_ECC_UNC_ADDR) != 0) || (BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR) != 0)) */
+
+    } /* if (nd_info.ECC_Enabled) */
+
+    /* Advance the source and destination addresses, decrement the length
+	 also clear offset (offs) as it is only needed for the first loop   */
+
+	source_address += NAND_CACHE_SIZE;
+	dest_address   += len;
+	length         -= len;
+   offs            = 0;
+
+  } /* for (i = 0; i < slices; i++) */
+
+  /* Return if crc/correctable/uncorrectable error detected */
+
+  if ((uncorr_error) || (crc_error))
+  {
+    return(NDR_UNCORRECTABLE_ERROR);
+  }
+
+  if (corr_error)
+  {
+    return(NDR_CORRECTABLE_ERROR);
+  }
+
+  /* Return success */
+
+  return(NDR_SUCCESS);
+}
+
+
+/**************************
+ * Write a block or page  *
+ **************************/
+
+/* Entry   : unit_size - Size of a block or page
+             num_units - The number of blocks or pages on the device
+             unit      - The block or page number to start at
+             data      - Source address
+             offset    - Offset within the block or page to begin writing from
+             length    - The number of bytes to write
+
+   Returns : NDR error code (see header file)
+
+   Notes   : If the source address is misaligned then performance will suffer. */
+
+
+static NDR_ERROR write_nand(BLI_UINT64 unit_size, BLI_UINT32 unit_count, BLI_UINT32 unit, BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  /* Locals */
+
+  BLI_UINT32  source_address_wr;
+  BLI_UINT32  source_address_rd;
+  BLI_UINT64  dest_address;
+  BLI_UINT32  dest_page;
+  BLI_UINT64  start_offs;
+  BLI_UINT64  slice;
+  BLI_UINT32  slices;
+  BLI_UINT32  source;
+  BLI_UINT32  len;
+  BLI_UINT32  llen;
+  BLI_UINT32  clen;
+  BLI_UINT32  crc;
+  BLI_UINT32  status;
+  BLI_UINT32  *clear;
+  BLI_UINT8  *sparebuff8;
+  BLI_UINT8  *sparebuff;
+  BLI_INT32   result,copy;
+  BLI_BOOL    uncorr_error;
+  BLI_BOOL    corr_error;
+  BLI_UINT32  i,j,k;
+
+  /* Bail if the driver is not initialised */
+
+  if (!nand_driver_initialised)
+  {
+    return(NDR_NOT_INITIALISED);
+  }
+
+  /* Check the unit number, offset and length are legal */
+
+  #if PARAM_CHECK
+  if (unit >= unit_count)
+  {
+    return(NDR_ILLEGAL_BLOCK_OR_PAGE);
+  }
+
+  if (offset >= unit_size)
+  {
+    return(NDR_ILLEGAL_OFFSET);
+  }
+
+  if ((length == 0) || (length > unit_size))
+  {
+    return(NDR_ILLEGAL_LENGTH);
+  }
+
+  if ((offset + length) > unit_size)
+  {
+    return(NDR_CANT_CROSS_BOUNDARY);
+  }
+
+  if(offset & virt_page_mask)
+  {
+     return(NDR_ILLEGAL_OFFSET);
+  }
+  #endif
+
+  /* Deactivate SYNCSPAREONWRITE flag if ECC is hamming */
+
+  if (ecctype == NDR_ECC_TYPE_HAMMING)
+  {
+    flags &= ~NDR_FLAGS_SYNCSPAREONWRITE;
+  }
+
+  /* Calculate the start address and offset in NAND */
+
+  start_offs   = (unit * unit_size) + offset;
+  slice        = lrshift64(start_offs, virt_page_shift);
+  dest_address = (slice * virt_page_size);
+
+  /* Ensure controller is ready before we start */
+
+  result = wait_ready();
+
+  if (result != NDR_SUCCESS)
+  {
+    return(result);
+  }
+
+  /* Set the destination address */
+
+  source_address_wr = (BLI_UINT32) data;
+  source_address_rd = (BLI_UINT32) data;
+
+  /* Clear the correctable / uncorrectable error readback */
+
+  BCHP_REG(BCHP_NAND_ECC_CORR_ADDR)     = 0;
+  BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_ADDR)      = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR)  = 0;
+
+  /* Calculate the number of slices we need to write */
+
+  slices = length / virt_page_size;
+  slices += ((length % virt_page_size) + (virt_page_size - 1)) / virt_page_size;
+
+  /* Write the slices */
+
+  for (i = 0; i < slices; i++)
+  {
+    /* Calculate the length for this slice */
+
+    if (length > virt_page_size)
+    {
+      len = virt_page_size;
+    }
+    else
+    {
+      len = length;
+    }
+
+    /* WRITE - Inner_loop */
+
+    llen = len;
+
+	/* Set the spare buffer pointer and its copy count */
+    sparebuff8  = (BLI_UINT8*)&sparebuffer[0];
+    copy = (spare_area_size + 0xF) & 0x30;
+
+	for (k = 0; k < (copy *sub_pages_per_page); k++)
+  	    sparebuffer[k] = 0xff;
+
+	/* Read the spare area and store it in sparebuffer */
+	if (flags & NDR_FLAGS_SYNCSPAREONWRITE)
+	{
+		dest_page = (dest_address & 0xFFFFFFFF) >> virt_page_shift;
+		sparebuff = (BLI_UINT8*)&pagebuffer_w[0];
+		result = read_spare(dest_page,sparebuff );
+		if (result != NDR_SUCCESS)
+		{
+	      return(result);
+		}
+		for (j = 0; j < sub_pages_per_page; j++)
+		{
+      		memcopy08(sparebuff8, sparebuff, spare_area_size);
+      		sparebuff8 += copy;
+			sparebuff  += spare_area_size;
+  		}
+
+	}
+	sparebuff8  = &sparebuffer[0];
+    for (j = 0; j < sub_pages_per_page; j++)
+    {
+      /* Are we writing less than the NAND_CACHE_SIZE? */
+
+      if (llen < NAND_CACHE_SIZE)
+      {
+        clen = llen;
+      }
+      else
+      {
+        clen = NAND_CACHE_SIZE;
+      }
+
+      llen -= NAND_CACHE_SIZE;
+
+
+      /* If source misaligned (or writing less than a page) then copy to aligned buffer */
+
+      if ((source_address_wr & 3) || (clen != NAND_CACHE_SIZE))
+      {
+        clear = (BLI_UINT32*)&pagebuffer_w[0];
+        k = NAND_CACHE_SIZE / 16;
+
+        while (k--)
+        {
+          *clear++ = 0xffffffff;
+          *clear++ = 0xffffffff;
+          *clear++ = 0xffffffff;
+          *clear++ = 0xffffffff;
+        }
+        memcopy08((BLI_UINT8*)&pagebuffer_w[0], (BLI_UINT8*)source_address_wr, clen);
+        source = (BLI_UINT32)&pagebuffer_w[0];
+      }
+      else
+      {
+        source = source_address_wr;
+      }
+
+      /* Set Base Address */
+
+      BCHP_REG(BCHP_NAND_CMD_ADDRESS)     = (dest_address + (j * NAND_CACHE_SIZE)) & 0xFFFFFFFF;
+      BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = lrshift64((dest_address + (j * NAND_CACHE_SIZE)), 32) | cs_ext_select;
+
+      /* Increment source address now! */
+
+      source_address_wr += NAND_CACHE_SIZE;
+
+      /* Now copy the data to the slice cache - MUST USE WORD TRANSFERS! */
+
+      memcopy32((BLI_UINT8*)PHYS_TO_KSEG1(NAND_CACHE_BASE), (BLI_UINT8*)source, NAND_CACHE_SIZE);
+
+      if ((flags & NDR_FLAGS_CRC) || (flags & NDR_FLAGS_USEDMARKER))
+      {
+        /* Generate the CRC - Place in spare area */
+
+        if (flags & NDR_FLAGS_CRC)
+        {
+          crc = calc_crc32((BLI_UINT8*)source, 0, nand_crc_table, NAND_CACHE_SIZE);
+          sparebuff8[nand_data_crc32_offset + 3] = (crc >> 0)  & 0xff;
+          sparebuff8[nand_data_crc32_offset + 2] = (crc >> 8)  & 0xff;
+          sparebuff8[nand_data_crc32_offset + 1] = (crc >> 16) & 0xff;
+          sparebuff8[nand_data_crc32_offset + 0] = (crc >> 24) & 0xff;
+        }
+
+        /* Set PAGEUSED */
+        if (flags & NDR_FLAGS_USEDMARKER)
+        {
+          if(sub_pages_per_page == 1)
+          	sparebuff8[nand_data_valid_offset] = 0xf0 + j;
+		  else /* For 2k/4k page write mode, write only 0xF0 */
+		  	sparebuff8[nand_data_valid_offset] = 0xf0;
+        }
+      }
+	  /* Write OOB registers */
+	  nand_write_oob((BLI_UINT32*)&sparebuff8[0],copy);
+	  sparebuff8 += copy;
+
+      /* Tell the controller to write the data */
+
+      BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_PROGRAM_PAGE << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+
+      /* Wait for controller ready */
+
+      result = wait_ready();
+
+      if (result != NDR_SUCCESS)
+      {
+        return(result);
+      }
+
+      /* Check for error */
+
+      status = BCHP_REG(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_FLASH_STATUS_MASK;
+
+      if (status & DEVICE_STATUS_ERROR)
+      {
+        return(NDR_DEVICE_PROGRAM_ERROR);
+      }
+
+      #ifdef CHECK_WRITEPROTECT
+      if (!(status & DEVICE_STATUS_NOT_WRITE_PROTECT))
+      {
+        return(NDR_WRITE_PROTECTED);
+      }
+      #endif
+    } /* for (j = 0; j < sub_pages_per_page; j++) */
+
+    /* Verify */
+
+    if (flags & NDR_FLAGS_VERIFY)
+    {
+      corr_error = false;
+      uncorr_error = false;
+      llen = len;
+
+      for (j = 0; j < sub_pages_per_page; j++)
+      {
+        /* Are we writing less than the NAND_CACHE_SIZE? */
+
+        if (llen < NAND_CACHE_SIZE)
+        {
+          clen = llen;
+        }
+        else
+        {
+          clen = NAND_CACHE_SIZE;
+        }
+
+        llen -= NAND_CACHE_SIZE;
+
+        /* Set Base Address */
+
+        BCHP_REG(BCHP_NAND_CMD_ADDRESS)     = (dest_address + (j * NAND_CACHE_SIZE)) & 0xffffffff;
+        BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = lrshift64((dest_address + (j * NAND_CACHE_SIZE)), 32) | cs_ext_select;
+
+        /* Tell the controller to read the data */
+
+        BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_PAGE_READ << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+
+        /* Wait for controller ready */
+
+        result = wait_ready();
+
+        if (result != NDR_SUCCESS)
+        {
+          return(result);
+        }
+
+        /* Set corr/uncorr error vars */
+
+        if ((BCHP_REG(BCHP_NAND_ECC_CORR_ADDR) != 0) || (BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) != 0))
+        {
+          corr_error = TRUE;
+        }
+
+        if ((BCHP_REG(BCHP_NAND_ECC_UNC_ADDR) != 0) || (BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR) != 0))
+        {
+          uncorr_error = TRUE;
+        }
+
+        /* Now Check we got back what we wrote */
+		 memcopy32(&pagebuffer_r[0], (BLI_UINT8*)PHYS_TO_KSEG1(NAND_CACHE_BASE), NAND_CACHE_SIZE);
+        if (!memcompare08((BLI_UINT8*)source_address_rd, &pagebuffer_r[0], clen))
+        {
+        	return(NDR_DEVICE_VERIFY_ERROR);
+
+        }
+        /* Fix the source address */
+
+        source_address_rd += NAND_CACHE_SIZE;
+
+        /* IF ECC is enabled check the hardware for errors */
+
+        if (nd_info.ECC_Enabled)
+        {
+          if (uncorr_error)
+          {
+            BCHP_REG(BCHP_NAND_ECC_UNC_ADDR) = 0;
+            BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR) = 0;
+            return(NDR_DEVICE_ECC_ERROR);
+          }
+          if (corr_error)
+          {
+			/* Let read decide what to do instead of verify */
+			BCHP_REG(BCHP_NAND_ECC_CORR_ADDR) = 0;
+            BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+	  	  }
+        }
+
+      } /* for (j = 0; j < sub_pages_per_page; j++) */
+    } /* if (verify) */
+
+    /* Fix source address offset and length, increment dest address */
+
+    dest_address   += virt_page_size;
+    length         -= len;
+
+  } /* for (i = 0; i < slices; i++) */
+
+  /* Return success */
+
+  return(NDR_SUCCESS);
+}
+#ifdef BCHP_NAND_ACC_CONTROL_CS0
+/**********************************
+ * Write a block with cache mode  *
+ **********************************/
+
+/* Entry   : unit_size - Size of a block
+             num_units - The number of blocks on the device
+             unit      - The block number to start at
+             data      - Source address
+             offset    - Offset within the block or page to begin writing from
+             length    - The number of bytes to write
+
+   Returns : NDR error code (see header file)
+
+   Notes   : If the source address is misaligned then performance will suffer. */
+
+static NDR_ERROR write_nandblock_cached(BLI_UINT64 unit_size, BLI_UINT32 unit_count, BLI_UINT32 unit, BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags)
+{
+  /* Locals */
+
+  BLI_UINT32  source_address_wr;
+  BLI_UINT32  source_address_rd;
+  BLI_UINT64  dest_address;
+  BLI_UINT64  start_offs;
+  BLI_UINT64  slice;
+  BLI_UINT32  slices;
+  BLI_UINT32  source;
+  BLI_UINT32  crc;
+  BLI_UINT32  status;
+  BLI_UINT32  *clear;
+  BLI_INT32   result,copy;
+  BLI_UINT32  i,j,k;
+  BLI_UINT32  reg,old_reg_value;
+  BLI_BOOL    uncorr_error,corr_error;
+
+  /* Bail if the driver is not initialised */
+
+  if (!nand_driver_initialised)
+  {
+    return(NDR_NOT_INITIALISED);
+  }
+
+  /* Check the unit number, offset and length are legal */
+
+  #if PARAM_CHECK
+  if (unit >= unit_count)
+  {
+    return(NDR_ILLEGAL_BLOCK_OR_PAGE);
+  }
+
+  if (offset >= unit_size)
+  {
+    return(NDR_ILLEGAL_OFFSET);
+  }
+
+  if (length != nd_info.Block_Size)
+  {
+    return(NDR_ILLEGAL_LENGTH);
+  }
+  if(offset & virt_page_mask)
+  {
+	  return(NDR_ILLEGAL_OFFSET);
+  }
+  if ((offset + length) > unit_size)
+  {
+    return(NDR_CANT_CROSS_BOUNDARY);
+  }
+
+  #endif
+
+  /* Calculate the start address and offset in NAND */
+
+  start_offs   = (unit * unit_size) + offset;
+  slice        = lrshift64(start_offs, virt_page_shift);
+  dest_address = (slice * virt_page_size);
+
+  /* Ensure controller is ready before we start */
+
+  result = wait_ready();
+
+  if (result != NDR_SUCCESS)
+  {
+    return(result);
+  }
+
+  /* Set the destination address */
+
+  source_address_wr = (BLI_UINT32) data;
+  source_address_rd = (BLI_UINT32) data;
+
+  copy = (spare_area_size + 0xF) & 0x30;
+
+ /* Calculate the number of slices we need to write */
+
+  slices = length / virt_page_size;
+
+  /* Write the slices */
+  old_reg_value = BCHP_REG(REG_ACC_CONTROL);
+  reg = old_reg_value;
+  reg |= BCHP_NAND_ACC_CONTROL_CACHE_MODE_EN_MASK;
+  BCHP_REG(REG_ACC_CONTROL) = reg;
+
+  for (i = 0; i < slices; i++)
+  {
+
+    if(i == (slices - 1))
+    {
+		reg |= BCHP_NAND_ACC_CONTROL_CACHE_MODE_LAST_PAGE_MASK;
+		BCHP_REG(REG_ACC_CONTROL) = reg;
+	}
+
+    for (j = 0; j < sub_pages_per_page; j++)
+    {
+      /* If source misaligned (or writing less than a page) then copy to aligned buffer */
+
+      if (source_address_wr & 3)
+      {
+        clear = (BLI_UINT32*)&pagebuffer_w[0];
+        k = NAND_CACHE_SIZE / 16;
+
+        while (k--)
+        {
+          *clear++ = 0xffffffff;
+          *clear++ = 0xffffffff;
+          *clear++ = 0xffffffff;
+          *clear++ = 0xffffffff;
+        }
+        memcopy08((BLI_UINT8*)&pagebuffer_w[0], (BLI_UINT8*)source_address_wr, NAND_CACHE_SIZE);
+        source = (BLI_UINT32)&pagebuffer_w[0];
+      }
+      else
+      {
+        source = source_address_wr;
+      }
+
+	  /* Clear Spare Buffer */
+      for (k = 0; k < copy; k++)
+  	    sparebuffer[k] = 0xff;
+
+      /* Set Base Address */
+
+      BCHP_REG(BCHP_NAND_CMD_ADDRESS)     = (dest_address + (j * NAND_CACHE_SIZE)) & 0xFFFFFFFF;
+      BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = lrshift64((dest_address + (j * NAND_CACHE_SIZE)), 32) | cs_ext_select;
+
+      /* Increment source address now! */
+
+      source_address_wr += NAND_CACHE_SIZE;
+
+      /* Now copy the data to the slice cache - MUST USE WORD TRANSFERS! */
+
+      memcopy32((BLI_UINT8*)PHYS_TO_KSEG1(NAND_CACHE_BASE), (BLI_UINT8*)source, NAND_CACHE_SIZE);
+
+      if ((flags & NDR_FLAGS_CRC) || (flags & NDR_FLAGS_USEDMARKER))
+      {
+        /* Generate the CRC - Place in spare area */
+
+        if (flags & NDR_FLAGS_CRC)
+        {
+          crc = calc_crc32((BLI_UINT8*)source, 0, nand_crc_table, NAND_CACHE_SIZE);
+          sparebuffer[nand_data_crc32_offset + 3] = (crc >> 0)  & 0xff;
+          sparebuffer[nand_data_crc32_offset + 2] = (crc >> 8)  & 0xff;
+          sparebuffer[nand_data_crc32_offset + 1] = (crc >> 16) & 0xff;
+          sparebuffer[nand_data_crc32_offset + 0] = (crc >> 24) & 0xff;
+        }
+        	/* Set PAGEUSED */
+		if (flags & NDR_FLAGS_USEDMARKER)
+		{
+		    if(sub_pages_per_page == 1)
+		    	sparebuffer[nand_data_valid_offset] = 0xf0 + j;
+		    else /* For 2k/4k page write mode, write only 0xF0 */
+				sparebuffer[nand_data_valid_offset] = 0xf0;
+        }
+
+      }
+      /* Write OOB registers */
+	  nand_write_oob((BLI_UINT32*)&sparebuffer[0],copy);
+
+      /* Tell the controller to write the data */
+
+      BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_PROGRAM_PAGE << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+
+      /* Wait for controller ready */
+      result = wait_ready();
+      if (result != NDR_SUCCESS)
+      {
+	     BCHP_REG(REG_ACC_CONTROL) = old_reg_value;
+        return(result);
+      }
+      status = BCHP_REG(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_FLASH_STATUS_MASK;
+      if (status & (DEVICE_STATUS_ERROR | DEVICE_STATUS_CACHE_ERROR))
+      {
+	     BCHP_REG(REG_ACC_CONTROL) = old_reg_value;
+	     return(NDR_DEVICE_PROGRAM_ERROR);
+      }
+
+    } /* for (j = 0; j < sub_pages_per_page; j++) */
+
+    /* Fix source address offset and length, increment dest address */
+
+    dest_address   += virt_page_size;
+    length         -= virt_page_size;
+
+  } /* for (i = 0; i < slices; i++) */
+
+  BCHP_REG(REG_ACC_CONTROL) = old_reg_value;
+
+
+  BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_STATUS_READ << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+  result = wait_ready();
+  if (result != NDR_SUCCESS) return(result);
+  /* Return success */
+  status = BCHP_REG(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_FLASH_STATUS_MASK;
+
+  if (status & (DEVICE_STATUS_ERROR | DEVICE_STATUS_CACHE_ERROR))
+  {
+  	return(NDR_DEVICE_PROGRAM_ERROR);
+  }
+  #ifdef CHECK_WRITEPROTECT
+  if (!(status & DEVICE_STATUS_NOT_WRITE_PROTECT))
+  {
+  	return(NDR_WRITE_PROTECTED);
+  }
+  #endif
+
+
+  if(!(flags & NDR_FLAGS_VERIFY))
+  	return(NDR_SUCCESS);
+
+  corr_error = false;
+  uncorr_error = false;
+
+  /* Clear the correctable / uncorrectable error readback */
+
+  BCHP_REG(BCHP_NAND_ECC_CORR_ADDR)     = 0;
+  BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_ADDR)      = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR)  = 0;
+
+  dest_address = (slice * virt_page_size);
+  source_address_rd = (BLI_UINT32) data;
+
+  old_reg_value = BCHP_REG(REG_ACC_CONTROL);
+  reg = old_reg_value;
+  reg |= BCHP_NAND_ACC_CONTROL_PREFETCH_EN_MASK;
+  BCHP_REG(REG_ACC_CONTROL) = reg;
+
+  for (i = 0; i < slices; i++)
+  {
+    for (j = 0; j < sub_pages_per_page; j++)
+    {
+
+        /* Set Base Address */
+        BCHP_REG(BCHP_NAND_CMD_ADDRESS)     = (dest_address + (j * NAND_CACHE_SIZE)) & 0xffffffff;
+        BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = lrshift64((dest_address + (j * NAND_CACHE_SIZE)), 32) | cs_ext_select;
+
+        /* Tell the controller to read the data */
+
+        BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_PAGE_READ << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+
+        /* Wait for controller ready */
+
+        result = wait_ready();
+
+        if (result != NDR_SUCCESS)
+        {
+		  BCHP_REG(REG_ACC_CONTROL) = old_reg_value;
+          return(result);
+        }
+
+        /* Set corr/uncorr error vars */
+
+        if ((BCHP_REG(BCHP_NAND_ECC_CORR_ADDR) != 0) || (BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) != 0))
+        {
+           corr_error = TRUE;
+        }
+
+        if ((BCHP_REG(BCHP_NAND_ECC_UNC_ADDR) != 0) || (BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR) != 0))
+        {
+          uncorr_error = TRUE;
+        }
+
+        memcopy32(&pagebuffer_r[0], (BLI_UINT8*)PHYS_TO_KSEG1(NAND_CACHE_BASE), NAND_CACHE_SIZE);
+        if (!memcompare08((BLI_UINT8*)source_address_rd, &pagebuffer_r[0], NAND_CACHE_SIZE))
+		{
+			BCHP_REG(REG_ACC_CONTROL) = old_reg_value;
+			return(NDR_DEVICE_VERIFY_ERROR);
+        }
+        source_address_rd += NAND_CACHE_SIZE;
+
+        if (nd_info.ECC_Enabled)
+        {
+          if (uncorr_error)
+		  {
+		     BCHP_REG(BCHP_NAND_ECC_UNC_ADDR) = 0;
+		     BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR) = 0;
+		     BCHP_REG(REG_ACC_CONTROL) = old_reg_value;
+		     return(NDR_DEVICE_ECC_ERROR);
+		  }
+		  if (corr_error)
+		  {
+			 /* Let read decide what to do instead of verify */
+		     BCHP_REG(BCHP_NAND_ECC_CORR_ADDR) = 0;
+		     BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+	  	  }
+        }
+      } /* for (j = 0; j < sub_pages_per_page; j++) */
+
+      /* Fix source address offset and length, increment dest address */
+      dest_address   += virt_page_size;
+
+  } /* for (i = 0; i < slices; i++) */
+
+    /* Return success */
+  BCHP_REG(REG_ACC_CONTROL) = old_reg_value;
+  return(NDR_SUCCESS);
+}
+#endif
+/****************************************************************************
+ *                               Subroutines                                *
+ ****************************************************************************/
+/*****************************
+ * Write Spare Registers     *
+ *****************************/
+static void nand_write_oob(BLI_UINT32 *buffer, BLI_INT32 oob_size)
+{
+    BLI_UINT32 *obb;
+	obb = buffer;
+
+	BCHP_REG(BCHP_NAND_SPARE_AREA_WRITE_OFS_0) = force_native_endian(obb[0]);
+    BCHP_REG(BCHP_NAND_SPARE_AREA_WRITE_OFS_4) = force_native_endian(obb[1]);
+    BCHP_REG(BCHP_NAND_SPARE_AREA_WRITE_OFS_8) = force_native_endian(obb[2]);
+    BCHP_REG(BCHP_NAND_SPARE_AREA_WRITE_OFS_C) = force_native_endian(obb[3]);
+	if (oob_size > 16)
+	{
+	    #if defined(BCHP_NAND_SPARE_AREA_WRITE_OFS_10)
+	    BCHP_REG(BCHP_NAND_SPARE_AREA_WRITE_OFS_10) = force_native_endian(obb[4]);
+	    BCHP_REG(BCHP_NAND_SPARE_AREA_WRITE_OFS_14) = force_native_endian(obb[5]);
+	    BCHP_REG(BCHP_NAND_SPARE_AREA_WRITE_OFS_18) = force_native_endian(obb[6]);
+	    BCHP_REG(BCHP_NAND_SPARE_AREA_WRITE_OFS_1C) = force_native_endian(obb[7]);
+		#endif
+	}
+}
+/*****************************
+ * Read Spare Registers      *
+ *****************************/
+static void nand_read_oob(BLI_UINT32 *buffer, BLI_INT32 oob_size)
+{
+    BLI_UINT32 *obb;
+	obb = buffer;
+
+	obb[0] = force_native_endian(BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_0));
+	obb[1] = force_native_endian(BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_4));
+	obb[2] = force_native_endian(BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_8));
+	obb[3] = force_native_endian(BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_C));
+	if (oob_size > 16)
+	{
+        #if defined(BCHP_NAND_SPARE_AREA_READ_OFS_10)
+		obb[4] = force_native_endian(BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_10));
+		obb[5] = force_native_endian(BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_14));
+		obb[6] = force_native_endian(BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_18));
+		obb[7] = force_native_endian(BCHP_REG(BCHP_NAND_SPARE_AREA_READ_OFS_1C));
+      	#endif
+	}
+}
+
+#ifdef FIX_BROKEN_BCM_NAND_AUTODETECT
+
+#ifdef BCHP_NAND_CMD_START_OPCODE_PARAMETER_READ
+/**************************************
+ * Calculate CRC16 for ONFI data      *
+ *************************************/
+static BLI_UINT16 nand_onfi_crc16(BLI_UINT16 crc, BLI_UINT8 *p, BLI_INT32 len)
+{
+	int i;
+	while (len--) {
+		crc ^= *p++ << 8;
+		for (i = 0; i < 8; i++)
+			crc = (crc << 1) ^ ((crc & 0x8000) ? 0x8005 : 0);
+	}
+	return crc;
+}
+/**************************************
+ * Detect ONFI compliant chips        *
+ **************************************/
+static BLI_BOOL nand_onfi_detect(void)
+{
+	BLI_INT32 i,result;
+	BLI_UINT32 temp, *ptr;
+	BLI_UINT16 crc,spare_sz;
+	BLI_UINT32 offset;
+	BLI_UINT32 nand_dev_id_1;
+	BLI_UINT8 O,N,F,I;
+	volatile BLI_UINT32 *nand_flash_cache = (BLI_UINT32*)PHYS_TO_KSEG1(NAND_CACHE_BASE);
+
+    /* Disable Auto detect */
+    temp = BCHP_REG(BCHP_NAND_CS_NAND_SELECT) ;
+	temp &= ~ BCHP_NAND_CS_NAND_SELECT_AUTO_DEVICE_ID_CONFIG_MASK;
+	BCHP_REG(BCHP_NAND_CS_NAND_SELECT) = temp;
+
+    /* reset the nand flash on BRCM_CHIP_SELECT CS  first */
+	temp = BCHP_REG(BCHP_NAND_CMD_START);
+	temp &= ~BCHP_NAND_CMD_START_OPCODE_MASK;
+	temp |= BCHP_NAND_CMD_START_OPCODE_FLASH_RESET << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+	BCHP_REG(BCHP_NAND_CMD_START) = temp;
+	result = wait_ready();
+    if (result != NDR_SUCCESS) return(FALSE);
+
+	BCHP_REG(BCHP_NAND_CMD_ADDRESS)     = 0x20;
+	BCHP_REG(BCHP_NAND_CMD_START)       = (BCHP_NAND_CMD_START_OPCODE_DEVICE_ID_READ << BCHP_NAND_CMD_START_OPCODE_SHIFT);
+
+	result = wait_ready();
+    if (result != NDR_SUCCESS) return(FALSE);
+
+    nand_dev_id_1 = BCHP_REG(BCHP_NAND_FLASH_DEVICE_ID);
+
+    O = (BLI_UINT8)((nand_dev_id_1 >> 24) & 0xFF);
+    N = (BLI_UINT8)((nand_dev_id_1 >> 16) & 0xFF);
+    F = (BLI_UINT8)((nand_dev_id_1 >> 8) & 0xFF);
+    I = (BLI_UINT8)(nand_dev_id_1 & 0xFF);
+
+    if(( O != 'O') || ( N != 'N' ) || ( F != 'F') || ( I != 'I'))return(FALSE);
+
+
+	BCHP_REG(BCHP_NAND_CMD_ADDRESS)  = 0;
+	BCHP_REG(BCHP_NAND_CMD_START)    = (BCHP_NAND_CMD_START_OPCODE_PARAMETER_READ << BCHP_NAND_CMD_START_OPCODE_SHIFT);;
+
+    result = wait_ready();
+	if (result != NDR_SUCCESS) return(FALSE);
+
+    ptr  =(BLI_UINT32 *) &pagebuffer_r[0];
+    for (i = 0; i < NAND_CACHE_SIZE/4; i++ )
+    {
+		temp = nand_flash_cache[i];
+		ptr[i] = force_native_endian(temp);
+    }
+    crc =0;
+    offset = 0;
+    for (i = 0; i < 2; i++)
+    {
+		offset = (i*256);
+		crc = *((unsigned short*)&pagebuffer_r[offset+ONFI_CRC_OFFSET]);
+		if (nand_onfi_crc16(ONFI_CRC_BASE, (BLI_UINT8*)&pagebuffer_r[offset], 254) == crc)
+		{
+			break;
+		}
+	}
+	if(i==2)  return(FALSE);
+
+	nand_device.page_size  = *((BLI_UINT32*)&pagebuffer_r[offset+ONFI_PAGE_SIZE_OFFSET]);
+	spare_sz               = *((BLI_UINT16*)&pagebuffer_r[offset+ONFI_SPARE_SIZE_OFFSET]);
+    nand_device.spare_size = (BLI_UINT32)spare_sz;
+    nand_device.block_size = *((BLI_UINT32*)&pagebuffer_r[offset+ONFI_NO_PAGE_PER_BLOCK_OFFSET]);
+	nand_device.block_size *=  nand_device.page_size;
+	nand_device.device_size = *((BLI_UINT32*)&pagebuffer_r[offset+ONFI_NO_BLOCK_PER_LUN]);
+	nand_device.device_size *= nand_device.block_size * (BLI_UINT32)pagebuffer_r[offset+ONFI_NO_LUN];
+    return (TRUE);
+
+}
+#endif /* BCHP_NAND_CMD_START_OPCODE_PARAMETER_READ */
+/**************************************************
+ * Supportive subroutine for nand_decode_ext_id() *
+ *************************************************/
+static BLI_INT32 nand_id_has_period(BLI_UINT8 *id_data, BLI_INT32 arrlen, BLI_INT32 period)
+{
+	BLI_INT32 i, j;
+	for (i = 0; i < period; i++)
+		for (j = i + period; j < arrlen; j += period)
+			if (id_data[i] != id_data[j])
+				return 0;
+	return 1;
+}
+/**************************************************
+ * Supportive subroutine for nand_decode_ext_id() *
+ *************************************************/
+static BLI_INT32 nand_id_len(BLI_UINT8 *id_data, BLI_INT32 arrlen)
+{
+	BLI_INT32 last_nonzero, period;
+
+	/* Find last non-zero byte */
+	for (last_nonzero = arrlen - 1; last_nonzero >= 0; last_nonzero--)
+		if (id_data[last_nonzero])
+			break;
+
+	/* All zeros */
+	if (last_nonzero < 0)
+		return 0;
+
+	/* Calculate wraparound period */
+	for (period = 1; period < arrlen; period++)
+		if (nand_id_has_period(id_data, arrlen, period))
+			break;
+
+	/* There's a repeated pattern */
+	if (period < arrlen)
+		return period;
+
+	/* There are trailing zeros */
+	if (last_nonzero < arrlen - 1)
+		return last_nonzero + 1;
+
+	/* No pattern detected */
+	return arrlen;
+}
+/**************************************
+ * Decode Extended ID of Nand chips   *
+ **************************************/
+static BLI_BOOL nand_decode_ext_id(BLI_UINT8 *id_data)
+{
+
+	BLI_INT32 extid, id_len;
+	BLI_UINT32 tmp;
+	BLI_UINT32 page_sz,spare_sz,block_sz;
+	BLI_INT8 cellinfo = id_data[2];
+	extid = id_data[3];
+	id_len = nand_id_len(id_data, 8);
+
+	/* Samsung Identification */
+	if (id_len == 6 && id_data[0] == MAN_SAMSUNG_ID &&
+			(cellinfo  & MAN_CI_CELLTYPE_MSK) &&
+			id_data[5] != 0x00) {
+
+		page_sz = 2048 << (extid & 0x03);
+		extid >>= 2;
+
+
+		switch (((extid >> 2) & 0x04) | (extid & 0x03))
+		{
+			case 1:
+				spare_sz = 128;
+				break;
+			case 2:
+				spare_sz = 218;
+				break;
+			case 3:
+				spare_sz = 400;
+				break;
+			case 4:
+				spare_sz = 436;
+				break;
+			case 5:
+				spare_sz = 512;
+				break;
+			case 6:
+			default:
+				spare_sz = 0;
+				break;
+		}
+		extid >>= 2;
+		block_sz= (128 * 1024) <<(((extid >> 1) & 0x04) | (extid & 0x03));
+
+	}
+	/* Hynix Identification */
+	else if (id_len == 6 && id_data[0] == MAN_HYNIX_ID &&
+			(cellinfo & MAN_CI_CELLTYPE_MSK))
+	{
+
+
+		page_sz = 2048 << (extid & 0x03);
+		extid >>= 2;
+		switch (((extid >> 2) & 0x04) | (extid & 0x03))
+		{
+			case 0:
+				spare_sz = 128;
+				break;
+			case 1:
+				spare_sz = 224;
+				break;
+			case 2:
+				spare_sz = 448;
+				break;
+			case 3:
+				spare_sz = 64;
+				break;
+			case 4:
+				spare_sz = 32;
+				break;
+			case 5:
+				spare_sz = 16;
+				break;
+			default:
+				spare_sz = 0;
+				break;
+		}
+		extid >>= 2;
+		tmp = ((extid >> 1) & 0x04) | (extid & 0x03);
+		if (tmp < 0x03)
+			block_sz= (128 * 1024) << tmp;
+		else if (tmp == 0x03)
+			block_sz= 768 * 1024;
+		else
+			block_sz= (64 * 1024) << tmp;
+
+	}
+	/* Other identification with Toshiba 24nm */
+	else
+	{
+		page_sz = 1024 << (extid & 0x03);
+
+		extid >>= 2;
+		spare_sz = (8 << (extid & 0x01)) * (page_sz >> 9);
+
+		extid >>= 2;
+		block_sz= (64 * 1024) << (extid & 0x03);
+
+		extid >>= 2;
+		if(extid & 0x01)
+		    spare_sz = 0; /* 16bit bus is not supported */
+		else
+		{
+
+
+			if (id_len >= 6 && id_data[0] == MAN_TOSHIBA_ID &&
+					!(cellinfo & MAN_CI_CELLTYPE_MSK) &&
+					(id_data[5] & 0x7) == 0x6 && !(id_data[4] & 0x80))
+			{
+				spare_sz = 32 * page_sz >> 9;
+			}
+			else if((id_data[0] == MAN_TOSHIBA_ID) &&  (id_data[1] == 0xdc) &&
+					(id_data[2] == 0x90) && (id_data[3] == 0x26) && (id_data[4] == 0x76) &&
+					(id_data[5] ==  0x15)&& (id_data[6] == 0x01) && (id_data[7] == 0x08))
+			{
+					spare_sz = 28 * page_sz >> 9;
+			}
+		}
+
+	}
+	if(spare_sz == 0)
+	    return FALSE;
+	else
+	{
+		nand_device.page_size 	=  page_sz;
+		nand_device.spare_size  =  spare_sz;
+		nand_device.block_size  =  block_sz;
+	}
+	return (TRUE);
+
+}
+#endif /* FIX_BROKEN_BCM_NAND_AUTODETECT */
+/***********************
+ * Initialise Hardware *
+ ***********************/
+
+/* Entry   : Pointer to variable to recieve NAND_CONFIG
+
+   Returns : TRUE (success), FALSE (failed)
+
+   Notes   : This does all the nasty setup to get the NAND device up and running */
+
+static BLI_BOOL initialise_hardware(BLI_UINT32 *config)
+{
+  /* Locals */
+
+  volatile BLI_INT32  delay;
+  volatile BLI_UINT32 reg;
+  BLI_UINT32 page_config;
+  #if !defined(FORCE_ECC_SPARE_AREA_LAYOUT) && !defined(READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE)
+  BLI_BOOL            valid;
+  #endif
+  #ifdef FIX_BROKEN_BCM_NAND_AUTODETECT
+  BLI_UINT32 dev_id, dev_id2;
+  BLI_UINT8  id[8];
+  BLI_BOOL            found;
+  BLI_INT32           result;
+  BLI_INT32           i;
+  #endif
+  #if defined(FORCE_ECC_SPARE_AREA_LAYOUT) || defined(READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE)  || defined(FIX_BROKEN_BCM_NAND_AUTODETECT)
+  BLI_UINT32          brcmecc;
+  #endif
+  #if defined (READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE)
+  BLI_UINT32          v1;
+  BLI_UINT32          v2;
+  #endif
+
+
+  /*-----------------------------------------------------------------------*/
+  /* Clear the Address bus XORing */
+
+  BCHP_REG(BCHP_NAND_CS_NAND_XOR) = 0;
+
+  /* Configure NAND_CMD_EXT_ADDRESS */
+
+  reg = BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS);
+  reg &= ~BCHP_NAND_CMD_EXT_ADDRESS_CS_SEL_MASK;
+
+  #ifdef SYSTEM_IS_NAND_ONLY
+  reg |= (0 << BCHP_NAND_CMD_EXT_ADDRESS_CS_SEL_SHIFT);
+  #else
+  reg |= (1 << BCHP_NAND_CMD_EXT_ADDRESS_CS_SEL_SHIFT);
+  #endif
+
+  BCHP_REG(BCHP_NAND_CMD_EXT_ADDRESS) = reg;
+
+  /* Set the chip select */
+
+  reg = BCHP_REG(BCHP_NAND_CS_NAND_SELECT);
+  reg &= ~BCHP_NAND_CS_NAND_SELECT_EBI_CS_0_SEL_MASK;
+  reg &= ~BCHP_NAND_CS_NAND_SELECT_EBI_CS_1_SEL_MASK;
+
+  BCHP_REG(BCHP_NAND_CS_NAND_SELECT) = reg;
+
+  /* Detect the ONFI chips before autodetect */
+  #ifdef FIX_BROKEN_BCM_NAND_AUTODETECT
+  found = FALSE;
+  #ifdef BCHP_NAND_CMD_START_OPCODE_PARAMETER_READ
+  found = nand_onfi_detect();
+  #else
+  found = FALSE;
+  #endif
+  #endif
+
+  /* Request Autodetect of flash chip ID and size */
+
+  reg  = BCHP_REG(BCHP_NAND_CS_NAND_SELECT);
+  reg  |= BCHP_NAND_CS_NAND_SELECT_AUTO_DEVICE_ID_CONFIG_MASK;
+
+  BCHP_REG(BCHP_NAND_CS_NAND_SELECT) = reg;
+
+  /* Wait 20 milliseconds for autodetect to complete */
+
+  delay = DELAY_ONE_MSEC * 20;
+  while (delay--) reg = BCHP_REG(REG_CONFIG);
+
+  #ifdef FIX_BROKEN_BCM_NAND_AUTODETECT
+
+  BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_FLASH_RESET << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+  result = wait_ready();
+  if (result != NDR_SUCCESS) return(FALSE);
+  BCHP_REG(BCHP_NAND_CMD_ADDRESS)  = 0;
+  BCHP_REG(BCHP_NAND_CMD_START) = BCHP_NAND_CMD_START_OPCODE_DEVICE_ID_READ << BCHP_NAND_CMD_START_OPCODE_SHIFT;
+  result = wait_ready();
+  if (result != NDR_SUCCESS) return(FALSE);
+
+  dev_id = BCHP_REG(BCHP_NAND_FLASH_DEVICE_ID);
+  dev_id2 = BCHP_REG(BCHP_NAND_FLASH_DEVICE_ID_EXT);
+
+  id[0] =(BLI_UINT8) (dev_id >> 24) & 0xFF;
+  id[1] =(BLI_UINT8) (dev_id >> 16) & 0xFF;
+  id[2] =(BLI_UINT8) (dev_id >> 8) & 0xFF;
+  id[3] =(BLI_UINT8) (dev_id >> 0) & 0xFF;
+  id[4] =(BLI_UINT8) (dev_id2 >> 24) & 0xFF;
+  id[5] =(BLI_UINT8) (dev_id2 >> 16) & 0xFF;
+  id[6] =(BLI_UINT8) (dev_id2 >> 8) & 0xFF;
+  id[7] =(BLI_UINT8) (dev_id2 >> 0) & 0xFF;
+  if (dev_id == 0)
+  {
+	 return(FALSE);
+  }
+  /* Disable AUTO Device ID detection */
+  reg = BCHP_REG(BCHP_NAND_CS_NAND_SELECT) ;
+  reg &= ~ BCHP_NAND_CS_NAND_SELECT_AUTO_DEVICE_ID_CONFIG_MASK;
+  BCHP_REG(BCHP_NAND_CS_NAND_SELECT) = reg;
+  if(found != TRUE)
+  {
+	for(i = 0; i < MAX_NAND_IDS; i++)
+	{
+		if(nand_ids[i].id == id[1])
+			break;
+	}
+	if(i == MAX_NAND_IDS)return(FALSE);
+	nand_device.device_size =  nand_ids[i].msize;
+
+	found = nand_decode_ext_id(&id[0]);
+	if(found != TRUE) return(FALSE);
+
+  }
+
+  /* Parameter check */
+  if((nand_device.page_size < 2048) || (nand_device.page_size > 4096)) return (FALSE);
+  if(nand_device.spare_size > 256) return (FALSE);
+  if(nand_device.block_size > (512UL << 10)) return (FALSE);
+  if((nand_device.device_size < (128UL << 20)) || (nand_device.device_size > (512UL << 20))) return (FALSE);
+
+    /* Set config */
+  reg = BCHP_REG(REG_CONFIG);
+  reg &= ~(BCHP_NAND_CONFIG_BLOCK_SIZE_MASK | BCHP_NAND_CONFIG_DEVICE_SIZE_MASK | BCHP_NAND_CONFIG_PAGE_SIZE_MASK);
+
+  dev_id = (nand_device.block_size == 0x20000)?BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_128KB:(nand_device.block_size == 0x40000)?BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_256KB:BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_512KB;
+  reg |= dev_id << BCHP_NAND_CONFIG_BLOCK_SIZE_SHIFT;
+
+  dev_id = (nand_device.device_size == (128UL << 20))?BCHP_NAND_CONFIG_DEVICE_SIZE_DVC_SIZE_128MB:(nand_device.device_size == (256UL << 20))?BCHP_NAND_CONFIG_DEVICE_SIZE_DVC_SIZE_256MB:BCHP_NAND_CONFIG_DEVICE_SIZE_DVC_SIZE_512MB;
+  reg |= dev_id << BCHP_NAND_CONFIG_DEVICE_SIZE_SHIFT;
+
+  dev_id = (nand_device.page_size == 2048)?BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_2KB:BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_4KB;
+  reg |= dev_id << BCHP_NAND_CONFIG_PAGE_SIZE_SHIFT;
+
+  BCHP_REG(REG_CONFIG) = reg;
+
+  sub_pages_per_page = nand_device.page_size/NAND_CACHE_SIZE;
+  chip_spare_area_size = nand_device.spare_size;
+  spare_area_size    = nand_device.spare_size/sub_pages_per_page;
+
+  #ifndef SYSTEM_IS_NAND_ONLY
+
+  /* Hack to support Micron 2048+224 nand chip */
+  if(spare_area_size > 32)
+  {
+    spare_area_size = 32;
+  }
+  brcmecc          = (spare_area_size == 16)?4:12;
+
+  #ifdef FORCE_HAMMING_FOR_LEGACY_CHIP
+  if(spare_area_size == 16) brcmecc = 15;
+  #endif
+  reg   = BCHP_REG(REG_ACC_CONTROL);
+  reg   &= ~( BCHP_NAND_ACC_CONTROL_ECC_LEVEL_MASK | BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_MASK);
+  reg   |= (brcmecc << BCHP_NAND_ACC_CONTROL_ECC_LEVEL_SHIFT);
+  reg   |= (spare_area_size << BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_SHIFT);
+
+  BCHP_REG(REG_ACC_CONTROL) = reg;
+
+  #endif /* SYSTEM_IS_NAND_ONLY */
+
+  sub_pages_per_page = spare_area_size = brcmecc = 0;
+
+  #endif /* FIX_BROKEN_BCM_NAND_AUTODETECT */
+
+  /*-----------------------------------------------------------------------*/
+
+  /* Now we read the ECC type and spare area size and use
+     this to calculate 'ecc_spare_area_layout' for later  */
+
+  #if !defined(FORCE_ECC_SPARE_AREA_LAYOUT) && !defined(READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE)
+
+  #if defined(BCHP_NAND_ACC_CONTROL_ECC_LEVEL_MASK)
+
+  reg   = BCHP_REG(REG_ACC_CONTROL);
+  reg  &= BCHP_NAND_ACC_CONTROL_ECC_LEVEL_MASK;
+  reg >>= BCHP_NAND_ACC_CONTROL_ECC_LEVEL_SHIFT;
+
+  switch(reg)
+  {
+    case 4:
+      ecctype = NDR_ECC_TYPE_BCH4;
+      errorbits = 4;
+    break;
+
+    case 8:
+      ecctype = NDR_ECC_TYPE_BCH8;
+      errorbits = 8;
+    break;
+
+    case 12:
+      ecctype = NDR_ECC_TYPE_BCH12;
+      errorbits = 12;
+    break;
+
+    case 15:
+      ecctype = NDR_ECC_TYPE_HAMMING;
+      errorbits = 1;
+    break;
+
+    default:
+      return(FALSE);
+    break;
+  }
+
+  #else
+
+  ecctype = NDR_ECC_TYPE_HAMMING;
+  errorbits = 1;
+
+  #endif
+
+  /* Get the spare area size */
+
+  #if defined(BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_MASK)
+
+  reg   = BCHP_REG(REG_ACC_CONTROL);
+  reg  &= BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_MASK;
+  reg >>= BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_SHIFT;
+
+  spare_area_size = reg;
+
+  #else
+
+  spare_area_size = 16;
+
+  #endif
+
+  /* Now check to see if the above correponds to one
+     of our supported modes!
+  */
+  valid = false;
+
+  if ((ecctype == NDR_ECC_TYPE_HAMMING) && (spare_area_size == 16))
+  {
+    ecc_spare_area_layout = NDR_LAYOUT_HAMMING_16B_SPARE;
+    valid = true;
+  }
+
+  if ((ecctype == NDR_ECC_TYPE_BCH4) && (spare_area_size == 16))
+  {
+    ecc_spare_area_layout = NDR_LAYOUT_BCH4_16B_SPARE;
+    valid = true;
+  }
+
+  if ((ecctype == NDR_ECC_TYPE_BCH8) && (spare_area_size == 27))
+  {
+    ecc_spare_area_layout = NDR_LAYOUT_BCH8_27B_SPARE;
+    valid = true;
+  }
+
+
+  if ((ecctype == NDR_ECC_TYPE_BCH12) && (spare_area_size == 27))
+  {
+    ecc_spare_area_layout = NDR_LAYOUT_BCH12_27B_SPARE;
+    valid = true;
+  }
+
+  if ((ecctype == NDR_ECC_TYPE_BCH8) && (spare_area_size == 32))
+  {
+    ecc_spare_area_layout = NDR_LAYOUT_BCH8_32B_SPARE;
+    valid = true;
+  }
+
+  if ((ecctype == NDR_ECC_TYPE_BCH12) && (spare_area_size == 32))
+  {
+    ecc_spare_area_layout = NDR_LAYOUT_BCH12_32B_SPARE;
+    valid = true;
+  }
+
+  if ((ecctype == NDR_ECC_TYPE_BCH12) && (spare_area_size == 28))
+  {
+    ecc_spare_area_layout = NDR_LAYOUT_BCH12_28B_SPARE;
+    valid = true;
+  }
+
+  if (!valid) return(false);
+
+  #endif /* #ifndef FORCE_ECC_SPARE_AREA_LAYOUT */
+
+  /*-----------------------------------------------------------------------*/
+
+  #if defined(FORCE_ECC_SPARE_AREA_LAYOUT) || defined (READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE)
+
+  #ifdef READ_ECC_SPARE_AREA_LAYOUT_FROM_COOKIE
+
+  reg = BCHP_REG(BCHP_NAND_SEMAPHORE);
+
+  if ((reg & 0xc0) != 0xc0)
+  {
+    return(false);
+  }
+
+  v1  = reg & 7;
+  v2  = (reg >> 3) & 7;
+  v2 ^=7;
+  if (v1 != v2)
+  {
+    return(false);
+  }
+
+  ecc_spare_area_layout = v1;
+
+  #else
+
+  ecc_spare_area_layout = FORCE_ECC_SPARE_AREA_LAYOUT;
+
+  #endif
+
+  switch(ecc_spare_area_layout)
+  {
+    case  NDR_LAYOUT_HAMMING_16B_SPARE:
+      brcmecc = 15;
+      ecctype = NDR_ECC_TYPE_HAMMING;
+      spare_area_size = 16;
+      errorbits = 1;
+    break;
+
+    case  NDR_LAYOUT_BCH4_16B_SPARE:
+      brcmecc = 4;
+      ecctype = NDR_ECC_TYPE_BCH4;
+      spare_area_size = 16;
+      errorbits = 4;
+    break;
+
+    case  NDR_LAYOUT_BCH8_27B_SPARE:
+      brcmecc = 8;
+      ecctype = NDR_ECC_TYPE_BCH8;
+      spare_area_size = 27;
+      errorbits = 8;
+    break;
+
+    case  NDR_LAYOUT_BCH8_32B_SPARE:
+      brcmecc = 8;
+      ecctype = NDR_ECC_TYPE_BCH8;
+      spare_area_size = 32;
+      errorbits = 8;
+    break;
+
+    case  NDR_LAYOUT_BCH12_27B_SPARE:
+      brcmecc = 12;
+      ecctype = NDR_ECC_TYPE_BCH12;
+      spare_area_size = 27;
+      errorbits = 12;
+    break;
+
+    case  NDR_LAYOUT_BCH12_32B_SPARE:
+      brcmecc = 12;
+      ecctype = NDR_ECC_TYPE_BCH12;
+      spare_area_size = 32;
+      errorbits = 12;
+    break;
+
+	case  NDR_LAYOUT_BCH12_28B_SPARE:
+      brcmecc = 12;
+      ecctype = NDR_ECC_TYPE_BCH12;
+      spare_area_size = 28;
+      errorbits = 12;
+    break;
+
+	default:
+      return(false);
+    break;
+  }
+
+  /* Sanity check that the fields exist! */
+
+  #if !defined(BCHP_NAND_ACC_CONTROL_ECC_LEVEL_MASK) || !defined(BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_MASK)
+  #error ERROR - No Fields in NAND_ACC_CONTROL for ECC level / Spare area size
+  #endif
+
+  /* Now set the Level / Spare area size */
+
+  reg = BCHP_REG(REG_ACC_CONTROL);
+
+  reg &= ~BCHP_NAND_ACC_CONTROL_ECC_LEVEL_MASK;
+  reg |= brcmecc << BCHP_NAND_ACC_CONTROL_ECC_LEVEL_SHIFT;
+
+  #if defined(BCHP_NAND_ACC_CONTROL_ECC_LEVEL_0_MASK)
+  reg &= ~BCHP_NAND_ACC_CONTROL_ECC_LEVEL_0_MASK;
+  reg |= brcmecc << BCHP_NAND_ACC_CONTROL_ECC_LEVEL_0_SHIFT;
+  #endif
+
+  reg &= ~BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_MASK;
+  reg |= spare_area_size << BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_SHIFT;
+
+  #if defined(BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_0_MASK)
+  reg &= ~BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_0_MASK;
+  reg |= spare_area_size << BCHP_NAND_ACC_CONTROL_SPARE_AREA_SIZE_0_SHIFT;
+  #endif
+
+  BCHP_REG(REG_ACC_CONTROL) = reg;
+
+  #endif /* FORCE_ECC_SPARE_AREA_LAYOUT */
+
+  /*-----------------------------------------------------------------------*/
+
+
+  /* Set the Correctable Error Threshold */
+
+  #if defined(BCHP_NAND_CORR_STAT_THRESHOLD)
+
+  reg = sparemaps[ecc_spare_area_layout].corr_stat_threshold;
+
+  #if !defined(SYSTEM_IS_NAND_ONLY) && defined(BCHP_NAND_CORR_STAT_THRESHOLD_CORR_STAT_THRESHOLD_CS1_SHIFT)
+
+  reg <<= BCHP_NAND_CORR_STAT_THRESHOLD_CORR_STAT_THRESHOLD_CS1_SHIFT;
+
+  #endif
+
+  BCHP_REG(BCHP_NAND_CORR_STAT_THRESHOLD) = reg;
+
+  #endif /* defined(BCHP_NAND_CORR_STAT_THRESHOLD) */
+
+  /* Set The NAND Access Control */
+
+  reg  =  BCHP_REG(REG_ACC_CONTROL);
+
+  reg |=  BCHP_NAND_ACC_CONTROL_RD_ECC_EN_MASK;         /* Enable Read ECC for blocks 1-?             */
+  reg |=  BCHP_NAND_ACC_CONTROL_WR_ECC_EN_MASK;         /* Enable write ECC for all blocks            */
+  #if defined(BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK)
+  reg |=  BCHP_NAND_ACC_CONTROL_RD_ECC_BLK0_EN_MASK;    /* Enable Read ECC for block 0                */
+  #endif
+  reg |=  BCHP_NAND_ACC_CONTROL_WR_PREEMPT_EN_MASK;     /* Enable Pre-emption                         */
+  reg |=  BCHP_NAND_ACC_CONTROL_PAGE_HIT_EN_MASK;       /* Enable page hit detection                  */
+  #if defined(BCHP_NAND_ACC_CONTROL_RD_ERASED_ECC_EN_MASK)
+  reg &= ~BCHP_NAND_ACC_CONTROL_RD_ERASED_ECC_EN_MASK;  /* Reading erased blocks DOES NOT cause error */
+  #endif
+  #if defined(BCHP_NAND_ACC_CONTROL_PARTIAL_PAGE_EN_MASK)
+  #ifdef FORCE_2K_PAGEWRITES
+  reg &= ~BCHP_NAND_ACC_CONTROL_PARTIAL_PAGE_EN_MASK;   /* New controller behaviour                   */
+  reg &= ~BCHP_NAND_ACC_CONTROL_FAST_PGM_RDIN_MASK;     /* Disable program page random data input     */
+  #else
+  reg |= BCHP_NAND_ACC_CONTROL_PARTIAL_PAGE_EN_MASK;    /* Old controller behaviour                   */
+  reg |= BCHP_NAND_ACC_CONTROL_FAST_PGM_RDIN_MASK;      /* Enable program page random data input      */
+  #endif
+  #endif
+
+  #ifdef FORCE_HAMMING_FOR_LEGACY_CHIP
+  /* For OLD config */
+  if(errorbits == 1)
+  {
+	 reg |= BCHP_NAND_ACC_CONTROL_PARTIAL_PAGE_EN_MASK;    /* Old controller behaviour                   */
+  	 reg |= BCHP_NAND_ACC_CONTROL_FAST_PGM_RDIN_MASK;      /* Enable program page random data input      */
+  }
+  #endif
+  /* For 4K page size, dont use partial page programming */
+  page_config   = BCHP_REG(REG_CONFIG);
+  page_config   = get_page_size(page_config);
+  if(page_config == 4096)
+  {
+  	reg &= ~BCHP_NAND_ACC_CONTROL_PARTIAL_PAGE_EN_MASK;   /* New controller behaviour                   */
+    reg &= ~BCHP_NAND_ACC_CONTROL_FAST_PGM_RDIN_MASK;     /* Disable program page random data input     */
+  }
+
+  BCHP_REG(REG_ACC_CONTROL) = reg;
+
+  /* Clear the correctable and uncorrectable addresses */
+
+  BCHP_REG(BCHP_NAND_ECC_CORR_ADDR)     = 0;
+  BCHP_REG(BCHP_NAND_ECC_CORR_EXT_ADDR) = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_ADDR)      = 0;
+  BCHP_REG(BCHP_NAND_ECC_UNC_EXT_ADDR)  = 0;
+
+  /* DAWN Specific High Speed Mode */
+  #if !defined(SYSTEM_IS_NAND_ONLY)
+  #if defined (FORCE_2K_PAGEWRITES) && defined (PACE_NAND_ENABLE_HIGHSPEED)
+  if(errorbits > 1)
+  {
+	BCHP_REG(BCHP_NAND_TIMING_1_CS1) = 0x33333248;
+	BCHP_REG(BCHP_NAND_TIMING_2_CS1) = 0x80000876;
+  }
+  #else
+  BCHP_REG(BCHP_NAND_TIMING_1_CS1) = BCHP_REG(BCHP_NAND_TIMING_1_CS0);
+  BCHP_REG(BCHP_NAND_TIMING_2_CS1) = BCHP_REG(BCHP_NAND_TIMING_2_CS0);
+  #endif
+  #endif
+
+  /* - Also sets cs_ext_select for later access                  */
+
+  reg = BCHP_REG(BCHP_NAND_CS_NAND_SELECT);
+  #ifdef SYSTEM_IS_NAND_ONLY
+  BCHP_REG(BCHP_NAND_CS_NAND_SELECT) = reg | BCHP_NAND_CS_NAND_SELECT_EBI_CS_0_USES_NAND_MASK;
+  cs_ext_select = 0x00000000;
+  #else
+  BCHP_REG(BCHP_NAND_CS_NAND_SELECT) = reg | BCHP_NAND_CS_NAND_SELECT_EBI_CS_1_USES_NAND_MASK;
+  cs_ext_select = 0x00010000;
+  #endif
+
+  /*-----------------------------------------------------------------------*/
+
+  /* Return the contents config register */
+
+  *config = BCHP_REG(REG_CONFIG);
+
+  return(TRUE);
+}
+
+
+/*****************************
+ * Wait for Controller ready *
+ *****************************/
+
+/* Entry   : ** NO ARGUMENTS **
+
+   Returns : either NDR_SUCCESS or DEVICE_NOT_READY
+
+   Notes   : We use a nice long timeout of approx 200 milliseconds which
+             is more than enough time for any NAND command to complete.  */
+
+static NDR_ERROR wait_ready(BLI_VOID)
+{
+  /* Locals */
+
+  BLI_INT32 delay;
+
+  /* Maximum wait time = 200 milliseconds */
+
+  delay = DELAY_ONE_MSEC * 200;
+
+  /* Wait for controller ready */
+
+  while (delay--)
+  {
+    if (BCHP_REG(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_CTLR_READY_MASK)
+    {
+      return(NDR_SUCCESS);
+    }
+  }
+
+  /* If we get here then we timed out */
+
+  return(NDR_DEVICE_NOT_READY);
+}
+
+
+/**********************
+ * Return Device Size *
+ **********************/
+
+static BLI_UINT64 get_device_size(BLI_UINT32 nand_config)
+{
+  BLI_UINT64 shft,size;
+  BLI_INT32  i;
+  shft = ((nand_config & BCHP_NAND_CONFIG_DEVICE_SIZE_MASK) >> BCHP_NAND_CONFIG_DEVICE_SIZE_SHIFT);
+  size = (4 * MEGA);
+  for (i = 0; i < shft; i++)
+  {
+    size += size;
+  }
+  return(size);
+}
+
+
+/*********************
+ * Return Block Size *
+ *********************/
+
+static BLI_INT32 get_block_size(BLI_UINT32 nand_config)
+{
+  switch((nand_config & BCHP_NAND_CONFIG_BLOCK_SIZE_MASK) >> BCHP_NAND_CONFIG_BLOCK_SIZE_SHIFT)
+  {
+    #if defined(BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_512KB)
+    case BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_512KB:
+      return  512 * 1024;
+    #endif
+
+    #if defined(BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_256KB)
+    case BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_256KB:
+      return  256 * 1024;
+    #endif
+
+    case BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_128KB:
+      return  128 * 1024;
+
+    case BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_16KB:
+      return  16 * 1024;
+
+    case BCHP_NAND_CONFIG_BLOCK_SIZE_BK_SIZE_8KB:
+      return  8 * 1024;
+
+    default:
+      return -1;
+  }
+}
+
+
+/********************
+ * Return Page Size *
+ ********************/
+
+static BLI_INT32 get_page_size(BLI_UINT32 nand_config)
+{
+  switch((nand_config & BCHP_NAND_CONFIG_PAGE_SIZE_MASK) >> BCHP_NAND_CONFIG_PAGE_SIZE_SHIFT)
+  {
+    case BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_512:
+      return 512;
+
+    case BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_2KB:
+      return 2 * 1024;
+
+    #if defined(BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_4KB)
+    case BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_4KB:
+      return 4 * 1024;
+    #endif
+
+    #if defined(BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_8KB)
+    case BCHP_NAND_CONFIG_PAGE_SIZE_PG_SIZE_8KB:
+      return 8 * 1024;
+    #endif
+
+    default:
+      return -1;
+  }
+}
+
+
+/********************************
+ * Force dword to native endian *
+ ********************************/
+
+/* To be more accurate, flip the word if needed so when you
+   store it in memory and cast a byte pointer to that address
+   the data is read back correctly                            */
+
+static BLI_UINT32 force_native_endian(BLI_UINT32 value)
+{
+  /* Locals */
+
+  BLI_UINT32 a,b,c,d;
+
+  /* Only flip if on a little endian system */
+
+  if (little_endian)
+  {
+    a = (value >> 24) & 0xff;
+    b = (value >> 16) & 0xff;
+    c = (value >> 8)  & 0xff;
+    d = (value)       & 0xff;
+    return((d << 24) | (c << 16) | (b << 8) | a);
+  }
+
+  /* System is big endian - Do nothing */
+
+  else
+  {
+    return(value);
+  }
+
+}
+
+
+/************
+ * MEMCOPY8 *
+ ************/
+
+/* Copies n bytes from source to dest */
+
+static BLI_VOID memcopy08(BLI_VOID *dest, BLI_VOID *source, BLI_UINT32 len)
+{
+  BLI_UINT8 *d = (BLI_UINT8*)dest;
+  BLI_UINT8 *s = (BLI_UINT8*)source;
+
+  while(len--)
+  {
+    *d++ = *s++;
+  }
+}
+
+
+/************
+ * MEMSET8 *
+ ************/
+/* set n bytes of dest with source byte */
+
+static BLI_VOID memset08(BLI_VOID *dest, BLI_UINT8 source, BLI_UINT32 len)
+{
+  BLI_UINT8 *d = (BLI_UINT8*)dest;
+
+  while(len--)
+  {
+    *d++ = source;
+  }
+}
+/*************
+ * MEMCOPY32 *
+ *************/
+
+/* Copies len bytes from source to dest
+
+   len must be a multiple of 16 bytes (4 words)
+
+   source and dest *MUST* be word aligned  */
+
+static BLI_VOID memcopy32(BLI_VOID *dest, BLI_VOID *source, BLI_UINT32 len)
+{
+  BLI_UINT32  *d  = (BLI_UINT32*)dest;
+  BLI_UINT32  *s  = (BLI_UINT32*)source;
+
+  len /= 16;
+
+  while(len--)
+  {
+    *d++ = *s++;
+    *d++ = *s++;
+    *d++ = *s++;
+    *d++ = *s++;
+  }
+}
+/***************
+ * MEMCOMPARE8 *
+ ***************/
+
+/* Compares len bytes between source and dest */
+
+static BLI_BOOL memcompare08(BLI_VOID *source1, BLI_VOID *source2, BLI_UINT32 len)
+{
+  BLI_UINT8 *s1 = (BLI_UINT8*)source1;
+  BLI_UINT8 *s2 = (BLI_UINT8*)source2;
+
+  while(len--)
+  {
+    if (*s1++ != *s2++) return(FALSE);
+  }
+
+  return(TRUE);
+}
+/****************
+ * MEMCOMPARE32 *
+ ****************/
+
+/* Compares len bytes between source and dest
+
+   len must be a multiple of 32 bytes (8 words)
+
+   source and dest *MUST* be word aligned */
+
+static BLI_BOOL memcompare32(BLI_VOID *source1, BLI_VOID *source2, BLI_UINT32 len)
+{
+  BLI_UINT32 *s1 = (BLI_UINT32*)source1;
+  BLI_UINT32 *s2 = (BLI_UINT32*)source2;
+  len /= 32;
+
+  while(len--)
+  {
+    if (*s1++ != *s2++) return(FALSE);
+    if (*s1++ != *s2++) return(FALSE);
+    if (*s1++ != *s2++) return(FALSE);
+    if (*s1++ != *s2++) return(FALSE);
+    if (*s1++ != *s2++) return(FALSE);
+    if (*s1++ != *s2++) return(FALSE);
+    if (*s1++ != *s2++) return(FALSE);
+    if (*s1++ != *s2++) return(FALSE);
+  }
+
+  return(TRUE);
+}
+
+/**********************
+ * Generate CRC Table *
+ **********************/
+
+static BLI_VOID generate_crc_table(BLI_VOID)
+{
+  /* Locals */
+
+  BLI_INT32   i,j;
+  BLI_UINT32  c;
+
+  /* Generate */
+
+  for (i = 0; i < 256; ++i)
+  {
+    for (c = i << 24, j = 8; j > 0; --j)
+    {
+      c = c & 0x80000000 ? (c << 1) ^ CRC32_POLY : (c << 1);
+    }
+    nand_crc_table[i] = c;
+  }
+}
+
+
+/*****************
+ * Calculate CRC *
+ *****************/
+
+/* Calculates the CRC of count bytes
+
+   count must be a multiple of 4 bytes!  */
+
+BLI_UINT32 calc_crc32(BLI_VOID *source, BLI_UINT32 crc, BLI_UINT32* crctable, BLI_UINT32 count)
+{
+  BLI_UINT8* s   = (BLI_UINT8*)source;
+  count /= 4;
+
+  while(count--)
+  {
+    crc = (crc << 8) ^ crctable[(crc >> 24) ^ *s++];
+    crc = (crc << 8) ^ crctable[(crc >> 24) ^ *s++];
+    crc = (crc << 8) ^ crctable[(crc >> 24) ^ *s++];
+    crc = (crc << 8) ^ crctable[(crc >> 24) ^ *s++];
+  }
+
+  return(crc);
+}
+
+/****************
+ * 64 bit shift *
+ ****************/
+
+/* 64-bit logical right shift that allows this driver not to depend on libgcc */
+
+static BLI_UINT64 lrshift64(BLI_UINT64 arg, BLI_UINT8 shift)
+{
+  BLI_INT32 shift32, carry;
+  union
+  {
+    BLI_UINT64 LL;
+    BLI_UINT32 L[2];
+    BLI_UINT8  B[8];
+  } t1 , t2;
+
+  if (shift == 0)
+  {
+    t2.LL = arg;
+  }
+  else if (shift >= 64)
+  {
+    t2.LL = 0;
+  }
+  else
+  {
+    t1.LL = arg;
+
+    /* Decide if we are little or big-endian */
+    t2.LL = 1;
+    if (t2.B[0] == 1)
+    {
+      /* Little endian */
+
+      /* Is the shift >= 32? */
+      if ((shift32 = 32 - shift) <= 0)
+      {
+        t2.L[1] = 0;
+        t2.L[0] = t1.L[1] >> (-shift32);
+      }
+      else
+      {
+        /* Work out the carry from the higher word to the lower word */
+        carry = t1.L[1] << shift32;
+
+        /* Shift the higher word in the right direction */
+        t2.L[1] = t1.L[1] >> shift;
+
+        /* Shift the lower word and OR in the carry */
+        t2.L[0] = (t1.L[0] >> shift) | carry;
+      }
+    }
+    else
+    {
+      /* Big endian */
+
+      /* Is the shift >= 32? */
+      if ((shift32 = 32 - shift) <= 0)
+      {
+        t2.L[0] = 0;
+        t2.L[1] = t1.L[0] >> (-shift32);
+      }
+      else
+      {
+        /* Work out the carry from the higher word to the lower word */
+        carry = t1.L[0] << shift32;
+
+        /* Shift the higher word in the right direction */
+        t2.L[0] = t1.L[0] >> shift;
+
+        /* Shift the lower word and OR in the carry */
+        t2.L[1] = (t1.L[1] >> shift) | carry;
+      }
+    }
+  }
+  return t2.LL;
+}
+static BLI_INT32 countsetbits(BLI_UINT8 * ptr, BLI_INT32 nbytes)
+{
+
+  BLI_UINT8 nbits,byte;
+  BLI_INT32 count = 0;
+  while(nbytes)
+  {
+	nbits = 8;
+	byte = *ptr;
+	while(nbits)
+	{
+	    if(byte & 1)
+		   count++;
+		byte >>= 1;
+		nbits--;
+	}
+	ptr++;
+	nbytes--;
+  }
+  return count;
+}
+/****************************************************************************
+ *                                 Export Symbols                           *
+ ****************************************************************************/
+#if defined(LINUX) || defined(__linux__)
+MODULE_AUTHOR("Pace PLC");
+MODULE_LICENSE("GPL");
+EXPORT_SYMBOL(nand_dev_init);
+EXPORT_SYMBOL(nand_dev_shutdown);
+EXPORT_SYMBOL(nand_dev_get_info);
+EXPORT_SYMBOL(nand_dev_enable_ecc);
+EXPORT_SYMBOL(nand_dev_read_block);
+EXPORT_SYMBOL(nand_dev_read_page);
+EXPORT_SYMBOL(nand_dev_read_vpage);
+EXPORT_SYMBOL(nand_dev_read_anywhere);
+EXPORT_SYMBOL(nand_dev_read_anywhere_raw);
+EXPORT_SYMBOL(nand_dev_write_block);
+EXPORT_SYMBOL(nand_dev_write_page);
+EXPORT_SYMBOL(nand_dev_write_vpage);
+EXPORT_SYMBOL(nand_dev_write_anywhere);
+EXPORT_SYMBOL(nand_dev_erase_block);
+EXPORT_SYMBOL(nand_dev_copy_block);
+EXPORT_SYMBOL(nand_dev_is_vpage_used);
+EXPORT_SYMBOL(nand_dev_read_spare);
+EXPORT_SYMBOL(nand_dev_write_spare);
+EXPORT_SYMBOL(nand_dev_is_block_erased);
+EXPORT_SYMBOL(nand_dev_is_page_erased);
+EXPORT_SYMBOL(nand_dev_is_vpage_erased);
+EXPORT_SYMBOL(nand_dev_is_block_bad);
+EXPORT_SYMBOL(nand_dev_mark_block_bad);
+EXPORT_SYMBOL(nand_dev_calc_crc32);
+#endif
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/pacenand/pacenand_base.c kernel-current/drivers/mtd/pacenand/pacenand_base.c
--- kernel-3.3-3.0a-ref/drivers/mtd/pacenand/pacenand_base.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/mtd/pacenand/pacenand_base.c	2015-06-12 16:27:20.016116063 +0200
@@ -0,0 +1,1433 @@
+/****************************************************************************
+ *                                                                          *
+ * File        : pacenand_base.c                                            *
+ *                                                                          *
+ * Description : Interface between the low-level Pace NAND driver and the   *
+ *               Linux kernel MTD subsystem                                 *
+ *                                                                          *
+ * Author      : Arif Hussain / Neil Crossley / Sumil Patel                 *
+ *                                                                          *
+ * Copyright   : Pace Micro Technology 2011/2013 (c)                        *
+ *                                                                          *
+ *               The copyright in this material is owned by                 *
+ *               Pace Microtechnology PLC ("Pace"). This                    *
+ *               material is regarded as a highly confidential              *
+ *               trade secret of Pace. It may not be reproduced,            *
+ *               used, sold or in any other way exploited or                *
+ *               transferred to any third party without the prior           *
+ *               written permission of Pace.                                *
+ *                                                                          *
+ * History     : Second version, supports BCH ECC                           *
+ *             : Third version updated by Sumil for 4K chips support and    *
+ *               handling JFFS2 cleanmarker in raw(ECC disabled) mode       *
+ *                                                                          *
+ ****************************************************************************/
+
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <stdbool.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/slab.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/flashchip.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/version.h>
+#include <linux/mtd/pacenand.h>
+#ifdef CONFIG_NS_ABS_POS
+#include <asm/io.h>
+#endif
+#if defined(LINUX) || defined(__linux__)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
+#include "linux/brcmstb/brcmstb.h"
+#else
+#include "asm/brcmstb/brcmstb.h"
+#endif
+#else
+#include "bchp_nand.h"
+#endif
+
+#define DRIVER_NAME "pacenand"
+#define DRIVER_INFO  "Pace STB NAND driver"
+#define CONTROLLER_VER    (10 * CONFIG_BRCMNAND_MAJOR_VERS + \
+    CONFIG_BRCMNAND_MINOR_VERS)
+
+
+#if defined(CONFIG_PACE_SYSTEM_IS_NAND_ONLY)
+#define SYSTEM_IS_NAND_ONLY            1
+#endif
+
+#if CONTROLLER_VER >= 60
+
+#define REG_ACC_CONTROL(cs) (BCHP_NAND_ACC_CONTROL_CS0 + ((cs) << 4))
+
+#define REG_CONFIG(cs) (BCHP_NAND_CONFIG_CS0 + ((cs) << 4))
+
+#define REG_TIMING_1(cs) (BCHP_NAND_TIMING_1_CS0 + ((cs) << 4))
+#define REG_TIMING_2(cs) (BCHP_NAND_TIMING_2_CS0 + ((cs) << 4))
+
+#else /* CONTROLLER_VER < 60 */
+
+#define REG_ACC_CONTROL(cs) \
+  ((cs) == 0 ? BCHP_NAND_ACC_CONTROL : \
+   (BCHP_NAND_ACC_CONTROL_CS1 + (((cs) - 1) << 4)))
+
+#define REG_CONFIG(cs) \
+  ((cs) == 0 ? BCHP_NAND_CONFIG : \
+   (BCHP_NAND_CONFIG_CS1 + (((cs) - 1) << 4)))
+
+#define REG_TIMING_1(cs) \
+  ((cs) == 0 ? BCHP_NAND_TIMING_1 : \
+   (BCHP_NAND_TIMING_1_CS1 + (((cs) - 1) << 4)))
+#define REG_TIMING_2(cs) \
+  ((cs) == 0 ? BCHP_NAND_TIMING_2 : \
+   (BCHP_NAND_TIMING_2_CS1 + (((cs) - 1) << 4)))
+
+#define WR_CORR_THRESH(cs, val) do { \
+  BDEV_WR(BCHP_NAND_CORR_STAT_THRESHOLD, \
+    ((val) & BCHP_NAND_CORR_STAT_THRESHOLD_CORR_STAT_THRESHOLD_MASK) \
+        << BCHP_NAND_CORR_STAT_THRESHOLD_CORR_STAT_THRESHOLD_SHIFT); \
+  } while (0);
+
+#endif /* CONTROLLER_VER < 60 */
+
+//#define CONFIG_MTD_PACENAND_DEBUG
+#if defined(CONFIG_MTD_PARTITIONS)
+static struct mtd_partition *parts = NULL;
+static const char           *part_probes[] = { "cmdlinepart", NULL };
+static unsigned int         nr_parts = 0;
+#endif
+static spinlock_t           chip_lock;
+static wait_queue_head_t    wq;
+static flstate_t            state = FL_READY;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,31)
+#define device_size(mtd)   ((mtd)->size)
+#endif
+
+#define BREG_PA(x)    (BPHYSADDR(BCHP_##x##_REG_START))
+#define BREG_LEN(x)   (BCHP_##x##_REG_END + 4 - BCHP_##x##_REG_START)
+#define FC_SLICE_LEN  512
+
+
+struct pacenand_pm_info
+{
+  #ifdef CONFIG_BRCM_HAS_EDU
+  uint32_t edu_config;
+  #endif
+  uint32_t nand_cs_nand_select;
+  uint32_t nand_cs_nand_xor;
+  uint32_t corr_stat_threshold;
+  uint32_t acc_control;
+  uint32_t config;
+  uint32_t timing_1;
+  uint32_t timing_2;
+};
+
+struct pacenand_info
+{
+  struct platform_device  *pdev;
+  struct mtd_info         mtd;
+  struct mtd_partition    *parts;
+  NAND_DEV_INFO           *pacenand;
+  struct pacenand_pm_info *pm_info;
+  uint32_t                cs;
+};
+
+struct pacenand_stats
+{
+  uint32_t      writtenpages;
+  uint32_t      erasedblocks;
+  uint32_t      writtenblocks;
+};
+static struct pacenand_stats nand_stats;
+static struct nand_ecclayout  nand_oob;
+static struct pacenand_info   *info;
+static int      pacenand_get_device(struct mtd_info *mtd, int new_state);
+static void     pacenand_release_device(struct mtd_info *mtd);
+static void     pacenand_init_mtd(struct pacenand_info *info);
+
+static int32_t countsetbits(uint8_t * ptr, int32_t nbytes);
+
+/**
+* countsetbits -    Helper Function to find out number of bits set in array
+* @param ptr        Pointer to array
+* @param nbytes     Length of array
+*/
+static int32_t countsetbits(uint8_t * ptr, int32_t nbytes)
+{
+
+  uint8_t nbits,byte;
+  int32_t count = 0;
+  while(nbytes)
+  {
+	nbits = 8;
+	byte = *ptr;
+	while(nbits)
+	{
+	    if(byte & 1)
+		   count++;
+		byte >>= 1;
+		nbits--;
+	}
+	ptr++;
+	nbytes--;
+  }
+  return count;
+}
+/**
+* pacenand_write -  [MTD Interface] NAND write
+* @param mtd        MTD device structure
+* @param to         offset to write to
+* @param len        number of bytes to write
+* @param retlen     pointer to variable to store the number of written bytes
+* @param buf        the data to write
+*
+* Pace driver NAND write
+*
+* Note - Patched for BCH ECC support, now syncs the oob (spare area) on the first data write, this is
+*        needed as the ECC covers both the data area and the OOB too (except the OOB used to store
+*        the ECC data)
+*/
+
+static int pacenand_write(struct mtd_info *mtd, loff_t to, size_t len, size_t *retlen, const uint8_t *buf)
+{
+  int ret = 0;
+  uint32_t flag = 0;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s to %0llx len %d\n", __FUNCTION__, to, len);
+  #endif
+
+  pacenand_get_device(mtd, FL_WRITING);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s calling write_nand mtd->size %lx to %llx len %d\n", __FUNCTION__, (long)mtd->size, to, len);
+  #endif
+
+  /* As Part of Legacy, JFFS2 supports read/write of cleanmarker in Non BCH-ECC mode(i.e. ECC disabled/Hamming ECC)
+   * So if write is requested for first page of block, we pre-assume that cleanmarker is already written in its
+   * spare area using pacenand_write_oob().NDR_FLAGS_SYNCSPAREONWRITE flag is added only for first page write of
+   * each block to ensure that cleanmarker is read back from spare area before actual physical write and will be
+   * written along with page data in BCH-ECC enabled mode.This flag is not needed for UBIFS,
+   * but we pre-assume that it is harmless to UBIFS.
+  */
+  if((to & (mtd->erasesize -1)) == 0) flag = NDR_FLAGS_SYNCSPAREONWRITE;
+
+  #ifdef CONFIG_MTD_PACENAND_VERIFY_WRITE
+  ret = nand_dev_write_anywhere((void *)buf, (uint64_t)to, len, flag | NDR_FLAGS_VERIFY);
+  #else
+  ret = nand_dev_write_anywhere((void *)buf, (uint64_t)to, len, flag);
+  #endif
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s write_nand returned %d\n", __FUNCTION__, ret);
+  #endif
+
+  if (ret != NDR_SUCCESS)
+  {
+    printk("%s: error writing to NAND, error %d\n", __FUNCTION__, ret);
+    *retlen = len;
+    ret = -EIO;
+  }
+  else
+  {
+    *retlen = len;
+  }
+
+  /* log stats */
+  if((to & (mtd->erasesize -1)) == 0) nand_stats.writtenblocks++;
+  nand_stats.writtenpages++;
+
+  pacenand_release_device(mtd);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_erase - [MTD Interface] erase block(s)
+* @param mtd        MTD device structure
+* @param instr      erase instruction
+*
+* Pace driver NAND erase one or more blocks
+*/
+
+static int pacenand_erase(struct mtd_info *mtd, struct erase_info *instr)
+{
+  int startblock, endblock, i, ret = 0;
+  NDR_ERROR result;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s addr %08lx, len %ld\n", __FUNCTION__, (unsigned long)instr->addr, (unsigned long)instr->len);
+  #endif
+
+  startblock = instr->addr / mtd->erasesize;
+  endblock = (instr->addr + instr->len) / mtd->erasesize;
+  instr->state = MTD_ERASING;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s startblock %d endblock %d\n", __FUNCTION__, startblock, endblock);
+  #endif
+
+  pacenand_get_device(mtd, FL_ERASING);
+
+  for (i = startblock; i < endblock; i++)
+  {
+    if (nand_dev_is_block_bad(i) == NDR_BLOCK_IS_GOOD)
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("-->%s calling nand_dev_erase_block with block %d\n", __FUNCTION__, i);
+      #endif
+
+      result = nand_dev_erase_block(i);
+
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("-->%s nand_dev_erase_block returned %d\n", __FUNCTION__, result);
+      #endif
+
+      if (result != NDR_SUCCESS)
+      {
+        if (result == NDR_DEVICE_ERASE_ERROR)
+        {
+          #ifdef CONFIG_MTD_PACENAND_DEBUG
+          printk("-->%s error while erasing block %d, should mark block bad\n", __FUNCTION__, i);
+          #endif
+          nand_dev_mark_block_bad(i);
+        }
+
+        #ifdef CONFIG_MTD_PACENAND_DEBUG
+        printk("-->%s got error %d while erasing block %d\n", __FUNCTION__, result, i);
+        #endif
+
+        instr->state = MTD_ERASE_FAILED;
+        goto erase_exit;
+      }
+    }
+    else
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("-->%s block %d is already bad\n", __FUNCTION__, i);
+      #endif
+
+      instr->state = MTD_ERASE_FAILED;
+      goto erase_exit;
+    }
+  }
+  instr->state = MTD_ERASE_DONE;
+
+  erase_exit:
+  ret = (instr->state == MTD_ERASE_DONE) ? 0 : -EIO;
+
+  /* log stats */
+  nand_stats.erasedblocks++;
+
+  pacenand_release_device(mtd);
+
+  /* Do call back function */
+  if (!ret)
+  {
+    mtd_erase_callback(instr);
+  }
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_read - [MTD Interface] MTD read data
+* @param mtd        MTD device structure
+* @param from       offset to read from
+* @param len        number of bytes to read
+* @param retlen     pointer to variable to store the number of read bytes
+* @param buf        the data buffer to put data in
+*
+* Pace driver NAND read data
+*/
+
+static int pacenand_read(struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, uint8_t *buf)
+{
+  int ret = 0;
+  NAND_DEV_INFO *pacenand = (NAND_DEV_INFO*) mtd->priv;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s from %0llx len %d\n", __FUNCTION__, from, len);
+  /* When doing debugging, set the buffer to dummy values */
+  memset(buf, 0xA5, len);
+  #endif
+
+  /* Do not allow reads past end of device */
+
+  if (unlikely((from + len) > device_size(mtd)))
+  {
+    return -EINVAL;
+  }
+
+  /* If trying to read zero data, then just return */
+
+  else if (!len)
+  {
+    return *retlen = 0;
+  }
+
+  /* Do the read NAND function */
+  pacenand_get_device(mtd, FL_READING);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s calling read_nand mtd->size %lx from %llx\n", __FUNCTION__, (long)device_size(mtd), from);
+  #endif
+
+  ret = nand_dev_read_anywhere(buf, (uint64_t)from, len, /*NDR_FLAGS_CRC */ 0);
+
+  /* As Part of Legacy, JFFS2 supports read/write of cleanmarker in Non BCH-ECC mode(i.e. ECC disabled/Hamming ECC)
+   * So If driver uses BCH-ECC, read on the page(first page of each block) whose spare area is written
+   * with cleanmarker using pacenand_write_oob() will return Non-Correctable Error on read if its data area
+   * is not written with other data(cleanmarker node of 256 byte) using pacenand_write().
+   * Following functionality ensure that Non-Correctable Errors resulting from cleanmarker are discarded
+   * with keeping consideration of 8-bit ECC flash where each page is prone to bit errors but not more than
+   * 8-bit/512 bytes subpage.This functionality has no impact on UBIFS.
+  */
+  if ((ret == NDR_UNCORRECTABLE_ERROR) && ((from & (mtd->erasesize -1)) == 0) && (len <= FC_SLICE_LEN))
+  {
+     uint8_t       bufraw[FC_SLICE_LEN];
+     uint8_t       buffix[256];
+     int i, err;
+     int oob_bitflips,data_bitflips,total_bitflips,oob_nbits,data_nbits,thresold,subpages,eccbytes;
+     memset(&bufraw, 0xff, sizeof(bufraw));
+     err = nand_dev_read_spare(((uint32_t)from/mtd->writesize),bufraw);
+     if(err == NDR_SUCCESS)
+     {
+
+	 	for(i = 0; i < pacenand->Spare_Area_ECC_Bytes; i++)
+	   		buffix[i] = bufraw[pacenand->Spare_Area_ECC_bytes[i]];
+        subpages = pacenand->Virt_Page_Size/FC_SLICE_LEN;
+        eccbytes = pacenand->Spare_Area_ECC_Bytes/subpages;
+        oob_nbits = eccbytes << 3;
+	    oob_bitflips = oob_nbits - countsetbits(&buffix[0],eccbytes);
+	    memset(&bufraw, 0xff, sizeof(bufraw));
+		err = nand_dev_read_anywhere_raw(bufraw,(uint64_t)from, FC_SLICE_LEN,0);
+		if(err == NDR_SUCCESS)
+		{
+			data_nbits = FC_SLICE_LEN << 3;
+			data_bitflips = data_nbits - countsetbits(bufraw,FC_SLICE_LEN);
+			total_bitflips = data_bitflips + oob_bitflips;
+			thresold = (pacenand->ECC_Type == 0)?1:(pacenand->ECC_Type == 1)?2:(pacenand->ECC_Type == 2)?6:9;
+			if(!oob_bitflips || (total_bitflips < thresold))
+			{
+				memset(buf, 0xff, len);
+				ret = NDR_SUCCESS;
+			}
+		}
+     }
+  }
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s read_nand returned %d\n", __FUNCTION__, ret);
+  #endif
+
+  /* Was the read successful? */
+  if (ret != NDR_SUCCESS)
+  {
+    *retlen = len; /* Return len even with failure */
+
+    /* Return the right error code if the error was correctable */
+    if (ret == NDR_CORRECTABLE_ERROR)
+    {
+	  mtd->ecc_stats.corrected += 1;
+      ret = -EUCLEAN;
+    }
+
+    /* Return the right error code if the error was uncorrectable */
+    else if (ret == NDR_UNCORRECTABLE_ERROR)
+    {
+	  mtd->ecc_stats.failed += 1;
+      ret = -EBADMSG;
+    }
+
+    /* General failure */
+    else
+    {
+      ret = -EIO;
+    }
+  }
+
+  /* Read was successful */
+  else
+  {
+    *retlen = len;
+  }
+
+  /* log stats */
+  mtd->ecc_stats.erasedblocks = nand_stats.erasedblocks;
+  mtd->ecc_stats.writtenblocks = nand_stats.writtenblocks;
+  mtd->ecc_stats.writtenpages = nand_stats.writtenpages;
+
+  pacenand_release_device(mtd);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s retlen %d len %d\n", __FUNCTION__, *retlen, len);
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/*
+
+ struct mtd_oob_ops - oob operation operands
+ @mode: operation mode
+
+ @len:  number of data bytes to write/read
+
+ @retlen: number of data bytes written/read
+
+ @ooblen: number of oob bytes to write/read
+ @oobretlen:  number of oob bytes written/read
+ @ooboffs:  offset of oob data in the oob area (only relevant when
+  mode = MTD_OPS_PLACE_OOB or MTD_OPS_RAW)
+ @datbuf: data buffer - if NULL only oob data are read/written
+ @oobbuf: oob data buffer
+
+ Note, it is allowed to read more than one OOB area at one go, but not write.
+ The interface assumes that the OOB write requests program only one page's
+ OOB area.
+
+struct mtd_oob_ops {
+  unsigned int  mode;
+  size_t    len;
+  size_t    retlen;
+  size_t    ooblen;
+  size_t    oobretlen;
+  uint32_t  ooboffs;
+  uint8_t   *datbuf;
+  uint8_t   *oobbuf;
+};
+
+*/
+
+/**
+* pacenand_read_oob - [MTD Interface] MTD read OOB
+* @param mtd        MTD device structure
+* @param from       OOB offset to read from
+* @param ops        OOB ops structure
+*
+* Note, it is allowed to read more than one OOB area at one go
+*/
+
+static int pacenand_read_oob(struct mtd_info *mtd, loff_t from, struct mtd_oob_ops *ops)
+{
+  NAND_DEV_INFO *pacenand = (NAND_DEV_INFO*) mtd->priv;
+  NDR_ERROR     ne;
+  int           realpage;
+  int           pageoffs;
+  int           readlen = ops->ooblen;
+  int           offs = ops->ooboffs;
+  int           oobsize = pacenand->Spare_Area_Free;
+  uint8_t       *buf = ops->oobbuf;
+  int           ret = 0;
+  int           len;
+  uint8_t       bufraw[256];
+  uint8_t       buffix[256];
+  int           i;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s read OOB\n", __FUNCTION__);
+  printk("   from offset %llx\n", from);
+  #endif
+
+  if (unlikely((from + offs + readlen) > device_size(mtd)))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   attempt read beyond end of device\n");
+    #endif
+    return -EINVAL;
+  }
+
+  if(!readlen)
+  {
+	#ifdef CONFIG_MTD_PACENAND_DEBUG
+	printk("   read length is zero\n");
+    #endif
+	ops->oobretlen = ops->ooblen;
+	return 0;
+  }
+  realpage = (int)((unsigned long)from / mtd->writesize);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("   reading from page %d ooblen %d ooboffs %d mode %d\n", realpage, readlen, offs, ops->mode);
+  #endif
+
+  pacenand_get_device(mtd, FL_READING);
+
+  /* Quick check that the offset is within the selected page, if not then
+     increment realpage until it is (probably not likley to happen but
+     it would be legal)                                                   */
+
+  pageoffs = offs / oobsize;
+  if (pageoffs)
+  {
+    realpage += pageoffs;
+    offs %= oobsize;
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   skipping %d pages (offset not within current page)\n", pageoffs);
+    #endif
+  }
+
+  /* Main read loop */
+
+  for (;;)
+  {
+    /* Read the spare area */
+    ne = nand_dev_read_spare(realpage, bufraw);
+    if (ne != NDR_SUCCESS)
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("   error reading from NAND, error %d\n", ne);
+      #endif
+      ret = -EINVAL;
+      break;
+    }
+
+    /* Rearrange */
+
+    memset(&buffix, 0xff, oobsize);
+
+    for (i = 0; i < oobsize; i++)
+    {
+      buffix[i] = bufraw[pacenand->Spare_Area_Bytes[i]];
+    }
+
+    /* Copy data back to caller */
+
+    if ((offs + readlen) > oobsize)
+    {
+      len = oobsize - offs;
+    }
+    else
+    {
+      len = readlen;
+    }
+
+    memcpy(buf, &buffix[offs], len);
+    buf += len;
+
+    /* Clear offs, decrement bytes to read, bail if finished */
+
+    offs = 0;
+    readlen -= len;
+    realpage ++;
+
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   %d OOB bytes left to read \n", readlen);
+    #endif
+
+    if (readlen <= 0)
+    {
+      break;
+    }
+  }
+
+  /* Exit */
+  pacenand_release_device(mtd);
+
+  if (ret == 0)
+  {
+  	ops->oobretlen = ops->ooblen;
+  }
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_write_oob - [MTD Interface] MTD write OOB
+* @param mtd        MTD device structure
+* @param to         OOB offset to write to
+* @param ops        OOB ops structure
+*
+* Note, it is allowed to read more than one OOB area at one go, but not write.
+* The interface assumes that the OOB write requests program only one page's
+* OOB area.
+*/
+
+static int pacenand_write_oob(struct mtd_info *mtd, loff_t to, struct mtd_oob_ops *ops)
+{
+  NAND_DEV_INFO *pacenand = (NAND_DEV_INFO*) mtd->priv;
+  NDR_ERROR     ne;
+  int           realpage;
+  int           writelen = ops->ooblen;
+  int           offs = ops->ooboffs;
+  int           oobsize = pacenand->Spare_Area_Free;
+  uint8_t       *buf = ops->oobbuf;
+  int           ret = 0;
+  uint8_t       bufraw[256];
+  uint8_t       buffix[256];
+  int           i;
+
+  /* Support for ubiformat */
+  if ((ops->len)  && (ops->datbuf != NULL)) ret = pacenand_write(mtd,to, ops->len, &(ops->retlen), ops->datbuf);
+  if(ret) return ret;
+  if(!ops->ooblen) return ret;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s write OOB\n", __FUNCTION__);
+  printk("   to offset %llx\n", to);
+  #endif
+
+  if (unlikely((to + offs + writelen) > device_size(mtd)))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   attempt read beyond end of device\n");
+    #endif
+    return -EINVAL;
+  }
+
+  if (unlikely((offs / oobsize) != 0))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   offset %d not within current page\n", offs);
+    #endif
+    return -EINVAL;
+  }
+
+  if (unlikely((writelen + offs) > oobsize))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   write length %d greater than oob size\n", writelen);
+    #endif
+    return -EINVAL;
+  }
+  if(!writelen)
+  {
+	#ifdef CONFIG_MTD_PACENAND_DEBUG
+	printk("   write length is zero\n");
+    #endif
+  	ops->oobretlen = ops->ooblen;
+  	return 0;
+  }
+  realpage = (int)((unsigned long)to / mtd->writesize);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("   writing to page %d ooblen %d ooboffs %d mode %d\n", realpage, writelen, offs, ops->mode);
+  #endif
+
+  pacenand_get_device(mtd, FL_WRITING);
+
+  /* Prepare spare area buffer */
+
+  memset(&bufraw, 0xff, oobsize);
+  memcpy(&bufraw[offs], buf, writelen);
+
+  /* Rearrange */
+
+  memset(&buffix, 0xff, sizeof(buffix));
+
+  for (i = 0; i < oobsize; i++)
+  {
+    buffix[pacenand->Spare_Area_Bytes[i]] = bufraw[i];
+  }
+
+  /* Write */
+  ne = nand_dev_write_spare(realpage, buffix);
+
+  if (ne != NDR_SUCCESS)
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   error writing to NAND, error %d\n", ne);
+    #endif
+    ret = -EINVAL;
+  }
+
+  /* Exit */
+
+  pacenand_release_device(mtd);
+
+  if (ret == 0)
+  {
+    ops->oobretlen = ops->ooblen;
+  }
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_writev - [MTD Interface] Pace NAND driver write vector function (not implemented)
+* @param mtd        MTD device structure
+* @param vecs       the iovectors to write
+* @param count      number of vectors
+* @param to         offset to write to
+* @param retlen     pointer to variable to store the number of written bytes
+*
+* Pace NAND write with kvec.
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+static int pacenand_writev(struct mtd_info *mtd, const struct kvec *vecs, unsigned long count, loff_t to, size_t *retlen)
+{
+  printk("-->%s count %08lX to %0llx\n", __FUNCTION__, count, to);
+  return 0;
+}
+#endif
+
+
+/**
+* pacenand_sync - [MTD Interface] synchronise flash contents
+* @param mtd    MTD device structure
+*
+* Sync is actually a wait for chip ready function
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+static void pacenand_sync(struct mtd_info *mtd)
+{
+  printk("-->%s\n", __FUNCTION__);
+}
+#endif
+
+
+/**
+* pacenand_unlock - [MTD Interface] unlock block(s)
+* @param mtd    MTD device structure
+* @param ofs    offset relative to MTD start
+* @param len    number of bytes to unlock
+*
+* Unlock one or more blocks
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,31)
+
+static int pacenand_unlock(struct mtd_info *mtd, loff_t llofs, uint64_t len)
+{
+  printk("-->%s llofs %0llx len %lld\n", __FUNCTION__, llofs, len);
+  return 0;
+}
+
+#else
+
+static int pacenand_unlock(struct mtd_info *mtd, loff_t llofs, size_t len)
+{
+  printk("-->%s llofs %0llx len %d\n", __FUNCTION__, llofs, len);
+  return 0;
+}
+
+#endif
+
+#endif
+
+
+/**
+* pacenand_suspend - [MTD Interface] suspend the NAND flash
+* @param mtd    MTD device structure
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+
+static int pacenand_suspend(struct mtd_info *mtd)
+{
+  printk("-->%s\n", __FUNCTION__);
+  return 0;
+}
+
+#endif
+
+
+/**
+* pacenand_resume - [MTD Interface] resume the NAND flash
+* @param mtd    MTD device structure
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+
+static void pacenand_resume(struct mtd_info *mtd)
+{
+  printk("-->%s  \n", __FUNCTION__);
+}
+
+#endif
+
+
+/**
+* pacenand_block_isbad - [MTD Interface] return flag indicating block state (1 = bad, 0 = good)
+* @param mtd    MTD device structure
+* @param ofs     offset relative to MTD start
+*/
+
+static int pacenand_block_isbad(struct mtd_info *mtd, loff_t ofs)
+{
+  uint32_t block;
+  int ret = 0;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s ofs %0llx\n", __FUNCTION__, ofs);
+  #endif
+
+  block = (uint32_t)ofs / mtd->erasesize;
+  pacenand_get_device(mtd, FL_READING);
+
+  #ifdef CONFIG_MTD_PACENAND_CLEAR_BAD_BLOCK_MARKERS
+
+  /* This code will clear the bad block marker */
+
+  if (nand_dev_is_block_bad(block) != NDR_BLOCK_IS_GOOD)
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("-->%s WARNING: erasing block %d and clearing the bad block flag\n", __FUNCTION__, block);
+    #endif
+    if ((ret = nand_dev_erase_block(block)) != NDR_SUCCESS)
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("-->%s ERROR: unable to erase block %d, error %d\n", __FUNCTION__, block, ret);
+      #endif
+      ret = 1;
+    }
+    else
+    {
+      ret = (nand_dev_is_block_bad(block) == NDR_BLOCK_IS_GOOD) ? 0 : 1;
+    }
+  }
+
+  #else
+
+  ret = (nand_dev_is_block_bad(block) == NDR_BLOCK_IS_GOOD) ? 0 : 1;
+
+  #endif
+
+  pacenand_release_device(mtd);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s block %d at offset %0llx is %s\n", __FUNCTION__, block, ofs, ret ? "bad" : "good");
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_block_markbad - [MTD Interface] mark the block at the given offset as bad
+* @param mtd    MTD device structure
+* @param ofs    offset relative to MTD start
+*
+* Mark the block as bad
+*/
+
+static int pacenand_block_markbad(struct mtd_info *mtd, loff_t ofs)
+{
+  uint32_t block;
+  int ret = 0;
+
+  block = (uint32_t)ofs / mtd->erasesize;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s ofs %0llx block %d\n", __FUNCTION__, ofs, block);
+  #endif
+
+  if ((ret = nand_dev_mark_block_bad(block)) != 0)
+  {
+    ret = -EIO;
+  }
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+  return ret;
+}
+
+
+/**
+* pacenand_probe - [MTD Interface] Initialise the device
+* @param pdev    MTD platform device structure
+*
+* Initialise the device
+*/
+
+static int __devinit pacenand_probe(struct platform_device *pdev)
+{
+  struct brcmnand_platform_data *pd = pdev->dev.platform_data;
+  struct device_node *dn = pdev->dev.of_node;
+  int i;
+
+  #if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 0, 0)
+  const char *part_probe_types[] = { "cmdlinepart", "ofpart", "RedBoot",NULL };
+  #elif defined(CONFIG_MTD_PARTITIONS)
+  /* for 2.6.37 compatibility only */
+  int nr_parts = 0;
+  int err = 0;
+  struct mtd_partition *parts = NULL;
+  const char *part_probe_types[] = { "cmdlinepart", "RedBoot", NULL };
+  #endif
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s\n", __FUNCTION__);
+  #endif
+
+  printk(DRIVER_INFO " using Pace NAND controller\n");
+
+  /* If driver already initialised return an error */
+  i = nand_dev_init();
+  if (!((i == 0) || (i == NDR_ALREADY_INITIALISED)))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("-->%s nand_dev_init() failed to initialise the NAND driver %d\n", __FUNCTION__, i);
+    #endif
+    return -EPERM;
+  }
+  else if (!(info = kzalloc(sizeof(struct pacenand_info), GFP_KERNEL)))
+  {
+    return -ENOMEM;
+  }
+  else if (!(info->pm_info = kzalloc(sizeof(struct pacenand_pm_info), GFP_KERNEL)))
+  {
+    return -ENOMEM;
+  }
+  else
+  {
+    if (nand_dev_get_info(&info->pacenand) != 0)
+    {
+      return -EIO;
+    }
+  }
+  info->pdev = pdev;
+
+  #ifdef SYSTEM_IS_NAND_ONLY
+
+  info->cs = 0;
+
+  #else
+
+  info->cs = 1;
+
+  #endif
+
+  dev_set_drvdata(&pdev->dev, info);
+  state = FL_READY;
+  init_waitqueue_head(&wq);
+  spin_lock_init(&chip_lock);
+  pacenand_init_mtd(info);
+
+	#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 0, 0)
+
+	if (dn)
+	{
+		struct mtd_part_parser_data ppdata = {.of_node = dn };
+		mtd_device_parse_register(&info->mtd, part_probe_types, &ppdata, NULL, 0);
+	}
+	else
+	{
+		mtd_device_parse_register(&info->mtd, part_probe_types, NULL, pd->parts, pd->nr_parts);
+	}
+
+  #elif defined(CONFIG_MTD_PARTITIONS)
+
+  if (mtd_has_cmdlinepart())
+  {
+    /* Parse the MTD partitions, if defined on the command line */
+    nr_parts = parse_mtd_partitions(&info->mtd, part_probes, &parts, 0);
+    if (nr_parts <= 0)
+    {
+      /* If none on cmdline, then look for platform data */
+      nr_parts = pd->nr_parts;
+      parts = pd->parts;
+    }
+    if ((parts) && (nr_parts))
+    {
+      if ((err = add_mtd_partitions(&info->mtd, parts, nr_parts)) != 0)
+      {
+        panic("Pace NAND driver could not add MTD partitions!\n");
+      }
+    }
+  }
+
+  #endif
+  /* init stat */
+  nand_stats.writtenpages = 0;
+  nand_stats.erasedblocks = 0;
+  nand_stats.writtenblocks = 0;
+
+  return 0;
+}
+
+
+/**
+* pacenand_remove - [MTD Interface] Deinitialise the device
+* @param pdev    MTD platform device structure
+*
+* Deinitialise the device
+*/
+
+static int __devexit pacenand_remove(struct platform_device *pdev)
+{
+  dev_set_drvdata(&pdev->dev, NULL);
+  if (info->pm_info)
+  {
+    kfree(info->pm_info);
+  }
+  if (info)
+  {
+    kfree(info);
+  }
+
+  return 0;
+}
+
+
+/**
+* pacenand_init_mtd -  [MTD Interface] Deinitialise the device
+* @param pacenand_info - Pace NAND information structure pointer
+*
+* Initialise the MTD structure
+*/
+
+static void pacenand_init_mtd(struct pacenand_info *info)
+{
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  int i;
+  #endif
+
+  /* Build the nand_oob structure */
+
+  memset(&nand_oob, 0, sizeof(nand_oob));
+  nand_oob.oobavail = info->pacenand->Spare_Area_Free;
+  nand_oob.oobfree[0].offset = 0;
+  nand_oob.oobfree[0].length = info->pacenand->Spare_Area_Free;
+  nand_oob.oobfree[1].offset = 0;
+  nand_oob.oobfree[1].length = 0;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s %d bytes free in OOB\n", __FUNCTION__, info->pacenand->Spare_Area_Free);
+  printk("Log to phys translate list is ...\n");
+  for (i = 0; i < info->pacenand->Spare_Area_Free; i++)
+  {
+    printk("Log %2d is phys %2d\n", i, info->pacenand->Spare_Area_Bytes[i]);
+  }
+  #endif
+
+  /* Fill in remaining MTD driver data */
+
+  info->mtd.type = MTD_NANDFLASH;
+  info->mtd.flags = MTD_CAP_NANDFLASH;
+
+  info->mtd.erase = pacenand_erase;
+  info->mtd.point = NULL;
+  info->mtd.unpoint = NULL;
+  info->mtd.read = pacenand_read;
+  info->mtd.write = pacenand_write;
+  info->mtd.read_oob = pacenand_read_oob;
+  info->mtd.write_oob = pacenand_write_oob;
+
+  /* Not needed? */
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  info->mtd.writev = pacenand_writev;
+  info->mtd.sync = pacenand_sync;
+  #else
+  info->mtd.writev = NULL;
+  info->mtd.sync = NULL;
+  #endif
+  info->mtd.sync = NULL;
+  info->mtd.lock = NULL;
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  info->mtd.unlock = pacenand_unlock;
+  #else
+  info->mtd.unlock = NULL;
+  #endif
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  info->mtd.suspend = pacenand_suspend;
+  info->mtd.resume = pacenand_resume;
+  #else
+  info->mtd.suspend = NULL;
+  info->mtd.resume = NULL;
+  #endif
+  info->mtd.block_isbad = pacenand_block_isbad;
+  info->mtd.block_markbad = pacenand_block_markbad;
+
+  /* Propagate ECC layout to mtd_info */
+
+  info->mtd.ecclayout = &nand_oob;
+  info->mtd.ecc_stats.failed = 0;
+  info->mtd.ecc_stats.corrected = 0;
+
+  /* NAND page size & block size */
+
+  info->mtd.writesize = info->pacenand->Virt_Page_Size;
+  info->mtd.writebufsize = info->mtd.writesize;
+
+  /* OOB size for MLC NAND varies depend on the chip */
+
+  info->mtd.oobsize = info->pacenand->Spare_Area_Size;
+
+  info->mtd.oobavail = nand_oob.oobavail;
+
+  info->mtd.erasesize = info->pacenand->Block_Size;
+  #if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,31)
+  info->mtd.eccsize = info->pacenand->Virt_Page_Size;
+  info->mtd.ecctype = MTD_ECC_NONE;
+  #endif
+  info->mtd.subpage_sft = 0;  /* this is a right shift (divide) */
+  info->mtd.size = info->pacenand->Device_Size;
+  info->mtd.name = dev_name(&info->pdev->dev);
+  info->mtd.dev.parent = &info->pdev->dev;
+  info->mtd.reboot_notifier.notifier_call = NULL;
+
+  /* use the priv slot to store the nand_info structure pointer */
+
+  info->mtd.priv = (NAND_DEV_INFO *)info->pacenand;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s device size %d, block size=%d, oob size=%d, write size=%d spare area size = %d\n", __FUNCTION__, (unsigned int)info->mtd.size, info->mtd.erasesize, info->mtd.oobsize, info->mtd.writesize, info->pacenand->Spare_Area_Size);
+  #endif
+
+  info->mtd.owner = THIS_MODULE;
+}
+
+
+/**
+* Power management save/restore functions
+*
+*/
+
+#define HIF_ENABLED_IRQ(bit) \
+  (!BDEV_RD_F(HIF_INTR2_CPU_MASK_STATUS, bit##_INTR))
+
+#define CMD_FLASH_RESET    0x09
+#define FLASH_RESET_TIMEOUT 200000
+
+static int pacenand_pm_suspend(struct device *dev)
+{
+  if (brcm_pm_deep_sleep())
+  {
+
+    struct pacenand_info *info = dev_get_drvdata(dev);
+
+    if ((info) && (info->pm_info))
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("%s : Save(0x%X:%d)\n", __FUNCTION__,(unsigned int) info, info->cs);
+      #endif
+
+      #ifdef CONFIG_BRCM_HAS_EDU
+      info->pm_info->edu_config = BDEV_RD(BCHP_EDU_CONFIG);
+      #endif
+      info->pm_info->nand_cs_nand_select = BDEV_RD(BCHP_NAND_CS_NAND_SELECT);
+      info->pm_info->nand_cs_nand_xor = BDEV_RD(BCHP_NAND_CS_NAND_XOR);
+      info->pm_info->corr_stat_threshold = BDEV_RD(BCHP_NAND_CORR_STAT_THRESHOLD);
+      info->pm_info->acc_control = BDEV_RD(REG_ACC_CONTROL(info->cs));
+      info->pm_info->config = BDEV_RD(REG_CONFIG(info->cs));
+      info->pm_info->timing_1 = BDEV_RD(REG_TIMING_1(info->cs));
+      info->pm_info->timing_2 = BDEV_RD(REG_TIMING_2(info->cs));
+      state = FL_PM_SUSPENDED;
+    }
+  }
+  return 0;
+}
+
+static int pacenand_pm_resume(struct device *dev)
+{
+  if (brcm_pm_deep_sleep())
+  {
+
+    struct pacenand_info *info = dev_get_drvdata(dev);
+    unsigned int delay;
+    volatile unsigned int reg;
+
+    if ((info) && (info->pm_info))
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("%s : Restore\n", __FUNCTION__);
+      #endif
+
+      #ifdef CONFIG_BRCM_HAS_EDU
+      BDEV_WR_RB(BCHP_EDU_CONFIG, info->pm_info->edu_config);
+      BDEV_WR(BCHP_EDU_ERR_STATUS, 0);
+      BDEV_WR(BCHP_EDU_DONE, 0);
+      BDEV_WR(BCHP_EDU_DONE, 0);
+      BDEV_WR(BCHP_EDU_DONE, 0);
+      BDEV_WR(BCHP_EDU_DONE, 0);
+      #endif
+
+      BDEV_WR_RB(BCHP_NAND_CS_NAND_SELECT, info->pm_info->nand_cs_nand_select);
+      BDEV_WR_RB(BCHP_NAND_CS_NAND_XOR, info->pm_info->nand_cs_nand_xor);
+      BDEV_WR_RB(BCHP_NAND_CORR_STAT_THRESHOLD, info->pm_info->corr_stat_threshold);
+      BDEV_WR_RB(REG_ACC_CONTROL(info->cs), info->pm_info->acc_control);
+      BDEV_WR_RB(REG_CONFIG(info->cs), info->pm_info->config);
+      BDEV_WR_RB(REG_TIMING_1(info->cs), info->pm_info->timing_1);
+      BDEV_WR_RB(REG_TIMING_2(info->cs), info->pm_info->timing_2);
+      HIF_ACK_IRQ(NAND_CTLRDY);
+
+      /* Reset the chip, required by some chips after power-up */
+      BDEV_WR_RB(BCHP_NAND_CMD_EXT_ADDRESS, info->cs << 16);
+      BDEV_WR_RB(BCHP_NAND_CMD_ADDRESS, 0);
+      BDEV_WR_RB(BCHP_NAND_CMD_START, CMD_FLASH_RESET << BCHP_NAND_CMD_START_OPCODE_SHIFT);
+
+      /* Wait up to 20 milliseconds for autodetect to complete.
+         Wait for INTFC_STATUS.CTLR_READY to be cleared, and then to be set, with timeouts. */
+
+      delay = FLASH_RESET_TIMEOUT;
+      reg = 1;
+
+      while ((delay--) && (reg))
+      {
+        reg = BDEV_RD(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_CTLR_READY_MASK;
+      }
+
+      while ((delay--) && (!reg))
+      {
+        reg = BDEV_RD(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_CTLR_READY_MASK;
+      }
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      if (!reg)
+      {
+        printk("%s : !!! FLASH_RESET timeout !!!\n", __FUNCTION__);
+      }
+      else
+      {
+        printk("%s : FLASH_RESET took %d reads !!!\n", __FUNCTION__, FLASH_RESET_TIMEOUT - delay);
+      }
+      #endif
+      state = ( state == FL_PM_SUSPENDED)? FL_READY : state;
+    }
+  }
+  return 0;
+}
+
+
+static const struct dev_pm_ops pacenand_pm_ops = {
+  .suspend = pacenand_pm_suspend,
+  .resume = pacenand_pm_resume,
+};
+
+
+static struct platform_driver driver = {
+  .driver = {
+      .name = DRIVER_NAME,
+      .owner = THIS_MODULE,
+      .pm = &pacenand_pm_ops,
+    },
+  .probe = pacenand_probe,
+  .remove = __devexit_p(pacenand_remove),
+};
+
+
+static int __init pacenand_plat_init(void)
+{
+  if (!request_mem_region(BREG_PA(NAND), BREG_LEN(NAND), DRIVER_NAME))
+  {
+    printk(KERN_ERR "%s: can't request memory region\n", __func__);
+    return -ENODEV;
+  }
+  platform_driver_register(&driver);
+  return 0;
+}
+
+static void __exit pacenand_plat_exit(void)
+{
+  platform_driver_unregister(&driver);
+}
+
+
+/**
+* pacenand_get_device - [GENERIC] Get chip for selected access
+* @param mtd    MTD device structure
+* @param new_state  the state which is requested
+*
+* Get the device and lock it for exclusive access
+*/
+
+static int pacenand_get_device(struct mtd_info *mtd, int new_state)
+{
+  DECLARE_WAITQUEUE(wait, current);
+
+  /*
+   * Grab the lock and see if the device is available
+   */
+  for (;;)
+  {
+    spin_lock(&chip_lock);
+
+    /* If the chip is available, use it straight away */
+
+    if (state == FL_READY)
+    {
+      state = new_state;
+      spin_unlock(&chip_lock);
+      break;
+    }
+
+    /* If the new state is to suspend the chip... */
+
+    else if (new_state == FL_PM_SUSPENDED)
+    {
+      spin_unlock(&chip_lock);
+      return (state == FL_PM_SUSPENDED) ? 0 : -EAGAIN;
+    }
+
+    /* Chip isn't available, so cycle round on a wait queue until woken up */
+
+    set_current_state(TASK_UNINTERRUPTIBLE);
+    add_wait_queue(&wq, &wait);
+    spin_unlock(&chip_lock);
+    if (!in_interrupt())
+    {
+      schedule();
+    }
+    remove_wait_queue(&wq, &wait);
+  }
+  return 0;
+}
+
+
+/**
+* pacenand_release_device - [GENERIC] release chip
+* @param mtd    MTD device structure
+*
+* Deselect, release chip lock and wake up anyone waiting on the device
+*/
+
+static void pacenand_release_device(struct mtd_info *mtd)
+{
+  /* Release the chip, and wake up any threads that are waiting on it */
+  spin_lock(&chip_lock);
+  state = FL_READY;
+  wake_up(&wq);
+  spin_unlock(&chip_lock);
+}
+
+
+/**
+* Module init/exit and declarations
+*/
+
+module_init(pacenand_plat_init);
+module_exit(pacenand_plat_exit);
+
+MODULE_ALIAS(DRIVER_NAME);
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Pace plc");
+MODULE_DESCRIPTION("Pace NAND flash driver");
diff -Naur kernel-3.3-3.0a-ref/drivers/mtd/pacenand/pacenand_base.c.orig kernel-current/drivers/mtd/pacenand/pacenand_base.c.orig
--- kernel-3.3-3.0a-ref/drivers/mtd/pacenand/pacenand_base.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/mtd/pacenand/pacenand_base.c.orig	2015-06-12 16:27:19.920068066 +0200
@@ -0,0 +1,1410 @@
+/****************************************************************************
+ *                                                                          *
+ * File        : pacenand_base.c                                            *
+ *                                                                          *
+ * Description : Interface between the low-level Pace NAND driver and the   *
+ *               Linux kernel MTD subsystem                                 *
+ *                                                                          *
+ * Author      : Arif Hussain / Neil Crossley / Sumil Patel                 *
+ *                                                                          *
+ * Copyright   : Pace Micro Technology 2011/2013 (c)                        *
+ *                                                                          *
+ *               The copyright in this material is owned by                 *
+ *               Pace Microtechnology PLC ("Pace"). This                    *
+ *               material is regarded as a highly confidential              *
+ *               trade secret of Pace. It may not be reproduced,            *
+ *               used, sold or in any other way exploited or                *
+ *               transferred to any third party without the prior           *
+ *               written permission of Pace.                                *
+ *                                                                          *
+ * History     : Second version, supports BCH ECC                           *
+ *             : Third version updated by Sumil for 4K chips support and    *
+ *               handling JFFS2 cleanmarker in raw(ECC disabled) mode       *
+ *                                                                          *
+ ****************************************************************************/
+
+#include <linux/init.h>
+#include <linux/device.h>
+#include <linux/platform_device.h>
+#include <linux/types.h>
+#include <stdbool.h>
+#include <linux/module.h>
+#include <linux/moduleparam.h>
+#include <linux/vmalloc.h>
+#include <linux/slab.h>
+#include <linux/errno.h>
+#include <linux/string.h>
+#include <linux/mtd/mtd.h>
+#include <linux/mtd/flashchip.h>
+#include <linux/mtd/nand.h>
+#include <linux/mtd/partitions.h>
+#include <linux/delay.h>
+#include <linux/interrupt.h>
+#include <linux/version.h>
+#include <linux/mtd/pacenand.h>
+#ifdef CONFIG_NS_ABS_POS
+#include <asm/io.h>
+#endif
+#if defined(LINUX) || defined(__linux__)
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(3,3,0)
+#include "linux/brcmstb/brcmstb.h"
+#else
+#include "asm/brcmstb/brcmstb.h"
+#endif
+#else
+#include "bchp_nand.h"
+#endif
+
+#define DRIVER_NAME "pacenand"
+#define DRIVER_INFO  "Pace STB NAND driver"
+#define CONTROLLER_VER    (10 * CONFIG_BRCMNAND_MAJOR_VERS + \
+    CONFIG_BRCMNAND_MINOR_VERS)
+
+
+#if defined(CONFIG_PACE_SYSTEM_IS_NAND_ONLY)
+#define SYSTEM_IS_NAND_ONLY            1
+#endif
+
+#if CONTROLLER_VER >= 60
+
+#define REG_ACC_CONTROL(cs) (BCHP_NAND_ACC_CONTROL_CS0 + ((cs) << 4))
+
+#define REG_CONFIG(cs) (BCHP_NAND_CONFIG_CS0 + ((cs) << 4))
+
+#define REG_TIMING_1(cs) (BCHP_NAND_TIMING_1_CS0 + ((cs) << 4))
+#define REG_TIMING_2(cs) (BCHP_NAND_TIMING_2_CS0 + ((cs) << 4))
+
+#else /* CONTROLLER_VER < 60 */
+
+#define REG_ACC_CONTROL(cs) \
+  ((cs) == 0 ? BCHP_NAND_ACC_CONTROL : \
+   (BCHP_NAND_ACC_CONTROL_CS1 + (((cs) - 1) << 4)))
+
+#define REG_CONFIG(cs) \
+  ((cs) == 0 ? BCHP_NAND_CONFIG : \
+   (BCHP_NAND_CONFIG_CS1 + (((cs) - 1) << 4)))
+
+#define REG_TIMING_1(cs) \
+  ((cs) == 0 ? BCHP_NAND_TIMING_1 : \
+   (BCHP_NAND_TIMING_1_CS1 + (((cs) - 1) << 4)))
+#define REG_TIMING_2(cs) \
+  ((cs) == 0 ? BCHP_NAND_TIMING_2 : \
+   (BCHP_NAND_TIMING_2_CS1 + (((cs) - 1) << 4)))
+
+#define WR_CORR_THRESH(cs, val) do { \
+  BDEV_WR(BCHP_NAND_CORR_STAT_THRESHOLD, \
+    ((val) & BCHP_NAND_CORR_STAT_THRESHOLD_CORR_STAT_THRESHOLD_MASK) \
+        << BCHP_NAND_CORR_STAT_THRESHOLD_CORR_STAT_THRESHOLD_SHIFT); \
+  } while (0);
+
+#endif /* CONTROLLER_VER < 60 */
+
+//#define CONFIG_MTD_PACENAND_DEBUG
+#if defined(CONFIG_MTD_PARTITIONS)
+static struct mtd_partition *parts = NULL;
+static const char           *part_probes[] = { "cmdlinepart", NULL };
+static unsigned int         nr_parts = 0;
+#endif
+static spinlock_t           chip_lock;
+static wait_queue_head_t    wq;
+static flstate_t            state = FL_READY;
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,31)
+#define device_size(mtd)   ((mtd)->size)
+#endif
+
+#define BREG_PA(x)    (BPHYSADDR(BCHP_##x##_REG_START))
+#define BREG_LEN(x)   (BCHP_##x##_REG_END + 4 - BCHP_##x##_REG_START)
+#define FC_SLICE_LEN  512
+
+
+struct pacenand_pm_info
+{
+  #ifdef CONFIG_BRCM_HAS_EDU
+  uint32_t edu_config;
+  #endif
+  uint32_t nand_cs_nand_select;
+  uint32_t nand_cs_nand_xor;
+  uint32_t corr_stat_threshold;
+  uint32_t acc_control;
+  uint32_t config;
+  uint32_t timing_1;
+  uint32_t timing_2;
+};
+
+struct pacenand_info
+{
+  struct platform_device  *pdev;
+  struct mtd_info         mtd;
+  struct mtd_partition    *parts;
+  NAND_DEV_INFO           *pacenand;
+  struct pacenand_pm_info *pm_info;
+  uint32_t                cs;
+};
+
+static struct nand_ecclayout  nand_oob;
+static struct pacenand_info   *info;
+static int      pacenand_get_device(struct mtd_info *mtd, int new_state);
+static void     pacenand_release_device(struct mtd_info *mtd);
+static void     pacenand_init_mtd(struct pacenand_info *info);
+
+static int32_t countsetbits(uint8_t * ptr, int32_t nbytes);
+
+/**
+* countsetbits -    Helper Function to find out number of bits set in array
+* @param ptr        Pointer to array
+* @param nbytes     Length of array
+*/
+static int32_t countsetbits(uint8_t * ptr, int32_t nbytes)
+{
+
+  uint8_t nbits,byte;
+  int32_t count = 0;
+  while(nbytes)
+  {
+	nbits = 8;
+	byte = *ptr;
+	while(nbits)
+	{
+	    if(byte & 1)
+		   count++;
+		byte >>= 1;
+		nbits--;
+	}
+	ptr++;
+	nbytes--;
+  }
+  return count;
+}
+/**
+* pacenand_write -  [MTD Interface] NAND write
+* @param mtd        MTD device structure
+* @param to         offset to write to
+* @param len        number of bytes to write
+* @param retlen     pointer to variable to store the number of written bytes
+* @param buf        the data to write
+*
+* Pace driver NAND write
+*
+* Note - Patched for BCH ECC support, now syncs the oob (spare area) on the first data write, this is
+*        needed as the ECC covers both the data area and the OOB too (except the OOB used to store
+*        the ECC data)
+*/
+
+static int pacenand_write(struct mtd_info *mtd, loff_t to, size_t len, size_t *retlen, const uint8_t *buf)
+{
+  int ret = 0;
+  uint32_t flag = 0;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s to %0llx len %d\n", __FUNCTION__, to, len);
+  #endif
+
+  pacenand_get_device(mtd, FL_WRITING);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s calling write_nand mtd->size %lx to %llx len %d\n", __FUNCTION__, (long)mtd->size, to, len);
+  #endif
+
+  /* As Part of Legacy, JFFS2 supports read/write of cleanmarker in Non BCH-ECC mode(i.e. ECC disabled/Hamming ECC)
+   * So if write is requested for first page of block, we pre-assume that cleanmarker is already written in its
+   * spare area using pacenand_write_oob().NDR_FLAGS_SYNCSPAREONWRITE flag is added only for first page write of
+   * each block to ensure that cleanmarker is read back from spare area before actual physical write and will be
+   * written along with page data in BCH-ECC enabled mode.This flag is not needed for UBIFS,
+   * but we pre-assume that it is harmless to UBIFS.
+  */
+  if((to & (mtd->erasesize -1)) == 0) flag = NDR_FLAGS_SYNCSPAREONWRITE;
+
+  #ifdef CONFIG_MTD_PACENAND_VERIFY_WRITE
+  ret = nand_dev_write_anywhere((void *)buf, (uint64_t)to, len, flag | NDR_FLAGS_VERIFY);
+  #else
+  ret = nand_dev_write_anywhere((void *)buf, (uint64_t)to, len, flag);
+  #endif
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s write_nand returned %d\n", __FUNCTION__, ret);
+  #endif
+
+  if (ret != NDR_SUCCESS)
+  {
+    printk("%s: error writing to NAND, error %d\n", __FUNCTION__, ret);
+    *retlen = len;
+    ret = -EIO;
+  }
+  else
+  {
+    *retlen = len;
+  }
+
+  pacenand_release_device(mtd);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_erase - [MTD Interface] erase block(s)
+* @param mtd        MTD device structure
+* @param instr      erase instruction
+*
+* Pace driver NAND erase one or more blocks
+*/
+
+static int pacenand_erase(struct mtd_info *mtd, struct erase_info *instr)
+{
+  int startblock, endblock, i, ret = 0;
+  NDR_ERROR result;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s addr %08lx, len %ld\n", __FUNCTION__, (unsigned long)instr->addr, (unsigned long)instr->len);
+  #endif
+
+  startblock = instr->addr / mtd->erasesize;
+  endblock = (instr->addr + instr->len) / mtd->erasesize;
+  instr->state = MTD_ERASING;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s startblock %d endblock %d\n", __FUNCTION__, startblock, endblock);
+  #endif
+
+  pacenand_get_device(mtd, FL_ERASING);
+
+  for (i = startblock; i < endblock; i++)
+  {
+    if (nand_dev_is_block_bad(i) == NDR_BLOCK_IS_GOOD)
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("-->%s calling nand_dev_erase_block with block %d\n", __FUNCTION__, i);
+      #endif
+
+      result = nand_dev_erase_block(i);
+
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("-->%s nand_dev_erase_block returned %d\n", __FUNCTION__, result);
+      #endif
+
+      if (result != NDR_SUCCESS)
+      {
+        if (result == NDR_DEVICE_ERASE_ERROR)
+        {
+          #ifdef CONFIG_MTD_PACENAND_DEBUG
+          printk("-->%s error while erasing block %d, should mark block bad\n", __FUNCTION__, i);
+          #endif
+          nand_dev_mark_block_bad(i);
+        }
+
+        #ifdef CONFIG_MTD_PACENAND_DEBUG
+        printk("-->%s got error %d while erasing block %d\n", __FUNCTION__, result, i);
+        #endif
+
+        instr->state = MTD_ERASE_FAILED;
+        goto erase_exit;
+      }
+    }
+    else
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("-->%s block %d is already bad\n", __FUNCTION__, i);
+      #endif
+
+      instr->state = MTD_ERASE_FAILED;
+      goto erase_exit;
+    }
+  }
+  instr->state = MTD_ERASE_DONE;
+
+  erase_exit:
+  ret = (instr->state == MTD_ERASE_DONE) ? 0 : -EIO;
+
+  pacenand_release_device(mtd);
+
+  /* Do call back function */
+  if (!ret)
+  {
+    mtd_erase_callback(instr);
+  }
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_read - [MTD Interface] MTD read data
+* @param mtd        MTD device structure
+* @param from       offset to read from
+* @param len        number of bytes to read
+* @param retlen     pointer to variable to store the number of read bytes
+* @param buf        the data buffer to put data in
+*
+* Pace driver NAND read data
+*/
+
+static int pacenand_read(struct mtd_info *mtd, loff_t from, size_t len, size_t *retlen, uint8_t *buf)
+{
+  int ret = 0;
+  NAND_DEV_INFO *pacenand = (NAND_DEV_INFO*) mtd->priv;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s from %0llx len %d\n", __FUNCTION__, from, len);
+  /* When doing debugging, set the buffer to dummy values */
+  memset(buf, 0xA5, len);
+  #endif
+
+  /* Do not allow reads past end of device */
+
+  if (unlikely((from + len) > device_size(mtd)))
+  {
+    return -EINVAL;
+  }
+
+  /* If trying to read zero data, then just return */
+
+  else if (!len)
+  {
+    return *retlen = 0;
+  }
+
+  /* Do the read NAND function */
+  pacenand_get_device(mtd, FL_READING);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s calling read_nand mtd->size %lx from %llx\n", __FUNCTION__, (long)device_size(mtd), from);
+  #endif
+
+  ret = nand_dev_read_anywhere(buf, (uint64_t)from, len, /*NDR_FLAGS_CRC */ 0);
+
+  /* As Part of Legacy, JFFS2 supports read/write of cleanmarker in Non BCH-ECC mode(i.e. ECC disabled/Hamming ECC)
+   * So If driver uses BCH-ECC, read on the page(first page of each block) whose spare area is written
+   * with cleanmarker using pacenand_write_oob() will return Non-Correctable Error on read if its data area
+   * is not written with other data(cleanmarker node of 256 byte) using pacenand_write().
+   * Following functionality ensure that Non-Correctable Errors resulting from cleanmarker are discarded
+   * with keeping consideration of 8-bit ECC flash where each page is prone to bit errors but not more than
+   * 8-bit/512 bytes subpage.This functionality has no impact on UBIFS.
+  */
+  if ((ret == NDR_UNCORRECTABLE_ERROR) && ((from & (mtd->erasesize -1)) == 0) && (len <= FC_SLICE_LEN))
+  {
+     uint8_t       bufraw[FC_SLICE_LEN];
+     uint8_t       buffix[256];
+     int i, err;
+     int oob_bitflips,data_bitflips,total_bitflips,oob_nbits,data_nbits,thresold,subpages,eccbytes;
+     memset(&bufraw, 0xff, sizeof(bufraw));
+     err = nand_dev_read_spare(((uint32_t)from/mtd->writesize),bufraw);
+     if(err == NDR_SUCCESS)
+     {
+
+	 	for(i = 0; i < pacenand->Spare_Area_ECC_Bytes; i++)
+	   		buffix[i] = bufraw[pacenand->Spare_Area_ECC_bytes[i]];
+        subpages = pacenand->Virt_Page_Size/FC_SLICE_LEN;
+        eccbytes = pacenand->Spare_Area_ECC_Bytes/subpages;
+        oob_nbits = eccbytes << 3;
+	    oob_bitflips = oob_nbits - countsetbits(&buffix[0],eccbytes);
+	    memset(&bufraw, 0xff, sizeof(bufraw));
+		err = nand_dev_read_anywhere_raw(bufraw,(uint64_t)from, FC_SLICE_LEN,0);
+		if(err == NDR_SUCCESS)
+		{
+			data_nbits = FC_SLICE_LEN << 3;
+			data_bitflips = data_nbits - countsetbits(bufraw,FC_SLICE_LEN);
+			total_bitflips = data_bitflips + oob_bitflips;
+			thresold = (pacenand->ECC_Type == 0)?1:(pacenand->ECC_Type == 1)?2:(pacenand->ECC_Type == 2)?6:9;
+			if(!oob_bitflips || (total_bitflips < thresold))
+			{
+				memset(buf, 0xff, len);
+				ret = NDR_SUCCESS;
+			}
+		}
+     }
+  }
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s read_nand returned %d\n", __FUNCTION__, ret);
+  #endif
+
+  /* Was the read successful? */
+  if (ret != NDR_SUCCESS)
+  {
+    *retlen = len; /* Return len even with failure */
+
+    /* Return the right error code if the error was correctable */
+    if (ret == NDR_CORRECTABLE_ERROR)
+    {
+	  mtd->ecc_stats.corrected += 1;
+      ret = -EUCLEAN;
+    }
+
+    /* Return the right error code if the error was uncorrectable */
+    else if (ret == NDR_UNCORRECTABLE_ERROR)
+    {
+	  mtd->ecc_stats.failed += 1;
+      ret = -EBADMSG;
+    }
+
+    /* General failure */
+    else
+    {
+      ret = -EIO;
+    }
+  }
+
+  /* Read was successful */
+  else
+  {
+    *retlen = len;
+  }
+
+  pacenand_release_device(mtd);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s retlen %d len %d\n", __FUNCTION__, *retlen, len);
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/*
+
+ struct mtd_oob_ops - oob operation operands
+ @mode: operation mode
+
+ @len:  number of data bytes to write/read
+
+ @retlen: number of data bytes written/read
+
+ @ooblen: number of oob bytes to write/read
+ @oobretlen:  number of oob bytes written/read
+ @ooboffs:  offset of oob data in the oob area (only relevant when
+  mode = MTD_OPS_PLACE_OOB or MTD_OPS_RAW)
+ @datbuf: data buffer - if NULL only oob data are read/written
+ @oobbuf: oob data buffer
+
+ Note, it is allowed to read more than one OOB area at one go, but not write.
+ The interface assumes that the OOB write requests program only one page's
+ OOB area.
+
+struct mtd_oob_ops {
+  unsigned int  mode;
+  size_t    len;
+  size_t    retlen;
+  size_t    ooblen;
+  size_t    oobretlen;
+  uint32_t  ooboffs;
+  uint8_t   *datbuf;
+  uint8_t   *oobbuf;
+};
+
+*/
+
+/**
+* pacenand_read_oob - [MTD Interface] MTD read OOB
+* @param mtd        MTD device structure
+* @param from       OOB offset to read from
+* @param ops        OOB ops structure
+*
+* Note, it is allowed to read more than one OOB area at one go
+*/
+
+static int pacenand_read_oob(struct mtd_info *mtd, loff_t from, struct mtd_oob_ops *ops)
+{
+  NAND_DEV_INFO *pacenand = (NAND_DEV_INFO*) mtd->priv;
+  NDR_ERROR     ne;
+  int           realpage;
+  int           pageoffs;
+  int           readlen = ops->ooblen;
+  int           offs = ops->ooboffs;
+  int           oobsize = pacenand->Spare_Area_Free;
+  uint8_t       *buf = ops->oobbuf;
+  int           ret = 0;
+  int           len;
+  uint8_t       bufraw[256];
+  uint8_t       buffix[256];
+  int           i;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s read OOB\n", __FUNCTION__);
+  printk("   from offset %llx\n", from);
+  #endif
+
+  if (unlikely((from + offs + readlen) > device_size(mtd)))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   attempt read beyond end of device\n");
+    #endif
+    return -EINVAL;
+  }
+
+  if(!readlen)
+  {
+	#ifdef CONFIG_MTD_PACENAND_DEBUG
+	printk("   read length is zero\n");
+    #endif
+	ops->oobretlen = ops->ooblen;
+	return 0;
+  }
+  realpage = (int)((unsigned long)from / mtd->writesize);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("   reading from page %d ooblen %d ooboffs %d mode %d\n", realpage, readlen, offs, ops->mode);
+  #endif
+
+  pacenand_get_device(mtd, FL_READING);
+
+  /* Quick check that the offset is within the selected page, if not then
+     increment realpage until it is (probably not likley to happen but
+     it would be legal)                                                   */
+
+  pageoffs = offs / oobsize;
+  if (pageoffs)
+  {
+    realpage += pageoffs;
+    offs %= oobsize;
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   skipping %d pages (offset not within current page)\n", pageoffs);
+    #endif
+  }
+
+  /* Main read loop */
+
+  for (;;)
+  {
+    /* Read the spare area */
+    ne = nand_dev_read_spare(realpage, bufraw);
+    if (ne != NDR_SUCCESS)
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("   error reading from NAND, error %d\n", ne);
+      #endif
+      ret = -EINVAL;
+      break;
+    }
+
+    /* Rearrange */
+
+    memset(&buffix, 0xff, oobsize);
+
+    for (i = 0; i < oobsize; i++)
+    {
+      buffix[i] = bufraw[pacenand->Spare_Area_Bytes[i]];
+    }
+
+    /* Copy data back to caller */
+
+    if ((offs + readlen) > oobsize)
+    {
+      len = oobsize - offs;
+    }
+    else
+    {
+      len = readlen;
+    }
+
+    memcpy(buf, &buffix[offs], len);
+    buf += len;
+
+    /* Clear offs, decrement bytes to read, bail if finished */
+
+    offs = 0;
+    readlen -= len;
+    realpage ++;
+
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   %d OOB bytes left to read \n", readlen);
+    #endif
+
+    if (readlen <= 0)
+    {
+      break;
+    }
+  }
+
+  /* Exit */
+  pacenand_release_device(mtd);
+
+  if (ret == 0)
+  {
+  	ops->oobretlen = ops->ooblen;
+  }
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_write_oob - [MTD Interface] MTD write OOB
+* @param mtd        MTD device structure
+* @param to         OOB offset to write to
+* @param ops        OOB ops structure
+*
+* Note, it is allowed to read more than one OOB area at one go, but not write.
+* The interface assumes that the OOB write requests program only one page's
+* OOB area.
+*/
+
+static int pacenand_write_oob(struct mtd_info *mtd, loff_t to, struct mtd_oob_ops *ops)
+{
+  NAND_DEV_INFO *pacenand = (NAND_DEV_INFO*) mtd->priv;
+  NDR_ERROR     ne;
+  int           realpage;
+  int           writelen = ops->ooblen;
+  int           offs = ops->ooboffs;
+  int           oobsize = pacenand->Spare_Area_Free;
+  uint8_t       *buf = ops->oobbuf;
+  int           ret = 0;
+  uint8_t       bufraw[256];
+  uint8_t       buffix[256];
+  int           i;
+
+  /* Support for ubiformat */
+  if ((ops->len)  && (ops->datbuf != NULL)) ret = pacenand_write(mtd,to, ops->len, &(ops->retlen), ops->datbuf);
+  if(ret) return ret;
+  if(!ops->ooblen) return ret;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s write OOB\n", __FUNCTION__);
+  printk("   to offset %llx\n", to);
+  #endif
+
+  if (unlikely((to + offs + writelen) > device_size(mtd)))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   attempt read beyond end of device\n");
+    #endif
+    return -EINVAL;
+  }
+
+  if (unlikely((offs / oobsize) != 0))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   offset %d not within current page\n", offs);
+    #endif
+    return -EINVAL;
+  }
+
+  if (unlikely((writelen + offs) > oobsize))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   write length %d greater than oob size\n", writelen);
+    #endif
+    return -EINVAL;
+  }
+  if(!writelen)
+  {
+	#ifdef CONFIG_MTD_PACENAND_DEBUG
+	printk("   write length is zero\n");
+    #endif
+  	ops->oobretlen = ops->ooblen;
+  	return 0;
+  }
+  realpage = (int)((unsigned long)to / mtd->writesize);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("   writing to page %d ooblen %d ooboffs %d mode %d\n", realpage, writelen, offs, ops->mode);
+  #endif
+
+  pacenand_get_device(mtd, FL_WRITING);
+
+  /* Prepare spare area buffer */
+
+  memset(&bufraw, 0xff, oobsize);
+  memcpy(&bufraw[offs], buf, writelen);
+
+  /* Rearrange */
+
+  memset(&buffix, 0xff, sizeof(buffix));
+
+  for (i = 0; i < oobsize; i++)
+  {
+    buffix[pacenand->Spare_Area_Bytes[i]] = bufraw[i];
+  }
+
+  /* Write */
+  ne = nand_dev_write_spare(realpage, buffix);
+
+  if (ne != NDR_SUCCESS)
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("   error writing to NAND, error %d\n", ne);
+    #endif
+    ret = -EINVAL;
+  }
+
+  /* Exit */
+
+  pacenand_release_device(mtd);
+
+  if (ret == 0)
+  {
+    ops->oobretlen = ops->ooblen;
+  }
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_writev - [MTD Interface] Pace NAND driver write vector function (not implemented)
+* @param mtd        MTD device structure
+* @param vecs       the iovectors to write
+* @param count      number of vectors
+* @param to         offset to write to
+* @param retlen     pointer to variable to store the number of written bytes
+*
+* Pace NAND write with kvec.
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+static int pacenand_writev(struct mtd_info *mtd, const struct kvec *vecs, unsigned long count, loff_t to, size_t *retlen)
+{
+  printk("-->%s count %08lX to %0llx\n", __FUNCTION__, count, to);
+  return 0;
+}
+#endif
+
+
+/**
+* pacenand_sync - [MTD Interface] synchronise flash contents
+* @param mtd    MTD device structure
+*
+* Sync is actually a wait for chip ready function
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+static void pacenand_sync(struct mtd_info *mtd)
+{
+  printk("-->%s\n", __FUNCTION__);
+}
+#endif
+
+
+/**
+* pacenand_unlock - [MTD Interface] unlock block(s)
+* @param mtd    MTD device structure
+* @param ofs    offset relative to MTD start
+* @param len    number of bytes to unlock
+*
+* Unlock one or more blocks
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+
+#if LINUX_VERSION_CODE >= KERNEL_VERSION(2,6,31)
+
+static int pacenand_unlock(struct mtd_info *mtd, loff_t llofs, uint64_t len)
+{
+  printk("-->%s llofs %0llx len %lld\n", __FUNCTION__, llofs, len);
+  return 0;
+}
+
+#else
+
+static int pacenand_unlock(struct mtd_info *mtd, loff_t llofs, size_t len)
+{
+  printk("-->%s llofs %0llx len %d\n", __FUNCTION__, llofs, len);
+  return 0;
+}
+
+#endif
+
+#endif
+
+
+/**
+* pacenand_suspend - [MTD Interface] suspend the NAND flash
+* @param mtd    MTD device structure
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+
+static int pacenand_suspend(struct mtd_info *mtd)
+{
+  printk("-->%s\n", __FUNCTION__);
+  return 0;
+}
+
+#endif
+
+
+/**
+* pacenand_resume - [MTD Interface] resume the NAND flash
+* @param mtd    MTD device structure
+*/
+
+#ifdef CONFIG_MTD_PACENAND_DEBUG
+
+static void pacenand_resume(struct mtd_info *mtd)
+{
+  printk("-->%s  \n", __FUNCTION__);
+}
+
+#endif
+
+
+/**
+* pacenand_block_isbad - [MTD Interface] return flag indicating block state (1 = bad, 0 = good)
+* @param mtd    MTD device structure
+* @param ofs     offset relative to MTD start
+*/
+
+static int pacenand_block_isbad(struct mtd_info *mtd, loff_t ofs)
+{
+  uint32_t block;
+  int ret = 0;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s ofs %0llx\n", __FUNCTION__, ofs);
+  #endif
+
+  block = (uint32_t)ofs / mtd->erasesize;
+  pacenand_get_device(mtd, FL_READING);
+
+  #ifdef CONFIG_MTD_PACENAND_CLEAR_BAD_BLOCK_MARKERS
+
+  /* This code will clear the bad block marker */
+
+  if (nand_dev_is_block_bad(block) != NDR_BLOCK_IS_GOOD)
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("-->%s WARNING: erasing block %d and clearing the bad block flag\n", __FUNCTION__, block);
+    #endif
+    if ((ret = nand_dev_erase_block(block)) != NDR_SUCCESS)
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("-->%s ERROR: unable to erase block %d, error %d\n", __FUNCTION__, block, ret);
+      #endif
+      ret = 1;
+    }
+    else
+    {
+      ret = (nand_dev_is_block_bad(block) == NDR_BLOCK_IS_GOOD) ? 0 : 1;
+    }
+  }
+
+  #else
+
+  ret = (nand_dev_is_block_bad(block) == NDR_BLOCK_IS_GOOD) ? 0 : 1;
+
+  #endif
+
+  pacenand_release_device(mtd);
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s block %d at offset %0llx is %s\n", __FUNCTION__, block, ofs, ret ? "bad" : "good");
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+
+  return ret;
+}
+
+
+/**
+* pacenand_block_markbad - [MTD Interface] mark the block at the given offset as bad
+* @param mtd    MTD device structure
+* @param ofs    offset relative to MTD start
+*
+* Mark the block as bad
+*/
+
+static int pacenand_block_markbad(struct mtd_info *mtd, loff_t ofs)
+{
+  uint32_t block;
+  int ret = 0;
+
+  block = (uint32_t)ofs / mtd->erasesize;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s ofs %0llx block %d\n", __FUNCTION__, ofs, block);
+  #endif
+
+  if ((ret = nand_dev_mark_block_bad(block)) != 0)
+  {
+    ret = -EIO;
+  }
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s complete, returning %d\n", __FUNCTION__, ret);
+  #endif
+  return ret;
+}
+
+
+/**
+* pacenand_probe - [MTD Interface] Initialise the device
+* @param pdev    MTD platform device structure
+*
+* Initialise the device
+*/
+
+static int __devinit pacenand_probe(struct platform_device *pdev)
+{
+  struct brcmnand_platform_data *pd = pdev->dev.platform_data;
+  struct device_node *dn = pdev->dev.of_node;
+  int i;
+
+  #if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 0, 0)
+  const char *part_probe_types[] = { "cmdlinepart", "ofpart", "RedBoot",NULL };
+  #elif defined(CONFIG_MTD_PARTITIONS)
+  /* for 2.6.37 compatibility only */
+  int nr_parts = 0;
+  int err = 0;
+  struct mtd_partition *parts = NULL;
+  const char *part_probe_types[] = { "cmdlinepart", "RedBoot", NULL };
+  #endif
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s\n", __FUNCTION__);
+  #endif
+
+  printk(DRIVER_INFO " using Pace NAND controller\n");
+
+  /* If driver already initialised return an error */
+  i = nand_dev_init();
+  if (!((i == 0) || (i == NDR_ALREADY_INITIALISED)))
+  {
+    #ifdef CONFIG_MTD_PACENAND_DEBUG
+    printk("-->%s nand_dev_init() failed to initialise the NAND driver %d\n", __FUNCTION__, i);
+    #endif
+    return -EPERM;
+  }
+  else if (!(info = kzalloc(sizeof(struct pacenand_info), GFP_KERNEL)))
+  {
+    return -ENOMEM;
+  }
+  else if (!(info->pm_info = kzalloc(sizeof(struct pacenand_pm_info), GFP_KERNEL)))
+  {
+    return -ENOMEM;
+  }
+  else
+  {
+    if (nand_dev_get_info(&info->pacenand) != 0)
+    {
+      return -EIO;
+    }
+  }
+  info->pdev = pdev;
+
+  #ifdef SYSTEM_IS_NAND_ONLY
+
+  info->cs = 0;
+
+  #else
+
+  info->cs = 1;
+
+  #endif
+
+  dev_set_drvdata(&pdev->dev, info);
+  state = FL_READY;
+  init_waitqueue_head(&wq);
+  spin_lock_init(&chip_lock);
+  pacenand_init_mtd(info);
+
+	#if LINUX_VERSION_CODE >= KERNEL_VERSION(3, 0, 0)
+
+	if (dn)
+	{
+		struct mtd_part_parser_data ppdata = {.of_node = dn };
+		mtd_device_parse_register(&info->mtd, part_probe_types, &ppdata, NULL, 0);
+	}
+	else
+	{
+		mtd_device_parse_register(&info->mtd, part_probe_types, NULL, pd->parts, pd->nr_parts);
+	}
+
+  #elif defined(CONFIG_MTD_PARTITIONS)
+
+  if (mtd_has_cmdlinepart())
+  {
+    /* Parse the MTD partitions, if defined on the command line */
+    nr_parts = parse_mtd_partitions(&info->mtd, part_probes, &parts, 0);
+    if (nr_parts <= 0)
+    {
+      /* If none on cmdline, then look for platform data */
+      nr_parts = pd->nr_parts;
+      parts = pd->parts;
+    }
+    if ((parts) && (nr_parts))
+    {
+      if ((err = add_mtd_partitions(&info->mtd, parts, nr_parts)) != 0)
+      {
+        panic("Pace NAND driver could not add MTD partitions!\n");
+      }
+    }
+  }
+
+  #endif
+
+  return 0;
+}
+
+
+/**
+* pacenand_remove - [MTD Interface] Deinitialise the device
+* @param pdev    MTD platform device structure
+*
+* Deinitialise the device
+*/
+
+static int __devexit pacenand_remove(struct platform_device *pdev)
+{
+  dev_set_drvdata(&pdev->dev, NULL);
+  if (info->pm_info)
+  {
+    kfree(info->pm_info);
+  }
+  if (info)
+  {
+    kfree(info);
+  }
+
+  return 0;
+}
+
+
+/**
+* pacenand_init_mtd -  [MTD Interface] Deinitialise the device
+* @param pacenand_info - Pace NAND information structure pointer
+*
+* Initialise the MTD structure
+*/
+
+static void pacenand_init_mtd(struct pacenand_info *info)
+{
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  int i;
+  #endif
+
+  /* Build the nand_oob structure */
+
+  memset(&nand_oob, 0, sizeof(nand_oob));
+  nand_oob.oobavail = info->pacenand->Spare_Area_Free;
+  nand_oob.oobfree[0].offset = 0;
+  nand_oob.oobfree[0].length = info->pacenand->Spare_Area_Free;
+  nand_oob.oobfree[1].offset = 0;
+  nand_oob.oobfree[1].length = 0;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s %d bytes free in OOB\n", __FUNCTION__, info->pacenand->Spare_Area_Free);
+  printk("Log to phys translate list is ...\n");
+  for (i = 0; i < info->pacenand->Spare_Area_Free; i++)
+  {
+    printk("Log %2d is phys %2d\n", i, info->pacenand->Spare_Area_Bytes[i]);
+  }
+  #endif
+
+  /* Fill in remaining MTD driver data */
+
+  info->mtd.type = MTD_NANDFLASH;
+  info->mtd.flags = MTD_CAP_NANDFLASH;
+
+  info->mtd.erase = pacenand_erase;
+  info->mtd.point = NULL;
+  info->mtd.unpoint = NULL;
+  info->mtd.read = pacenand_read;
+  info->mtd.write = pacenand_write;
+  info->mtd.read_oob = pacenand_read_oob;
+  info->mtd.write_oob = pacenand_write_oob;
+
+  /* Not needed? */
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  info->mtd.writev = pacenand_writev;
+  info->mtd.sync = pacenand_sync;
+  #else
+  info->mtd.writev = NULL;
+  info->mtd.sync = NULL;
+  #endif
+  info->mtd.sync = NULL;
+  info->mtd.lock = NULL;
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  info->mtd.unlock = pacenand_unlock;
+  #else
+  info->mtd.unlock = NULL;
+  #endif
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  info->mtd.suspend = pacenand_suspend;
+  info->mtd.resume = pacenand_resume;
+  #else
+  info->mtd.suspend = NULL;
+  info->mtd.resume = NULL;
+  #endif
+  info->mtd.block_isbad = pacenand_block_isbad;
+  info->mtd.block_markbad = pacenand_block_markbad;
+
+  /* Propagate ECC layout to mtd_info */
+
+  info->mtd.ecclayout = &nand_oob;
+  info->mtd.ecc_stats.failed = 0;
+  info->mtd.ecc_stats.corrected = 0;
+
+  /* NAND page size & block size */
+
+  info->mtd.writesize = info->pacenand->Virt_Page_Size;
+  info->mtd.writebufsize = info->mtd.writesize;
+
+  /* OOB size for MLC NAND varies depend on the chip */
+
+  info->mtd.oobsize = info->pacenand->Spare_Area_Size;
+
+  info->mtd.oobavail = nand_oob.oobavail;
+
+  info->mtd.erasesize = info->pacenand->Block_Size;
+  #if LINUX_VERSION_CODE < KERNEL_VERSION(2,6,31)
+  info->mtd.eccsize = info->pacenand->Virt_Page_Size;
+  info->mtd.ecctype = MTD_ECC_NONE;
+  #endif
+  info->mtd.subpage_sft = 0;  /* this is a right shift (divide) */
+  info->mtd.size = info->pacenand->Device_Size;
+  info->mtd.name = dev_name(&info->pdev->dev);
+  info->mtd.dev.parent = &info->pdev->dev;
+  info->mtd.reboot_notifier.notifier_call = NULL;
+
+  /* use the priv slot to store the nand_info structure pointer */
+
+  info->mtd.priv = (NAND_DEV_INFO *)info->pacenand;
+
+  #ifdef CONFIG_MTD_PACENAND_DEBUG
+  printk("-->%s device size %d, block size=%d, oob size=%d, write size=%d spare area size = %d\n", __FUNCTION__, (unsigned int)info->mtd.size, info->mtd.erasesize, info->mtd.oobsize, info->mtd.writesize, info->pacenand->Spare_Area_Size);
+  #endif
+
+  info->mtd.owner = THIS_MODULE;
+}
+
+
+/**
+* Power management save/restore functions
+*
+*/
+
+#define HIF_ENABLED_IRQ(bit) \
+  (!BDEV_RD_F(HIF_INTR2_CPU_MASK_STATUS, bit##_INTR))
+
+#define CMD_FLASH_RESET    0x09
+#define FLASH_RESET_TIMEOUT 200000
+
+static int pacenand_pm_suspend(struct device *dev)
+{
+  if (brcm_pm_deep_sleep())
+  {
+
+    struct pacenand_info *info = dev_get_drvdata(dev);
+
+    if ((info) && (info->pm_info))
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("%s : Save(0x%X:%d)\n", __FUNCTION__,(unsigned int) info, info->cs);
+      #endif
+
+      #ifdef CONFIG_BRCM_HAS_EDU
+      info->pm_info->edu_config = BDEV_RD(BCHP_EDU_CONFIG);
+      #endif
+      info->pm_info->nand_cs_nand_select = BDEV_RD(BCHP_NAND_CS_NAND_SELECT);
+      info->pm_info->nand_cs_nand_xor = BDEV_RD(BCHP_NAND_CS_NAND_XOR);
+      info->pm_info->corr_stat_threshold = BDEV_RD(BCHP_NAND_CORR_STAT_THRESHOLD);
+      info->pm_info->acc_control = BDEV_RD(REG_ACC_CONTROL(info->cs));
+      info->pm_info->config = BDEV_RD(REG_CONFIG(info->cs));
+      info->pm_info->timing_1 = BDEV_RD(REG_TIMING_1(info->cs));
+      info->pm_info->timing_2 = BDEV_RD(REG_TIMING_2(info->cs));
+      state = FL_PM_SUSPENDED;
+    }
+  }
+  return 0;
+}
+
+static int pacenand_pm_resume(struct device *dev)
+{
+  if (brcm_pm_deep_sleep())
+  {
+
+    struct pacenand_info *info = dev_get_drvdata(dev);
+    unsigned int delay;
+    volatile unsigned int reg;
+
+    if ((info) && (info->pm_info))
+    {
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      printk("%s : Restore\n", __FUNCTION__);
+      #endif
+
+      #ifdef CONFIG_BRCM_HAS_EDU
+      BDEV_WR_RB(BCHP_EDU_CONFIG, info->pm_info->edu_config);
+      BDEV_WR(BCHP_EDU_ERR_STATUS, 0);
+      BDEV_WR(BCHP_EDU_DONE, 0);
+      BDEV_WR(BCHP_EDU_DONE, 0);
+      BDEV_WR(BCHP_EDU_DONE, 0);
+      BDEV_WR(BCHP_EDU_DONE, 0);
+      #endif
+
+      BDEV_WR_RB(BCHP_NAND_CS_NAND_SELECT, info->pm_info->nand_cs_nand_select);
+      BDEV_WR_RB(BCHP_NAND_CS_NAND_XOR, info->pm_info->nand_cs_nand_xor);
+      BDEV_WR_RB(BCHP_NAND_CORR_STAT_THRESHOLD, info->pm_info->corr_stat_threshold);
+      BDEV_WR_RB(REG_ACC_CONTROL(info->cs), info->pm_info->acc_control);
+      BDEV_WR_RB(REG_CONFIG(info->cs), info->pm_info->config);
+      BDEV_WR_RB(REG_TIMING_1(info->cs), info->pm_info->timing_1);
+      BDEV_WR_RB(REG_TIMING_2(info->cs), info->pm_info->timing_2);
+      HIF_ACK_IRQ(NAND_CTLRDY);
+
+      /* Reset the chip, required by some chips after power-up */
+      BDEV_WR_RB(BCHP_NAND_CMD_EXT_ADDRESS, info->cs << 16);
+      BDEV_WR_RB(BCHP_NAND_CMD_ADDRESS, 0);
+      BDEV_WR_RB(BCHP_NAND_CMD_START, CMD_FLASH_RESET << BCHP_NAND_CMD_START_OPCODE_SHIFT);
+
+      /* Wait up to 20 milliseconds for autodetect to complete.
+         Wait for INTFC_STATUS.CTLR_READY to be cleared, and then to be set, with timeouts. */
+
+      delay = FLASH_RESET_TIMEOUT;
+      reg = 1;
+
+      while ((delay--) && (reg))
+      {
+        reg = BDEV_RD(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_CTLR_READY_MASK;
+      }
+
+      while ((delay--) && (!reg))
+      {
+        reg = BDEV_RD(BCHP_NAND_INTFC_STATUS) & BCHP_NAND_INTFC_STATUS_CTLR_READY_MASK;
+      }
+      #ifdef CONFIG_MTD_PACENAND_DEBUG
+      if (!reg)
+      {
+        printk("%s : !!! FLASH_RESET timeout !!!\n", __FUNCTION__);
+      }
+      else
+      {
+        printk("%s : FLASH_RESET took %d reads !!!\n", __FUNCTION__, FLASH_RESET_TIMEOUT - delay);
+      }
+      #endif
+      state = ( state == FL_PM_SUSPENDED)? FL_READY : state;
+    }
+  }
+  return 0;
+}
+
+
+static const struct dev_pm_ops pacenand_pm_ops = {
+  .suspend = pacenand_pm_suspend,
+  .resume = pacenand_pm_resume,
+};
+
+
+static struct platform_driver driver = {
+  .driver = {
+      .name = DRIVER_NAME,
+      .owner = THIS_MODULE,
+      .pm = &pacenand_pm_ops,
+    },
+  .probe = pacenand_probe,
+  .remove = __devexit_p(pacenand_remove),
+};
+
+
+static int __init pacenand_plat_init(void)
+{
+  if (!request_mem_region(BREG_PA(NAND), BREG_LEN(NAND), DRIVER_NAME))
+  {
+    printk(KERN_ERR "%s: can't request memory region\n", __func__);
+    return -ENODEV;
+  }
+  platform_driver_register(&driver);
+  return 0;
+}
+
+static void __exit pacenand_plat_exit(void)
+{
+  platform_driver_unregister(&driver);
+}
+
+
+/**
+* pacenand_get_device - [GENERIC] Get chip for selected access
+* @param mtd    MTD device structure
+* @param new_state  the state which is requested
+*
+* Get the device and lock it for exclusive access
+*/
+
+static int pacenand_get_device(struct mtd_info *mtd, int new_state)
+{
+  DECLARE_WAITQUEUE(wait, current);
+
+  /*
+   * Grab the lock and see if the device is available
+   */
+  for (;;)
+  {
+    spin_lock(&chip_lock);
+
+    /* If the chip is available, use it straight away */
+
+    if (state == FL_READY)
+    {
+      state = new_state;
+      spin_unlock(&chip_lock);
+      break;
+    }
+
+    /* If the new state is to suspend the chip... */
+
+    else if (new_state == FL_PM_SUSPENDED)
+    {
+      spin_unlock(&chip_lock);
+      return (state == FL_PM_SUSPENDED) ? 0 : -EAGAIN;
+    }
+
+    /* Chip isn't available, so cycle round on a wait queue until woken up */
+
+    set_current_state(TASK_UNINTERRUPTIBLE);
+    add_wait_queue(&wq, &wait);
+    spin_unlock(&chip_lock);
+    if (!in_interrupt())
+    {
+      schedule();
+    }
+    remove_wait_queue(&wq, &wait);
+  }
+  return 0;
+}
+
+
+/**
+* pacenand_release_device - [GENERIC] release chip
+* @param mtd    MTD device structure
+*
+* Deselect, release chip lock and wake up anyone waiting on the device
+*/
+
+static void pacenand_release_device(struct mtd_info *mtd)
+{
+  /* Release the chip, and wake up any threads that are waiting on it */
+  spin_lock(&chip_lock);
+  state = FL_READY;
+  wake_up(&wq);
+  spin_unlock(&chip_lock);
+}
+
+
+/**
+* Module init/exit and declarations
+*/
+
+module_init(pacenand_plat_init);
+module_exit(pacenand_plat_exit);
+
+MODULE_ALIAS(DRIVER_NAME);
+MODULE_LICENSE("GPL");
+MODULE_AUTHOR("Pace plc");
+MODULE_DESCRIPTION("Pace NAND flash driver");
diff -Naur kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmgenet.c kernel-current/drivers/net/ethernet/broadcom/genet/bcmgenet.c
--- kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmgenet.c	2013-08-28 01:30:59.000000000 +0200
+++ kernel-current/drivers/net/ethernet/broadcom/genet/bcmgenet.c	2015-06-12 16:27:20.044130062 +0200
@@ -328,7 +328,6 @@
 	/* update stats */
 	dev->stats.tx_bytes += buf_len;
 	dev->stats.tx_packets++;
-
 	dev->trans_start = jiffies;
 
 	return 0;
@@ -441,7 +440,7 @@
 	struct BcmEnet_devctrl *pDevCtrl = container_of(work,
 			struct BcmEnet_devctrl, bcmgenet_link_work);
 
-	bcmgenet_mii_setup(pDevCtrl->dev);
+	bcmgenet_mii_setup(pDevCtrl->dev, 0);
 }
 /* --------------------------------------------------------------------------
 Name: bcmgenet_gphy_link_timer
@@ -515,6 +514,7 @@
 	struct BcmEnet_devctrl *pDevCtrl = netdev_priv(dev);
 	unsigned long dma_ctrl;
 	volatile struct uniMacRegs *umac = pDevCtrl->umac;
+	unsigned int do_reinit = 0;
 
 	TRACE(("%s: bcmgenet_open\n", dev->name));
 
@@ -536,12 +536,23 @@
 	if (pDevCtrl->wol_enabled) {
 		/* From WOL-enabled suspend, switch to regular clock */
 		clk_disable(pDevCtrl->clk_wol);
+		do_reinit = 1;
+	}
+	/* If we've ever gone into deep sleep, re-initialize UMAC and MII
+         * configuration */
+	if (brcm_pm_deep_sleep() || pDevCtrl->hw_suspend) {
+                TRACE(("%s: reinit from deep sleep\n", dev->name));
+		do_reinit = 1;
+        }
+
+	if (do_reinit) {
 		/* init umac registers to synchronize s/w with h/w */
 		init_umac(pDevCtrl, true);
 		/* Speed settings must be restored */
 		bcmgenet_mii_init(dev);
-		bcmgenet_mii_setup(dev);
+		bcmgenet_mii_setup(dev, 1);
 	}
+        pDevCtrl->hw_suspend = 0;
 
 	if (pDevCtrl->phyType == BRCM_PHY_TYPE_INT)
 		pDevCtrl->ext->ext_pwr_mgmt |= EXT_ENERGY_DET_MASK;
@@ -1271,7 +1282,19 @@
 		dev->stats.tx_bytes += ((skb->len < ETH_ZLEN) ?
 				ETH_ZLEN : skb->len);
 		dev->stats.tx_packets++;
-
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	switch (skb->pkt_type) {
+	  case PACKET_BROADCAST:
+	    dev->stats.tx_broadcast_packets++;
+	    break;
+
+	  case PACKET_MULTICAST:
+	    dev->stats.tx_multicast_packets++;
+	    dev->stats.tx_multicast_bytes += ((skb->len < ETH_ZLEN) ?
+					      ETH_ZLEN : skb->len);
+	    break;
+	}
+#endif
 	} else {
 		/* xmit head */
 		mapping = dma_map_single(&pDevCtrl->dev->dev,
@@ -1312,6 +1335,11 @@
 		tDma_ring->tdma_write_pointer = (write_ptr << 1);
 		dev->stats.tx_bytes += skb_headlen(skb);
 
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+		if (skb->pkt_type == PACKET_MULTICAST)
+		  dev->stats.tx_multicast_bytes += skb_headlen(skb);
+#endif
+
 		/* xmit fragment */
 		for (i = 0; i < nr_frags; i++) {
 			skb_frag_t *frag = &skb_shinfo(skb)->frags[i];
@@ -1361,8 +1389,23 @@
 			tDma_ring->tdma_write_pointer = (write_ptr << 1);
 			/* update stats */
 			dev->stats.tx_bytes += frag->size;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+			if (skb->pkt_type == PACKET_MULTICAST)
+			  dev->stats.tx_multicast_bytes += frag->size;
+#endif
 		}
 		dev->stats.tx_packets++;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+		switch (skb->pkt_type)
+		{
+			case PACKET_BROADCAST:
+			  dev->stats.tx_broadcast_packets++;
+			  break;
+			case PACKET_MULTICAST:
+			  dev->stats.tx_multicast_packets++;
+			  break;
+		}
+#endif
 	}
 
 #if (CONFIG_BRCM_GENET_VERSION > 1) && defined(CONFIG_NET_SCH_MULTIQ)
@@ -1684,7 +1727,7 @@
 	/* Link UP/DOWN event */
 	if (pDevCtrl->irq0_stat & (UMAC_IRQ_LINK_UP|UMAC_IRQ_LINK_DOWN)) {
 		pDevCtrl->irq0_stat &= ~(UMAC_IRQ_LINK_UP|UMAC_IRQ_LINK_DOWN);
-		bcmgenet_mii_setup(pDevCtrl->dev);
+		bcmgenet_mii_setup(pDevCtrl->dev, 0);
 	}
 
 	/* Re-enable interrupts */
@@ -1892,8 +1935,17 @@
 			pDevCtrl->dev->stats.rx_packets++;
 			pDevCtrl->dev->stats.rx_bytes += len;
 			if (dmaFlag & DMA_RX_MULT)
-				pDevCtrl->dev->stats.multicast++;
-
+			{
+			  pDevCtrl->dev->stats.multicast++;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+			  pDevCtrl->dev->stats.rx_multicast_packets++;
+			  pDevCtrl->dev->stats.rx_multicast_bytes += skb->len;
+#endif
+			}
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+			if (dmaFlag & DMA_RX_BRDCAST)
+			  pDevCtrl->dev->stats.rx_broadcast_packets++;
+#endif
 			skb->queue_mapping = i;
 			/* Notify kernel */
 			netif_receive_skb(skb);
@@ -2138,7 +2190,17 @@
 		dev->stats.rx_packets++;
 		dev->stats.rx_bytes += len;
 		if (dmaFlag & DMA_RX_MULT)
-			dev->stats.multicast++;
+		{
+		  dev->stats.multicast++;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+		  dev->stats.rx_multicast_packets++;
+		  dev->stats.rx_multicast_bytes += skb->len;
+#endif
+		}
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+		if (dmaFlag & DMA_RX_BRDCAST)
+		  dev->stats.rx_broadcast_packets++;
+#endif
 
 		/* Notify kernel */
 #ifdef CONFIG_BCMGENET_RX_DESC_THROTTLE
@@ -3164,7 +3226,7 @@
 		err = mii_ethtool_sset(&pDevCtrl->mii, cmd);
 		if (err < 0)
 			return err;
-		bcmgenet_mii_setup(dev);
+		bcmgenet_mii_setup(dev, 0);
 
 		if (cmd->maxrxpkt != 0)
 			DmaDescThres = cmd->maxrxpkt;
@@ -3463,6 +3525,16 @@
 	case SIOCSMIIREG:
 		val = generic_mii_ioctl(&pDevCtrl->mii, if_mii(rq), cmd, NULL);
 		break;
+	case SIOCSAR8035WOLENABLE:
+		printk("\n Wol cleaning and Enabling \n");
+		bcmgenet_mii_AR8035_WolEnable(pDevCtrl->dev);
+		val = 0;
+		break;
+	case SIOCSAR8035WOLDISABLE: 	
+		printk("\n Wol cleaning and DiSabling \n");
+		bcmgenet_mii_AR8035_WolDisable(pDevCtrl->dev);
+		val = 0;
+		break;	
 	default:
 		val = -EINVAL;
 		break;
@@ -3598,8 +3670,9 @@
 		pDevCtrl->timer.function = bcmgenet_gphy_link_timer;
 	} else {
 		/* check link status */
-		bcmgenet_mii_setup(dev);
+		bcmgenet_mii_setup(dev, 0);
 	}
+        pDevCtrl->hw_suspend = 0;
 
 	netif_carrier_off(pDevCtrl->dev);
 	pDevCtrl->next_dev = eth_root_dev;
@@ -3649,6 +3722,7 @@
 		val = bcmgenet_close(pDevCtrl->dev);
 	}
 
+        pDevCtrl->hw_suspend = brcm_pm_deep_sleep();
 	return val;
 }
 
diff -Naur kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmgenet.h kernel-current/drivers/net/ethernet/broadcom/genet/bcmgenet.h
--- kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmgenet.h	2013-08-28 01:30:59.000000000 +0200
+++ kernel-current/drivers/net/ethernet/broadcom/genet/bcmgenet.h	2015-06-12 16:27:20.044130062 +0200
@@ -156,6 +156,7 @@
 	struct DmaDesc saved_rx_desc[TOTAL_DESC];
 	u32 int_mask;
 	u32 rbuf_ctrl;
+	int hw_suspend;
 };
 
 #if defined(CONFIG_BCMGENET_DUMP_TRACE)
diff -Naur kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmgenet.h.orig kernel-current/drivers/net/ethernet/broadcom/genet/bcmgenet.h.orig
--- kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmgenet.h.orig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/net/ethernet/broadcom/genet/bcmgenet.h.orig	2015-06-12 16:27:19.535876077 +0200
@@ -0,0 +1,207 @@
+/*
+ *
+ * Copyright (c) 2002-2008 Broadcom Corporation
+ *
+ * This program is free software; you can redistribute it and/or modify
+ * it under the terms of the GNU General Public License version 2 as
+ * published by the Free Software Foundation.
+ *
+ * This program is distributed in the hope that it will be useful,
+ * but WITHOUT ANY WARRANTY; without even the implied warranty of
+ * MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE. See the
+ * GNU General Public License for more details.
+ *
+ * You should have received a copy of the GNU General Public License
+ * along with this program; if not, write to the Free Software
+ * Foundation, Inc., 59 Temple Place - Suite 330, Boston, MA 02111-1307, USA.
+ *
+ *
+*/
+#ifndef __BCMGENET_H__
+#define __BCMGENET_H__
+
+#define CARDNAME				"bcmgenet"
+#define VERSION     "2.0"
+#define VER_STR     "v" VERSION " " __DATE__ " " __TIME__
+
+#define pr_fmt(fmt)				CARDNAME ": " fmt
+
+#include <linux/skbuff.h>
+#include <linux/netdevice.h>
+#include <linux/spinlock.h>
+#include <linux/clk.h>
+#include <linux/mii.h>
+
+#include "bcmgenet_map.h"
+
+/* total number of Buffer Descriptors, same for Rx/Tx */
+#define TOTAL_DESC				256
+/* which ring is descriptor based */
+#define DESC_INDEX				16
+/* Body(1500) + EH_SIZE(14) + VLANTAG(4) + BRCMTAG(6) + FCS(4) = 1528.
+ * 1536 is multiple of 256 bytes
+ */
+#define ENET_MAX_MTU_SIZE       1536
+#define DMA_MAX_BURST_LENGTH    0x10
+
+#define GENET_TX_RING_COUNT		16
+#define GENET_RX_RING_COUNT		16
+#define GENET_ALLOC_TX_RING		1
+#define GENET_ALLOC_RX_RING		0
+
+#define ETH_CRC_LEN             4
+
+/* misc. configuration */
+#define CLEAR_ALL_HFB			0xFF
+#define DMA_FC_THRESH_HI		(TOTAL_DESC >> 4)
+#define DMA_FC_THRESH_LO		5
+
+
+struct Enet_CB {
+	struct sk_buff      *skb;
+	volatile struct DmaDesc    *BdAddr;
+	DEFINE_DMA_UNMAP_ADDR(dma_addr);
+	DEFINE_DMA_UNMAP_LEN(dma_len);
+};
+
+/* power management mode */
+#define GENET_POWER_CABLE_SENSE	0
+#define GENET_POWER_WOL_MAGIC	1
+#define GENET_POWER_WOL_ACPI	2
+#define GENET_POWER_PASSIVE		3
+
+/*
+ * device context
+ */
+struct BcmEnet_devctrl {
+	struct net_device *dev;	/* ptr to net_device */
+	struct net_device *next_dev;
+	spinlock_t      lock;		/* Serializing lock */
+	spinlock_t		bh_lock;	/* soft IRQ lock */
+	struct mii_if_info mii;		/* mii interface info */
+	struct mutex mdio_mutex;	/* mutex for mii_read/write */
+	wait_queue_head_t	wq;		/* mii wait queue */
+	struct timer_list timer;	/* Link status timer */
+
+	struct napi_struct napi;	/* NAPI for descriptor based rx */
+	struct napi_struct ring_napi;	/* NAPI for ring buffer */
+	unsigned long base_addr;	/* GENET register start address. */
+	volatile struct uniMacRegs *umac;	/* UNIMAC register */
+	volatile struct rbufRegs	*rbuf;	/* rbuf registers */
+	volatile struct intrl2Regs *intrl2_0;	/* INTR2_0 registers */
+	volatile struct intrl2Regs *intrl2_1;	/* INTR2_1 registers */
+	volatile struct SysRegs    *sys;	/* sys register */
+	volatile struct GrBridgeRegs *grb;	/* Grb */
+	volatile struct ExtRegs    *ext;	/* Extention register */
+	volatile unsigned long *hfb;/* HFB registers */
+#if CONFIG_BRCM_GENET_VERSION > 1
+	volatile struct tbufRegs *tbuf;	/* tbuf register for GENET2 */
+	volatile struct hfbRegs  *hfbReg;	/* hfb register for GENET2 */
+#endif
+
+	/* transmit variables */
+	volatile struct tDmaRegs *txDma;/* location of tx Dma register */
+	volatile struct DmaDesc *txBds;	/* location of tx Dma BD ring */
+	struct Enet_CB *txCbs;	/* locaation of tx control block pool */
+	int	nrTxBds;		/* number of transmit bds */
+	int	txFreeBds;		/* # of free transmit bds */
+	int	txLastCIndex;	/* consumer index for the last xmit call */
+
+	struct Enet_CB *txRingCBs[16];	/* tx ring buffer control block*/
+	unsigned int txRingSize[16];	/* size of each tx ring */
+	unsigned int txRingCIndex[16];	/* last consumer index of each ring*/
+	int txRingFreeBds[16];	/* # of free bds for each ring */
+	unsigned char *txRingStart[16];	/* tx ring start addr */
+
+	/* receive variables */
+	volatile struct rDmaRegs *rxDma;	/* location of rx dma  */
+	volatile struct DmaDesc *rxBds;		/* location of rx bd ring */
+	volatile struct DmaDesc *rxBdAssignPtr;	/*next rx bd to assign buffer*/
+	struct Enet_CB *rxCbs;	/* location of rx control block pool */
+	int	nrRxBds;	/* number of receive bds */
+	int	rxBufLen;	/* size of rx buffers for DMA */
+
+	struct Enet_CB *rxRingCbs[16];	/* rx ring buffer control */
+	unsigned int rxRingSize[16];	/* size of each ring */
+	unsigned int rxRingCIndex[16];	/* consumer index for each ring */
+	unsigned int rxRingDiscCnt[16];	/* # of discarded pkt for each ring */
+	unsigned char *rxRingStart[16];	/* ring buffer start addr.*/
+
+	/* other misc variables */
+	int irq0;	/* regular IRQ */
+	int	irq1;	/* ring buf IRQ */
+	int phyAddr;
+	int	phyType;
+	int	phySpeed;
+	int	extPhy;
+	int	bIPHdrOptimize;
+	unsigned int irq0_stat;	/* sw copy of irq0 status, for IRQ BH */
+	unsigned int irq1_stat;	/* sw copy of irq1 status, for NAPI rx */
+
+	struct work_struct bcmgenet_irq_work;	/* bottom half work */
+	struct work_struct bcmgenet_link_work;	/* GPHY link status work */
+	int    devnum;		/* 0=EMAC_0, 1=EMAC_1 */
+	struct clk *clk;
+	int dev_opened;		/* device opened. */
+	int dev_asleep;		/* device is at sleep */
+	struct platform_device *pdev;
+
+	/* WOL */
+	unsigned long	wol_enabled;
+	struct	clk *clk_wol;
+	int	clock_active;
+	u32	wolopts;
+
+	/* S3 warm boot */
+	struct DmaDesc saved_rx_desc[TOTAL_DESC];
+	u32 int_mask;
+	u32 rbuf_ctrl;
+};
+
+#if defined(CONFIG_BCMGENET_DUMP_TRACE)
+#define TRACE(x)        (printk x)
+#else
+#define TRACE(x)
+#endif
+
+/* These macros are defined to deal with register map change
+ * between GENET1.1 and GENET2. Only those currently being used
+ * by driver are defined.
+ */
+#if CONFIG_BRCM_GENET_VERSION > 1
+
+#define GENET_TBUF_CTRL(pdev)			(pdev->tbuf->tbuf_ctrl)
+#define GENET_TBUF_BP_MC(pdev)			(pdev->tbuf->tbuf_bp_mc)
+#define GENET_TBUF_ENDIAN_CTRL(pdev)	(pdev->tbuf->tbuf_endian_ctrl)
+#define GENET_TBUF_FLUSH_CTRL(pdev)		(pdev->sys->tbuf_flush_ctrl)
+#define GENET_RBUF_FLUSH_CTRL(pdev)		(pdev->sys->rbuf_flush_ctrl)
+#define GENET_RGMII_OOB_CTRL(pdev)		(pdev->ext->rgmii_oob_ctrl)
+#define GENET_RGMII_IB_STATUS(pdev)		(pdev->ext->rgmii_ib_status)
+#define GENET_RGMII_LED_STATUS(pdev)	(pdev->ext->rgmii_led_ctrl)
+#define GENET_HFB_CTRL(pdev)			(pdev->hfbReg->hfb_ctrl)
+#define GENET_HFB_FLTR_LEN(pdev, i)		(pdev->hfbReg->hfb_fltr_len[i])
+
+#else
+
+#define GENET_TBUF_CTRL(pdev)			(pdev->rbuf->tbuf_ctrl)
+#define GENET_TBUF_BP_MC(pdev)			(pdev->rbuf->tbuf_bp_mc)
+#define GENET_TBUF_ENDIAN_CTRL(pdev)		(pdev->rbuf->tbuf_endian_ctrl)
+#define GENET_TBUF_FLUSH_CTRL(pdev)		(pdev->rbuf->tbuf_flush_ctrl)
+#define GENET_RBUF_FLUSH_CTRL(pdev)		(pdev->rbuf->rbuf_flush_ctrl)
+#define GENET_RGMII_OOB_CTRL(pdev)		(pdev->rbuf->rgmii_oob_ctrl)
+#define GENET_RGMII_IB_STATUS(pdev)		(pdev->rbuf->rgmii_ib_status)
+#define GENET_RGMII_LED_STATUS(pdev)		(pdev->rbuf->rgmii_led_ctrl)
+#define GENET_HFB_CTRL(pdev)			(pdev->rbuf->rbuf_hfb_ctrl)
+#define GENET_HFB_FLTR_LEN(pdev, i)		(pdev->rbuf->rbuf_fltr_len[i])
+
+#endif /* CONFIG_BRCM_GENET_VERSION > 1 */
+
+#if CONFIG_BRCM_GENET_VERSION < 3
+#define GENET_BP_IN_EN_SHIFT			16
+#define GENET_BP_MASK				0xffff
+#else
+#define GENET_BP_IN_EN_SHIFT			17
+#define GENET_BP_MASK				0x1ffff
+#endif
+
+#endif /* __BCMGENET_H__ */
diff -Naur kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmmii.c kernel-current/drivers/net/ethernet/broadcom/genet/bcmmii.c
--- kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmmii.c	2013-08-28 01:30:59.000000000 +0200
+++ kernel-current/drivers/net/ethernet/broadcom/genet/bcmmii.c	2015-06-12 16:27:20.044130062 +0200
@@ -139,10 +139,160 @@
 }
 
 /*
+ * disable hibernate mode for PHY 
+ */
+void bcmgenet_mii_AR8035_WolEnable(struct net_device *dev)
+{
+  uint16_t val_out1 = 0, val_out2 = 0, val_out3 = 0, val_tmp=0;
+  struct BcmEnet_devctrl *pDevCtrl = netdev_priv(dev);
+ 
+  printk("\n bcmii: bcmgenet_mii_AR8035_WolEnable \n"); 	
+  
+  printk("configuring instance #%d with phyAddr %d\n", pDevCtrl->pdev->id, pDevCtrl->phyAddr);
+  
+  if (pDevCtrl->phyAddr == BRCM_PHY_ID_NONE)
+  	return;
+
+  /* set MAC ADDRESS */
+  printk("\n bcmgenet_mii_AR8035_WolEnable: MAC ADDRESS = %02x.%02x.%02x.%02x.%02x.%02x \n", (uint8_t) dev->dev_addr[0],
+  											     (uint8_t) dev->dev_addr[1],
+											     (uint8_t) dev->dev_addr[2],
+											     (uint8_t) dev->dev_addr[3],
+											     (uint8_t) dev->dev_addr[4],
+											     (uint8_t) dev->dev_addr[5]);
+											     
+   											     
+   val_out1 = (uint8_t) (dev->dev_addr[0]);
+   val_out1 <<=8;
+   val_out1 |= (uint8_t) (dev->dev_addr[1]);
+   val_out2 = (uint8_t) (dev->dev_addr[2]);
+   val_out2 <<=8;
+   val_out2 |= (uint8_t) (dev->dev_addr[3]);
+   val_out3 = (uint8_t) (dev->dev_addr[4]);
+   val_out3 <<=8;
+   val_out3 |= (uint8_t) (dev->dev_addr[5]);
+   
+   
+   printk("\n bcmgenet_mii_AR8035_WolEnable: MAC ADDRESS to be written in MMD3 registers= %x %x %x \n", val_out1,
+  											          val_out2,
+											          val_out3);
+
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x804A);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_tmp = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,val_out1);
+   val_out1 = 1;
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x804A);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_out1 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x804B);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_tmp = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,val_out2);
+   val_out2 = 2;
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x804B);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_out2 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x804C);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_tmp = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,val_out3);
+   val_out3 = 3;
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x804C);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_out3 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   
+   printk("\n bcmgenet_mii_AR8035_WolEnable: MAC ADDRESS written in MMD3 registers= %x %x %x \n", val_out1,
+  											          val_out2,
+											          val_out3);
+												  
+   /* enable WOL mechanism */
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x8012);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_out1 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   val_out1 = val_out1 | 0x20;
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x8012);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_tmp = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,val_out1);
+   		
+   
+   /* switch INT to WOL_INT */
+   val_out1 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0x12);
+   printk("\n bcmii: int_interrupt register value before write = 0x%x for AR8035 \n",val_out1);
+   val_out1 = val_out1 | 0x1;
+   printk("\n bcmii: int_interrupt register value to write = 0x%x for AR8035 \n",val_out1);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0x12,val_out1);	
+   val_out1 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0x12);
+   printk("\n bcmii: int_interrupt register value after write = 0x%x for AR8035 \n",val_out1);									  
+   
+   /* More power savings */
+   val_out1 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0x0);
+   val_out1 = val_out1 | 0x400;
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0x0,val_out1);
+   
+   printk("\n bcmii: WOL pooling enabled for AR8035 \n");
+
+}
+
+void bcmgenet_mii_AR8035_WolDisable(struct net_device *dev)
+{
+  uint16_t val_out1 = 0, val_tmp = 0;
+  struct BcmEnet_devctrl *pDevCtrl = netdev_priv(dev);
+ 
+  printk("\n bcmii: bcmgenet_mii_AR8035_WolDisable \n"); 
+  if (pDevCtrl->phyAddr == BRCM_PHY_ID_NONE)
+  	return;	
+  
+  /* Clear interrupt */
+   val_out1 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0x13);
+
+  /* Disable WOL mechanism */
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x8012);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_out1 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   val_out1 = val_out1 & 0xFFDF;
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD,0x3);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,0x8012);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xD, 0x4003);
+   val_tmp = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0xE);
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0xE,val_out1);
+   
+   /* switch WOL_INT to normal INT */
+   val_out1 = bcmgenet_mii_read(dev, pDevCtrl->phyAddr, 0x12);
+   val_out1 = val_out1 & 0xFFFE;
+   bcmgenet_mii_write(dev, pDevCtrl->phyAddr,0x12,val_out1);
+   
+   
+   printk("\n bcmii: WOL pooling disabled for AR8035 \n");
+
+}
+
+void bcmgenet_mii_AR8035_WolPacketsSend(struct net_device *dev)
+{
+  struct BcmEnet_devctrl *pDevCtrl = netdev_priv(dev);
+  if (pDevCtrl->phyAddr == BRCM_PHY_ID_NONE)
+  	return;
+  return;
+}
+
+
+/*
  * setup netdev link state when PHY link status change and
  * update UMAC and RGMII block when link up
  */
-void bcmgenet_mii_setup(struct net_device *dev)
+void bcmgenet_mii_setup(struct net_device *dev, unsigned int force)
 {
 	struct BcmEnet_devctrl *pDevCtrl = netdev_priv(dev);
 	struct ethtool_cmd ecmd;
@@ -155,7 +305,7 @@
 
 	cur_link = mii_link_ok(&pDevCtrl->mii);
 	prev_link = netif_carrier_ok(pDevCtrl->dev);
-	if (cur_link && !prev_link) {
+	if ((cur_link && !prev_link) || force) {
 		mii_ethtool_gset(&pDevCtrl->mii, &ecmd);
 		/*
 		 * program UMAC and RGMII block based on established link
diff -Naur kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmmii.h kernel-current/drivers/net/ethernet/broadcom/genet/bcmmii.h
--- kernel-3.3-3.0a-ref/drivers/net/ethernet/broadcom/genet/bcmmii.h	2013-08-28 01:30:59.000000000 +0200
+++ kernel-current/drivers/net/ethernet/broadcom/genet/bcmmii.h	2015-06-12 16:27:20.044130062 +0200
@@ -45,10 +45,13 @@
 Prototypes
 ****************************************************************************/
 
-extern void bcmgenet_mii_setup(struct net_device *dev);
+extern void bcmgenet_mii_setup(struct net_device *dev, unsigned int force);
 extern int bcmgenet_mii_init(struct net_device *dev);
 extern int bcmgenet_mii_probe(struct net_device *dev, void *p);
 extern void bcmgenet_mii_reset(struct net_device *dev);
 extern void bcmgenet_ephy_workaround(struct net_device *dev);
+void bcmgenet_mii_AR8035_WolEnable(struct net_device *dev);
+void bcmgenet_mii_AR8035_WolDisable(struct net_device *dev); 
+void bcmgenet_mii_AR8035_WolPacketsSend(struct net_device *dev);
 
 #endif /* _BCMMII_H_ */
diff -Naur kernel-3.3-3.0a-ref/drivers/sysinfo/Kconfig kernel-current/drivers/sysinfo/Kconfig
--- kernel-3.3-3.0a-ref/drivers/sysinfo/Kconfig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/sysinfo/Kconfig	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1,7 @@
+#
+# sysinfo subsystem configuration
+# SYSINFO is a system information managment API
+#
+config SYSINFO_SUPPORT
+ bool "Sysinfo driver"
+
diff -Naur kernel-3.3-3.0a-ref/drivers/sysinfo/Makefile kernel-current/drivers/sysinfo/Makefile
--- kernel-3.3-3.0a-ref/drivers/sysinfo/Makefile	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/sysinfo/Makefile	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1 @@
+obj-$(CONFIG_SYSINFO_SUPPORT)        +=sysinfo.o
diff -Naur kernel-3.3-3.0a-ref/drivers/sysinfo/sysinfo.c kernel-current/drivers/sysinfo/sysinfo.c
--- kernel-3.3-3.0a-ref/drivers/sysinfo/sysinfo.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/sysinfo/sysinfo.c	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1,635 @@
+/*
+ *  sysinfo.c
+ *
+ *  This file contains the implementation of the AON read/writer
+ *  interface module with the user space.
+ *
+ *  Created by Samir MOUHOUNE on 10/07/2013.
+ *  Copyright 2013 Pace plc. All rights reserved.
+ *
+ *  The copyright in this material is owned by Pace
+ *  plc ("Pace"). This material is regarded as a
+ *  highly confidential trade secret of Pace. It may not be
+ *  reproduced, used, sold or in any other way exploited or
+ *  transferred to any third party without the prior
+ *  written permission of Pace.
+ *
+ */
+
+
+#include <linux/module.h>
+#include <linux/fs.h>
+#include <linux/kernel_stat.h>
+#include <linux/tick.h>
+#include <linux/brcmstb/brcmstb.h>
+#include <linux/string.h>
+
+#ifdef CONFIG_BCM7425B0
+#define BCHP_AVS_RO_REGISTERS_0_PVT_TEMPERATURE_MNTR_STATUS 0x00432b00 /* Indicate PVT monitor sel 000(Temperature Monitoring) measurements data, validity of data and measurement done status */
+#elif CONFIG_BCM7429B0
+#define BCHP_AVS_RO_REGISTERS_0_PVT_TEMPERATURE_MNTR_STATUS 0x00423300 /* Indicate PVT monitor sel 000(Temperature Monitoring) measurements data, validity of data and measurement done status */
+#endif
+
+#define BCHP_AVS_RO_REGISTERS_0_PVT_TEMPERATURE_MNTR_STATUS_data_MASK 0x000003ff
+#define BCHP_AVS_RO_REGISTERS_0_PVT_TEMPERATURE_MNTR_STATUS_data_SHIFT 0
+#define BCHP_AVS_RO_REGISTERS_0_PVT_TEMPERATURE_MNTR_STATUS_data_DEFAULT 0x00000000
+
+#include <linux/sysinfo.h>
+#include "sysinfo_priv.h"
+
+#include <linux/reboot.h>
+#include <asm/reboot.h>
+#include <linux/slab.h>
+#include <linux/suspend.h>
+
+MODULE_AUTHOR ("Pace");
+MODULE_DESCRIPTION ("System Information Management interface");
+MODULE_SUPPORTED_DEVICE ("");
+MODULE_LICENSE ("Pace Proprietary");
+
+
+/*
+ *
+ *  Module param
+ *
+ */
+static int sysinfo_major = 0;/*Major Number will be set dynamically*/
+
+module_param (sysinfo_major,  int, 0644);
+MODULE_PARM_DESC (sysinfo_major,  "Device major number");
+
+
+static struct sysinfo sys_info;
+
+/*static procInfo proc_info;*/
+static int nb_processes;
+
+#ifdef CONFIG_SMP
+    extern int nr_cpu_ids;
+#else
+    #define nr_cpu_ids 1
+#endif /*CONFIG_SMP*/
+
+#ifndef arch_irq_stat_cpu
+#define arch_irq_stat_cpu(cpu) 0
+#endif
+#ifndef arch_irq_stat
+#define arch_irq_stat() 0
+#endif
+#ifndef arch_idle_time
+#define arch_idle_time(cpu) 0
+#endif
+
+
+static u64 get_idle_time(int cpu)
+{
+    u64 idle, idle_time = get_cpu_idle_time_us(cpu, NULL);
+
+    if (idle_time == -1ULL)
+    {
+        /* !NO_HZ so we can rely on cpustat.idle */
+        idle = kcpustat_cpu(cpu).cpustat[CPUTIME_IDLE];
+        idle += arch_idle_time(cpu);
+    } else
+        idle = usecs_to_cputime64(idle_time);
+
+    return idle;
+}
+
+static u64 get_iowait_time(int cpu)
+{
+    u64 iowait, iowait_time = get_cpu_iowait_time_us(cpu, NULL);
+
+    if (iowait_time == -1ULL)
+        /* !NO_HZ so we can rely on cpustat.iowait */
+        iowait = kcpustat_cpu(cpu).cpustat[CPUTIME_IOWAIT];
+    else
+        iowait = usecs_to_cputime64(iowait_time);
+
+    return iowait;
+}
+
+
+extern void si_meminfo(struct sysinfo *val);
+
+
+/*
+*
+*
+*get_memory_status
+*
+*This method will return the total and the free memory.
+*
+*
+*/
+
+int get_memory_status(unsigned long arg)
+{
+    int status = 0;
+    size_t ctr=0;
+    /*struct memInfo mem_info;*/
+    struct memInfo mem_info;
+    struct sysinfo val;
+
+
+    si_meminfo(&val);
+
+    mem_info.freeram =val.freeram*4;/*size should be in KO instead of pages*/
+    mem_info.totalram =val.totalram*4;/*size should be in KO instead of pages*/
+
+    logsysinfo("get_memory_status () - freeram = %lu \n",mem_info.freeram);
+    logsysinfo("get_memory_status () - totalram = %lu \n",mem_info.totalram );
+
+    ctr = copy_to_user((memInfo*)arg,&mem_info,sizeof(mem_info));
+
+    
+    if(ctr)
+        return EFAULT;
+
+    return status;
+}
+
+
+/*
+*
+*
+*show_stat
+*
+*This method will return the list of all online processors and their states
+*
+*
+*/
+int get_processor(unsigned long arg)
+{
+    int i;
+    unsigned long jif;
+    struct timespec boottime;
+    unsigned int temperature;
+    size_t ctr=0;
+    struct procList proc_list;
+    
+
+    
+    getboottime(&boottime);
+    jif = boottime.tv_sec;
+
+    proc_list.nbcpu=0;
+    for_each_online_cpu(i)
+    {
+        proc_list.nbcpu++;
+        if(proc_list.nbcpu > SYSINFO_MAX_PROCESSOR)
+        {
+          errorsysinfo("sysinfo can only handle %d cpus\n",SYSINFO_MAX_PROCESSOR);
+          return EFAULT;
+        }
+    
+        proc_list.procinfo[i].user = proc_list.procinfo[i].nice = proc_list.procinfo[i].system = proc_list.procinfo[i].idle = proc_list.procinfo[i].iowait =
+        proc_list.procinfo[i].irq = proc_list.procinfo[i].softirq = proc_list.procinfo[i].steal = 0;
+        proc_list.procinfo[i].guest = proc_list.procinfo[i].guest_nice =proc_list.procinfo[i].processes=proc_list.procinfo[i].nbr_running=proc_list.procinfo[i].nbr_iowait= 0;
+        /* Copy values here to work around gcc-2.95.3, gcc-2.96 */
+        proc_list.procinfo[i].cpu=i;
+        logsysinfo("cpu %d\n",proc_list.procinfo[i].cpu);
+#ifdef CONFIG_CPU_BMIPS
+        strcpy(proc_list.procinfo[i].arch, "mipsel"); /*char arch[10]*/
+#else
+        strcpy(proc_list.procinfo[i].arch, "unknown"); /*char arch[10]*/
+#endif
+        proc_list.procinfo[i].user = kcpustat_cpu(i).cpustat[CPUTIME_USER];
+        proc_list.procinfo[i].nice = kcpustat_cpu(i).cpustat[CPUTIME_NICE];
+        proc_list.procinfo[i].system = kcpustat_cpu(i).cpustat[CPUTIME_SYSTEM];
+        proc_list.procinfo[i].idle = get_idle_time(i);
+        proc_list.procinfo[i].iowait = get_iowait_time(i);
+        proc_list.procinfo[i].irq = kcpustat_cpu(i).cpustat[CPUTIME_IRQ];
+        proc_list.procinfo[i].softirq = kcpustat_cpu(i).cpustat[CPUTIME_SOFTIRQ];
+        proc_list.procinfo[i].steal = kcpustat_cpu(i).cpustat[CPUTIME_STEAL];
+        proc_list.procinfo[i].guest = kcpustat_cpu(i).cpustat[CPUTIME_GUEST];
+        proc_list.procinfo[i].guest_nice = kcpustat_cpu(i).cpustat[CPUTIME_GUEST_NICE];
+
+        temperature=BDEV_RD(BCHP_AVS_RO_REGISTERS_0_PVT_TEMPERATURE_MNTR_STATUS) & BCHP_AVS_RO_REGISTERS_0_PVT_TEMPERATURE_MNTR_STATUS_data_MASK;
+        proc_list.procinfo[i].temperature = (418000 - (556 * temperature))/1000;
+        logsysinfo("proc_list.procinfo[%d] cpu:%d arch:%s temperature:%lu\n",i,proc_list.procinfo[i].cpu,proc_list.procinfo[i].arch,proc_list.procinfo[i].temperature);
+        /*proc_list.procinfo[i].processes=total_forks;
+        proc_list.procinfo[i].nbr_running=nr_running();
+        proc_list.procinfo[i].nbr_iowait=nr_iowait();*/
+        
+    }
+
+    logsysinfo("get_processor proc_list.nbcpu:%d\n",proc_list.nbcpu);
+    ctr = copy_to_user((procList*)arg,&proc_list,sizeof(struct procList));
+    if(ctr)
+        return EFAULT;
+    return 0;
+}
+
+static const char * const task_state_array[] = {
+    "R (running)",        /*   0 */
+    "S (sleeping)",        /*   1 */
+    "D (disk sleep)",    /*   2 */
+    "T (stopped)",        /*   4 */
+    "t (tracing stop)",    /*   8 */
+    "Z (zombie)",        /*  16 */
+    "X (dead)",        /*  32 */
+    "x (dead)",        /*  64 */
+    "K (wakekill)",        /* 128 */
+    "W (waking)",        /* 256 */
+};
+
+
+static inline const char *get_task_state(struct task_struct *tsk)
+{
+    unsigned int state = (tsk->state & TASK_REPORT) | tsk->exit_state;
+    const char * const *p = &task_state_array[0];
+
+    while (state)
+    {
+        p++;
+        state >>= 1;
+    }
+    return *p;
+}
+
+
+unsigned long get_task_vsize(struct mm_struct *mm)
+{
+    struct vm_area_struct *vma;
+    struct rb_node *p;
+    unsigned long vsize = 0;
+
+    down_read(&mm->mmap_sem);
+    for (p = rb_first(&mm->mm_rb); p; p = rb_next(p))
+    {
+        vma = rb_entry(p, struct vm_area_struct, vm_rb);
+        vsize += vma->vm_end - vma->vm_start;
+    }
+    up_read(&mm->mmap_sem);
+    return (vsize/1024);  /*vsize in KB*/
+}
+
+
+/*
+*
+*
+*
+*get_process_status
+*
+*This method will return the list of all the processes with their information
+*
+*
+*
+*/
+int get_process_status(unsigned long arg)
+{
+    struct task_struct *task;
+    const char* tmp_state;
+    char* tmp_comm;
+    int i= 0;
+    int j = 0;
+    size_t ctr=0;
+    cputime_t cputime = 0;
+
+    unsigned long totalCPUTime = 0;
+    unsigned long tmp_cpuusage=0;
+    unsigned long tmp_idleCpuTime=0;
+    unsigned long maxproc=0;
+    
+    struct taskList *task_list=(taskList*)arg;
+    struct taskInfo *task_info=NULL;
+
+    ctr = copy_from_user(&(maxproc),&(task_list->maxproc),sizeof(unsigned long));
+    if (ctr)
+    {
+      errorsysinfo("copy from maxproc failed\n");
+      return EFAULT;
+    }
+
+    for_each_online_cpu(j)
+    {
+        tmp_idleCpuTime = tmp_idleCpuTime + get_idle_time(j);
+        tmp_idleCpuTime = tmp_idleCpuTime + get_iowait_time(j);
+        tmp_idleCpuTime = tmp_idleCpuTime + kcpustat_cpu(j).cpustat[CPUTIME_STEAL];
+        totalCPUTime = totalCPUTime + kcpustat_cpu(j).cpustat[CPUTIME_USER];
+        totalCPUTime = totalCPUTime + kcpustat_cpu(j).cpustat[CPUTIME_NICE];
+        totalCPUTime = totalCPUTime + kcpustat_cpu(j).cpustat[CPUTIME_SYSTEM];
+        totalCPUTime = totalCPUTime + get_idle_time(j);
+        totalCPUTime = totalCPUTime + get_iowait_time(j);
+        totalCPUTime = totalCPUTime + kcpustat_cpu(j).cpustat[CPUTIME_IRQ];
+        totalCPUTime = totalCPUTime + kcpustat_cpu(j).cpustat[CPUTIME_SOFTIRQ];
+        totalCPUTime = totalCPUTime + kcpustat_cpu(j).cpustat[CPUTIME_STEAL];
+        totalCPUTime = totalCPUTime + kcpustat_cpu(j).cpustat[CPUTIME_GUEST];
+        totalCPUTime = totalCPUTime + kcpustat_cpu(j).cpustat[CPUTIME_GUEST_NICE];
+    }
+
+    tmp_cpuusage=((totalCPUTime-tmp_idleCpuTime)*100)/totalCPUTime;/*CPU usage in %*/
+    ctr = put_user(tmp_cpuusage,&(task_list->cpuusage));
+    if (ctr)
+    {
+      errorsysinfo("copy to cpuusage failed\n");
+      return EFAULT;
+    }
+
+    
+
+    rcu_read_lock ();
+    nb_processes = nr_processes();
+    if(nb_processes > maxproc)
+    {
+      logsysinfo("nb_processes(%lu) > maxproc(%lu)\n",(unsigned long)nb_processes,maxproc);
+      rcu_read_unlock ();
+      return EAGAIN;
+    }
+
+    task_info = kmalloc(maxproc*sizeof(struct taskInfo), GFP_KERNEL);
+    if(task_info == NULL)
+    {
+      errorsysinfo("alloc nb_processes %lu failed\n",(unsigned long)nb_processes);
+      rcu_read_unlock ();
+      return EFAULT;
+    }
+    memset(task_info,0,sizeof(task_info));
+    for_each_process(task)
+    {
+        tmp_state= get_task_state(task);
+        memcpy(task_info[i].state, tmp_state, strlen(tmp_state)+1);
+        tmp_comm=task->comm;
+        memcpy(task_info[i].comm, tmp_comm, strlen(tmp_comm)+1);
+        task_info[i].pid=task->pid;
+        task_info[i].prio=task->prio;
+        if(task->mm)
+        {
+          task_info[i].vsize = get_task_vsize(task->mm);
+        }
+        else
+        {
+          task_info[i].vsize=0;
+        }
+
+        cputime = task->utime+task->stime;
+
+        task_info[i].CPUTime=cputime_to_usecs(cputime);/*CPU TIME is usecs*/
+
+        logsysinfo("[ %s ]  PID: %d  state: %s Priority :%d  vsize:%lu\n",task_info[i].comm , task_info[i].pid,task_info[i].state,task_info[i].prio,task_info[i].vsize);
+        i++;
+    }
+    rcu_read_unlock ();
+
+    ctr = copy_to_user(task_list->taskinfo,task_info,maxproc*sizeof(struct taskInfo));
+    kfree(task_info);
+    if (ctr)
+    {
+      errorsysinfo("copy to taskinfo failed\n");
+      return EFAULT;
+    }
+
+    ctr = put_user(i,&(task_list->nbproc));
+    if (ctr)
+    {
+      errorsysinfo("copy to nbproc failed\n");
+      return EFAULT;
+    }
+
+
+    return 0;
+}
+
+
+int system_reboot(void)
+{
+#ifdef CONFIG_CPU_BMIPS
+    machine_restart("reboot");
+#endif
+    return 0;
+}
+
+#define DATA(reg,shift,val) do { \
+        BDEV_WR(BCHP_GIO_##reg, \
+                ((BDEV_RD(BCHP_GIO_##reg) & \
+                 ~(1 << shift)) | ((val) << shift)));\
+        } while (0)
+	
+	 
+int sysinfo_standby(const char *state)
+{
+    int ret;
+    
+    if (strstr(brcm_cfe_boardname, "700") != NULL)
+    {
+    /* AON_GPIO_02  CM_PWR_EN   O   GPIO    HIgh    PULL_HIGH   totem-pole  HIgh    cable modem power switch. 1=> cable modem power ON */
+    DATA(AON_DATA_LO, 20, 0);
+    }	
+
+    logsysinfo("***** pm_suspend in\n");
+    /*pm_suspend() is where user space write to /sys/power/state ands up*/
+    if(state && !strcmp(state,"cm_disable"))
+        DATA(AON_DATA_LO, 2, 0);
+    ret=pm_suspend(PM_SUSPEND_MEM);
+    logsysinfo("***** pm_suspend out\n");
+    if (strstr(brcm_cfe_boardname, "700") != NULL)
+    {
+    DATA(AON_DATA_LO, 2, 1);
+    DATA(AON_DATA_LO, 20, 1);
+    /*printk("\n ***** force Slow Blanking pio 34 to 0 at S3 exit ");*/
+    DATA(DATA_HI, 2, 1);
+    }
+    if (strstr(brcm_cfe_boardname, "3000") != NULL)
+    {
+    /*printk("\n ***** force Slow Blanking pio 58 to 0 at S3 exit ");*/
+    DATA(DATA_HI, 26, 1);
+    }
+    if (strstr(brcm_cfe_boardname, "7010") != NULL)
+    {
+    /*printk("\n ***** force Slow Blanking pio 16 to 0 at S3 exit ");*/
+    DATA(DATA_LO, 16, 1);
+    }
+    
+    return ret;
+}
+
+
+/***********************************************************************************************
+ *
+ *  Char device functions
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  sysinfo_open
+ *
+ */
+static int sysinfo_open(struct inode *inode, struct file *filp)
+{
+    logsysinfo("An instance of %s has been opened.\n", sysinfo_NAME);
+    return 0;
+}
+
+
+/*
+ *
+ *  sysinfo_close
+ *
+ */
+static int sysinfo_close(struct inode *inode, struct file *file)
+{
+    logsysinfo("One instance of %s has been closed.\n", sysinfo_NAME);
+    return 0;
+}
+
+
+/*
+ *
+ *  sysinfo_ioctl
+ *
+ */
+long sysinfo_ioctl(struct file *filp,unsigned int cmd, unsigned long arg)
+{
+    if (_IOC_TYPE(cmd) != sysinfo_IOC_MAGIC)
+    {
+        logsysinfo("Unrecognized ioctl command prefix.\n");
+        return 1;
+    }
+    if (_IOC_NR(cmd) > MAX_IOCTL_CMD_NMBR)
+    {
+        logsysinfo("ioctl command number out of range.\n");
+        return 1;
+    }
+    switch (cmd)
+    {
+        case GET_MEMORY_STATUS:
+            logsysinfo("ioctl cmd = GET_MEMORY_STATUS.\n");
+            get_memory_status(arg);
+            break;
+      case GET_PROCESS_STATUS:
+            logsysinfo("ioctl cmd =  GET_PROCESS_STATUS.\n");
+            return ((long)get_process_status(arg));
+            break;
+      case GET_PROCESSOR:
+            logsysinfo("ioctl cmd =  GET_PROCESSOR.\n");
+            get_processor(arg);
+            break;
+      case GET_NB_PROC:
+            logsysinfo("ioctl cmd =  GET_NB_PROC.\n");
+            nb_processes = nr_processes();
+            if (put_user(nb_processes, (int *)arg)) return EFAULT;
+            break;
+      case GET_NB_CPU:
+            logsysinfo("ioctl cmd =  GET_NB_CPU.\n");
+            if (put_user(nr_cpu_ids, (int *)arg)) return EFAULT;
+            break;
+      case CPU_REBOOT_CMD:
+            logsysinfo("ioctl cmd =  CPU_REBOOT_CMD.\n");
+            system_reboot();
+            break;
+      case STANDBY_CM_ENABLE:
+            logsysinfo("ioctl cmd =  STANDBY_CM_ENABLE.\n");
+            sysinfo_standby("cm_enable");
+            break;
+      case STANDBY_CM_DISABLE:
+            logsysinfo("ioctl cmd =  STANDBY_CM_DISABLE.\n");
+            sysinfo_standby("cm_disable");
+            break;
+      default:
+            logsysinfo("ioctl cmd = default.\n");
+            return 1;
+    }
+    return 0;
+}
+
+
+/*
+ *
+ *  sysinfo_read
+ *
+ */
+static ssize_t sysinfo_read(struct file *file, char *buff, size_t ctr, loff_t *offp)
+{
+   /*TODO  to be implemented*/
+    return 0;
+}
+
+
+/***********************************************************************************************
+ *
+ *  Functions uses to write in the device buffer
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  _sysinfo_write
+ *
+ *
+ *
+ */
+static ssize_t sysinfo_write(struct file *file, const char *buff, size_t ctr,loff_t *woof)
+{
+/*TODO to be implemnted*/
+    return 0;
+}
+
+
+struct file_operations sysinfo_fops = {
+    owner: THIS_MODULE,
+    open: sysinfo_open,
+    release: sysinfo_close,
+    read: sysinfo_read,
+    write: sysinfo_write,
+    unlocked_ioctl: sysinfo_ioctl,
+};
+
+
+
+/***********************************************************************************************
+ *
+ *  init and exit functions
+ *
+ ***********************************************************************************************/
+
+/*
+ *
+ *  sysinfo_init
+ *
+ */
+static int __init sysinfo_init(void)
+{
+    int result;
+
+    logsysinfo("enter sysinfo_init()\n");
+
+    /*
+     *  Register char sysinfo device
+     */
+    result = register_chrdev(sysinfo_major, sysinfo_NAME, &sysinfo_fops);
+    if (result < 0)
+    {
+        errorsysinfo("sysinfo: can't get major %d\n",sysinfo_major);
+        return result;
+    }
+
+    if(sysinfo_major == 0) sysinfo_major = result; /* dynamic */
+
+    logsysinfo("sysinfo device created with %i major number\n",sysinfo_major);
+
+
+    logsysinfo("Registered %s, at major number = %d.\n\n",sysinfo_NAME, sysinfo_major);
+    logsysinfo("To use %s, you must create a device file.\n", sysinfo_NAME);
+    logsysinfo("If this has not already been done, then enter:\n");
+    logsysinfo("mknod /dev/%s c %d 0\n\n", sysinfo_NAME, sysinfo_major);
+    logsysinfo("Also set appropriate permissions for /dev/%s.\n\n", sysinfo_NAME);
+
+    return 0;
+}
+
+
+/*
+ *
+ *  sysinfo_cleanup
+ *
+ */
+static void __exit sysinfo_cleanup(void)
+{
+    logsysinfo("enter sysinfo_cleanup\n");
+    unregister_chrdev(sysinfo_major, sysinfo_NAME);
+}
+
+module_init(sysinfo_init);
+module_exit(sysinfo_cleanup);
diff -Naur kernel-3.3-3.0a-ref/drivers/sysinfo/sysinfo_priv.h kernel-current/drivers/sysinfo/sysinfo_priv.h
--- kernel-3.3-3.0a-ref/drivers/sysinfo/sysinfo_priv.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/drivers/sysinfo/sysinfo_priv.h	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1,51 @@
+/*
+ *  sysinfo_priv.h
+ *
+ *  This file contains the implementation of the system information API
+ *  interface module with the user space.
+ *
+ *  Created by Samir MOUHOUNE on 10/07/2013.
+ *  Copyright 2013 Pace plc. All rights reserved.
+ *
+ *  The copyright in this material is owned by Pace
+ *  plc ("Pace"). This material is regarded as a
+ *  highly confidential trade secret of Pace. It may not be
+ *  reproduced, used, sold or in any other way exploited or
+ *  transferred to any third party without the prior
+ *  written permission of Pace.
+ *
+ */
+
+#ifndef sysinfo_PRIV_H
+#define sysinfo_PRIV_H
+
+
+
+
+/*#define sysinfo_DEBUG*/ /*To Enable kernel traces*/
+
+#ifdef sysinfo_DEBUG
+#define logsysinfo(...) \
+        printk("[sysinfo] "__VA_ARGS__);
+#else
+#define logsysinfo(...)
+#endif
+#define errorsysinfo(...) \
+        printk("[sysinfo] ERROR "__VA_ARGS__);
+
+
+#define sysinfo_NAME "sysinfo"
+
+
+
+
+static ssize_t sysinfo_write(struct file *file, const char *buff, size_t ctr,loff_t *woof);
+static ssize_t sysinfo_read(struct file *file, char *buff, size_t ctr, loff_t *offp);
+static int sysinfo_init (void );
+static void sysinfo_cleanup ( void );
+
+int get_memory_status(unsigned long arg);
+int get_process_status(unsigned long arg); /*get status for all processes*/
+int get_processor(unsigned long arg);
+
+#endif /* sysinfo_PRIV_H */
diff -Naur kernel-3.3-3.0a-ref/drivers/usb/core/devio.c kernel-current/drivers/usb/core/devio.c
--- kernel-3.3-3.0a-ref/drivers/usb/core/devio.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/drivers/usb/core/devio.c	2015-06-12 16:27:19.916066066 +0200
@@ -1435,6 +1435,225 @@
 
 	return 0;
 }
+#define CONFIG_PACE_TT_USB_COMMANDS 1
+/* Pace change */
+#if defined(CONFIG_PACE_TT_USB_COMMANDS)
+#define DBGTEST(arg) printk arg
+static int proc_usb_test(struct dev_state *ps, void *arg)
+{
+   struct usb_device *pRootHub = ps->dev;
+   struct usb_device *pDevice;
+   struct usbdevfs_usb_test TestInfo;
+   int port_num;
+   int ret;
+   unsigned int response = 0;
+   char *buf;
+   int index, len;
+   u16 portchange = 0;
+   u16 portstatus = 0;
+   struct usb_port_status *portsts;
+
+   if (!pRootHub)
+   {
+      DBGTEST(("USB_TEST: pRootHub is NULL\n"));
+      return -EINVAL;
+   }
+    DBGTEST(("USB_TEST: pRootHub is valid\n"));
+
+   /* usb_show_device(pRootHub); */
+
+   if (copy_from_user(&TestInfo, (void *)arg, sizeof(TestInfo)))
+      return -EFAULT;
+
+   DBGTEST(("USB_TEST: --> Port %d, action %d, response=%u\n",
+      TestInfo.port_num, TestInfo.action, TestInfo.response));
+
+   port_num = TestInfo.port_num;
+   ret = 0;
+   if (port_num < 0)
+   {
+      pDevice = pRootHub;
+   }
+   else
+   {
+      DBGTEST(("USB_TEST: Hub max children %d",  pRootHub->maxchild));
+      if ((pRootHub->maxchild) && (port_num < USB_MAXCHILDREN))
+      {
+         pDevice = pRootHub->children[port_num];
+      }
+      else
+      {
+         DBGTEST(("USB_TEST: max child failed ---------------"));
+         return -EINVAL;
+      }
+   }
+
+   DBGTEST(("USB_TEST: pDevice %d\n", pDevice));
+
+   switch (TestInfo.action)
+   {
+   case TEST_DEVICE_CONNECTED:
+      response = (pDevice)?1:0;
+      DBGTEST(("USB_TEST: The response is %d ret %d", response, ret));
+      break;
+
+   case TEST_POWER_OFF:
+      /*
+      info("USB_TEST: --> Port %d, POWER OFF, response=%u", TestInfo.port_num, TestInfo.response);
+      info("USB_TEST: Hub [0x%08x] max children %d", pRootHub, pRootHub->maxchild);
+      for (index=0; index < pRootHub->maxchild; index++)
+      {
+         info("USB_TEST: Child %d = [0x%08x]",  index, pRootHub->children[index]);
+      }
+      */
+      ret = usb_control_msg(pRootHub, usb_sndctrlpipe(pRootHub, 0),
+               USB_REQ_CLEAR_FEATURE, USB_RT_PORT, USB_PORT_FEAT_POWER,
+               port_num + 1, NULL, 0, HZ);
+      if (ret < 0) {
+         err("HUB_PORT: --> %s (%d) failed (err = %d)", __FUNCTION__, pDevice->devnum, ret);
+      }
+
+      /* disconnect device if any */
+      if (pRootHub->children[port_num])
+         usb_disconnect(&pRootHub->children[port_num]);
+      break;
+
+   case TEST_POWER_ON:
+      ret = usb_control_msg (pRootHub, usb_sndctrlpipe(pRootHub, 0),
+               USB_REQ_SET_FEATURE, USB_RT_PORT, USB_PORT_FEAT_POWER,
+               port_num + 1, NULL, 0, HZ);
+      if (ret < 0) {
+         err("HUB_PORT: --> %s (%d) failed (err = %d)", __FUNCTION__, pDevice->devnum, ret);
+      }
+      break;
+
+   case TEST_PORT_STATUS:
+      portsts = kmalloc(sizeof(*portsts), GFP_KERNEL);
+      if (portsts) {
+         ret = usb_control_msg(pRootHub, usb_rcvctrlpipe(pRootHub, 0),
+               USB_REQ_GET_STATUS, USB_DIR_IN | USB_RT_PORT, 0,
+               port_num + 1, portsts, sizeof(struct usb_hub_status), HZ);
+         if (ret < 0) {
+            err("HUB_PORT: --> %s (%d) failed (err = %d)", __FUNCTION__, pRootHub->devnum, ret);
+         }
+         else {
+            portstatus = le16_to_cpu(portsts->wPortStatus);
+            portchange = le16_to_cpu(portsts->wPortChange);
+            DBGTEST(("port %d, portstatus 0x%04x, change 0x%04x", port_num, portstatus, portchange));
+            response = portstatus;
+         }
+         kfree(portsts);
+      }
+      break;
+
+   case TEST_SPEED:
+      if (!pDevice)
+      {
+         response = 3;
+         break;
+      }
+      switch (pDevice->speed)
+      {
+      case USB_SPEED_LOW:
+          response = 0; break;
+      case USB_SPEED_FULL:
+          response = 1; break;
+      case USB_SPEED_HIGH:
+          response = 2;break;
+      default:
+         response = 3; break;
+      }
+      break;
+
+   case TEST_VENDOR_ID:
+      if (pDevice)
+      {
+         response = (pDevice->descriptor.idVendor << 16) | pDevice->descriptor.idProduct;
+      }
+      else
+      {
+         response = 0;
+      }
+      break;
+
+  case TEST_DEVICE_MS:
+      if (!pDevice)
+      {
+         response = 0;
+         break;
+      }
+      if((pDevice->config->interface[0]->altsetting->desc.bInterfaceClass == 8)
+       &&(pDevice->config->interface[0]->altsetting->desc.bInterfaceSubClass == 6))
+         response = 1;
+      else
+         response = 0;
+      break;
+
+   case TEST_STRING_MANUF:
+   case TEST_STRING_PROD:
+   case TEST_STRING_SERNUM:
+      if (!pDevice)
+      {
+         response = 0;
+         break;
+      }
+      if (TestInfo.action == TEST_STRING_MANUF)
+         index = pDevice->descriptor.iManufacturer;
+      else if (TestInfo.action == TEST_STRING_PROD)
+         index = pDevice->descriptor.iProduct;
+      else
+         index = pDevice->descriptor.iSerialNumber;
+
+      if (!index)
+      {
+         response = 0;
+         ret = 0;
+      }
+      else if (!(buf = kmalloc(256, GFP_KERNEL)))
+      {
+         /* failed to allocate buffer */
+         ret = -ENOMEM;
+      }
+      else if ((len = usb_string(pDevice, index, buf, 256)) <= 0)
+      {
+         /* failed to get string */
+         kfree(buf);
+      }
+
+      else
+      {
+         DBGTEST(("KERN_INFO %s\n", buf));
+         if (copy_to_user((void *)TestInfo.pBuf, buf, len))
+         {
+            DBGTEST(("USB_TEST: --> Failed to copy to user"));
+            ret = -EFAULT;
+         }
+         else
+         {
+            response = 1;
+         }
+         kfree(buf);
+      }
+      break;
+
+   default:
+      break;
+
+   } /* End of switch() */
+   TestInfo.response = response;
+   if (copy_to_user((void *)arg, &TestInfo, sizeof(TestInfo)))
+   {
+      DBGTEST(("USB_TEST: --> Failed to copy to user"));
+      ret = -EFAULT;
+   }
+   else
+      ret = 0;
+
+   DBGTEST(("USB_TEST: --> The response is %d return %d\n", TestInfo.response, ret));
+
+   return ret;
+}
+#endif /* #ifdef PACE_TT_USB_COMMANDS */
 
 static int processcompl(struct async *as, void __user * __user *arg)
 {
@@ -1907,6 +2126,12 @@
 		ret = proc_setconfig(ps, p);
 		break;
 
+#if defined (CONFIG_PACE_TT_USB_COMMANDS)
+              /* Pace change */
+	case USBDEVFS_TEST:
+	      ret = proc_usb_test(ps, (void *)p);
+	      break;
+#endif /* #ifdef PACE_TT_USB_COMMANDS  */
 	case USBDEVFS_SUBMITURB:
 		snoop(&dev->dev, "%s: SUBMITURB\n", __func__);
 		ret = proc_submiturb(ps, p);
diff -Naur kernel-3.3-3.0a-ref/drivers/usb/serial/Kconfig kernel-current/drivers/usb/serial/Kconfig
--- kernel-3.3-3.0a-ref/drivers/usb/serial/Kconfig	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/drivers/usb/serial/Kconfig	2015-06-12 16:27:19.984100064 +0200
@@ -56,6 +56,13 @@
 	  support" be compiled as a module for this driver to be used
 	  properly.
 
+config DISABLE_USB_SERIAL_READING
+	bool "Disable usb serial reading in driver"
+	default n
+	help
+	  Disabling the reading is driver specific (not done at generic driver level).
+	  Writing, for displaying message, is not concerned.
+
 config USB_SERIAL_AIRCABLE
 	tristate "USB AIRcable Bluetooth Dongle Driver"
 	help
diff -Naur kernel-3.3-3.0a-ref/drivers/usb/serial/pl2303.c kernel-current/drivers/usb/serial/pl2303.c
--- kernel-3.3-3.0a-ref/drivers/usb/serial/pl2303.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/drivers/usb/serial/pl2303.c	2015-06-12 16:27:19.984100064 +0200
@@ -777,6 +777,7 @@
 
 static void pl2303_process_read_urb(struct urb *urb)
 {
+#ifndef CONFIG_DISABLE_USB_SERIAL_READING
 	struct usb_serial_port *port = urb->context;
 	struct pl2303_private *priv = usb_get_serial_port_data(port);
 	struct tty_struct *tty;
@@ -825,6 +826,7 @@
 
 	tty_flip_buffer_push(tty);
 	tty_kref_put(tty);
+#endif
 }
 
 /* All of the device info needed for the PL2303 SIO serial converter */
diff -Naur kernel-3.3-3.0a-ref/drivers/usb/serial/usb-serial.c kernel-current/drivers/usb/serial/usb-serial.c
--- kernel-3.3-3.0a-ref/drivers/usb/serial/usb-serial.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/drivers/usb/serial/usb-serial.c	2015-06-12 16:27:20.012114063 +0200
@@ -270,7 +270,9 @@
 static int serial_open(struct tty_struct *tty, struct file *filp)
 {
 	struct usb_serial_port *port = tty->driver_data;
-
+/* Force boad rate to 115200 */
+	 
+	 tty_termios_encode_baud_rate(tty->termios,115200,115200);
 	dbg("%s - port %d", __func__, port->number);
 	return tty_port_open(&port->port, tty, filp);
 }
diff -Naur kernel-3.3-3.0a-ref/fs/char_dev.c kernel-current/fs/char_dev.c
--- kernel-3.3-3.0a-ref/fs/char_dev.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/char_dev.c	2015-06-12 16:27:19.952084065 +0200
@@ -24,6 +24,10 @@
 
 #include "internal.h"
 
+#ifdef CONFIG_KDEV_DRIVER
+#include <linux/kdev.h>
+#endif
+
 /*
  * capabilities for /dev/mem, /dev/kmem and similar directly mappable character
  * devices
@@ -80,6 +84,43 @@
 
 #endif /* CONFIG_PROC_FS */
 
+
+#ifdef CONFIG_KDEV_DRIVER
+
+int chardev_getList(kdev_ioc_getDevices_t * listOfCharDev)
+{
+  unsigned int index;
+  unsigned int offset = 0;
+  struct char_device_struct * cd;
+  
+  mutex_lock(&chrdevs_lock);
+  index = listOfCharDev->devs_nb;
+  
+  for(offset = 0; offset < CHRDEV_MAJOR_HASH_SIZE; offset++)
+  {
+    for (cd = chrdevs[offset]; cd; cd = cd->next)
+    {
+      listOfCharDev->devs[index].device_type = KDEV_CHAR_DEV;
+      strlcpy(listOfCharDev->devs[index].device_name, cd->name, sizeof(cd->name));
+      listOfCharDev->devs[index].major = cd->major;
+      listOfCharDev->devs[index].min_minor = cd->baseminor;
+      listOfCharDev->devs[index].max_minor = cd->minorct;
+      
+      index++;
+      if(index == (sizeof(listOfCharDev->devs)/sizeof(kdev_dev_t)))
+        return 1;
+    }
+  }
+  
+  listOfCharDev->devs_nb = index;
+  mutex_unlock(&chrdevs_lock);
+  
+  return 0;
+}
+
+#endif /* CONFIG_KDEV_DRIVER */
+
+
 /*
  * Register a single major with a specified minor range.
  *
diff -Naur kernel-3.3-3.0a-ref/fs/jffs2/compr.c kernel-current/fs/jffs2/compr.c
--- kernel-3.3-3.0a-ref/fs/jffs2/compr.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/jffs2/compr.c	2015-06-12 16:27:19.940078065 +0200
@@ -12,6 +12,11 @@
  *
  */
 
+#ifdef CONFIG_JFFS2_ENCRYPTION
+#include <linux/crypto.h>
+#include <linux/scatterlist.h>
+#endif /* CONFIG_JFFS2_ENCRYPTION */
+
 #include "compr.h"
 
 static DEFINE_SPINLOCK(jffs2_compressor_list_lock);
@@ -25,6 +30,65 @@
 /* Statistics for blocks stored without compression */
 static uint32_t none_stat_compr_blocks=0,none_stat_decompr_blocks=0,none_stat_compr_size=0;
 
+#ifdef CONFIG_JFFS2_ENCRYPTION
+static uint8_t aes_key[JFFS2_CRYPTO_KEYSIZE]=
+{   0xbf,0x18,0x6a,0x73,
+    0xec,0x86,0x3f,0x25,
+	0x9b,0xe8,0x03,0x52,
+	0x43,0xd7,0x37,0x8c,
+	0xbf,0x18,0x6a,0x73,
+	0xb3,0x68,0x3a,0x25,
+	0x9b,0xe8,0x33,0x52,
+	0x40,0xd7,0x15,0x3c
+};
+
+/**
+* aes_crypt - encrypt / decrypt data.
+* @str: the data to crypt
+* @len: length of the data
+* @crypto_key: the cryptographic key to use to crypt the data
+*
+* This function applies AES encryption to the data. It is done in counter
+* mode, which means that encryption and decryption are the same operation,
+* i.e., it XORs the same generated bitstream, so it can be used both for
+* encryption / decryption. Returns zero in case of success and a negative
+* error code in case of failure.
+*
+* WARNING: The operation is done in-place, so @str mutates!
+*/
+static int aes_crypt(void *str, int len)
+{
+	struct crypto_blkcipher *tfm;
+	struct blkcipher_desc desc;
+	struct scatterlist sg;
+	uint8_t iv[JFFS2_CRYPTO_KEYSIZE];
+	int err;
+
+	tfm = crypto_alloc_blkcipher(JFFS2_CRYPTO_ALGORITHM, 0, 0);
+	if (IS_ERR(tfm)) {
+		err = PTR_ERR(tfm);
+		printk(KERN_WARNING "JFFS2: failed to load transform for aes, error %d\n", err);
+		return err;
+	}
+
+	err = crypto_blkcipher_setkey(tfm, aes_key, JFFS2_CRYPTO_KEYSIZE);
+	if (err) {
+		printk(KERN_WARNING "JFFS2: cannot set the AES key, flags %#x, error %d\n",
+			  crypto_blkcipher_get_flags(tfm), err);
+		return err;
+	}
+
+	memset(&sg, 0, sizeof(struct scatterlist));
+	sg_set_buf(&sg, str, len);
+	memset(iv, 0, JFFS2_CRYPTO_KEYSIZE);
+	desc.info = iv;
+	desc.tfm = tfm;
+	desc.flags = 0;
+	err = crypto_blkcipher_encrypt(&desc, &sg, &sg, len);
+	crypto_free_blkcipher(tfm);
+	return err;
+}
+#endif /* CONFIG_JFFS2_ENCRYPTION */
 
 /*
  * Return 1 to use this compression
@@ -82,6 +146,12 @@
 		printk(KERN_WARNING "JFFS2: No memory for compressor allocation. Compression failed.\n");
 		return ret;
 	}
+	
+#ifdef CONFIG_JFFS2_ENCRYPTION
+	// Initialise compress buff with no compressed one in order to avoid bad encryption
+	memcpy(output_buf, data_in, *cdatalen);
+#endif /* CONFIG_JFFS2_ENCRYPTION */
+
 	orig_slen = *datalen;
 	orig_dlen = *cdatalen;
 	spin_lock(&jffs2_compressor_list_lock);
@@ -105,6 +175,13 @@
 		*cdatalen = orig_dlen;
 		err = this->compress(data_in, output_buf, datalen, cdatalen);
 
+#ifdef CONFIG_JFFS2_ENCRYPTION
+		if ( aes_crypt(output_buf, *cdatalen) )
+		{       
+			printk(KERN_WARNING "JFFS2: failed to crypt buffer in [%s:%d]\n", __FUNCTION__, __LINE__);
+		}
+#endif /* CONFIG_JFFS2_ENCRYPTION */
+
 		spin_lock(&jffs2_compressor_list_lock);
 		this->usecount--;
 		if (!err) {
@@ -154,6 +231,15 @@
 	uint32_t orig_slen, orig_dlen;
 	uint32_t best_slen=0, best_dlen=0;
 
+#ifdef CONFIG_JFFS2_ENCRYPTION
+	unsigned char *encrypt_buf = NULL;
+	encrypt_buf = kmalloc(*datalen,GFP_KERNEL);
+	if (!encrypt_buf) {
+		printk(KERN_WARNING "JFFS2: No memory for compressor allocation. Compression failed.\n");
+		return ret;
+	}
+#endif /* CONFIG_JFFS2_ENCRYPTION */
+
 	if (c->mount_opts.override_compr)
 		mode = c->mount_opts.compr;
 	else
@@ -240,9 +326,28 @@
 
 	if (ret == JFFS2_COMPR_NONE) {
 		*cpage_out = data_in;
+		
+#ifdef CONFIG_JFFS2_ENCRYPTION
+		memcpy(encrypt_buf, data_in, *cdatalen);
+
+		if ( aes_crypt(encrypt_buf, *cdatalen) )
+		{
+			printk(KERN_WARNING "JFFS2: failed to crypt buffer in [%s:%d]\n", __FUNCTION__, __LINE__);
+		}
+			
+		*cpage_out = encrypt_buf;
+#endif /* CONFIG_JFFS2_ENCRYPTION */
+
 		*datalen = *cdatalen;
 		none_stat_compr_blocks++;
 		none_stat_compr_size += *datalen;
+		
+#ifdef CONFIG_JFFS2_ENCRYPTION
+	}
+	else {
+		if (encrypt_buf != NULL)
+		   kfree(encrypt_buf);
+#endif /* CONFIG_JFFS2_ENCRYPTION */
 	}
 	return ret;
 }
@@ -252,7 +357,7 @@
 		     unsigned char *data_out, uint32_t cdatalen, uint32_t datalen)
 {
 	struct jffs2_compressor *this;
-	int ret;
+	int ret=0;
 
 	/* Older code had a bug where it would write non-zero 'usercompr'
 	   fields. Deal with it. */
@@ -262,6 +367,12 @@
 	switch (comprtype & 0xff) {
 	case JFFS2_COMPR_NONE:
 		/* This should be special-cased elsewhere, but we might as well deal with it */
+#ifdef CONFIG_JFFS2_ENCRYPTION
+		if ( aes_crypt(cdata_in, cdatalen) )
+		{
+			printk(KERN_WARNING "JFFS2: failed to decrypt buffer in [%s:%d]\n", __FUNCTION__, __LINE__);
+		}
+#endif /* CONFIG_JFFS2_ENCRYPTION */
 		memcpy(data_out, cdata_in, datalen);
 		none_stat_decompr_blocks++;
 		break;
@@ -274,6 +385,12 @@
 			if (comprtype == this->compr) {
 				this->usecount++;
 				spin_unlock(&jffs2_compressor_list_lock);
+#ifdef CONFIG_JFFS2_ENCRYPTION
+				if ( aes_crypt(cdata_in, cdatalen) )
+				{
+					printk(KERN_WARNING "JFFS2: failed to decrypt buffer in [%s:%d]\n", __FUNCTION__, __LINE__);
+				}
+#endif /* CONFIG_JFFS2_ENCRYPTION */
 				ret = this->decompress(cdata_in, data_out, cdatalen, datalen);
 				spin_lock(&jffs2_compressor_list_lock);
 				if (ret) {
diff -Naur kernel-3.3-3.0a-ref/fs/jffs2/compr.h kernel-current/fs/jffs2/compr.h
--- kernel-3.3-3.0a-ref/fs/jffs2/compr.h	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/jffs2/compr.h	2015-06-12 16:27:19.940078065 +0200
@@ -102,4 +102,11 @@
 void jffs2_lzo_exit(void);
 #endif
 
+#ifdef CONFIG_JFFS2_ENCRYPTION
+/* 128 bit key size in bytes for JFFS2 */
+#define JFFS2_CRYPTO_KEYSIZE 32 
+/* AES in counter mode is the encryption algorithm */
+#define JFFS2_CRYPTO_ALGORITHM "ctr(aes)"
+#endif /* CONFIG_JFFS2_ENCRYPTION */
+
 #endif /* __JFFS2_COMPR_H__ */
diff -Naur kernel-3.3-3.0a-ref/fs/jffs2/compr_zlib.c kernel-current/fs/jffs2/compr_zlib.c
--- kernel-3.3-3.0a-ref/fs/jffs2/compr_zlib.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/jffs2/compr_zlib.c	2015-06-12 16:27:19.940078065 +0200
@@ -180,6 +180,13 @@
 	}
 	zlib_inflateEnd(&inf_strm);
 	mutex_unlock(&inflate_mutex);
+
+#ifdef CONFIG_JFFS2_ENCRYPTION
+	if (ret != Z_STREAM_END) {
+	    return ret;
+	}
+#endif /* CONFIG_JFFS2_ENCRYPTION */
+	
 	return 0;
 }
 
diff -Naur kernel-3.3-3.0a-ref/fs/jffs2/fs.c kernel-current/fs/jffs2/fs.c
--- kernel-3.3-3.0a-ref/fs/jffs2/fs.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/jffs2/fs.c	2015-06-12 16:27:19.924070065 +0200
@@ -692,6 +692,8 @@
 	int ret = 0;
 
 	if (jffs2_cleanmarker_oob(c)) {
+		if(!jffs2_oob_write_enabled(c))
+			printk(KERN_INFO "JFFS2 doesn't use OOB.\n");
 		/* NAND flash... do setup accordingly */
 		ret = jffs2_nand_flash_setup(c);
 		if (ret)
diff -Naur kernel-3.3-3.0a-ref/fs/jffs2/Kconfig kernel-current/fs/jffs2/Kconfig
--- kernel-3.3-3.0a-ref/fs/jffs2/Kconfig	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/jffs2/Kconfig	2015-06-12 16:27:19.944080065 +0200
@@ -186,3 +186,10 @@
 	  decompression) at the expense of size.
 
 endchoice
+
+config JFFS2_ENCRYPTION
+	bool "JFFS2 AES encryption"
+	depends on CRYPTO_AES && CRYPTO_CTR
+	help
+	  Activate AES encryption on JFFS2 compression/decompression.
+
diff -Naur kernel-3.3-3.0a-ref/fs/jffs2/os-linux.h kernel-current/fs/jffs2/os-linux.h
--- kernel-3.3-3.0a-ref/fs/jffs2/os-linux.h	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/jffs2/os-linux.h	2015-06-12 16:27:19.924070065 +0200
@@ -107,6 +107,7 @@
 #endif
 
 #define jffs2_cleanmarker_oob(c) (c->mtd->type == MTD_NANDFLASH)
+#define jffs2_oob_write_enabled(c) (c->mtd->flags & MTD_OOB_WRITEABLE)
 
 #define jffs2_wbuf_dirty(c) (!!(c)->wbuf_len)
 
diff -Naur kernel-3.3-3.0a-ref/fs/jffs2/read.c kernel-current/fs/jffs2/read.c
--- kernel-3.3-3.0a-ref/fs/jffs2/read.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/jffs2/read.c	2015-06-12 16:27:19.944080065 +0200
@@ -134,6 +134,16 @@
 			goto out_decomprbuf;
 		}
 	}
+#ifdef CONFIG_JFFS2_ENCRYPTION
+	else
+	{
+		ret = jffs2_decompress(c, f, JFFS2_COMPR_NONE, readbuf, decomprbuf, je32_to_cpu(ri->csize), je32_to_cpu(ri->dsize));
+		if (ret) {
+			printk(KERN_WARNING "Error: jffs2_decompress returned %d\n", ret);
+			goto out_decomprbuf;
+		}
+	}
+#endif /* CONFIG_JFFS2_ENCRYPTION */
 
 	if (len < je32_to_cpu(ri->dsize)) {
 		memcpy(buf, decomprbuf+ofs, len);
diff -Naur kernel-3.3-3.0a-ref/fs/jffs2/wbuf.c kernel-current/fs/jffs2/wbuf.c
--- kernel-3.3-3.0a-ref/fs/jffs2/wbuf.c	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/jffs2/wbuf.c	2015-06-12 16:27:19.924070065 +0200
@@ -1026,6 +1026,9 @@
 	int cmlen = min_t(int, c->oobavail, OOB_CM_SIZE);
 	struct mtd_oob_ops ops;
 
+    if(!jffs2_oob_write_enabled(c))
+    	return 0;
+
 	ops.mode = MTD_OPS_AUTO_OOB;
 	ops.ooblen = NR_OOB_SCAN_PAGES * c->oobavail;
 	ops.oobbuf = c->oobbuf;
@@ -1069,6 +1072,9 @@
 	struct mtd_oob_ops ops;
 	int ret, cmlen = min_t(int, c->oobavail, OOB_CM_SIZE);
 
+    if(!jffs2_oob_write_enabled(c))
+    	return 0;
+
 	ops.mode = MTD_OPS_AUTO_OOB;
 	ops.ooblen = cmlen;
 	ops.oobbuf = c->oobbuf;
@@ -1095,6 +1101,9 @@
 	struct mtd_oob_ops ops;
 	int cmlen = min_t(int, c->oobavail, OOB_CM_SIZE);
 
+    if(!jffs2_oob_write_enabled(c))
+	    	return 0;
+
 	ops.mode = MTD_OPS_AUTO_OOB;
 	ops.ooblen = cmlen;
 	ops.oobbuf = (uint8_t *)&oob_cleanmarker;
diff -Naur kernel-3.3-3.0a-ref/fs/Kconfig kernel-current/fs/Kconfig
--- kernel-3.3-3.0a-ref/fs/Kconfig	2013-08-28 01:31:05.000000000 +0200
+++ kernel-current/fs/Kconfig	2015-06-12 16:27:20.016116063 +0200
@@ -57,6 +57,28 @@
           for filesystems like NFS and for the flock() system
           call. Disabling this option saves about 11k.
 
+
+menu "Unmount monitoring and force closing files"
+config UMOUNT_MONITOR_OPEN_FD
+	bool "monitor the opened file descriptors" if EXPERT
+	default n
+	help
+	 monitor all the open fd on an unmounted filesystem
+	 
+config UNMOUNT_MONITOR_OPEN_FD_LAZY_ONLY
+	bool "monitor the opened file descriptors only when we do lazy umount" if EXPERT
+	default n
+	help
+	 the normal umount will behave as before
+	 
+config UNMOUNT_MONITOR_OPEN_FD_FORCE_CLOSE
+	bool "close the remaining file descriptors" if EXPERT
+	default n
+	help
+	 will do a close on all fd in the umounted fs
+	 
+
+endmenu
 source "fs/notify/Kconfig"
 
 source "fs/quota/Kconfig"
diff -Naur kernel-3.3-3.0a-ref/fs/namespace.c kernel-current/fs/namespace.c
--- kernel-3.3-3.0a-ref/fs/namespace.c	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/fs/namespace.c	2015-06-12 16:27:20.016116063 +0200
@@ -20,6 +20,9 @@
 #include <linux/fs_struct.h>	/* get_fs_root et.al. */
 #include <linux/fsnotify.h>	/* fsnotify_vfsmount_delete */
 #include <linux/uaccess.h>
+#include <linux/sched.h>
+#include <linux/fdtable.h>
+#include <linux/dcache.h>
 #include "pnode.h"
 #include "internal.h"
 
@@ -1087,16 +1090,68 @@
 
 static void shrink_submounts(struct mount *mnt, struct list_head *umounts);
 
+#ifdef CONFIG_UNMOUNT_MONITOR_OPEN_FD_FORCE_CLOSE
+static void __put_unused_fd(struct files_struct *files, unsigned int fd)
+{
+	struct fdtable *fdt = files_fdtable(files);
+	__FD_CLR(fd, fdt->open_fds);
+	if (fd < files->next_fd)
+		files->next_fd = fd;
+}
+#endif 
 static int do_umount(struct mount *mnt, int flags)
 {
 	struct super_block *sb = mnt->mnt.mnt_sb;
 	int retval;
 	LIST_HEAD(umount_list);
-
 	retval = security_sb_umount(&mnt->mnt, flags);
 	if (retval)
 		return retval;
-
+        
+#ifdef CONFIG_UMOUNT_MONITOR_OPEN_FD
+	/* PACE PATCH   */
+#ifdef CONFIG_UNMOUNT_MONITOR_OPEN_FD_LAZY_ONLY	
+	if (flags & MNT_DETACH)
+#endif	
+	{
+	struct files_struct *files;
+    	const struct task_struct *p, *g;
+	struct file * filp;
+	struct fdtable *fdt;
+	struct dentry *dentry_file;
+	int fd;
+	do_each_thread (g, p) {
+	   
+	   files=p->files;
+	   if (!files)
+	      continue;
+	   spin_lock(&files->file_lock);
+	   fdt = files_fdtable(files);
+	   for (fd=0;fd<fdt->max_fds;fd++)
+	   {	
+	      filp = fdt->fd[fd];
+	      
+              if ((filp) && (filp->f_path.mnt==&mnt->mnt))
+	      {
+	         char buf[256], buf1[256];
+	         dentry_file=filp->f_path.dentry;
+	         printk("*** found open file descriptor %s%s from task : %s  \n",dentry_path(mnt->mnt_mountpoint,buf1,256),dentry_path(dentry_file,buf,256),p->comm);
+#ifdef CONFIG_UNMOUNT_MONITOR_OPEN_FD_FORCE_CLOSE
+                 printk("     ---> force close file\n");	 
+		 rcu_assign_pointer(fdt->fd[fd], NULL);
+	        /* FD_CLR(fd, fdt->close_on_exec);*/
+	        __put_unused_fd(files, fd);
+	        retval = filp_close(filp, files);
+#endif
+		  
+	      }   
+	    }
+	   spin_unlock(&files->file_lock);
+	  } while_each_thread (g, p);	
+	}
+	
+	/* PACE PATCH   */
+#endif /* CONFIG_UMOUNT_MONITOR_OPEN_FD */	
 	/*
 	 * Allow userspace to request a mountpoint be expired rather than
 	 * unmounting unconditionally. Unmount only happens if:
@@ -1507,8 +1562,8 @@
 
 static int graft_tree(struct mount *mnt, struct path *path)
 {
-	if (mnt->mnt.mnt_sb->s_flags & MS_NOUSER)
-		return -EINVAL;
+/*	if (mnt->mnt.mnt_sb->s_flags & MS_NOUSER)
+		return -EINVAL; */
 
 	if (S_ISDIR(path->dentry->d_inode->i_mode) !=
 	      S_ISDIR(mnt->mnt.mnt_root->d_inode->i_mode))
diff -Naur kernel-3.3-3.0a-ref/fs/proc/Kconfig kernel-current/fs/proc/Kconfig
--- kernel-3.3-3.0a-ref/fs/proc/Kconfig	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/fs/proc/Kconfig	2015-06-12 16:27:19.992104064 +0200
@@ -58,6 +58,123 @@
 	  building a kernel for install/rescue disks or your system is very
 	  limited in memory.
 
+menuconfig SYSCTL_CONFIG
+	bool "Enable /proc/sys/ entries modifications"
+	default n
+       depends on PROC_SYSCTL
+	---help---
+	  Say Y to be able to change entries value?
+	  
+	  For each entrie, kernel accept a specific range of values.
+	  
+	  Say N to keep the default values.
+	  
+if SYSCTL_CONFIG	  
+	  
+menuconfig PROC_SYSCTL_SETTINGS
+	bool "/proc/sys entries hardcoded value"		
+	default n
+	---help---
+     Forces value related to /proc/sys entries 
+	  even without /proc/sys enabled
+
+if PROC_SYSCTL_SETTINGS
+config RANDOMIZE_VA_SPACE
+	bool "randomize_va_space"
+	default n
+	---help---
+         set to 1 by default, meaning NO randomization (the other value is 2)
+         set through the option COMPAT_BRK
+
+config TCP_SYN_COOKIES
+	bool "tcp_syncookies"
+	default n
+	select SYN_COOKIES
+	---help---
+         set to 0 by default (1 otherwise)
+         set through the option SYN_COOKIES
+
+config DMESG_RESTRICT
+	bool "dmesg_restrict"
+	default n
+	select SECURITY_DMESG_RESTRICT
+	---help---
+         set to 0 by default (1 otherwise)
+         set through the option SECURITY_DMESG_RESTRICT
+
+config KPTR_RESTRICT
+	bool "kptr_restrict"
+	default n
+	---help---
+         set to 0 by default (1 otherwise)
+
+config ACCEPT_SOURCE_ROUTE
+	bool "accept_source_route"
+	default y
+	---help---
+         set to 1 by default (0 otherwise)
+
+config ACCEPT_REDIRECTS
+	bool "accept_redirects"
+	default y
+	---help---
+         set to 1 by default (0 otherwise)
+
+config SECURE_REDIRECTS
+	bool "secure_redirects"
+	default y
+	---help---
+         set to 1 by default (0 otherwise)
+		
+config RP_FILTER
+	bool "rp_filter"
+	default n
+	---help---
+         set to 0 by default (1 otherwise)
+
+config IP_FORWARD
+	bool "ip_forward"
+	default n
+	---help---
+         set to 0 by default (1 otherwise)
+	
+config ICMP_ECHO_IGNORE_ALL		
+	bool "icmp_echo_ignore_all"
+	default n
+	---help---
+         set to 0 by default (1 otherwise)
+
+config TCP_SACK		
+	bool "tcp_sack"
+	default y
+	---help---
+         set to 1 by default (0 otherwise)
+
+config TCP_TIMESTAMPS		
+	bool "tcp_timestamps"
+	default y
+	---help---
+         set to 1 by default (0 otherwise)
+		
+endif			
+			
+config  PROC_SYSCTL_RO_STATE
+	bool "Put all entries in read-only state"
+	depends on PROC_SYSCTL
+	default n
+	---help---
+	  Forces all entries of /proc/sys to the read-only state
+	  
+config  PROC_SYSCTL_MODULES_DISABLED_SETTING
+	bool "Allow to modify the entry \"modules_disabled\""
+	depends on PROC_SYSCTL_RO_STATE
+	default n
+	---help---
+	  This option allows to still change the entry "modules_disable" 
+	  although the /proc/sys entries are forced to read-only state
+	  
+endif
+	    	  
 config PROC_PAGE_MONITOR
  	default y
 	depends on PROC_FS && MMU
diff -Naur kernel-3.3-3.0a-ref/fs/proc/proc_sysctl.c kernel-current/fs/proc/proc_sysctl.c
--- kernel-3.3-3.0a-ref/fs/proc/proc_sysctl.c	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/fs/proc/proc_sysctl.c	2015-06-12 16:27:19.992104064 +0200
@@ -47,6 +47,17 @@
 		inode->i_mode |= S_IFREG;
 		inode->i_op = &proc_sys_inode_operations;
 		inode->i_fop = &proc_sys_file_operations;
+#ifdef CONFIG_PROC_SYSCTL_RO_STATE
+		if (table->procname != NULL){
+#ifdef CONFIG_PROC_SYSCTL_MODULES_DISABLED_SETTING
+		  if (strcmp(table->procname, "modules_disabled")) 
+#endif
+		     {
+		        inode->i_mode &= ~S_IWUSR & ~S_IWGRP & ~S_IWOTH;
+			    table->mode &= ~S_IWUSR & ~S_IWGRP & ~S_IWOTH;	
+		     }
+		}
+#endif
 	} else {
 		inode->i_mode |= S_IFDIR;
 		clear_nlink(inode);
diff -Naur kernel-3.3-3.0a-ref/fs/ramfs/inode.c kernel-current/fs/ramfs/inode.c
--- kernel-3.3-3.0a-ref/fs/ramfs/inode.c	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/fs/ramfs/inode.c	2015-06-12 16:27:19.984100064 +0200
@@ -263,7 +263,14 @@
 static struct dentry *rootfs_mount(struct file_system_type *fs_type,
 	int flags, const char *dev_name, void *data)
 {
-	return mount_nodev(fs_type, flags|MS_NOUSER, data, ramfs_fill_super);
+	static int once;
+
+	if (once)
+		return ERR_PTR(-ENODEV);
+	else
+		once++;
+
+	return mount_nodev(fs_type, flags, data, ramfs_fill_super);
 }
 
 static void ramfs_kill_sb(struct super_block *sb)
diff -Naur kernel-3.3-3.0a-ref/fs/ramfs/inode.c.orig kernel-current/fs/ramfs/inode.c.orig
--- kernel-3.3-3.0a-ref/fs/ramfs/inode.c.orig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/fs/ramfs/inode.c.orig	2015-06-12 16:27:19.639928074 +0200
@@ -0,0 +1,305 @@
+/*
+ * Resizable simple ram filesystem for Linux.
+ *
+ * Copyright (C) 2000 Linus Torvalds.
+ *               2000 Transmeta Corp.
+ *
+ * Usage limits added by David Gibson, Linuxcare Australia.
+ * This file is released under the GPL.
+ */
+
+/*
+ * NOTE! This filesystem is probably most useful
+ * not as a real filesystem, but as an example of
+ * how virtual filesystems can be written.
+ *
+ * It doesn't get much simpler than this. Consider
+ * that this file implements the full semantics of
+ * a POSIX-compliant read-write filesystem.
+ *
+ * Note in particular how the filesystem does not
+ * need to implement any data structures of its own
+ * to keep track of the virtual data: using the VFS
+ * caches is sufficient.
+ */
+
+#include <linux/fs.h>
+#include <linux/pagemap.h>
+#include <linux/highmem.h>
+#include <linux/time.h>
+#include <linux/init.h>
+#include <linux/string.h>
+#include <linux/backing-dev.h>
+#include <linux/ramfs.h>
+#include <linux/sched.h>
+#include <linux/parser.h>
+#include <linux/magic.h>
+#include <linux/slab.h>
+#include <asm/uaccess.h>
+#include "internal.h"
+
+#define RAMFS_DEFAULT_MODE	0755
+
+static const struct super_operations ramfs_ops;
+static const struct inode_operations ramfs_dir_inode_operations;
+
+static struct backing_dev_info ramfs_backing_dev_info = {
+	.name		= "ramfs",
+	.ra_pages	= 0,	/* No readahead */
+	.capabilities	= BDI_CAP_NO_ACCT_AND_WRITEBACK |
+			  BDI_CAP_MAP_DIRECT | BDI_CAP_MAP_COPY |
+			  BDI_CAP_READ_MAP | BDI_CAP_WRITE_MAP | BDI_CAP_EXEC_MAP,
+};
+
+struct inode *ramfs_get_inode(struct super_block *sb,
+				const struct inode *dir, umode_t mode, dev_t dev)
+{
+	struct inode * inode = new_inode(sb);
+
+	if (inode) {
+		inode->i_ino = get_next_ino();
+		inode_init_owner(inode, dir, mode);
+		inode->i_mapping->a_ops = &ramfs_aops;
+		inode->i_mapping->backing_dev_info = &ramfs_backing_dev_info;
+		mapping_set_gfp_mask(inode->i_mapping, GFP_HIGHUSER);
+		mapping_set_unevictable(inode->i_mapping);
+		inode->i_atime = inode->i_mtime = inode->i_ctime = CURRENT_TIME;
+		switch (mode & S_IFMT) {
+		default:
+			init_special_inode(inode, mode, dev);
+			break;
+		case S_IFREG:
+			inode->i_op = &ramfs_file_inode_operations;
+			inode->i_fop = &ramfs_file_operations;
+			break;
+		case S_IFDIR:
+			inode->i_op = &ramfs_dir_inode_operations;
+			inode->i_fop = &simple_dir_operations;
+
+			/* directory inodes start off with i_nlink == 2 (for "." entry) */
+			inc_nlink(inode);
+			break;
+		case S_IFLNK:
+			inode->i_op = &page_symlink_inode_operations;
+			break;
+		}
+	}
+	return inode;
+}
+
+/*
+ * File creation. Allocate an inode, and we're done..
+ */
+/* SMP-safe */
+static int
+ramfs_mknod(struct inode *dir, struct dentry *dentry, umode_t mode, dev_t dev)
+{
+	struct inode * inode = ramfs_get_inode(dir->i_sb, dir, mode, dev);
+	int error = -ENOSPC;
+
+	if (inode) {
+		d_instantiate(dentry, inode);
+		dget(dentry);	/* Extra count - pin the dentry in core */
+		error = 0;
+		dir->i_mtime = dir->i_ctime = CURRENT_TIME;
+	}
+	return error;
+}
+
+static int ramfs_mkdir(struct inode * dir, struct dentry * dentry, umode_t mode)
+{
+	int retval = ramfs_mknod(dir, dentry, mode | S_IFDIR, 0);
+	if (!retval)
+		inc_nlink(dir);
+	return retval;
+}
+
+static int ramfs_create(struct inode *dir, struct dentry *dentry, umode_t mode, struct nameidata *nd)
+{
+	return ramfs_mknod(dir, dentry, mode | S_IFREG, 0);
+}
+
+static int ramfs_symlink(struct inode * dir, struct dentry *dentry, const char * symname)
+{
+	struct inode *inode;
+	int error = -ENOSPC;
+
+	inode = ramfs_get_inode(dir->i_sb, dir, S_IFLNK|S_IRWXUGO, 0);
+	if (inode) {
+		int l = strlen(symname)+1;
+		error = page_symlink(inode, symname, l);
+		if (!error) {
+			d_instantiate(dentry, inode);
+			dget(dentry);
+			dir->i_mtime = dir->i_ctime = CURRENT_TIME;
+		} else
+			iput(inode);
+	}
+	return error;
+}
+
+static const struct inode_operations ramfs_dir_inode_operations = {
+	.create		= ramfs_create,
+	.lookup		= simple_lookup,
+	.link		= simple_link,
+	.unlink		= simple_unlink,
+	.symlink	= ramfs_symlink,
+	.mkdir		= ramfs_mkdir,
+	.rmdir		= simple_rmdir,
+	.mknod		= ramfs_mknod,
+	.rename		= simple_rename,
+};
+
+static const struct super_operations ramfs_ops = {
+	.statfs		= simple_statfs,
+	.drop_inode	= generic_delete_inode,
+	.show_options	= generic_show_options,
+};
+
+struct ramfs_mount_opts {
+	umode_t mode;
+};
+
+enum {
+	Opt_mode,
+	Opt_err
+};
+
+static const match_table_t tokens = {
+	{Opt_mode, "mode=%o"},
+	{Opt_err, NULL}
+};
+
+struct ramfs_fs_info {
+	struct ramfs_mount_opts mount_opts;
+};
+
+static int ramfs_parse_options(char *data, struct ramfs_mount_opts *opts)
+{
+	substring_t args[MAX_OPT_ARGS];
+	int option;
+	int token;
+	char *p;
+
+	opts->mode = RAMFS_DEFAULT_MODE;
+
+	while ((p = strsep(&data, ",")) != NULL) {
+		if (!*p)
+			continue;
+
+		token = match_token(p, tokens, args);
+		switch (token) {
+		case Opt_mode:
+			if (match_octal(&args[0], &option))
+				return -EINVAL;
+			opts->mode = option & S_IALLUGO;
+			break;
+		/*
+		 * We might like to report bad mount options here;
+		 * but traditionally ramfs has ignored all mount options,
+		 * and as it is used as a !CONFIG_SHMEM simple substitute
+		 * for tmpfs, better continue to ignore other mount options.
+		 */
+		}
+	}
+
+	return 0;
+}
+
+int ramfs_fill_super(struct super_block *sb, void *data, int silent)
+{
+	struct ramfs_fs_info *fsi;
+	struct inode *inode = NULL;
+	struct dentry *root;
+	int err;
+
+	save_mount_options(sb, data);
+
+	fsi = kzalloc(sizeof(struct ramfs_fs_info), GFP_KERNEL);
+	sb->s_fs_info = fsi;
+	if (!fsi) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	err = ramfs_parse_options(data, &fsi->mount_opts);
+	if (err)
+		goto fail;
+
+	sb->s_maxbytes		= MAX_LFS_FILESIZE;
+	sb->s_blocksize		= PAGE_CACHE_SIZE;
+	sb->s_blocksize_bits	= PAGE_CACHE_SHIFT;
+	sb->s_magic		= RAMFS_MAGIC;
+	sb->s_op		= &ramfs_ops;
+	sb->s_time_gran		= 1;
+
+	inode = ramfs_get_inode(sb, NULL, S_IFDIR | fsi->mount_opts.mode, 0);
+	if (!inode) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	root = d_alloc_root(inode);
+	sb->s_root = root;
+	if (!root) {
+		err = -ENOMEM;
+		goto fail;
+	}
+
+	return 0;
+fail:
+	kfree(fsi);
+	sb->s_fs_info = NULL;
+	iput(inode);
+	return err;
+}
+
+struct dentry *ramfs_mount(struct file_system_type *fs_type,
+	int flags, const char *dev_name, void *data)
+{
+	return mount_nodev(fs_type, flags, data, ramfs_fill_super);
+}
+
+static struct dentry *rootfs_mount(struct file_system_type *fs_type,
+	int flags, const char *dev_name, void *data)
+{
+	return mount_nodev(fs_type, flags|MS_NOUSER, data, ramfs_fill_super);
+}
+
+static void ramfs_kill_sb(struct super_block *sb)
+{
+	kfree(sb->s_fs_info);
+	kill_litter_super(sb);
+}
+
+static struct file_system_type ramfs_fs_type = {
+	.name		= "ramfs",
+	.mount		= ramfs_mount,
+	.kill_sb	= ramfs_kill_sb,
+};
+static struct file_system_type rootfs_fs_type = {
+	.name		= "rootfs",
+	.mount		= rootfs_mount,
+	.kill_sb	= kill_litter_super,
+};
+
+static int __init init_ramfs_fs(void)
+{
+	return register_filesystem(&ramfs_fs_type);
+}
+module_init(init_ramfs_fs)
+
+int __init init_rootfs(void)
+{
+	int err;
+
+	err = bdi_init(&ramfs_backing_dev_info);
+	if (err)
+		return err;
+
+	err = register_filesystem(&rootfs_fs_type);
+	if (err)
+		bdi_destroy(&ramfs_backing_dev_info);
+
+	return err;
+}
diff -Naur kernel-3.3-3.0a-ref/include/linux/bmoca.h kernel-current/include/linux/bmoca.h
--- kernel-3.3-3.0a-ref/include/linux/bmoca.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/bmoca.h	2015-06-12 16:27:20.004110063 +0200
@@ -1,5 +1,5 @@
 /*
- * Copyright (C) 2010 Broadcom Corporation
+ * Copyright (C) 2013 Broadcom Corporation
  *
  * This program is free software; you can redistribute it and/or modify
  * it under the terms of the GNU General Public License version 2 as
@@ -36,6 +36,14 @@
 #define MOCA_BAND_E		6
 #define MOCA_BAND_F		7
 #define MOCA_BAND_G		8
+#define MOCA_BAND_H		9
+#define MOCA_BAND_MAX		10
+
+#define MOCA_BAND_NAMES { \
+	"highrf", "midrf", "wanrf", \
+	"ext_d", "d_low", "d_high", \
+	"e", "f", "g", "h"\
+}
 
 #define MOCA_BOOT_FLAGS_BONDED	(1 << 0)
 
@@ -54,12 +62,20 @@
 #define MOCA_IOCTL_GET_DRV_INFO	_IOR(MOCA_IOC_MAGIC, 0, struct moca_kdrv_info)
 #define MOCA_IOCTL_SET_CPU_RATE	_IOR(MOCA_IOC_MAGIC, 7, unsigned int)
 #define MOCA_IOCTL_SET_PHY_RATE	_IOR(MOCA_IOC_MAGIC, 8, unsigned int)
+#define MOCA_IOCTL_GET_3450_REG	_IOR(MOCA_IOC_MAGIC, 9, unsigned int) /* Reserved */
+#define MOCA_IOCTL_SET_3450_REG	_IOR(MOCA_IOC_MAGIC, 10, unsigned int) /* Reserved */
+#define MOCA_IOCTL_PM_SUSPEND   _IO(MOCA_IOC_MAGIC, 11)
+#define MOCA_IOCTL_PM_WOL	_IO(MOCA_IOC_MAGIC, 12)
+#define MOCA_IOCTL_CLK_SSC	_IO(MOCA_IOC_MAGIC, 13)
 
 #define MOCA_DEVICE_ID_UNREGISTERED  (-1)
 
 /* this must match MoCAOS_IFNAMSIZE */
 #define MOCA_IFNAMSIZ		16
 
+/* ID value hinting ioctl caller to use returned IFNAME as is */
+#define MOCA_IFNAME_USE_ID    0xffffffff
+
 /* Legacy version of moca_kdrv_info */
 struct moca_kdrv_info_v2 {
 	__u32			version;
@@ -103,7 +119,7 @@
 	__u32			macaddr_lo;
 
 	__u32			phy_freq;
-	__u32			cpu_freq;
+	__u32			device_id;
 
 	__u32			chip_id;
 };
@@ -119,6 +135,17 @@
 	__u32			boot_flags;
 };
 
+/* MoCA PM states */
+enum moca_pm_states {
+	MOCA_ACTIVE,
+	MOCA_SUSPENDING,
+	MOCA_SUSPENDING_WAITING_ACK,
+	MOCA_SUSPENDING_GOT_ACK,
+	MOCA_SUSPENDED,
+	MOCA_RESUMING,
+	MOCA_NONE
+ };
+
 #ifdef __KERNEL__
 
 static inline void mac_to_u32(uint32_t *hi, uint32_t *lo, const uint8_t *mac)
@@ -150,21 +177,27 @@
 	u32			hw_rev;  /* this is the chip_id */
 	u32			rf_band;
 
-	int			useDma;
-	int			useSpi;
-
+	int			use_dma;
+	int			use_spi;
+	int			devId;
 	u32			chip_id;
+
+#ifdef CONFIG_SMP
+	int			smp_processor_id;
+#endif
 };
 
 enum {
 	HWREV_MOCA_11		= 0x1100,
 	HWREV_MOCA_11_LITE	= 0x1101,
 	HWREV_MOCA_11_PLUS	= 0x1102,
+	HWREV_MOCA_20_ALT	= 0x2000, /* for backward compatibility */
 	HWREV_MOCA_20_GEN21	= 0x2001,
 	HWREV_MOCA_20_GEN22	= 0x2002,
 	HWREV_MOCA_20_GEN23	= 0x2003,
 };
 
+
 #define MOCA_PROTVER_11		0x1100
 #define MOCA_PROTVER_20		0x2000
 #define MOCA_PROTVER_MASK	0xff00
diff -Naur kernel-3.3-3.0a-ref/include/linux/brcmstb/brcmapi.h kernel-current/include/linux/brcmstb/brcmapi.h
--- kernel-3.3-3.0a-ref/include/linux/brcmstb/brcmapi.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/brcmstb/brcmapi.h	2015-06-12 16:27:19.924070065 +0200
@@ -47,6 +47,13 @@
 #define BRCM_RX_HOOK_NETACCEL	0
 #define BRCM_RX_HOOK_EROUTER	1
 
+/* RT031011 Pace change */
+#define FLASH_TYPE_NONE		0
+#define FLASH_TYPE_NOR		1
+#define FLASH_TYPE_NAND		2
+#define FLASH_TYPE_SPI		3
+#define FLASH_TYPE_MAX		FLASH_TYPE_SPI
+
 #if defined(CONFIG_MIPS)
 void __init brcm_free_bootmem(unsigned long addr, unsigned long size);
 void brcm_tlb_init(void);
@@ -86,6 +93,12 @@
 	int			docsis_platform;
 };
 
+/* @RCA Pace change : So we can have a partition map for more than one device */
+struct brcm_mtd_partition_map {
+     int    num_parts;
+     struct mtd_partition * partition_map;
+};
+
 int bmem_find_region(unsigned long addr, unsigned long size);
 int bmem_region_info(int idx, unsigned long *addr, unsigned long *size);
 int bmem_get_page(struct mm_struct *mm, struct vm_area_struct *vma,
@@ -103,6 +116,7 @@
 }
 
 int brcm_alloc_macaddr(u8 *buf);
+int brcm_alloc_moca_macaddr(u8 *buf);
 
 extern spinlock_t brcm_magnum_spinlock;
 
diff -Naur kernel-3.3-3.0a-ref/include/linux/brcmstb/brcmstb.h kernel-current/include/linux/brcmstb/brcmstb.h
--- kernel-3.3-3.0a-ref/include/linux/brcmstb/brcmstb.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/brcmstb/brcmstb.h	2015-06-12 16:27:19.928072066 +0200
@@ -727,6 +727,7 @@
 extern unsigned long brcm_eth0_no_mdio;
 extern unsigned char brcm_eth0_phyaddr[CFE_STRING_SIZE];
 extern u8 brcm_primary_macaddr[IFHWADDRLEN];
+extern u8 brcm_moca_macaddr[IFHWADDRLEN];
 
 extern unsigned long brcm_moca_i2c_base;
 extern unsigned long brcm_moca_rf_band;
@@ -844,6 +845,12 @@
 int __init board_get_partition_map(struct mtd_partition **p);
 void __init brcm_wraparound_check(void);
 
+/* RT031011 Pace change */
+#define CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
+#if defined CONFIG_PACE_MULTI_DEVICE_MTD_SUPPORT
+int __init board_get_partition_map_pace(struct brcm_mtd_partition_map  **p);
+#endif
+
 void ebi_restore_settings(void);
 
 int __init bchip_strap_flash_type(void);
diff -Naur kernel-3.3-3.0a-ref/include/linux/capability.h kernel-current/include/linux/capability.h
--- kernel-3.3-3.0a-ref/include/linux/capability.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/capability.h	2015-06-12 16:27:19.980098064 +0200
@@ -416,7 +416,7 @@
 #else /* HAND-CODED capability initializers */
 
 # define CAP_EMPTY_SET    ((kernel_cap_t){{ 0, 0 }})
-# define CAP_FULL_SET     ((kernel_cap_t){{ ~0, ~0 }})
+# define CAP_FULL_SET ((kernel_cap_t){{ ~CAP_TO_MASK(CAP_SYS_PTRACE), ~0 }})
 # define CAP_FS_SET       ((kernel_cap_t){{ CAP_FS_MASK_B0 \
 				    | CAP_TO_MASK(CAP_LINUX_IMMUTABLE), \
 				    CAP_FS_MASK_B1 } })
diff -Naur kernel-3.3-3.0a-ref/include/linux/genid_driver.h kernel-current/include/linux/genid_driver.h
--- kernel-3.3-3.0a-ref/include/linux/genid_driver.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/include/linux/genid_driver.h	2015-06-12 16:27:19.932074066 +0200
@@ -0,0 +1,24 @@
+
+#ifndef GENID_DRIVER_H
+#define GENID_DRIVER_H
+
+#include <linux/ioctl.h>
+
+/***********************************************************************************************
+ *
+ *  Define
+ *
+ ***********************************************************************************************/
+#define DEVICE_NAME "GENID_DRIVER"
+/***********************************************************************************************
+ *
+ *  Ioctl
+ *
+ ***********************************************************************************************/
+#define GENID_DRIVER_IOR_MAGIC 'z'
+
+#define GENID_GETID           _IO(GENID_DRIVER_IOR_MAGIC, 1)
+
+
+#endif /* GENID_DRIVER_H */
+
diff -Naur kernel-3.3-3.0a-ref/include/linux/if_link.h kernel-current/include/linux/if_link.h
--- kernel-3.3-3.0a-ref/include/linux/if_link.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/if_link.h	2015-06-12 16:27:19.968092064 +0200
@@ -15,6 +15,17 @@
 	__u32	rx_dropped;		/* no space in linux buffers	*/
 	__u32	tx_dropped;		/* no space available in linux	*/
 	__u32	multicast;		/* multicast packets received	*/
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	__u32   rx_multicast_packets;  /* multicast packets received */
+	__u32   tx_multicast_packets;  /* multicast packets transmitted */
+	__u32   rx_multicast_bytes;  /* multicast bytes received */ 
+	__u32   tx_multicast_bytes;  /* multicast bytes transmitted */
+	__u32   rx_broadcast_packets;  /* broadcast packets received */
+	__u32   tx_broadcast_packets;  /* broadcast packets transmitted */
+	/* NOTE: Unicast packets are not counted but are instead calculated as needed
+	using total - (broadcast + multicast) */
+	__u32   rx_unknown_packets;  /* unknown protocol packets received */
+#endif
 	__u32	collisions;
 
 	/* detailed rx_errors: */
@@ -48,6 +59,17 @@
 	__u64	rx_dropped;		/* no space in linux buffers	*/
 	__u64	tx_dropped;		/* no space available in linux	*/
 	__u64	multicast;		/* multicast packets received	*/
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	__u64   rx_multicast_packets;  /* multicast packets received */
+	__u64   tx_multicast_packets;  /* multicast packets transmitted */
+	__u64   rx_multicast_bytes;  /* multicast bytes received */
+	__u64   tx_multicast_bytes;  /* multicast bytes transmitted */
+	__u64   rx_broadcast_packets;  /* broadcast packets received */
+	__u64   tx_broadcast_packets;  /* broadcast packets transmitted */
+	/* NOTE: Unicast packets are not counted but are instead calculated as needed
+	using total - (broadcast + multicast) */
+	__u64   rx_unknown_packets;  /* unknown protocol packets received */
+#endif
 	__u64	collisions;
 
 	/* detailed rx_errors: */
diff -Naur kernel-3.3-3.0a-ref/include/linux/Kbuild kernel-current/include/linux/Kbuild
--- kernel-3.3-3.0a-ref/include/linux/Kbuild	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/Kbuild	2015-06-12 16:27:19.968092064 +0200
@@ -142,6 +142,7 @@
 header-y += gen_stats.h
 header-y += generic_serial.h
 header-y += genetlink.h
+header-y += genid_driver.h
 header-y += gfs2_ondisk.h
 header-y += gigaset_dev.h
 header-y += hdlc.h
@@ -224,11 +225,14 @@
 header-y += jffs2.h
 header-y += joystick.h
 header-y += kd.h
+header-y += kdev.h
 header-y += kdev_t.h
 header-y += kernel.h
 header-y += kernelcapi.h
 header-y += keyboard.h
 header-y += keyctl.h
+header-y += kstorman.h
+header-y += kextstats.h
 header-y += l2tp.h
 header-y += limits.h
 header-y += llc.h
@@ -403,3 +407,4 @@
 header-y += x25.h
 header-y += xattr.h
 header-y += xfrm.h
+header-y += sysinfo.h
diff -Naur kernel-3.3-3.0a-ref/include/linux/kdev.h kernel-current/include/linux/kdev.h
--- kernel-3.3-3.0a-ref/include/linux/kdev.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/include/linux/kdev.h	2015-06-12 16:27:19.952084065 +0200
@@ -0,0 +1,61 @@
+/*
+ *  kdev.h
+ *
+ *  This file contains the implementation of the device 
+ *  interface module with the user space.
+ *
+ *  Created by Pace on 05/09/13.
+ *
+ */
+
+#ifndef KDEV_H
+#define KDEV_H
+
+#include <linux/ioctl.h>
+#include <linux/types.h>
+
+/***********************************************************************************************
+ *
+ *  Structures
+ *
+ ***********************************************************************************************/
+#define KDEV_DEVLIST_MAXSIZE 100
+#define KDEV_STR_MAXSIZE 64
+
+/*
+ *  data for devices list
+ */
+typedef enum
+{
+  KDEV_CHAR_DEV = 0,
+  KDEV_BLOCK_DEV
+} e_kdev_type_t;
+
+typedef struct
+{
+  e_kdev_type_t device_type;
+  char device_name[KDEV_STR_MAXSIZE + 1];
+  int major;
+  int min_minor;
+  int max_minor;
+} kdev_dev_t;
+
+typedef struct
+{
+  size_t devs_nb;
+  kdev_dev_t devs[KDEV_DEVLIST_MAXSIZE];
+} kdev_ioc_getDevices_t;
+
+/***********************************************************************************************
+ *
+ *  Ioctl
+ *
+ ***********************************************************************************************/
+#define KDEV_IOC_MAGIC 'y'
+
+#define KDEV_IOC_GET_ALL_DEVICES    _IOR(KDEV_IOC_MAGIC, 1, char *)
+
+#define KDEV_IOC_MAXNR 1
+
+
+#endif /* KDEV_H */
diff -Naur kernel-3.3-3.0a-ref/include/linux/kextstats.h kernel-current/include/linux/kextstats.h
--- kernel-3.3-3.0a-ref/include/linux/kextstats.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/include/linux/kextstats.h	2015-06-12 16:27:19.968092064 +0200
@@ -0,0 +1,48 @@
+/*
+ *  kextstats.h
+ *
+ *  This file contains the implementation of the extstats
+ *  interface module with the user space.
+ *
+ *  Created by Pace on 13/03/14.
+ *
+ */
+
+#ifndef KEXTSTATS_H
+#define KEXTSTATS_H
+
+#include <linux/ioctl.h>
+#include <linux/types.h>
+
+/***********************************************************************************************
+ *
+ *  Structures
+ *
+ ***********************************************************************************************/
+#define KEXTSTATS_STATLIST_MAXSIZE  100
+#define KEXTSTATS_STR_MAXSIZE 256
+
+/*
+ *  data for stat list
+ */
+typedef struct
+{
+  char stat[KEXTSTATS_STR_MAXSIZE + 1];
+} kextstats_stats_t;
+
+typedef struct
+{
+  size_t stats_nb;
+  kextstats_stats_t stats[KEXTSTATS_STATLIST_MAXSIZE];
+} kextstats_ioc_getstats_t;
+
+/***********************************************************************************************
+ *
+ *  Ioctl
+ *
+ ***********************************************************************************************/
+#define KEXTSTATS_IOC_MAGIC 'y'
+#define KEXTSTATS_IOC_GETSTATS       _IOR(KEXTSTATS_IOC_MAGIC,		0,  kextstats_ioc_getstats_t*)
+#define KEXTSTATS_IOC_MAXNR 2
+
+#endif /* KEXTSTATS_H */
diff -Naur kernel-3.3-3.0a-ref/include/linux/kstorman.h kernel-current/include/linux/kstorman.h
--- kernel-3.3-3.0a-ref/include/linux/kstorman.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/include/linux/kstorman.h	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1,94 @@
+/*
+ *  kstorman.h
+ *
+ *  This file contains the implementation of the storman 
+ *  interface module with the user space.  
+ *
+ *  Created by Pace on 19/07/13.
+ *
+ */
+
+#ifndef KSTORMAN_H
+#define KSTORMAN_H
+
+#include <linux/ioctl.h>
+#include <linux/types.h>
+
+/***********************************************************************************************
+ *
+ *  Structures
+ *
+ ***********************************************************************************************/
+#define KSTORMAN_MOUNTLIST_MAXSIZE  100
+#define KSTORMAN_BLKDEVLIST_MAXSIZE 100
+#define KSTORMAN_MTDLIST_MAXSIZE    64
+#define KSTORMAN_STR_MAXSIZE 100
+
+/*
+ *  data for mount list
+ */
+typedef struct
+{
+    char device[KSTORMAN_STR_MAXSIZE + 1];
+    char dir[KSTORMAN_STR_MAXSIZE + 1];
+    char type[KSTORMAN_STR_MAXSIZE + 1];
+    int flags;
+} kstorman_mount_t;
+
+typedef struct
+{
+    size_t mounts_nb;
+    kstorman_mount_t mounts[KSTORMAN_MOUNTLIST_MAXSIZE];
+} kstorman_ioc_getmounts_t;
+
+
+/*
+ *  data for block list
+ */
+typedef struct
+{
+    char name[KSTORMAN_STR_MAXSIZE + 1];
+    int major;
+    int minor;
+    char type[KSTORMAN_STR_MAXSIZE + 1];
+    char bus[KSTORMAN_STR_MAXSIZE + 1];
+    char mapped_to[KSTORMAN_STR_MAXSIZE + 1];
+} kstorman_blkdev_t;
+
+typedef struct
+{
+    size_t blkdevs_nb;
+    kstorman_blkdev_t blkdevs[KSTORMAN_BLKDEVLIST_MAXSIZE];
+} kstorman_ioc_getblocks_t;
+
+/*
+ *  data for mtd list
+ */
+typedef struct
+{
+    char name[KSTORMAN_STR_MAXSIZE + 1];
+    int index;
+    unsigned char type;
+} kstorman_mtd_t;
+
+typedef struct
+{
+    size_t mtd_nb;
+    kstorman_mtd_t mtd[KSTORMAN_MTDLIST_MAXSIZE];
+} kstorman_ioc_getmtd_t;
+
+/***********************************************************************************************
+ *
+ *  Ioctl
+ *
+ ***********************************************************************************************/
+#define KSTORMAN_IOC_MAGIC 'y'
+
+#define KSTORMAN_IOC_GETMOUNTS      _IOR(KSTORMAN_IOC_MAGIC,        0,  kstorman_ioc_getmounts_t*)
+#define KSTORMAN_IOC_GETBLOCKS      _IOR(KSTORMAN_IOC_MAGIC,        1,  kstorman_ioc_getblocks_t*)
+#define KSTORMAN_IOC_GETMTD         _IOR(KSTORMAN_IOC_MAGIC,        2,  kstorman_ioc_getmtd_t*)
+
+#define KSTORMAN_IOC_MAXNR 2
+
+
+#endif /* KSTORMAN_H */
diff -Naur kernel-3.3-3.0a-ref/include/linux/lsm_audit.h kernel-current/include/linux/lsm_audit.h
--- kernel-3.3-3.0a-ref/include/linux/lsm_audit.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/lsm_audit.h	2015-06-12 16:27:19.884050067 +0200
@@ -124,6 +124,10 @@
 					u32 denied;
 					uid_t ouid;
 				} fs;
+				struct {
+					int type, protocol;
+					struct sock *sk;
+				} net;
 			};
 		} apparmor_audit_data;
 #endif
diff -Naur kernel-3.3-3.0a-ref/include/linux/mqueue.h kernel-current/include/linux/mqueue.h
--- kernel-3.3-3.0a-ref/include/linux/mqueue.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/mqueue.h	2015-06-12 16:27:19.952084065 +0200
@@ -20,7 +20,7 @@
 
 #define MQ_PRIO_MAX 	32768
 /* per-uid limit of kernel memory used by mqueue, in bytes */
-#define MQ_BYTES_MAX	819200
+#define MQ_BYTES_MAX	1179648
 
 struct mq_attr {
 	long	mq_flags;	/* message queue flags			*/
diff -Naur kernel-3.3-3.0a-ref/include/linux/mtd/nand_flash_mapping.h kernel-current/include/linux/mtd/nand_flash_mapping.h
--- kernel-3.3-3.0a-ref/include/linux/mtd/nand_flash_mapping.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/include/linux/mtd/nand_flash_mapping.h	2015-06-12 16:27:19.916066066 +0200
@@ -0,0 +1,112 @@
+/***********************************************************************
+*       Copyright : PACE plc 2013 (c)
+*                   The copyright of this material is owned by Pace plc.
+*                   This material is regarded as a highly confidential
+*                   trade secret of Pace. It may not be produced, used,
+*                   sold or in any other way exploited or transferred to
+*                   any other third party without prior consent of Pace.
+***********************************************************************/
+
+#ifndef NAND_FLASH_MAPPING_H
+#define NAND_FLASH_MAPPING_H
+
+#define CFG_NAND_AUTO_DETECT_CONFIG 1
+#define CFG_NAND_FLASH_4K_CHIP 1
+
+#define NAND_FLASH_SIZE            (256*1024*1024)
+#define NAND_FLASH_512MB_SIZE      (512*1024*1024)
+#define NAND_FLASH_256MB_BLOCK_SIZE (0x20000)
+#define NAND_FLASH_512MB_BLOCK_SIZE (0x40000)
+
+#define NAND_FLASH_BL_START_ADDRESS        (0)
+
+/* Partition Names */
+#define NAND_FLASH_BL_DAPP_NAME             "dapp"
+#define NAND_FLASH_BL_DCSP_NAME             "dcsp"
+#define NAND_FLASH_BL_URDNL_NAME            "urdnl"
+#define NAND_FLASH_BL_SPARE_NAME            "spare"
+#define NAND_FLASH_LINUX_SCHNG_NAME         "seachange"
+#define NAND_FLASH_LINUX_AXIROS_NAME        "axiros"
+#define NAND_FLASH_LINUX_EPG_NAME           "epg"
+#define NAND_FLASH_LINUX_UI_NAME            "ui"
+#define NAND_FLASH_LINUX_VFS_NAME           "vfs"
+#define NAND_FLASH_LINUX_IRDETO_NAME        "irdeto"
+#define NAND_FLASH_LINUX_APPS_NAME          "apps"
+#define NAND_FLASH_LINUX_BROWSER_NAME       "browser"
+
+
+/* Fixed Partition Sizes */
+#define NAND_FLASH_BL_URDNL_SIZE            (13*1024*1024)  /* 0x00D00000 */
+#define NAND_FLASH_BL_BSECK_AND_UTSBL_SIZE  (1*1024*1024)   /* 0x00100000 */
+#define NAND_FLASH_LINUX_VFS_SIZE           (4*1024*1024)   /* 0x00400000 */
+
+#define NAND_FLASH_BL_URDNL_512MB_SIZE            NAND_FLASH_BL_URDNL_SIZE
+#define NAND_FLASH_BL_BSECK_AND_UTSBL_512MB_SIZE  NAND_FLASH_BL_BSECK_AND_UTSBL_SIZE
+#define NAND_FLASH_LINUX_VFS_512MB_SIZE           NAND_FLASH_LINUX_VFS_SIZE
+
+
+/* 512MB Configuration */
+#define NAND_FLASH_BL_DAPP_512MB_SIZE        (90*1024*1024)  /* 0x05A00000 */
+#define NAND_FLASH_BL_SPARE_512MB_SIZE       (21*1024*1024)  /* 0x01500000 */
+#define NAND_FLASH_BL_DCSP_512MB_SIZE        (NAND_FLASH_BL_DAPP_512MB_SIZE + NAND_FLASH_BL_URDNL_512MB_SIZE + NAND_FLASH_BL_BSECK_AND_UTSBL_512MB_SIZE)
+#define NAND_FLASH_BL_USED_512MB_SIZE        (NAND_FLASH_BL_DAPP_512MB_SIZE + NAND_FLASH_BL_URDNL_512MB_SIZE + NAND_FLASH_BL_DCSP_512MB_SIZE)
+#define NAND_FLASH_BL_TOTAL_512MB_SIZE       (NAND_FLASH_BL_USED_512MB_SIZE + NAND_FLASH_BL_SPARE_512MB_SIZE)
+#define NAND_FLASH_LINUX_SCHNG_512MB_SIZE    (4*1024*1024)   /* 0x00400000 */
+#define NAND_FLASH_LINUX_AXIROS_512MB_SIZE   (2*1024*1024)   /* 0x00100000 */
+#define NAND_FLASH_LINUX_EPG_512MB_SIZE      (100*1024*1024) /* 0x06400000 */
+#define NAND_FLASH_LINUX_IRDETO_512MB_SIZE   (5*1024*1024)   /* 0x00500000 */
+#define NAND_FLASH_LINUX_UI_512MB_SIZE       (40*1024*1024)  /* 0x02800000 */
+#define NAND_FLASH_LINUX_APPS_512MB_SIZE     (100*1024*1024) /* 0x06400000 */
+#define NAND_FLASH_LINUX_512MB_SIZE          (NAND_FLASH_LINUX_SCHNG_512MB_SIZE + NAND_FLASH_LINUX_AXIROS_512MB_SIZE + NAND_FLASH_LINUX_EPG_512MB_SIZE + NAND_FLASH_LINUX_IRDETO_512MB_SIZE + NAND_FLASH_LINUX_UI_512MB_SIZE + NAND_FLASH_LINUX_APPS_512MB_SIZE + NAND_FLASH_LINUX_VFS_512MB_SIZE)
+#define NAND_FLASH_LINUX_UNUSED_512MB_SIZE   (NAND_FLASH_512MB_SIZE - NAND_FLASH_BL_TOTAL_512MB_SIZE - NAND_FLASH_LINUX_512MB_SIZE)
+
+/* 256MB Configuration */
+#define NAND_FLASH_BL_DAPP_SIZE             (60*1024*1024)  /* 0x03C00000 */
+#define NAND_FLASH_BL_DCSP_SIZE            (NAND_FLASH_BL_DAPP_SIZE + NAND_FLASH_BL_URDNL_SIZE + NAND_FLASH_BL_BSECK_AND_UTSBL_SIZE)
+#define NAND_FLASH_BL_USED_SIZE            (NAND_FLASH_BL_DAPP_SIZE + NAND_FLASH_BL_URDNL_SIZE + NAND_FLASH_BL_DCSP_SIZE)
+#define NAND_FLASH_BL_SPARE_SIZE           (NAND_FLASH_BL_USED_SIZE/4)    /* 25% of used area */
+#define NAND_FLASH_BL_TOTAL_SIZE           (NAND_FLASH_BL_USED_SIZE + NAND_FLASH_BL_SPARE_SIZE)
+#define NAND_FLASH_LINUX_AXIROS_SIZE        (1*1024*1024)   /* 0x00100000 */
+#define NAND_FLASH_LINUX_EPG_SIZE           (30*1024*1024)  /* 0x01E00000 */
+#define NAND_FLASH_LINUX_IRDETO_SIZE        (NAND_FLASH_LINUX_EPG_SIZE)  /* 0x01E00000 */
+#define NAND_FLASH_LINUX_UI_SIZE            (30*1024*1024)  /* 0x01E00000 */
+#define NAND_FLASH_LINUX_BROWSER_SIZE       (5*1024*1024)   /* 0x00500000 */
+#define NAND_FLASH_LINUX_SCHNG_SIZE        (NAND_FLASH_SIZE - NAND_FLASH_BL_TOTAL_SIZE - NAND_FLASH_LINUX_AXIROS_SIZE - NAND_FLASH_LINUX_EPG_SIZE - NAND_FLASH_LINUX_UI_SIZE - NAND_FLASH_LINUX_BROWSER_SIZE - NAND_FLASH_LINUX_VFS_SIZE)
+
+/* Addresses: Pace Boot Loader area */
+/* 512MB Configuration */
+#define NAND_FLASH_BL_DAPP_512MB_ADDRESS         (NAND_FLASH_BL_START_ADDRESS)
+#define NAND_FLASH_BL_DCSP_512MB_ADDRESS         (NAND_FLASH_BL_DAPP_512MB_ADDRESS + NAND_FLASH_BL_DAPP_512MB_SIZE)
+#define NAND_FLASH_BL_URDNL_512MB_ADDRESS        (NAND_FLASH_BL_DCSP_512MB_ADDRESS + NAND_FLASH_BL_DCSP_512MB_SIZE)
+#define NAND_FLASH_BL_SPARE_512MB_ADDRESS        (NAND_FLASH_BL_URDNL_512MB_ADDRESS + NAND_FLASH_BL_URDNL_512MB_SIZE)
+
+
+/* 256MB Configurationn */
+#define NAND_FLASH_BL_DAPP_ADDRESS         (NAND_FLASH_BL_START_ADDRESS)
+#define NAND_FLASH_BL_DCSP_ADDRESS         (NAND_FLASH_BL_DAPP_ADDRESS + NAND_FLASH_BL_DAPP_SIZE)
+#define NAND_FLASH_BL_URDNL_ADDRESS        (NAND_FLASH_BL_DCSP_ADDRESS + NAND_FLASH_BL_DCSP_SIZE)
+#define NAND_FLASH_BL_SPARE_ADDRESS        (NAND_FLASH_BL_URDNL_ADDRESS + NAND_FLASH_BL_URDNL_SIZE)
+
+/* Addresses: Linux (application) area */
+
+/* 512MB Configuration */
+#define NAND_FLASH_LINUX_START_512MB_ADDRESS     (NAND_FLASH_BL_SPARE_512MB_ADDRESS + NAND_FLASH_BL_SPARE_512MB_SIZE)
+#define NAND_FLASH_LINUX_SCHNG_512MB_ADDRESS     (NAND_FLASH_LINUX_START_512MB_ADDRESS)
+#define NAND_FLASH_LINUX_AXIROS_512MB_ADDRESS    (NAND_FLASH_LINUX_SCHNG_512MB_ADDRESS + NAND_FLASH_LINUX_SCHNG_512MB_SIZE)
+#define NAND_FLASH_LINUX_EPG_512MB_ADDRESS       (NAND_FLASH_LINUX_AXIROS_512MB_ADDRESS + NAND_FLASH_LINUX_AXIROS_512MB_SIZE)
+#define NAND_FLASH_LINUX_UI_512MB_ADDRESS        (NAND_FLASH_LINUX_EPG_512MB_ADDRESS + NAND_FLASH_LINUX_EPG_512MB_SIZE)
+#define NAND_FLASH_LINUX_APPS_512MB_ADDRESS      (NAND_FLASH_LINUX_UI_512MB_ADDRESS + NAND_FLASH_LINUX_UI_512MB_SIZE)
+#define NAND_FLASH_LINUX_VFS_512MB_ADDRESS       (NAND_FLASH_LINUX_APPS_512MB_ADDRESS + NAND_FLASH_LINUX_APPS_512MB_SIZE)
+#define NAND_FLASH_LINUX_IRDETO_512MB_ADDRESS    (NAND_FLASH_LINUX_VFS_512MB_ADDRESS + NAND_FLASH_LINUX_VFS_512MB_SIZE)
+
+/* 256MB Configuration */
+#define NAND_FLASH_LINUX_START_ADDRESS     (NAND_FLASH_BL_SPARE_ADDRESS + NAND_FLASH_BL_SPARE_SIZE)
+#define NAND_FLASH_LINUX_SCHNG_ADDRESS     (NAND_FLASH_LINUX_START_ADDRESS)
+#define NAND_FLASH_LINUX_AXIROS_ADDRESS    (NAND_FLASH_LINUX_SCHNG_ADDRESS + NAND_FLASH_LINUX_SCHNG_SIZE)
+#define NAND_FLASH_LINUX_EPG_ADDRESS       (NAND_FLASH_LINUX_AXIROS_ADDRESS + NAND_FLASH_LINUX_AXIROS_SIZE)
+#define NAND_FLASH_LINUX_UI_ADDRESS        (NAND_FLASH_LINUX_EPG_ADDRESS + NAND_FLASH_LINUX_EPG_SIZE)
+#define NAND_FLASH_LINUX_BROWSER_ADDRESS   (NAND_FLASH_LINUX_UI_ADDRESS + NAND_FLASH_LINUX_UI_SIZE)
+#define NAND_FLASH_LINUX_VFS_ADDRESS       (NAND_FLASH_LINUX_BROWSER_ADDRESS + NAND_FLASH_LINUX_BROWSER_SIZE)
+#define NAND_FLASH_LINUX_IRDETO_ADDRESS    (NAND_FLASH_LINUX_EPG_ADDRESS)
+
+#endif /* NAND_FLASH_MAPPING_H */
diff -Naur kernel-3.3-3.0a-ref/include/linux/mtd/nor_flash_mapping.h kernel-current/include/linux/mtd/nor_flash_mapping.h
--- kernel-3.3-3.0a-ref/include/linux/mtd/nor_flash_mapping.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/include/linux/mtd/nor_flash_mapping.h	2015-06-12 16:27:19.916066066 +0200
@@ -0,0 +1,43 @@
+/***********************************************************************
+*       Copyright : PACE plc 2013 (c)
+*                   The copyright of this material is owned by Pace plc.
+*                   This material is regarded as a highly confidential
+*                   trade secret of Pace. It may not be produced, used,
+*                   sold or in any other way exploited or transferred to
+*                   any other third party without prior consent of Pace.
+***********************************************************************/
+
+#ifndef NOR_FLASH_MAPPING_H
+#define NOR_FLASH_MAPPING_H
+
+/* Partition Names */
+#define NOR_FLASH_FTSBL_NAME               "ftsbl"
+#define NOR_FLASH_FRDNL_NAME               "frdnl"
+#define NOR_FLASH_SDIF_NAME                "sdif"
+#define NOR_FLASH_UTSBL_NAME               "utsbl"
+#define NOR_FLASH_TBX_NAME                 "tbx"
+#define NOR_FLASH_OSY_NAME                 "osy"
+#define NOR_FLASH_FUT_NAME                 "fut"
+#define NOR_FLASH_BSECK_RELOAD_NAME        "bseckReload"
+
+/* Fixed Partition Sizes */
+#define NOR_FLASH_FTSBL_SIZE               0x0003FEF0
+#define NOR_FLASH_FRDNL_SIZE               0x00220000
+#define NOR_FLASH_SDIF_SIZE                0x00010000
+#define NOR_FLASH_UTSBL_SIZE               0x000A0000
+#define NOR_FLASH_TBX_SIZE                 0x00010000
+#define NOR_FLASH_OSY_SIZE                 0x00020000
+#define NOR_FLASH_FUT_SIZE                 0x00010000
+#define NOR_FLASH_BSECK_RELOAD_SIZE        0x00020000
+
+/* Addresses (offsets) */
+#define NOR_FLASH_FTSBL_ADDRESS            0x00060000
+#define NOR_FLASH_FRDNL_ADDRESS            0x000C0000
+#define NOR_FLASH_SDIF_ADDRESS             0x000B0000
+#define NOR_FLASH_UTSBL_ADDRESS            0x002E0000
+#define NOR_FLASH_TBX_ADDRESS              0x00380000
+#define NOR_FLASH_OSY_ADDRESS              0x00390000
+#define NOR_FLASH_FUT_ADDRESS              0x003D0000
+#define NOR_FLASH_BSECK_RELOAD_ADDRESS     0x003E0000
+
+#endif
diff -Naur kernel-3.3-3.0a-ref/include/linux/mtd/pacenand.h kernel-current/include/linux/mtd/pacenand.h
--- kernel-3.3-3.0a-ref/include/linux/mtd/pacenand.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/include/linux/mtd/pacenand.h	2015-06-12 16:27:19.920068066 +0200
@@ -0,0 +1,226 @@
+/****************************************************************************
+ *                                                                          *
+ * File        : nand_dev_new.h                                             *
+ *                                                                          *
+ * Description : Low level read/write functions for NAND flash using the    *
+ *               NEW Broadcom NAND flash controller                         *
+ *                                                                          *
+ * Author      : Neil Crossley (crossln1)/Sumil Patel                       *
+ *                                                                          *
+ * Copyright   : Pace Micro Technology 2007 (c)                             *
+ *                                                                          *
+ *               The copyright in this material is owned by                 *
+ *               Pace Microtechnology PLC ("Pace"). This                    *
+ *               material is regarded as a highly confidential              *
+ *               trade secret of Pace. It may not be reproduced,            *
+ *               used, sold or in any other way exploited or                *
+ *               transferred to any third party without the prior           *
+ *               written permission of Pace.                                *
+ *                                                                          *
+ * Notes       : Thanks to Simon Hemming for the previous driver (and also  *
+ *               figuring out how the hardware works) as well as John Smith *
+ *               for additional help                                        *
+ *                                                                          *
+ * History     : Initial Version by Neil                                    *
+ *             : Updated by Sumil for 4K Page Chip Support                  *
+ *                                                                          *
+ *                                                                          *
+ ****************************************************************************/
+
+/*******************************
+ * Disallow multiple including *
+ ******************************/
+
+#ifndef __NAND_DEV_NEW_INCLUDED__
+#define __NAND_DEV_NEW_INCLUDED__
+
+
+/***********
+ * Defines *
+ ***********/
+
+/* ECC Types */
+
+#define NDR_ECC_TYPE_HAMMING  0
+#define NDR_ECC_TYPE_BCH4     1
+#define NDR_ECC_TYPE_BCH8     2
+#define NDR_ECC_TYPE_BCH12    3
+
+/* ECC Type and Spare area layout */
+
+#define NDR_LAYOUT_HAMMING_16B_SPARE 0
+#define NDR_LAYOUT_BCH4_16B_SPARE    1
+#define NDR_LAYOUT_BCH8_27B_SPARE    2
+#define NDR_LAYOUT_BCH8_32B_SPARE    3
+#define NDR_LAYOUT_BCH12_27B_SPARE   4
+#define NDR_LAYOUT_BCH12_32B_SPARE   5
+#define NDR_LAYOUT_BCH12_28B_SPARE   6
+
+/* Flags for read/write */
+
+#define NDR_FLAGS_VERIFY            1
+#define NDR_FLAGS_CRC               2
+#define NDR_FLAGS_USEDMARKER        4
+#define NDR_FLAGS_LONGREADWRITE     0x100 /* Obsolete */
+#define NDR_FLAGS_SYNCSPAREONWRITE  0x200
+#define NDR_FLAGS_CACHEBLOCKWRITE   0x400
+
+
+/*************
+ * DataTypes *
+ *************/
+
+#ifndef __BLI_TYPES_DEFINED__
+#define __BLI_TYPES_DEFINED__
+#define BLI_INT8    int8_t
+#define BLI_UINT8   uint8_t
+#define BLI_INT16   int16_t
+#define BLI_UINT16  uint16_t
+#define BLI_INT32   int32_t
+#define BLI_UINT32  uint32_t
+#define BLI_INT64   int64_t
+#define BLI_UINT64  uint64_t
+#define BLI_VOID    void
+#define BLI_BOOL    uint32_t
+#define TRUE        true
+#define FALSE       false
+#endif
+
+
+/**************
+ * Structures *
+ **************/
+
+/* Device information structure, returned by nand_get_info
+
+   Device_ID is as follows ...
+
+    Byte 0 = Manufacturer code
+    Byte 1 = Device code
+    Byte 2 = May be used on some devices for extended device info
+    Byte 3 = as above                                              */
+
+typedef struct
+{
+  BLI_UINT8   Device_ID[4];               /* See Notes Above                                          */
+  BLI_UINT64  Device_Size;                /* Device size in bytes                                     */
+  BLI_UINT32  Block_Size;                 /* Block size in bytes                                      */
+  BLI_UINT32  Block_Count;                /* Number of blocks on device                               */
+  BLI_UINT32  Page_Size;                  /* Page size in bytes                                       */
+  BLI_UINT32  Spare_Size;     	 	   /* Original Spare Area Size of chip                         */
+  BLI_UINT32  Page_Count;                 /* Number of pages on device                                */
+  BLI_UINT32  Virt_Page_Size;             /* Virtual page size in bytes                               */
+  BLI_UINT32  Virt_Page_Count;            /* Number of virtual pages on device                        */
+  BLI_UINT32  Pages_Per_Block;            /* Number of pages per block                                */
+  BLI_UINT32  Virt_Pages_Per_Page;        /* Number of virtual pages per page                         */
+  BLI_UINT32  Virt_Pages_Per_Block;       /* Number of virtual pages per block                        */
+  BLI_UINT32  ECC_Spare_Area_Layout;      /* ECC Type + spare area layout                             */
+  BLI_UINT32  ECC_Type;                   /* Type of ECC used                                         */
+  BLI_UINT32  ECC_Bits;                   /* Number of bits ECC can handle                            */
+  BLI_BOOL    ECC_Enabled;                /* ECC Enabled readback                                     */
+  BLI_UINT32  Spare_Area_Size;            /* Size of the spare area                                   */
+  BLI_UINT32  Spare_Area_Free;            /* Number of free bytes in spare area                       */
+  BLI_UINT32  Spare_Area_ECC_Bytes;       /* Number of bytes used to store ECC data                   */
+  BLI_UINT8   Spare_Area_Bytes[256];      /* Spare area free bytes                                    */
+  BLI_UINT8   Spare_Area_ECC_bytes[256];  /* Spare area ECC byte positions                            */
+} NAND_DEV_INFO;
+
+
+/***************
+ * Return Codes *
+ ***************/
+
+typedef enum _tag_NDR_ERROR
+{
+  /* Success */
+
+  NDR_SUCCESS                   = 0,
+
+  /* Return codes from ...
+
+     nand_dev_read_block
+     nand_dev_read_page
+     nand_dev_copy_block  */
+
+  NDR_CORRECTABLE_ERROR         = 1,
+  NDR_UNCORRECTABLE_ERROR       = 2,
+
+  /* Return codes from nand_dev_is_block_bad */
+
+  NDR_BLOCK_IS_GOOD             = 0,
+  NDR_BLOCK_IS_BAD              = 1,
+
+  /* Return codes from nand_dev_is_vpage_used */
+
+  NDR_VPAGE_NOT_USED            = 0,
+  NDR_VPAGE_IS_USED             = 1,
+  NDR_VPAGE_IS_DEACTIVATED      = 2,
+
+  /* Return codes from ...
+
+     nand_dev_is_block_erased
+     nand_dev_is_page_erased   */
+
+  NDR_NOT_ERASED                = 0,
+  NDR_IS_ERASED                 = 1,
+
+  /* Negative error code - Always Fatal */
+
+  NDR_NOT_INITIALISED           = -1,
+  NDR_ALREADY_INITIALISED       = -2,
+  NDR_UNSUPPORTED_FUNCTION      = -3,
+  NDR_UNSUPPORTED_DEVICE        = -4,
+  NDR_ILLEGAL_BLOCK_OR_PAGE     = -5,
+  NDR_ERROR_COPY_TO_SAME_BLOCK  = -6,
+  NDR_ILLEGAL_OFFSET            = -7,
+  NDR_ILLEGAL_LENGTH            = -8,
+  NDR_CANT_CROSS_BOUNDARY       = -9,
+  NDR_DEVICE_NOT_READY          = -10,
+  NDR_DEVICE_PROGRAM_ERROR      = -11,
+  NDR_DEVICE_ECC_ERROR          = -12,
+  NDR_DEVICE_VERIFY_ERROR       = -13,
+  NDR_DEVICE_ERASE_ERROR        = -14,
+  NDR_WRITE_PROTECTED           = -15,
+  NDR_NO_NAND_PRESENT           = -16,
+  NDR_FATAL_ERROR               = -17,
+  NDR_SYS_ERROR                 = -18,
+  NDR_ILLEGAL_PARAMETER         = -19,
+} NDR_ERROR;
+
+
+/**************
+ * Prototypes *
+ **************/
+
+extern NDR_ERROR  nand_dev_init(BLI_VOID);
+extern NDR_ERROR  nand_dev_shutdown(BLI_VOID);
+extern NDR_ERROR  nand_dev_get_info(NAND_DEV_INFO **info);
+extern NDR_ERROR  nand_dev_enable_ecc(BLI_BOOL enable);
+extern NDR_ERROR  nand_dev_enable_crc(BLI_BOOL enable);
+extern NDR_ERROR  nand_dev_read_block(BLI_UINT32 block, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_read_page(BLI_UINT32 page, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_read_vpage(BLI_UINT32 vpage, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_read_anywhere(BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_read_anywhere_raw(BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_write_block(BLI_UINT32 block, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_write_page(BLI_UINT32 page, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_write_vpage(BLI_UINT32 vpage, BLI_VOID *data, BLI_UINT32 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_write_anywhere(BLI_VOID *data, BLI_UINT64 offset, BLI_UINT32 length, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_erase_block(BLI_UINT32 block);
+extern NDR_ERROR  nand_dev_copy_block(BLI_UINT32 destblock, BLI_UINT32 sourceblock, BLI_UINT32 vpignore, BLI_UINT32 flags);
+extern NDR_ERROR  nand_dev_is_vpage_used(BLI_UINT32 vpage);
+extern NDR_ERROR  nand_dev_read_spare(BLI_UINT32 vpage, BLI_VOID* data);
+extern NDR_ERROR  nand_dev_write_spare(BLI_UINT32 vpage, BLI_VOID* data);
+extern NDR_ERROR  nand_dev_is_block_erased(BLI_UINT32 block);
+extern NDR_ERROR  nand_dev_is_page_erased(BLI_UINT32 page);
+extern NDR_ERROR  nand_dev_is_vpage_erased(BLI_UINT32 vpage);
+extern NDR_ERROR  nand_dev_is_block_bad(BLI_UINT32 block);
+extern NDR_ERROR  nand_dev_mark_block_bad(BLI_UINT32 block);
+extern BLI_UINT32 nand_dev_calc_crc32(BLI_VOID* data, BLI_UINT32 crc, BLI_UINT32 count);
+
+
+/**************
+ * Endifs etc *
+ **************/
+
+#endif /*#ifndef __NAND_DEV_NEW_INCLUDED__*/
diff -Naur kernel-3.3-3.0a-ref/include/linux/netdev_features.h kernel-current/include/linux/netdev_features.h
--- kernel-3.3-3.0a-ref/include/linux/netdev_features.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/netdev_features.h	2015-06-12 16:27:19.968092064 +0200
@@ -55,6 +55,10 @@
 	NETIF_F_NOCACHE_COPY_BIT,	/* Use no-cache copyfromuser */
 	NETIF_F_LOOPBACK_BIT,		/* Enable loopback */
 
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	NETIF_F_EXTSTATS_BIT,		/* Support extended statistics */
+#endif
+
 	/*
 	 * Add your fresh new feature above and remember to update
 	 * netdev_features_strings[] in net/core/ethtool.c and maybe
@@ -99,6 +103,10 @@
 #define NETIF_F_UFO		__NETIF_F(UFO)
 #define NETIF_F_VLAN_CHALLENGED	__NETIF_F(VLAN_CHALLENGED)
 
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+#define NETIF_F_EXTSTATS	__NETIF_F(EXTSTATS)
+#endif
+
 /* Features valid for ethtool to change */
 /* = all defined minus driver/device-class-related */
 #define NETIF_F_NEVER_CHANGE	(NETIF_F_VLAN_CHALLENGED | \
diff -Naur kernel-3.3-3.0a-ref/include/linux/netdevice.h kernel-current/include/linux/netdevice.h
--- kernel-3.3-3.0a-ref/include/linux/netdevice.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/netdevice.h	2015-06-12 16:27:19.972094064 +0200
@@ -178,6 +178,19 @@
 	unsigned long	rx_dropped;
 	unsigned long	tx_dropped;
 	unsigned long	multicast;
+
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+    unsigned long   rx_multicast_packets;  /* multicast packets received */
+    unsigned long   tx_multicast_packets;  /* multicast packets transmitted */
+    unsigned long   rx_multicast_bytes;  /* multicast bytes received */ 
+    unsigned long   tx_multicast_bytes;  /* multicast bytes transmitted */
+    unsigned long   rx_broadcast_packets;  /* broadcast packets received */
+    unsigned long   tx_broadcast_packets;  /* broadcast packets transmitted */
+    /* NOTE: Unicast packets are not counted but are instead calculated as needed
+       using total - (broadcast + multicast) */
+    unsigned long   rx_unknown_packets;  /* unknown protocol packets received */
+#endif
+
 	unsigned long	collisions;
 	unsigned long	rx_length_errors;
 	unsigned long	rx_over_errors;
diff -Naur kernel-3.3-3.0a-ref/include/linux/sockios.h kernel-current/include/linux/sockios.h
--- kernel-3.3-3.0a-ref/include/linux/sockios.h	2013-08-28 01:31:06.000000000 +0200
+++ kernel-current/include/linux/sockios.h	2015-06-12 16:27:19.912064066 +0200
@@ -139,6 +139,8 @@
  */
  
 #define SIOCDEVPRIVATE	0x89F0	/* to 89FF */
+#define SIOCSAR8035WOLENABLE                 (SIOCDEVPRIVATE + 9)
+#define SIOCSAR8035WOLDISABLE                (SIOCDEVPRIVATE + 15)
 
 /*
  *	These 16 ioctl calls are protocol private
diff -Naur kernel-3.3-3.0a-ref/include/linux/sysinfo.h kernel-current/include/linux/sysinfo.h
--- kernel-3.3-3.0a-ref/include/linux/sysinfo.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/include/linux/sysinfo.h	2015-06-12 16:27:19.948082065 +0200
@@ -0,0 +1,94 @@
+/*
+ *  sysinfo.h
+ *
+ *  This file contains the implementation of the AON read/writer
+ *  interface module with the user space.
+ *
+ *  Created by Samir MOUHOUNE on 25/06/2013.
+ *  Copyright 2013 Pace plc. All rights reserved.
+ *
+ *  The copyright in this material is owned by Pace
+ *  plc ("Pace"). This material is regarded as a
+ *  highly confidential trade secret of Pace. It may not be
+ *  reproduced, used, sold or in any other way exploited or
+ *  transferred to any third party without the prior
+ *  written permission of Pace.
+ *
+ */
+
+#ifndef sysinfo_H
+#define sysinfo_H
+
+#include <linux/ioctl.h>
+
+
+/***********************************************************************************************
+ *
+ *  Ioctl
+ *
+ ***********************************************************************************************/
+#define MAX_IOCTL_CMD_NMBR 8
+#define sysinfo_IOC_MAGIC 'q'
+#define GET_NB_PROC _IOR(sysinfo_IOC_MAGIC, 1, unsigned long)
+#define GET_NB_CPU _IOR(sysinfo_IOC_MAGIC, 2, unsigned long)
+#define GET_MEMORY_STATUS _IOR(sysinfo_IOC_MAGIC, 3, unsigned long)
+#define GET_PROCESS_STATUS _IOR(sysinfo_IOC_MAGIC, 4, unsigned long)
+#define GET_PROCESSOR _IOR(sysinfo_IOC_MAGIC, 5, unsigned long)
+#define CPU_REBOOT_CMD _IOR(sysinfo_IOC_MAGIC, 6, unsigned long)
+#define STANDBY_CM_ENABLE _IOR(sysinfo_IOC_MAGIC, 7, unsigned long)
+#define STANDBY_CM_DISABLE _IOR(sysinfo_IOC_MAGIC, 8, unsigned long)
+#define SYSINFO_MAX_PROCESSOR 4
+/**/
+
+typedef struct procInfo
+{
+   int cpu;
+    unsigned long  user;
+    unsigned long  nice;
+    unsigned long  system;
+    unsigned long  idle;
+    unsigned long  iowait;
+    unsigned long  irq;
+    unsigned long  softirq;
+    unsigned long  steal;
+    unsigned long  guest;
+    unsigned long  guest_nice;
+    unsigned long  temperature;
+   int processes;
+   int nbr_running;
+   int nbr_iowait;
+   char arch [10];
+}procInfo;
+
+typedef struct procList
+{
+   int nbcpu;
+   struct procInfo procinfo[SYSINFO_MAX_PROCESSOR];
+}procList;
+
+typedef struct taskInfo
+{
+    char state[10];
+    char comm[50];
+    pid_t pid;
+    int prio;
+    unsigned long vsize;
+    unsigned int CPUTime;
+}taskInfo;
+
+typedef struct taskList
+{
+    unsigned long maxproc;
+    unsigned long nbproc;
+    unsigned long cpuusage;
+    struct taskInfo* taskinfo;
+}taskList;
+
+typedef struct memInfo
+{
+    unsigned long freeram;
+    unsigned long totalram;
+}memInfo;
+
+
+#endif /* sysinfo_H */
diff -Naur kernel-3.3-3.0a-ref/include/linux/usbdevice_fs.h kernel-current/include/linux/usbdevice_fs.h
--- kernel-3.3-3.0a-ref/include/linux/usbdevice_fs.h	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/include/linux/usbdevice_fs.h	2015-06-12 16:27:19.916066066 +0200
@@ -75,6 +75,30 @@
 	unsigned char slow;
 };
 
+#define CONFIG_PACE_TT_USB_COMMANDS 1
+/* RT210911 Pace change */
+#if defined (CONFIG_PACE_TT_USB_COMMANDS)
+typedef enum {
+   TEST_SPEED = 0,
+   TEST_POWER_OFF,
+   TEST_POWER_ON,
+   TEST_PORT_STATUS,
+   TEST_VENDOR_ID,
+   TEST_DEVICE_MS,
+   TEST_DEVICE_CONNECTED,
+   TEST_STRING_SERNUM,
+   TEST_STRING_PROD,
+   TEST_STRING_MANUF,
+   TEST_LAST
+} usb_test_code;
+
+struct usbdevfs_usb_test {
+   int port_num;
+   usb_test_code action;
+   unsigned int response;
+   char * pBuf;
+};
+#endif
 #define USBDEVFS_URB_SHORT_NOT_OK	0x01
 #define USBDEVFS_URB_ISO_ASAP		0x02
 #define USBDEVFS_URB_BULK_CONTINUATION	0x04
@@ -204,4 +228,7 @@
 #define USBDEVFS_CONNECT           _IO('U', 23)
 #define USBDEVFS_CLAIM_PORT        _IOR('U', 24, unsigned int)
 #define USBDEVFS_RELEASE_PORT      _IOR('U', 25, unsigned int)
+#if defined (CONFIG_PACE_TT_USB_COMMANDS)
+   #define USBDEVFS_TEST              _IOWR('U', 26, struct usbdevfs_usb_test)
+#endif //#ifdef TT_USB_SUPPORT
 #endif /* _LINUX_USBDEVICE_FS_H */
diff -Naur kernel-3.3-3.0a-ref/include/mtd/mtd-abi.h kernel-current/include/mtd/mtd-abi.h
--- kernel-3.3-3.0a-ref/include/mtd/mtd-abi.h	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/include/mtd/mtd-abi.h	2015-06-12 16:27:20.016116063 +0200
@@ -103,6 +103,7 @@
 #define MTD_BIT_WRITEABLE	0x800	/* Single bits can be flipped */
 #define MTD_NO_ERASE		0x1000	/* No erase necessary */
 #define MTD_POWERUP_LOCK	0x2000	/* Always locked after reset */
+#define MTD_OOB_WRITEABLE	0x4000	/* Use Out-Of-Band area */
 
 /* Some common devices / combinations of capabilities */
 #define MTD_CAP_ROM		0
@@ -249,6 +250,10 @@
 	__u32 failed;
 	__u32 badblocks;
 	__u32 bbtblocks;
+	__u32 writtenpages;
+	__u32 erasedblocks;
+	__u32 writtenblocks;
+
 };
 
 /*
diff -Naur kernel-3.3-3.0a-ref/include/net/inet_connection_sock.h kernel-current/include/net/inet_connection_sock.h
--- kernel-3.3-3.0a-ref/include/net/inet_connection_sock.h	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/include/net/inet_connection_sock.h	2015-06-12 16:27:19.952084065 +0200
@@ -23,7 +23,8 @@
 #include <net/inet_sock.h>
 #include <net/request_sock.h>
 
-#define INET_CSK_DEBUG 1
+
+//#define INET_CSK_DEBUG 1
 
 /* Cancel timers, when they are not required. */
 #undef INET_CSK_CLEAR_TIMERS
diff -Naur kernel-3.3-3.0a-ref/include/net/tcp.h kernel-current/include/net/tcp.h
--- kernel-3.3-3.0a-ref/include/net/tcp.h	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/include/net/tcp.h	2015-06-12 16:27:19.960088064 +0200
@@ -134,7 +134,7 @@
 					                 * for local resources.
 					                 */
 
-#define TCP_KEEPALIVE_TIME	(120*60*HZ)	/* two hours */
+#define TCP_KEEPALIVE_TIME	(240*HZ)	/* 4 minutes */
 #define TCP_KEEPALIVE_PROBES	9		/* Max of 9 keepalive probes	*/
 #define TCP_KEEPALIVE_INTVL	(75*HZ)
 
diff -Naur kernel-3.3-3.0a-ref/init/initramfs.c kernel-current/init/initramfs.c
--- kernel-3.3-3.0a-ref/init/initramfs.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/init/initramfs.c	2015-06-12 16:27:19.980098064 +0200
@@ -301,7 +301,7 @@
 	clean_path(collected, mode);
 	if (S_ISREG(mode)) {
 		int ml = maybe_link();
-		if (ml >= 0) {
+		/*if (ml >= 0)*/ {
 			int openflags = O_WRONLY|O_CREAT;
 			if (ml != 1)
 				openflags |= O_TRUNC;
@@ -572,6 +572,7 @@
 static int __init populate_rootfs(void)
 {
 	char *err = unpack_to_rootfs(__initramfs_start, __initramfs_size);
+	int error;
 	if (err)
 		panic(err);	/* Failed to decompress INTERNAL initramfs */
 	if (initrd_start) {
@@ -606,6 +607,11 @@
 		free_initrd();
 #endif
 	}
+#ifdef	CONFIG_BLK_DEV_INITRAMFS_RO
+	error = sys_mount("/", "/", NULL, MS_RDONLY | MS_NOSUID | MS_REMOUNT, NULL);
+	if (error)
+			printk(KERN_EMERG "Initramfs issue with remount on RO\n");
+#endif
 	return 0;
 }
 rootfs_initcall(populate_rootfs);
diff -Naur kernel-3.3-3.0a-ref/init/Kconfig kernel-current/init/Kconfig
--- kernel-3.3-3.0a-ref/init/Kconfig	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/init/Kconfig	2015-06-12 16:27:19.992104064 +0200
@@ -946,6 +946,12 @@
 
 source "usr/Kconfig"
 
+config BLK_DEV_INITRAMFS_RO
+	bool "Make Initramfs RO"
+	help
+	  by default initramfs is RW. We can make it RO.
+
+	  If unsure say N.
 endif
 
 config CC_OPTIMIZE_FOR_SIZE
@@ -965,7 +971,6 @@
 menuconfig EXPERT
 	bool "Configure standard kernel features (expert users)"
 	# Unhide debug options, to make the on-by-default options visible
-	select DEBUG_KERNEL
 	help
 	  This option allows certain base kernel options and settings
           to be disabled or tweaked. This is for specialized
@@ -1250,6 +1255,7 @@
 config COMPAT_BRK
 	bool "Disable heap randomization"
 	default y
+	depends on !RANDOMIZE_VA_SPACE
 	help
 	  Randomizing heap placement makes heap exploits harder, but it
 	  also breaks ancient binaries (including anything libc5 based).
diff -Naur kernel-3.3-3.0a-ref/init/Kconfig.orig kernel-current/init/Kconfig.orig
--- kernel-3.3-3.0a-ref/init/Kconfig.orig	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/init/Kconfig.orig	2015-06-12 16:27:19.984100064 +0200
@@ -0,0 +1,1453 @@
+config ARCH
+	string
+	option env="ARCH"
+
+config KERNELVERSION
+	string
+	option env="KERNELVERSION"
+
+config DEFCONFIG_LIST
+	string
+	depends on !UML
+	option defconfig_list
+	default "/lib/modules/$UNAME_RELEASE/.config"
+	default "/etc/kernel-config"
+	default "/boot/config-$UNAME_RELEASE"
+	default "$ARCH_DEFCONFIG"
+	default "arch/$ARCH/defconfig"
+
+config CONSTRUCTORS
+	bool
+	depends on !UML
+
+config HAVE_IRQ_WORK
+	bool
+
+config IRQ_WORK
+	bool
+	depends on HAVE_IRQ_WORK
+
+menu "General setup"
+
+config EXPERIMENTAL
+	bool "Prompt for development and/or incomplete code/drivers"
+	---help---
+	  Some of the various things that Linux supports (such as network
+	  drivers, file systems, network protocols, etc.) can be in a state
+	  of development where the functionality, stability, or the level of
+	  testing is not yet high enough for general use. This is usually
+	  known as the "alpha-test" phase among developers. If a feature is
+	  currently in alpha-test, then the developers usually discourage
+	  uninformed widespread use of this feature by the general public to
+	  avoid "Why doesn't this work?" type mail messages. However, active
+	  testing and use of these systems is welcomed. Just be aware that it
+	  may not meet the normal level of reliability or it may fail to work
+	  in some special cases. Detailed bug reports from people familiar
+	  with the kernel internals are usually welcomed by the developers
+	  (before submitting bug reports, please read the documents
+	  <file:README>, <file:MAINTAINERS>, <file:REPORTING-BUGS>,
+	  <file:Documentation/BUG-HUNTING>, and
+	  <file:Documentation/oops-tracing.txt> in the kernel source).
+
+	  This option will also make obsoleted drivers available. These are
+	  drivers that have been replaced by something else, and/or are
+	  scheduled to be removed in a future kernel release.
+
+	  Unless you intend to help test and develop a feature or driver that
+	  falls into this category, or you have a situation that requires
+	  using these features, you should probably say N here, which will
+	  cause the configurator to present you with fewer choices. If
+	  you say Y here, you will be offered the choice of using features or
+	  drivers that are currently considered to be in the alpha-test phase.
+
+config BROKEN
+	bool
+
+config BROKEN_ON_SMP
+	bool
+	depends on BROKEN || !SMP
+	default y
+
+config INIT_ENV_ARG_LIMIT
+	int
+	default 32 if !UML
+	default 128 if UML
+	help
+	  Maximum of each of the number of arguments and environment
+	  variables passed to init from the kernel command line.
+
+
+config CROSS_COMPILE
+	string "Cross-compiler tool prefix"
+	help
+	  Same as running 'make CROSS_COMPILE=prefix-' but stored for
+	  default make runs in this kernel build directory.  You don't
+	  need to set this unless you want the configured kernel build
+	  directory to select the cross-compiler automatically.
+
+config LOCALVERSION
+	string "Local version - append to kernel release"
+	help
+	  Append an extra string to the end of your kernel version.
+	  This will show up when you type uname, for example.
+	  The string you set here will be appended after the contents of
+	  any files with a filename matching localversion* in your
+	  object and source tree, in that order.  Your total string can
+	  be a maximum of 64 characters.
+
+config LOCALVERSION_AUTO
+	bool "Automatically append version information to the version string"
+	default y
+	help
+	  This will try to automatically determine if the current tree is a
+	  release tree by looking for git tags that belong to the current
+	  top of tree revision.
+
+	  A string of the format -gxxxxxxxx will be added to the localversion
+	  if a git-based tree is found.  The string generated by this will be
+	  appended after any matching localversion* files, and after the value
+	  set in CONFIG_LOCALVERSION.
+
+	  (The actual string used here is the first eight characters produced
+	  by running the command:
+
+	    $ git rev-parse --verify HEAD
+
+	  which is done within the script "scripts/setlocalversion".)
+
+config HAVE_KERNEL_GZIP
+	bool
+
+config HAVE_KERNEL_BZIP2
+	bool
+
+config HAVE_KERNEL_LZMA
+	bool
+
+config HAVE_KERNEL_XZ
+	bool
+
+config HAVE_KERNEL_LZO
+	bool
+
+choice
+	prompt "Kernel compression mode"
+	default KERNEL_GZIP
+	depends on HAVE_KERNEL_GZIP || HAVE_KERNEL_BZIP2 || HAVE_KERNEL_LZMA || HAVE_KERNEL_XZ || HAVE_KERNEL_LZO
+	help
+	  The linux kernel is a kind of self-extracting executable.
+	  Several compression algorithms are available, which differ
+	  in efficiency, compression and decompression speed.
+	  Compression speed is only relevant when building a kernel.
+	  Decompression speed is relevant at each boot.
+
+	  If you have any problems with bzip2 or lzma compressed
+	  kernels, mail me (Alain Knaff) <alain@knaff.lu>. (An older
+	  version of this functionality (bzip2 only), for 2.4, was
+	  supplied by Christian Ludwig)
+
+	  High compression options are mostly useful for users, who
+	  are low on disk space (embedded systems), but for whom ram
+	  size matters less.
+
+	  If in doubt, select 'gzip'
+
+config KERNEL_GZIP
+	bool "Gzip"
+	depends on HAVE_KERNEL_GZIP
+	help
+	  The old and tried gzip compression. It provides a good balance
+	  between compression ratio and decompression speed.
+
+config KERNEL_BZIP2
+	bool "Bzip2"
+	depends on HAVE_KERNEL_BZIP2
+	help
+	  Its compression ratio and speed is intermediate.
+	  Decompression speed is slowest among the three.  The kernel
+	  size is about 10% smaller with bzip2, in comparison to gzip.
+	  Bzip2 uses a large amount of memory. For modern kernels you
+	  will need at least 8MB RAM or more for booting.
+
+config KERNEL_LZMA
+	bool "LZMA"
+	depends on HAVE_KERNEL_LZMA
+	help
+	  The most recent compression algorithm.
+	  Its ratio is best, decompression speed is between the other
+	  two. Compression is slowest.	The kernel size is about 33%
+	  smaller with LZMA in comparison to gzip.
+
+config KERNEL_XZ
+	bool "XZ"
+	depends on HAVE_KERNEL_XZ
+	help
+	  XZ uses the LZMA2 algorithm and instruction set specific
+	  BCJ filters which can improve compression ratio of executable
+	  code. The size of the kernel is about 30% smaller with XZ in
+	  comparison to gzip. On architectures for which there is a BCJ
+	  filter (i386, x86_64, ARM, IA-64, PowerPC, and SPARC), XZ
+	  will create a few percent smaller kernel than plain LZMA.
+
+	  The speed is about the same as with LZMA: The decompression
+	  speed of XZ is better than that of bzip2 but worse than gzip
+	  and LZO. Compression is slow.
+
+config KERNEL_LZO
+	bool "LZO"
+	depends on HAVE_KERNEL_LZO
+	help
+	  Its compression ratio is the poorest among the 4. The kernel
+	  size is about 10% bigger than gzip; however its speed
+	  (both compression and decompression) is the fastest.
+
+endchoice
+
+config DEFAULT_HOSTNAME
+	string "Default hostname"
+	default "(none)"
+	help
+	  This option determines the default system hostname before userspace
+	  calls sethostname(2). The kernel traditionally uses "(none)" here,
+	  but you may wish to use a different default here to make a minimal
+	  system more usable with less configuration.
+
+config SWAP
+	bool "Support for paging of anonymous memory (swap)"
+	depends on MMU && BLOCK
+	default y
+	help
+	  This option allows you to choose whether you want to have support
+	  for so called swap devices or swap files in your kernel that are
+	  used to provide more virtual memory than the actual RAM present
+	  in your computer.  If unsure say Y.
+
+config SYSVIPC
+	bool "System V IPC"
+	---help---
+	  Inter Process Communication is a suite of library functions and
+	  system calls which let processes (running programs) synchronize and
+	  exchange information. It is generally considered to be a good thing,
+	  and some programs won't run unless you say Y here. In particular, if
+	  you want to run the DOS emulator dosemu under Linux (read the
+	  DOSEMU-HOWTO, available from <http://www.tldp.org/docs.html#howto>),
+	  you'll need to say Y here.
+
+	  You can find documentation about IPC with "info ipc" and also in
+	  section 6.4 of the Linux Programmer's Guide, available from
+	  <http://www.tldp.org/guides.html>.
+
+config SYSVIPC_SYSCTL
+	bool
+	depends on SYSVIPC
+	depends on SYSCTL
+	default y
+
+config POSIX_MQUEUE
+	bool "POSIX Message Queues"
+	depends on NET && EXPERIMENTAL
+	---help---
+	  POSIX variant of message queues is a part of IPC. In POSIX message
+	  queues every message has a priority which decides about succession
+	  of receiving it by a process. If you want to compile and run
+	  programs written e.g. for Solaris with use of its POSIX message
+	  queues (functions mq_*) say Y here.
+
+	  POSIX message queues are visible as a filesystem called 'mqueue'
+	  and can be mounted somewhere if you want to do filesystem
+	  operations on message queues.
+
+	  If unsure, say Y.
+
+config POSIX_MQUEUE_SYSCTL
+	bool
+	depends on POSIX_MQUEUE
+	depends on SYSCTL
+	default y
+
+config BSD_PROCESS_ACCT
+	bool "BSD Process Accounting"
+	help
+	  If you say Y here, a user level program will be able to instruct the
+	  kernel (via a special system call) to write process accounting
+	  information to a file: whenever a process exits, information about
+	  that process will be appended to the file by the kernel.  The
+	  information includes things such as creation time, owning user,
+	  command name, memory usage, controlling terminal etc. (the complete
+	  list is in the struct acct in <file:include/linux/acct.h>).  It is
+	  up to the user level program to do useful things with this
+	  information.  This is generally a good idea, so say Y.
+
+config BSD_PROCESS_ACCT_V3
+	bool "BSD Process Accounting version 3 file format"
+	depends on BSD_PROCESS_ACCT
+	default n
+	help
+	  If you say Y here, the process accounting information is written
+	  in a new file format that also logs the process IDs of each
+	  process and it's parent. Note that this file format is incompatible
+	  with previous v0/v1/v2 file formats, so you will need updated tools
+	  for processing it. A preliminary version of these tools is available
+	  at <http://www.gnu.org/software/acct/>.
+
+config FHANDLE
+	bool "open by fhandle syscalls"
+	select EXPORTFS
+	help
+	  If you say Y here, a user level program will be able to map
+	  file names to handle and then later use the handle for
+	  different file system operations. This is useful in implementing
+	  userspace file servers, which now track files using handles instead
+	  of names. The handle would remain the same even if file names
+	  get renamed. Enables open_by_handle_at(2) and name_to_handle_at(2)
+	  syscalls.
+
+config TASKSTATS
+	bool "Export task/process statistics through netlink (EXPERIMENTAL)"
+	depends on NET
+	default n
+	help
+	  Export selected statistics for tasks/processes through the
+	  generic netlink interface. Unlike BSD process accounting, the
+	  statistics are available during the lifetime of tasks/processes as
+	  responses to commands. Like BSD accounting, they are sent to user
+	  space on task exit.
+
+	  Say N if unsure.
+
+config TASK_DELAY_ACCT
+	bool "Enable per-task delay accounting (EXPERIMENTAL)"
+	depends on TASKSTATS
+	help
+	  Collect information on time spent by a task waiting for system
+	  resources like cpu, synchronous block I/O completion and swapping
+	  in pages. Such statistics can help in setting a task's priorities
+	  relative to other tasks for cpu, io, rss limits etc.
+
+	  Say N if unsure.
+
+config TASK_XACCT
+	bool "Enable extended accounting over taskstats (EXPERIMENTAL)"
+	depends on TASKSTATS
+	help
+	  Collect extended task accounting data and send the data
+	  to userland for processing over the taskstats interface.
+
+	  Say N if unsure.
+
+config TASK_IO_ACCOUNTING
+	bool "Enable per-task storage I/O accounting (EXPERIMENTAL)"
+	depends on TASK_XACCT
+	help
+	  Collect information on the number of bytes of storage I/O which this
+	  task has caused.
+
+	  Say N if unsure.
+
+config AUDIT
+	bool "Auditing support"
+	depends on NET
+	help
+	  Enable auditing infrastructure that can be used with another
+	  kernel subsystem, such as SELinux (which requires this for
+	  logging of avc messages output).  Does not do system-call
+	  auditing without CONFIG_AUDITSYSCALL.
+
+config AUDITSYSCALL
+	bool "Enable system-call auditing support"
+	depends on AUDIT && (X86 || PPC || S390 || IA64 || UML || SPARC64 || SUPERH || ARM)
+	default y if SECURITY_SELINUX
+	help
+	  Enable low-overhead system-call auditing infrastructure that
+	  can be used independently or with another kernel subsystem,
+	  such as SELinux.
+
+config AUDIT_WATCH
+	def_bool y
+	depends on AUDITSYSCALL
+	select FSNOTIFY
+
+config AUDIT_TREE
+	def_bool y
+	depends on AUDITSYSCALL
+	select FSNOTIFY
+
+config AUDIT_LOGINUID_IMMUTABLE
+	bool "Make audit loginuid immutable"
+	depends on AUDIT
+	help
+	  The config option toggles if a task setting its loginuid requires
+	  CAP_SYS_AUDITCONTROL or if that task should require no special permissions
+	  but should instead only allow setting its loginuid if it was never
+	  previously set.  On systems which use systemd or a similar central
+	  process to restart login services this should be set to true.  On older
+	  systems in which an admin would typically have to directly stop and
+	  start processes this should be set to false.  Setting this to true allows
+	  one to drop potentially dangerous capabilites from the login tasks,
+	  but may not be backwards compatible with older init systems.
+
+source "kernel/irq/Kconfig"
+
+menu "RCU Subsystem"
+
+choice
+	prompt "RCU Implementation"
+	default TREE_RCU
+
+config TREE_RCU
+	bool "Tree-based hierarchical RCU"
+	depends on !PREEMPT && SMP
+	help
+	  This option selects the RCU implementation that is
+	  designed for very large SMP system with hundreds or
+	  thousands of CPUs.  It also scales down nicely to
+	  smaller systems.
+
+config TREE_PREEMPT_RCU
+	bool "Preemptible tree-based hierarchical RCU"
+	depends on PREEMPT && SMP
+	help
+	  This option selects the RCU implementation that is
+	  designed for very large SMP systems with hundreds or
+	  thousands of CPUs, but for which real-time response
+	  is also required.  It also scales down nicely to
+	  smaller systems.
+
+config TINY_RCU
+	bool "UP-only small-memory-footprint RCU"
+	depends on !PREEMPT && !SMP
+	help
+	  This option selects the RCU implementation that is
+	  designed for UP systems from which real-time response
+	  is not required.  This option greatly reduces the
+	  memory footprint of RCU.
+
+config TINY_PREEMPT_RCU
+	bool "Preemptible UP-only small-memory-footprint RCU"
+	depends on PREEMPT && !SMP
+	help
+	  This option selects the RCU implementation that is designed
+	  for real-time UP systems.  This option greatly reduces the
+	  memory footprint of RCU.
+
+endchoice
+
+config PREEMPT_RCU
+	def_bool ( TREE_PREEMPT_RCU || TINY_PREEMPT_RCU )
+	help
+	  This option enables preemptible-RCU code that is common between
+	  the TREE_PREEMPT_RCU and TINY_PREEMPT_RCU implementations.
+
+config RCU_TRACE
+	bool "Enable tracing for RCU"
+	help
+	  This option provides tracing in RCU which presents stats
+	  in debugfs for debugging RCU implementation.
+
+	  Say Y here if you want to enable RCU tracing
+	  Say N if you are unsure.
+
+config RCU_FANOUT
+	int "Tree-based hierarchical RCU fanout value"
+	range 2 64 if 64BIT
+	range 2 32 if !64BIT
+	depends on TREE_RCU || TREE_PREEMPT_RCU
+	default 64 if 64BIT
+	default 32 if !64BIT
+	help
+	  This option controls the fanout of hierarchical implementations
+	  of RCU, allowing RCU to work efficiently on machines with
+	  large numbers of CPUs.  This value must be at least the fourth
+	  root of NR_CPUS, which allows NR_CPUS to be insanely large.
+	  The default value of RCU_FANOUT should be used for production
+	  systems, but if you are stress-testing the RCU implementation
+	  itself, small RCU_FANOUT values allow you to test large-system
+	  code paths on small(er) systems.
+
+	  Select a specific number if testing RCU itself.
+	  Take the default if unsure.
+
+config RCU_FANOUT_EXACT
+	bool "Disable tree-based hierarchical RCU auto-balancing"
+	depends on TREE_RCU || TREE_PREEMPT_RCU
+	default n
+	help
+	  This option forces use of the exact RCU_FANOUT value specified,
+	  regardless of imbalances in the hierarchy.  This is useful for
+	  testing RCU itself, and might one day be useful on systems with
+	  strong NUMA behavior.
+
+	  Without RCU_FANOUT_EXACT, the code will balance the hierarchy.
+
+	  Say N if unsure.
+
+config RCU_FAST_NO_HZ
+	bool "Accelerate last non-dyntick-idle CPU's grace periods"
+	depends on NO_HZ && SMP
+	default n
+	help
+	  This option causes RCU to attempt to accelerate grace periods
+	  in order to allow CPUs to enter dynticks-idle state more
+	  quickly.  On the other hand, this option increases the overhead
+	  of the dynticks-idle checking, particularly on systems with
+	  large numbers of CPUs.
+
+	  Say Y if energy efficiency is critically important, particularly
+	  	if you have relatively few CPUs.
+
+	  Say N if you are unsure.
+
+config TREE_RCU_TRACE
+	def_bool RCU_TRACE && ( TREE_RCU || TREE_PREEMPT_RCU )
+	select DEBUG_FS
+	help
+	  This option provides tracing for the TREE_RCU and
+	  TREE_PREEMPT_RCU implementations, permitting Makefile to
+	  trivially select kernel/rcutree_trace.c.
+
+config RCU_BOOST
+	bool "Enable RCU priority boosting"
+	depends on RT_MUTEXES && PREEMPT_RCU
+	default n
+	help
+	  This option boosts the priority of preempted RCU readers that
+	  block the current preemptible RCU grace period for too long.
+	  This option also prevents heavy loads from blocking RCU
+	  callback invocation for all flavors of RCU.
+
+	  Say Y here if you are working with real-time apps or heavy loads
+	  Say N here if you are unsure.
+
+config RCU_BOOST_PRIO
+	int "Real-time priority to boost RCU readers to"
+	range 1 99
+	depends on RCU_BOOST
+	default 1
+	help
+	  This option specifies the real-time priority to which preempted
+	  RCU readers are to be boosted.  If you are working with CPU-bound
+	  real-time applications, you should specify a priority higher then
+	  the highest-priority CPU-bound application.
+
+	  Specify the real-time priority, or take the default if unsure.
+
+config RCU_BOOST_DELAY
+	int "Milliseconds to delay boosting after RCU grace-period start"
+	range 0 3000
+	depends on RCU_BOOST
+	default 500
+	help
+	  This option specifies the time to wait after the beginning of
+	  a given grace period before priority-boosting preempted RCU
+	  readers blocking that grace period.  Note that any RCU reader
+	  blocking an expedited RCU grace period is boosted immediately.
+
+	  Accept the default if unsure.
+
+endmenu # "RCU Subsystem"
+
+config IKCONFIG
+	tristate "Kernel .config support"
+	---help---
+	  This option enables the complete Linux kernel ".config" file
+	  contents to be saved in the kernel. It provides documentation
+	  of which kernel options are used in a running kernel or in an
+	  on-disk kernel.  This information can be extracted from the kernel
+	  image file with the script scripts/extract-ikconfig and used as
+	  input to rebuild the current kernel or to build another kernel.
+	  It can also be extracted from a running kernel by reading
+	  /proc/config.gz if enabled (below).
+
+config IKCONFIG_PROC
+	bool "Enable access to .config through /proc/config.gz"
+	depends on IKCONFIG && PROC_FS
+	---help---
+	  This option enables access to the kernel configuration file
+	  through /proc/config.gz.
+
+config LOG_BUF_SHIFT
+	int "Kernel log buffer size (16 => 64KB, 17 => 128KB)"
+	range 12 21
+	default 17
+	help
+	  Select kernel log buffer size as a power of 2.
+	  Examples:
+	  	     17 => 128 KB
+		     16 => 64 KB
+	             15 => 32 KB
+	             14 => 16 KB
+		     13 =>  8 KB
+		     12 =>  4 KB
+
+#
+# Architectures with an unreliable sched_clock() should select this:
+#
+config HAVE_UNSTABLE_SCHED_CLOCK
+	bool
+
+menuconfig CGROUPS
+	boolean "Control Group support"
+	depends on EVENTFD
+	help
+	  This option adds support for grouping sets of processes together, for
+	  use with process control subsystems such as Cpusets, CFS, memory
+	  controls or device isolation.
+	  See
+		- Documentation/scheduler/sched-design-CFS.txt	(CFS)
+		- Documentation/cgroups/ (features for grouping, isolation
+					  and resource control)
+
+	  Say N if unsure.
+
+if CGROUPS
+
+config CGROUP_DEBUG
+	bool "Example debug cgroup subsystem"
+	default n
+	help
+	  This option enables a simple cgroup subsystem that
+	  exports useful debugging information about the cgroups
+	  framework.
+
+	  Say N if unsure.
+
+config CGROUP_FREEZER
+	bool "Freezer cgroup subsystem"
+	help
+	  Provides a way to freeze and unfreeze all tasks in a
+	  cgroup.
+
+config CGROUP_DEVICE
+	bool "Device controller for cgroups"
+	help
+	  Provides a cgroup implementing whitelists for devices which
+	  a process in the cgroup can mknod or open.
+
+config CPUSETS
+	bool "Cpuset support"
+	help
+	  This option will let you create and manage CPUSETs which
+	  allow dynamically partitioning a system into sets of CPUs and
+	  Memory Nodes and assigning tasks to run only within those sets.
+	  This is primarily useful on large SMP or NUMA systems.
+
+	  Say N if unsure.
+
+config PROC_PID_CPUSET
+	bool "Include legacy /proc/<pid>/cpuset file"
+	depends on CPUSETS
+	default y
+
+config CGROUP_CPUACCT
+	bool "Simple CPU accounting cgroup subsystem"
+	help
+	  Provides a simple Resource Controller for monitoring the
+	  total CPU consumed by the tasks in a cgroup.
+
+config RESOURCE_COUNTERS
+	bool "Resource counters"
+	help
+	  This option enables controller independent resource accounting
+	  infrastructure that works with cgroups.
+
+config CGROUP_MEM_RES_CTLR
+	bool "Memory Resource Controller for Control Groups"
+	depends on RESOURCE_COUNTERS
+	select MM_OWNER
+	help
+	  Provides a memory resource controller that manages both anonymous
+	  memory and page cache. (See Documentation/cgroups/memory.txt)
+
+	  Note that setting this option increases fixed memory overhead
+	  associated with each page of memory in the system. By this,
+	  20(40)bytes/PAGE_SIZE on 32(64)bit system will be occupied by memory
+	  usage tracking struct at boot. Total amount of this is printed out
+	  at boot.
+
+	  Only enable when you're ok with these trade offs and really
+	  sure you need the memory resource controller. Even when you enable
+	  this, you can set "cgroup_disable=memory" at your boot option to
+	  disable memory resource controller and you can avoid overheads.
+	  (and lose benefits of memory resource controller)
+
+	  This config option also selects MM_OWNER config option, which
+	  could in turn add some fork/exit overhead.
+
+config CGROUP_MEM_RES_CTLR_SWAP
+	bool "Memory Resource Controller Swap Extension"
+	depends on CGROUP_MEM_RES_CTLR && SWAP
+	help
+	  Add swap management feature to memory resource controller. When you
+	  enable this, you can limit mem+swap usage per cgroup. In other words,
+	  when you disable this, memory resource controller has no cares to
+	  usage of swap...a process can exhaust all of the swap. This extension
+	  is useful when you want to avoid exhaustion swap but this itself
+	  adds more overheads and consumes memory for remembering information.
+	  Especially if you use 32bit system or small memory system, please
+	  be careful about enabling this. When memory resource controller
+	  is disabled by boot option, this will be automatically disabled and
+	  there will be no overhead from this. Even when you set this config=y,
+	  if boot option "swapaccount=0" is set, swap will not be accounted.
+	  Now, memory usage of swap_cgroup is 2 bytes per entry. If swap page
+	  size is 4096bytes, 512k per 1Gbytes of swap.
+config CGROUP_MEM_RES_CTLR_SWAP_ENABLED
+	bool "Memory Resource Controller Swap Extension enabled by default"
+	depends on CGROUP_MEM_RES_CTLR_SWAP
+	default y
+	help
+	  Memory Resource Controller Swap Extension comes with its price in
+	  a bigger memory consumption. General purpose distribution kernels
+	  which want to enable the feature but keep it disabled by default
+	  and let the user enable it by swapaccount boot command line
+	  parameter should have this option unselected.
+	  For those who want to have the feature enabled by default should
+	  select this option (if, for some reason, they need to disable it
+	  then swapaccount=0 does the trick).
+config CGROUP_MEM_RES_CTLR_KMEM
+	bool "Memory Resource Controller Kernel Memory accounting (EXPERIMENTAL)"
+	depends on CGROUP_MEM_RES_CTLR && EXPERIMENTAL
+	default n
+	help
+	  The Kernel Memory extension for Memory Resource Controller can limit
+	  the amount of memory used by kernel objects in the system. Those are
+	  fundamentally different from the entities handled by the standard
+	  Memory Controller, which are page-based, and can be swapped. Users of
+	  the kmem extension can use it to guarantee that no group of processes
+	  will ever exhaust kernel resources alone.
+
+config CGROUP_PERF
+	bool "Enable perf_event per-cpu per-container group (cgroup) monitoring"
+	depends on PERF_EVENTS && CGROUPS
+	help
+	  This option extends the per-cpu mode to restrict monitoring to
+	  threads which belong to the cgroup specified and run on the
+	  designated cpu.
+
+	  Say N if unsure.
+
+menuconfig CGROUP_SCHED
+	bool "Group CPU scheduler"
+	default n
+	help
+	  This feature lets CPU scheduler recognize task groups and control CPU
+	  bandwidth allocation to such task groups. It uses cgroups to group
+	  tasks.
+
+if CGROUP_SCHED
+config FAIR_GROUP_SCHED
+	bool "Group scheduling for SCHED_OTHER"
+	depends on CGROUP_SCHED
+	default CGROUP_SCHED
+
+config CFS_BANDWIDTH
+	bool "CPU bandwidth provisioning for FAIR_GROUP_SCHED"
+	depends on EXPERIMENTAL
+	depends on FAIR_GROUP_SCHED
+	default n
+	help
+	  This option allows users to define CPU bandwidth rates (limits) for
+	  tasks running within the fair group scheduler.  Groups with no limit
+	  set are considered to be unconstrained and will run with no
+	  restriction.
+	  See tip/Documentation/scheduler/sched-bwc.txt for more information.
+
+config RT_GROUP_SCHED
+	bool "Group scheduling for SCHED_RR/FIFO"
+	depends on EXPERIMENTAL
+	depends on CGROUP_SCHED
+	default n
+	help
+	  This feature lets you explicitly allocate real CPU bandwidth
+	  to task groups. If enabled, it will also make it impossible to
+	  schedule realtime tasks for non-root users until you allocate
+	  realtime bandwidth for them.
+	  See Documentation/scheduler/sched-rt-group.txt for more information.
+
+endif #CGROUP_SCHED
+
+config BLK_CGROUP
+	tristate "Block IO controller"
+	depends on BLOCK
+	default n
+	---help---
+	Generic block IO controller cgroup interface. This is the common
+	cgroup interface which should be used by various IO controlling
+	policies.
+
+	Currently, CFQ IO scheduler uses it to recognize task groups and
+	control disk bandwidth allocation (proportional time slice allocation)
+	to such task groups. It is also used by bio throttling logic in
+	block layer to implement upper limit in IO rates on a device.
+
+	This option only enables generic Block IO controller infrastructure.
+	One needs to also enable actual IO controlling logic/policy. For
+	enabling proportional weight division of disk bandwidth in CFQ, set
+	CONFIG_CFQ_GROUP_IOSCHED=y; for enabling throttling policy, set
+	CONFIG_BLK_DEV_THROTTLING=y.
+
+	See Documentation/cgroups/blkio-controller.txt for more information.
+
+config DEBUG_BLK_CGROUP
+	bool "Enable Block IO controller debugging"
+	depends on BLK_CGROUP
+	default n
+	---help---
+	Enable some debugging help. Currently it exports additional stat
+	files in a cgroup which can be useful for debugging.
+
+endif # CGROUPS
+
+config CHECKPOINT_RESTORE
+	bool "Checkpoint/restore support" if EXPERT
+	default n
+	help
+	  Enables additional kernel features in a sake of checkpoint/restore.
+	  In particular it adds auxiliary prctl codes to setup process text,
+	  data and heap segment sizes, and a few additional /proc filesystem
+	  entries.
+
+	  If unsure, say N here.
+
+menuconfig NAMESPACES
+	bool "Namespaces support" if EXPERT
+	default !EXPERT
+	help
+	  Provides the way to make tasks work with different objects using
+	  the same id. For example same IPC id may refer to different objects
+	  or same user id or pid may refer to different tasks when used in
+	  different namespaces.
+
+if NAMESPACES
+
+config UTS_NS
+	bool "UTS namespace"
+	default y
+	help
+	  In this namespace tasks see different info provided with the
+	  uname() system call
+
+config IPC_NS
+	bool "IPC namespace"
+	depends on (SYSVIPC || POSIX_MQUEUE)
+	default y
+	help
+	  In this namespace tasks work with IPC ids which correspond to
+	  different IPC objects in different namespaces.
+
+config USER_NS
+	bool "User namespace (EXPERIMENTAL)"
+	depends on EXPERIMENTAL
+	default y
+	help
+	  This allows containers, i.e. vservers, to use user namespaces
+	  to provide different user info for different servers.
+	  If unsure, say N.
+
+config PID_NS
+	bool "PID Namespaces"
+	default y
+	help
+	  Support process id namespaces.  This allows having multiple
+	  processes with the same pid as long as they are in different
+	  pid namespaces.  This is a building block of containers.
+
+config NET_NS
+	bool "Network namespace"
+	depends on NET
+	default y
+	help
+	  Allow user space to create what appear to be multiple instances
+	  of the network stack.
+
+endif # NAMESPACES
+
+config SCHED_AUTOGROUP
+	bool "Automatic process group scheduling"
+	select EVENTFD
+	select CGROUPS
+	select CGROUP_SCHED
+	select FAIR_GROUP_SCHED
+	help
+	  This option optimizes the scheduler for common desktop workloads by
+	  automatically creating and populating task groups.  This separation
+	  of workloads isolates aggressive CPU burners (like build jobs) from
+	  desktop applications.  Task group autogeneration is currently based
+	  upon task session.
+
+config MM_OWNER
+	bool
+
+config SYSFS_DEPRECATED
+	bool "Enable deprecated sysfs features to support old userspace tools"
+	depends on SYSFS
+	default n
+	help
+	  This option adds code that switches the layout of the "block" class
+	  devices, to not show up in /sys/class/block/, but only in
+	  /sys/block/.
+
+	  This switch is only active when the sysfs.deprecated=1 boot option is
+	  passed or the SYSFS_DEPRECATED_V2 option is set.
+
+	  This option allows new kernels to run on old distributions and tools,
+	  which might get confused by /sys/class/block/. Since 2007/2008 all
+	  major distributions and tools handle this just fine.
+
+	  Recent distributions and userspace tools after 2009/2010 depend on
+	  the existence of /sys/class/block/, and will not work with this
+	  option enabled.
+
+	  Only if you are using a new kernel on an old distribution, you might
+	  need to say Y here.
+
+config SYSFS_DEPRECATED_V2
+	bool "Enable deprecated sysfs features by default"
+	default n
+	depends on SYSFS
+	depends on SYSFS_DEPRECATED
+	help
+	  Enable deprecated sysfs by default.
+
+	  See the CONFIG_SYSFS_DEPRECATED option for more details about this
+	  option.
+
+	  Only if you are using a new kernel on an old distribution, you might
+	  need to say Y here. Even then, odds are you would not need it
+	  enabled, you can always pass the boot option if absolutely necessary.
+
+config RELAY
+	bool "Kernel->user space relay support (formerly relayfs)"
+	help
+	  This option enables support for relay interface support in
+	  certain file systems (such as debugfs).
+	  It is designed to provide an efficient mechanism for tools and
+	  facilities to relay large amounts of data from kernel space to
+	  user space.
+
+	  If unsure, say N.
+
+config BLK_DEV_INITRD
+	bool "Initial RAM filesystem and RAM disk (initramfs/initrd) support"
+	depends on BROKEN || !FRV
+	help
+	  The initial RAM filesystem is a ramfs which is loaded by the
+	  boot loader (loadlin or lilo) and that is mounted as root
+	  before the normal boot procedure. It is typically used to
+	  load modules needed to mount the "real" root file system,
+	  etc. See <file:Documentation/initrd.txt> for details.
+
+	  If RAM disk support (BLK_DEV_RAM) is also included, this
+	  also enables initial RAM disk (initrd) support and adds
+	  15 Kbytes (more on some other architectures) to the kernel size.
+
+	  If unsure say Y.
+
+if BLK_DEV_INITRD
+
+source "usr/Kconfig"
+
+config BLK_DEV_INITRAMFS_RO
+	bool "Make Initramfs RO"
+	help
+	  by default initramfs is RW. We can make it RO.
+
+	  If unsure say N.
+endif
+
+config CC_OPTIMIZE_FOR_SIZE
+	bool "Optimize for size"
+	help
+	  Enabling this option will pass "-Os" instead of "-O2" to gcc
+	  resulting in a smaller kernel.
+
+	  If unsure, say Y.
+
+config SYSCTL
+	bool
+
+config ANON_INODES
+	bool
+
+menuconfig EXPERT
+	bool "Configure standard kernel features (expert users)"
+	# Unhide debug options, to make the on-by-default options visible
+	help
+	  This option allows certain base kernel options and settings
+          to be disabled or tweaked. This is for specialized
+          environments which can tolerate a "non-standard" kernel.
+          Only use this if you really know what you are doing.
+
+config UID16
+	bool "Enable 16-bit UID system calls" if EXPERT
+	depends on ARM || BLACKFIN || CRIS || FRV || H8300 || X86_32 || M68K || (S390 && !64BIT) || SUPERH || SPARC32 || (SPARC64 && COMPAT) || UML || (X86_64 && IA32_EMULATION)
+	default y
+	help
+	  This enables the legacy 16-bit UID syscall wrappers.
+
+config SYSCTL_SYSCALL
+	bool "Sysctl syscall support" if EXPERT
+	depends on PROC_SYSCTL
+	default n
+	select SYSCTL
+	---help---
+	  sys_sysctl uses binary paths that have been found challenging
+	  to properly maintain and use.  The interface in /proc/sys
+	  using paths with ascii names is now the primary path to this
+	  information.
+
+	  Almost nothing using the binary sysctl interface so if you are
+	  trying to save some space it is probably safe to disable this,
+	  making your kernel marginally smaller.
+
+	  If unsure say N here.
+
+config KALLSYMS
+	 bool "Load all symbols for debugging/ksymoops" if EXPERT
+	 default y
+	 help
+	   Say Y here to let the kernel print out symbolic crash information and
+	   symbolic stack backtraces. This increases the size of the kernel
+	   somewhat, as all symbols have to be loaded into the kernel image.
+
+config KALLSYMS_ALL
+	bool "Include all symbols in kallsyms"
+	depends on DEBUG_KERNEL && KALLSYMS
+	help
+	   Normally kallsyms only contains the symbols of functions for nicer
+	   OOPS messages and backtraces (i.e., symbols from the text and inittext
+	   sections). This is sufficient for most cases. And only in very rare
+	   cases (e.g., when a debugger is used) all symbols are required (e.g.,
+	   names of variables from the data sections, etc).
+
+	   This option makes sure that all symbols are loaded into the kernel
+	   image (i.e., symbols from all sections) in cost of increased kernel
+	   size (depending on the kernel configuration, it may be 300KiB or
+	   something like this).
+
+	   Say N unless you really need all symbols.
+
+config HOTPLUG
+	bool "Support for hot-pluggable devices" if EXPERT
+	default y
+	help
+	  This option is provided for the case where no hotplug or uevent
+	  capabilities is wanted by the kernel.  You should only consider
+	  disabling this option for embedded systems that do not use modules, a
+	  dynamic /dev tree, or dynamic device discovery.  Just say Y.
+
+config PRINTK
+	default y
+	bool "Enable support for printk" if EXPERT
+	help
+	  This option enables normal printk support. Removing it
+	  eliminates most of the message strings from the kernel image
+	  and makes the kernel more or less silent. As this makes it
+	  very difficult to diagnose system problems, saying N here is
+	  strongly discouraged.
+
+config BUG
+	bool "BUG() support" if EXPERT
+	default y
+	help
+          Disabling this option eliminates support for BUG and WARN, reducing
+          the size of your kernel image and potentially quietly ignoring
+          numerous fatal conditions. You should only consider disabling this
+          option for embedded systems with no facilities for reporting errors.
+          Just say Y.
+
+config ELF_CORE
+	default y
+	bool "Enable ELF core dumps" if EXPERT
+	help
+	  Enable support for generating core dumps. Disabling saves about 4k.
+
+
+config PCSPKR_PLATFORM
+	bool "Enable PC-Speaker support" if EXPERT
+	depends on HAVE_PCSPKR_PLATFORM
+	select I8253_LOCK
+	default y
+	help
+          This option allows to disable the internal PC-Speaker
+          support, saving some memory.
+
+config HAVE_PCSPKR_PLATFORM
+	bool
+
+config BASE_FULL
+	default y
+	bool "Enable full-sized data structures for core" if EXPERT
+	help
+	  Disabling this option reduces the size of miscellaneous core
+	  kernel data structures. This saves memory on small machines,
+	  but may reduce performance.
+
+config FUTEX
+	bool "Enable futex support" if EXPERT
+	default y
+	select RT_MUTEXES
+	help
+	  Disabling this option will cause the kernel to be built without
+	  support for "fast userspace mutexes".  The resulting kernel may not
+	  run glibc-based applications correctly.
+
+config EPOLL
+	bool "Enable eventpoll support" if EXPERT
+	default y
+	select ANON_INODES
+	help
+	  Disabling this option will cause the kernel to be built without
+	  support for epoll family of system calls.
+
+config SIGNALFD
+	bool "Enable signalfd() system call" if EXPERT
+	select ANON_INODES
+	default y
+	help
+	  Enable the signalfd() system call that allows to receive signals
+	  on a file descriptor.
+
+	  If unsure, say Y.
+
+config TIMERFD
+	bool "Enable timerfd() system call" if EXPERT
+	select ANON_INODES
+	default y
+	help
+	  Enable the timerfd() system call that allows to receive timer
+	  events on a file descriptor.
+
+	  If unsure, say Y.
+
+config EVENTFD
+	bool "Enable eventfd() system call" if EXPERT
+	select ANON_INODES
+	default y
+	help
+	  Enable the eventfd() system call that allows to receive both
+	  kernel notification (ie. KAIO) or userspace notifications.
+
+	  If unsure, say Y.
+
+config SHMEM
+	bool "Use full shmem filesystem" if EXPERT
+	default y
+	depends on MMU
+	help
+	  The shmem is an internal filesystem used to manage shared memory.
+	  It is backed by swap and manages resource limits. It is also exported
+	  to userspace as tmpfs if TMPFS is enabled. Disabling this
+	  option replaces shmem and tmpfs with the much simpler ramfs code,
+	  which may be appropriate on small systems without swap.
+
+config AIO
+	bool "Enable AIO support" if EXPERT
+	default y
+	help
+	  This option enables POSIX asynchronous I/O which may by used
+          by some high performance threaded applications. Disabling
+          this option saves about 7k.
+
+config EMBEDDED
+	bool "Embedded system"
+	select EXPERT
+	help
+	  This option should be enabled if compiling the kernel for
+	  an embedded system so certain expert options are available
+	  for configuration.
+
+config HAVE_PERF_EVENTS
+	bool
+	help
+	  See tools/perf/design.txt for details.
+
+config PERF_USE_VMALLOC
+	bool
+	help
+	  See tools/perf/design.txt for details
+
+menu "Kernel Performance Events And Counters"
+
+config PERF_EVENTS
+	bool "Kernel performance events and counters"
+	default y if (PROFILING || PERF_COUNTERS)
+	depends on HAVE_PERF_EVENTS
+	select ANON_INODES
+	select IRQ_WORK
+	help
+	  Enable kernel support for various performance events provided
+	  by software and hardware.
+
+	  Software events are supported either built-in or via the
+	  use of generic tracepoints.
+
+	  Most modern CPUs support performance events via performance
+	  counter registers. These registers count the number of certain
+	  types of hw events: such as instructions executed, cachemisses
+	  suffered, or branches mis-predicted - without slowing down the
+	  kernel or applications. These registers can also trigger interrupts
+	  when a threshold number of events have passed - and can thus be
+	  used to profile the code that runs on that CPU.
+
+	  The Linux Performance Event subsystem provides an abstraction of
+	  these software and hardware event capabilities, available via a
+	  system call and used by the "perf" utility in tools/perf/. It
+	  provides per task and per CPU counters, and it provides event
+	  capabilities on top of those.
+
+	  Say Y if unsure.
+
+config PERF_COUNTERS
+	bool "Kernel performance counters (old config option)"
+	depends on HAVE_PERF_EVENTS
+	help
+	  This config has been obsoleted by the PERF_EVENTS
+	  config option - please see that one for details.
+
+	  It has no effect on the kernel whether you enable
+	  it or not, it is a compatibility placeholder.
+
+	  Say N if unsure.
+
+config DEBUG_PERF_USE_VMALLOC
+	default n
+	bool "Debug: use vmalloc to back perf mmap() buffers"
+	depends on PERF_EVENTS && DEBUG_KERNEL
+	select PERF_USE_VMALLOC
+	help
+	 Use vmalloc memory to back perf mmap() buffers.
+
+	 Mostly useful for debugging the vmalloc code on platforms
+	 that don't require it.
+
+	 Say N if unsure.
+
+endmenu
+
+config VM_EVENT_COUNTERS
+	default y
+	bool "Enable VM event counters for /proc/vmstat" if EXPERT
+	help
+	  VM event counters are needed for event counts to be shown.
+	  This option allows the disabling of the VM event counters
+	  on EXPERT systems.  /proc/vmstat will only show page counts
+	  if VM event counters are disabled.
+
+config PCI_QUIRKS
+	default y
+	bool "Enable PCI quirk workarounds" if EXPERT
+	depends on PCI
+	help
+	  This enables workarounds for various PCI chipset
+          bugs/quirks. Disable this only if your target machine is
+          unaffected by PCI quirks.
+
+config SLUB_DEBUG
+	default y
+	bool "Enable SLUB debugging support" if EXPERT
+	depends on SLUB && SYSFS
+	help
+	  SLUB has extensive debug support features. Disabling these can
+	  result in significant savings in code size. This also disables
+	  SLUB sysfs support. /sys/slab will not exist and there will be
+	  no support for cache validation etc.
+
+config COMPAT_BRK
+	bool "Disable heap randomization"
+	default y
+	help
+	  Randomizing heap placement makes heap exploits harder, but it
+	  also breaks ancient binaries (including anything libc5 based).
+	  This option changes the bootup default to heap randomization
+	  disabled, and can be overridden at runtime by setting
+	  /proc/sys/kernel/randomize_va_space to 2.
+
+	  On non-ancient distros (post-2000 ones) N is usually a safe choice.
+
+choice
+	prompt "Choose SLAB allocator"
+	default SLUB
+	help
+	   This option allows to select a slab allocator.
+
+config SLAB
+	bool "SLAB"
+	help
+	  The regular slab allocator that is established and known to work
+	  well in all environments. It organizes cache hot objects in
+	  per cpu and per node queues.
+
+config SLUB
+	bool "SLUB (Unqueued Allocator)"
+	help
+	   SLUB is a slab allocator that minimizes cache line usage
+	   instead of managing queues of cached objects (SLAB approach).
+	   Per cpu caching is realized using slabs of objects instead
+	   of queues of objects. SLUB can use memory efficiently
+	   and has enhanced diagnostics. SLUB is the default choice for
+	   a slab allocator.
+
+config SLOB
+	depends on EXPERT
+	bool "SLOB (Simple Allocator)"
+	help
+	   SLOB replaces the stock allocator with a drastically simpler
+	   allocator. SLOB is generally more space efficient but
+	   does not perform as well on large systems.
+
+endchoice
+
+config MMAP_ALLOW_UNINITIALIZED
+	bool "Allow mmapped anonymous memory to be uninitialized"
+	depends on EXPERT && !MMU
+	default n
+	help
+	  Normally, and according to the Linux spec, anonymous memory obtained
+	  from mmap() has it's contents cleared before it is passed to
+	  userspace.  Enabling this config option allows you to request that
+	  mmap() skip that if it is given an MAP_UNINITIALIZED flag, thus
+	  providing a huge performance boost.  If this option is not enabled,
+	  then the flag will be ignored.
+
+	  This is taken advantage of by uClibc's malloc(), and also by
+	  ELF-FDPIC binfmt's brk and stack allocator.
+
+	  Because of the obvious security issues, this option should only be
+	  enabled on embedded devices where you control what is run in
+	  userspace.  Since that isn't generally a problem on no-MMU systems,
+	  it is normally safe to say Y here.
+
+	  See Documentation/nommu-mmap.txt for more information.
+
+config PROFILING
+	bool "Profiling support"
+	help
+	  Say Y here to enable the extended profiling support mechanisms used
+	  by profilers such as OProfile.
+
+#
+# Place an empty function call at each tracepoint site. Can be
+# dynamically changed for a probe function.
+#
+config TRACEPOINTS
+	bool
+
+source "arch/Kconfig"
+
+endmenu		# General setup
+
+config HAVE_GENERIC_DMA_COHERENT
+	bool
+	default n
+
+config SLABINFO
+	bool
+	depends on PROC_FS
+	depends on SLAB || SLUB_DEBUG
+	default y
+
+config RT_MUTEXES
+	boolean
+
+config BASE_SMALL
+	int
+	default 0 if BASE_FULL
+	default 1 if !BASE_FULL
+
+menuconfig MODULES
+	bool "Enable loadable module support"
+	help
+	  Kernel modules are small pieces of compiled code which can
+	  be inserted in the running kernel, rather than being
+	  permanently built into the kernel.  You use the "modprobe"
+	  tool to add (and sometimes remove) them.  If you say Y here,
+	  many parts of the kernel can be built as modules (by
+	  answering M instead of Y where indicated): this is most
+	  useful for infrequently used options which are not required
+	  for booting.  For more information, see the man pages for
+	  modprobe, lsmod, modinfo, insmod and rmmod.
+
+	  If you say Y here, you will need to run "make
+	  modules_install" to put the modules under /lib/modules/
+	  where modprobe can find them (you may need to be root to do
+	  this).
+
+	  If unsure, say Y.
+
+if MODULES
+
+config MODULE_FORCE_LOAD
+	bool "Forced module loading"
+	default n
+	help
+	  Allow loading of modules without version information (ie. modprobe
+	  --force).  Forced module loading sets the 'F' (forced) taint flag and
+	  is usually a really bad idea.
+
+config MODULE_UNLOAD
+	bool "Module unloading"
+	help
+	  Without this option you will not be able to unload any
+	  modules (note that some modules may not be unloadable
+	  anyway), which makes your kernel smaller, faster
+	  and simpler.  If unsure, say Y.
+
+config MODULE_FORCE_UNLOAD
+	bool "Forced module unloading"
+	depends on MODULE_UNLOAD && EXPERIMENTAL
+	help
+	  This option allows you to force a module to unload, even if the
+	  kernel believes it is unsafe: the kernel will remove the module
+	  without waiting for anyone to stop using it (using the -f option to
+	  rmmod).  This is mainly for kernel developers and desperate users.
+	  If unsure, say N.
+
+config MODVERSIONS
+	bool "Module versioning support"
+	help
+	  Usually, you have to use modules compiled with your kernel.
+	  Saying Y here makes it sometimes possible to use modules
+	  compiled for different kernels, by adding enough information
+	  to the modules to (hopefully) spot any changes which would
+	  make them incompatible with the kernel you are running.  If
+	  unsure, say N.
+
+config MODULE_SRCVERSION_ALL
+	bool "Source checksum for all modules"
+	help
+	  Modules which contain a MODULE_VERSION get an extra "srcversion"
+	  field inserted into their modinfo section, which contains a
+    	  sum of the source files which made it.  This helps maintainers
+	  see exactly which source was used to build a module (since
+	  others sometimes change the module source without updating
+	  the version).  With this option, such a "srcversion" field
+	  will be created for all modules.  If unsure, say N.
+
+endif # MODULES
+
+config INIT_ALL_POSSIBLE
+	bool
+	help
+	  Back when each arch used to define their own cpu_online_map and
+	  cpu_possible_map, some of them chose to initialize cpu_possible_map
+	  with all 1s, and others with all 0s.  When they were centralised,
+	  it was better to provide this option than to break all the archs
+	  and have several arch maintainers pursuing me down dark alleys.
+
+config STOP_MACHINE
+	bool
+	default y
+	depends on (SMP && MODULE_UNLOAD) || HOTPLUG_CPU
+	help
+	  Need stop_machine() primitive.
+
+source "block/Kconfig"
+
+config PREEMPT_NOTIFIERS
+	bool
+
+config PADATA
+	depends on SMP
+	bool
+
+source "kernel/Kconfig.locks"
diff -Naur kernel-3.3-3.0a-ref/Kconfig kernel-current/Kconfig
--- kernel-3.3-3.0a-ref/Kconfig	2013-08-28 01:30:55.000000000 +0200
+++ kernel-current/Kconfig	2015-06-12 16:27:19.960088064 +0200
@@ -9,3 +9,5 @@
 	option env="SRCARCH"
 
 source "arch/$SRCARCH/Kconfig"
+
+source "Kconfig.extstats"
diff -Naur kernel-3.3-3.0a-ref/Kconfig.extstats kernel-current/Kconfig.extstats
--- kernel-3.3-3.0a-ref/Kconfig.extstats	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/Kconfig.extstats	2015-06-12 16:27:19.960088064 +0200
@@ -0,0 +1,5 @@
+config BCM_KF_EXTSTATS
+       bool "Enable extended statistics on packets"
+       default n
+       ---help---
+	Enable the extended statistics on packets in kernel. New statistics will be available under the following path : /proc/net/dev_extstats
diff -Naur kernel-3.3-3.0a-ref/kernel/module.c kernel-current/kernel/module.c
--- kernel-3.3-3.0a-ref/kernel/module.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/kernel/module.c	2015-06-12 16:27:19.984100064 +0200
@@ -2513,7 +2513,7 @@
 {
 	const char *modmagic = get_modinfo(info, "vermagic");
 	int err;
-
+#if CONFIG_MODVERSIONS 
 	/* This is allowed: modprobe --force will invalidate it. */
 	if (!modmagic) {
 		err = try_to_force_load(mod, "bad vermagic");
@@ -2537,7 +2537,7 @@
 
 	/* Set up license info based on the info section */
 	set_license(mod, get_modinfo(info, "license"));
-
+#endif
 	return 0;
 }
 
diff -Naur kernel-3.3-3.0a-ref/kernel/panic.c kernel-current/kernel/panic.c
--- kernel-3.3-3.0a-ref/kernel/panic.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/kernel/panic.c	2015-06-12 16:27:20.012114063 +0200
@@ -74,6 +74,11 @@
 	long i, i_next = 0;
 	int state = 0;
 
+#ifdef CONFIG_REBOOT_ON_PANIC
+	printk( KERN_EMERG " !!! Reboot on PANIC !!!\n"); 
+        machine_restart(NULL);
+#endif
+
 	/*
 	 * It's possible to come here directly from a panic-assertion and
 	 * not have preempt disabled. Some functions called from here want
@@ -295,6 +300,11 @@
 	unsigned long flags;
 	static int spin_counter;
 
+#ifdef CONFIG_REBOOT_ON_OOPS
+	printk( KERN_EMERG " !!! Reboot on OOPS !!!\n"); 		
+    machine_restart(NULL);
+#endif
+
 	if (!pause_on_oops)
 		return;
 
diff -Naur kernel-3.3-3.0a-ref/kernel/signal.c kernel-current/kernel/signal.c
--- kernel-3.3-3.0a-ref/kernel/signal.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/kernel/signal.c	2015-06-12 16:27:20.008112063 +0200
@@ -38,6 +38,13 @@
 #include <asm/siginfo.h>
 #include "audit.h"	/* audit_signal_info() */
 
+#ifdef CONFIG_REBOOT_ON_SIGNAL
+#include <linux/reboot.h>
+/* Table of values specified in the kernel configuration */
+/* Value "0" means "any signal" */
+static int * SignalsValue = NULL;
+#endif
+
 /*
  * SLAB caches for signal bits.
  */
@@ -1055,6 +1062,52 @@
 	struct sigqueue *q;
 	int override_rlimit;
 
+#ifdef CONFIG_REBOOT_ON_SIGNAL
+	int i =0;
+	int reboot=0;
+
+	if (SignalsValue != NULL)
+	{
+		while(  SignalsValue[i] != SIGRTMAX)
+		{		
+			/* 0 as a specified value means "any signal" */ 
+			/* If 0 is not the first specified value, reboot on any matching signal */
+			/* If 0 is the first value and not the only value, reboot on any non-matching signal (soustractive logic) */
+			/* If 0 is the only value, reboot on any signal */
+			if ( sig == SignalsValue[i] )
+			{
+				if(SignalsValue[0] == 0) 
+				{	
+					reboot= 0;					
+				}
+				else
+				{
+					reboot=1;					
+				}
+				break;
+			}
+			else
+			{
+				if(SignalsValue[0] == 0)
+				{
+					reboot = 1;
+				}
+				else
+				{
+					reboot=0;					
+				}
+				i++;
+			}
+		}
+
+		if(reboot)
+		{
+			printk( KERN_EMERG "  !!! Reboot on signal (%u) !!!\n",sig);	
+        	machine_restart(NULL);
+		}
+	}
+	
+#endif
 	trace_signal_generate(sig, info, t);
 
 	assert_spin_locked(&t->sighand->siglock);
@@ -2335,6 +2388,11 @@
 
 		spin_unlock_irq(&sighand->siglock);
 
+#ifdef CONFIG_REBOOT_ON_FATAL_SIGNAL
+		printk( KERN_EMERG "  !!! Fatal signal (%u) - exec %s - pid %u!!!\n",info->si_signo,current->comm,current->pid);	
+       	machine_restart(NULL);
+#endif
+		
 		/*
 		 * Anything else is fatal, maybe with a core dump.
 		 */
@@ -3261,6 +3319,60 @@
 
 void __init signals_init(void)
 {
+
+
+#ifdef CONFIG_REBOOT_ON_SIGNAL
+	char * SignalsToRebootOn = NULL;
+	char * SignalsStringAlloc = NULL;
+	char * signal = NULL ;
+	int i = 0;
+	int nbSignals = 0;
+	int signalValue =0;
+
+	/* Careful freeing of an eventual previously allocated table */
+	kfree(SignalsValue);
+
+	/* Copy of specified signals because of the use of strsep (pointer value is modified)*/
+	SignalsToRebootOn = kstrdup(CONFIG_SIGNAL_TO_REBOOT_ON,GFP_KERNEL);
+	SignalsStringAlloc = SignalsToRebootOn;
+	
+	/* Count number of specified signals */
+	while (strsep(&SignalsToRebootOn,",") != NULL) nbSignals++;
+
+	/* Copy of specified signals because of the use of strsep ( the pointed string is also modified) */
+	SignalsToRebootOn = SignalsStringAlloc;
+	strcpy(SignalsToRebootOn,CONFIG_SIGNAL_TO_REBOOT_ON);
+
+	printk("SignalsToRebootOn(%u) = %s\n",nbSignals,SignalsToRebootOn);
+
+	/* Dynamic allocation of table containing signal values for nbSignals*/
+	/* +1 since table is terminated with value SIGRTMAX */
+	SignalsValue = kmalloc(sizeof(int)*(nbSignals+1),GFP_KERNEL);
+
+	/* Filling table with values enclosed between "()" */
+	if((SignalsToRebootOn  != NULL) && (SignalsValue != NULL))
+	{
+		do 
+		{		
+			signal = strsep(&SignalsToRebootOn,"(");
+			signal = strsep(&SignalsToRebootOn,")"); 
+			if (signal != NULL )
+			{
+				if (!kstrtol(signal,10,(long int *) &signalValue)) 	SignalsValue[i] = signalValue;								
+				i++;
+			}
+			else
+			{
+				SignalsValue[i] = SIGRTMAX;
+			}				
+			
+
+		} while (signal != NULL);
+	}
+
+	kfree(SignalsStringAlloc);
+#endif
+
 	sigqueue_cachep = KMEM_CACHE(sigqueue, SLAB_PANIC);
 }
 
diff -Naur kernel-3.3-3.0a-ref/kernel/sysctl.c kernel-current/kernel/sysctl.c
--- kernel-3.3-3.0a-ref/kernel/sysctl.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/kernel/sysctl.c	2015-06-12 16:27:19.992104064 +0200
@@ -1734,7 +1734,19 @@
 		mode = root->permissions(root, current->nsproxy, table);
 	else
 		mode = table->mode;
-
+		
+#ifdef CONFIG_PROC_SYSCTL_MODULES_DISABLED_SETTING
+	/* Allow the access and modification of only "/proc/sys/kernel/modules_disabled" and */
+	/* only for a task with the user "module" (uid 700)*/
+	/* by default - see proc_dointvec_minmax - once the value is set to 1, the value can not be set back to 0 */
+	/* This function is accessed twice : for opening and for writing */
+	if((current_euid()==700) && 
+	   (table!=NULL) &&  
+	   (table->procname !=NULL) && 
+	   (!strcmp(table->procname, "modules_disabled")) ){		
+		mode |= S_IWOTH;
+	}
+#endif
 	return test_perm(mode, op);
 }
 
diff -Naur kernel-3.3-3.0a-ref/kernel/trace/Kconfig kernel-current/kernel/trace/Kconfig
--- kernel-3.3-3.0a-ref/kernel/trace/Kconfig	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/kernel/trace/Kconfig	2015-06-12 16:27:20.008112063 +0200
@@ -119,7 +119,7 @@
 # be able to offer generic tracing facilities:
 #
 config TRACING_SUPPORT
-	bool
+	bool "Tracing support"
 	# PPC32 has no irqflags tracing support, but it can use most of the
 	# tracers anyway, they were tested to build and work. Note that new
 	# exceptions to this list aren't welcomed, better implement the
diff -Naur kernel-3.3-3.0a-ref/lib/vsprintf.c kernel-current/lib/vsprintf.c
--- kernel-3.3-3.0a-ref/lib/vsprintf.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/lib/vsprintf.c	2015-06-12 16:27:19.988102064 +0200
@@ -789,7 +789,13 @@
 	return number(buf, end, *(const netdev_features_t *)addr, spec);
 }
 
+
+#if !defined(CONFIG_PROC_SYSCTL_SETTINGS) || !defined(CONFIG_KPTR_RESTRICT)
 int kptr_restrict __read_mostly;
+#else
+int kptr_restrict __read_mostly = 1;
+#endif
+
 
 /*
  * Show a '%p' thing.  A kernel extension is that the '%p' is followed
diff -Naur kernel-3.3-3.0a-ref/mm/Kconfig kernel-current/mm/Kconfig
--- kernel-3.3-3.0a-ref/mm/Kconfig	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/mm/Kconfig	2015-06-12 16:27:19.992104064 +0200
@@ -193,6 +193,13 @@
 	  Allows the compaction of memory for the allocation of huge pages.
 
 #
+config MIN_FREE_KBYTES_MULTIPLIER
+	int "Minimum free kilo bytes multiplier"
+	default "2"
+	help
+	  Allows to set the multiplier of the /proc/sys/vm/min_free_kbytes	
+	  
+#
 # support for page migration
 #
 config MIGRATION
diff -Naur kernel-3.3-3.0a-ref/mm/oom_kill.c kernel-current/mm/oom_kill.c
--- kernel-3.3-3.0a-ref/mm/oom_kill.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/mm/oom_kill.c	2015-06-12 16:27:20.012114063 +0200
@@ -38,6 +38,10 @@
 #define CREATE_TRACE_POINTS
 #include <trace/events/oom.h>
 
+#ifdef CONFIG_REBOOT_ON_OOM
+#include <linux/reboot.h>
+#endif
+
 int sysctl_panic_on_oom;
 int sysctl_oom_kill_allocating_task;
 int sysctl_oom_dump_tasks = 1;
@@ -452,6 +456,11 @@
 		K(get_mm_counter(p->mm, MM_FILEPAGES)));
 	task_unlock(p);
 
+#ifdef CONFIG_REBOOT_ON_OOM
+		printk( KERN_EMERG " !!! Reboot on OOM !!!\n");
+        machine_restart(NULL);
+#endif
+
 	/*
 	 * Kill all user processes sharing p->mm in other thread groups, if any.
 	 * They don't get access to memory reserves or a higher scheduler
diff -Naur kernel-3.3-3.0a-ref/mm/page_alloc.c kernel-current/mm/page_alloc.c
--- kernel-3.3-3.0a-ref/mm/page_alloc.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/mm/page_alloc.c	2015-06-12 16:27:19.992104064 +0200
@@ -5066,8 +5066,11 @@
 	unsigned long lowmem_kbytes;
 
 	lowmem_kbytes = nr_free_buffer_pages() * (PAGE_SIZE >> 10);
-
+#ifdef CONFIG_MIN_FREE_KBYTES_MULTIPLIER
+	min_free_kbytes = CONFIG_MIN_FREE_KBYTES_MULTIPLIER * int_sqrt(lowmem_kbytes * 16);
+#else
 	min_free_kbytes = int_sqrt(lowmem_kbytes * 16);
+#endif		
 	if (min_free_kbytes < 128)
 		min_free_kbytes = 128;
 	if (min_free_kbytes > 65536)
diff -Naur kernel-3.3-3.0a-ref/net/8021q/vlan_core.c kernel-current/net/8021q/vlan_core.c
--- kernel-3.3-3.0a-ref/net/8021q/vlan_core.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/8021q/vlan_core.c	2015-06-12 16:27:19.976096064 +0200
@@ -58,10 +58,25 @@
 	rx_stats = this_cpu_ptr(vlan_dev_priv(vlan_dev)->vlan_pcpu_stats);
 
 	u64_stats_update_begin(&rx_stats->syncp);
+
 	rx_stats->rx_packets++;
 	rx_stats->rx_bytes += skb->len;
 	if (skb->pkt_type == PACKET_MULTICAST)
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	{
+#endif
 		rx_stats->rx_multicast++;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+		rx_stats->rx_multicast_packets++;
+		rx_stats->rx_multicast_bytes += skb->len;
+	}
+
+	if (skb->pkt_type == PACKET_MULTICAST)
+	{
+		rx_stats->rx_broadcast_packets++;
+	}
+#endif
+
 	u64_stats_update_end(&rx_stats->syncp);
 
 	return true;
diff -Naur kernel-3.3-3.0a-ref/net/8021q/vlan_dev.c kernel-current/net/8021q/vlan_dev.c
--- kernel-3.3-3.0a-ref/net/8021q/vlan_dev.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/8021q/vlan_dev.c	2015-06-12 16:27:19.976096064 +0200
@@ -143,6 +143,9 @@
 	struct vlan_ethhdr *veth = (struct vlan_ethhdr *)(skb->data);
 	unsigned int len;
 	int ret;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	u8 dest[ETH_ALEN];
+#endif
 
 	/* Handle non-VLAN frames if they are sent to us, for example by DHCP.
 	 *
@@ -170,6 +173,21 @@
 		u64_stats_update_begin(&stats->syncp);
 		stats->tx_packets++;
 		stats->tx_bytes += len;
+
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+		memcpy(&dest, skb->data, ETH_ALEN);
+
+		if (is_multicast_ether_addr(dest))
+		{
+		  stats->rx_multicast++;
+		  stats->rx_multicast_packets++;
+		  stats->rx_multicast_bytes += skb->len;
+		}
+		else if (is_broadcast_ether_addr(dest))
+		{
+		  stats->tx_broadcast_packets++;
+		}
+#endif
 		u64_stats_update_end(&stats->syncp);
 	} else {
 		this_cpu_inc(vlan_dev_priv(dev)->vlan_pcpu_stats->tx_dropped);
@@ -541,6 +559,10 @@
 			   NETIF_F_ALL_FCOE;
 
 	dev->features |= real_dev->vlan_features | NETIF_F_LLTX;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	dev->features |= NETIF_F_EXTSTATS;
+	real_dev->vlan_features |= NETIF_F_EXTSTATS;
+#endif
 	dev->gso_max_size = real_dev->gso_max_size;
 
 	/* ipv6 shared card related stuff */
@@ -636,6 +658,10 @@
 
 		for_each_possible_cpu(i) {
 			u64 rxpackets, rxbytes, rxmulticast, txpackets, txbytes;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+			u64 rxmulticastpackets, rxmulticastbytes, rxbroadcastpackets, rxunknownpackets;
+			u64 txmulticastpackets, txmulticastbytes, txbroadcastpackets;
+#endif
 			unsigned int start;
 
 			p = per_cpu_ptr(vlan_dev_priv(dev)->vlan_pcpu_stats, i);
@@ -646,6 +672,15 @@
 				rxmulticast	= p->rx_multicast;
 				txpackets	= p->tx_packets;
 				txbytes		= p->tx_bytes;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+				rxmulticastpackets = p->rx_multicast_packets;
+				txmulticastpackets = p->tx_multicast_packets;
+				rxmulticastbytes = p->rx_multicast_bytes;
+				txmulticastbytes = p->tx_multicast_bytes;
+				rxbroadcastpackets = p->rx_broadcast_packets;
+				txbroadcastpackets = p->tx_broadcast_packets;
+				rxunknownpackets = p->rx_unknown_packets;
+#endif
 			} while (u64_stats_fetch_retry_bh(&p->syncp, start));
 
 			stats->rx_packets	+= rxpackets;
@@ -653,6 +688,15 @@
 			stats->multicast	+= rxmulticast;
 			stats->tx_packets	+= txpackets;
 			stats->tx_bytes		+= txbytes;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+			stats->rx_multicast_packets += rxmulticastpackets;
+			stats->tx_multicast_packets += txmulticastpackets;
+			stats->rx_multicast_bytes += rxmulticastbytes;
+			stats->tx_multicast_bytes += txmulticastbytes;
+			stats->rx_broadcast_packets += rxbroadcastpackets;
+			stats->tx_broadcast_packets += txbroadcastpackets;
+			stats->rx_unknown_packets += rxunknownpackets;
+#endif
 			/* rx_errors & tx_dropped are u32 */
 			rx_errors	+= p->rx_errors;
 			tx_dropped	+= p->tx_dropped;
diff -Naur kernel-3.3-3.0a-ref/net/8021q/vlan.h kernel-current/net/8021q/vlan.h
--- kernel-3.3-3.0a-ref/net/8021q/vlan.h	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/8021q/vlan.h	2015-06-12 16:27:19.976096064 +0200
@@ -39,6 +39,15 @@
 	struct u64_stats_sync	syncp;
 	u32			rx_errors;
 	u32			tx_dropped;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	u64			rx_multicast_packets;  /* multicast packets received */
+	u64			tx_multicast_packets;  /* multicast packets transmitted */
+	u64			rx_multicast_bytes;  /* multicast bytes received */
+	u64			tx_multicast_bytes;  /* multicast bytes transmitted */
+	u64			rx_broadcast_packets;  /* broadcast packets received */
+	u64			tx_broadcast_packets;  /* broadcast packets transmitted */
+	u64			rx_unknown_packets;  /* unknown protocol packets received */
+#endif
 };
 
 struct netpoll;
diff -Naur kernel-3.3-3.0a-ref/net/bridge/br_device.c kernel-current/net/bridge/br_device.c
--- kernel-3.3-3.0a-ref/net/bridge/br_device.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/bridge/br_device.c	2015-06-12 16:27:19.972094064 +0200
@@ -22,6 +22,13 @@
 #include <asm/uaccess.h>
 #include "br_private.h"
 
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+static struct net_device_stats *br_dev_get_stats(struct net_device *dev)
+{
+  return &dev->stats;
+}
+#endif
+
 /* net device transmit always called with BH disabled */
 netdev_tx_t br_dev_xmit(struct sk_buff *skb, struct net_device *dev)
 {
@@ -30,14 +37,12 @@
 	struct net_bridge_fdb_entry *dst;
 	struct net_bridge_mdb_entry *mdst;
 	struct br_cpu_netstats *brstats = this_cpu_ptr(br->stats);
-
 #ifdef CONFIG_BRIDGE_NETFILTER
 	if (skb->nf_bridge && (skb->nf_bridge->mask & BRNF_BRIDGED_DNAT)) {
 		br_nf_pre_routing_finish_bridge_slow(skb);
 		return NETDEV_TX_OK;
 	}
 #endif
-
 	u64_stats_update_begin(&brstats->syncp);
 	brstats->tx_packets++;
 	brstats->tx_bytes += skb->len;
@@ -50,8 +55,19 @@
 
 	rcu_read_lock();
 	if (is_broadcast_ether_addr(dest))
-		br_flood_deliver(br, skb);
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	{
+	  dev->stats.tx_broadcast_packets++;
+#endif
+	  br_flood_deliver(br, skb);
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	}
+#endif
 	else if (is_multicast_ether_addr(dest)) {
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	  dev->stats.tx_multicast_packets++;
+	  dev->stats.tx_multicast_bytes += skb->len;
+#endif
 		if (unlikely(netpoll_tx_running(dev))) {
 			br_flood_deliver(br, skb);
 			goto out;
@@ -119,6 +135,9 @@
 						struct rtnl_link_stats64 *stats)
 {
 	struct net_bridge *br = netdev_priv(dev);
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	struct net_device_stats* br_stats = br_dev_get_stats(dev);
+#endif
 	struct br_cpu_netstats tmp, sum = { 0 };
 	unsigned int cpu;
 
@@ -141,6 +160,18 @@
 	stats->rx_bytes   = sum.rx_bytes;
 	stats->rx_packets = sum.rx_packets;
 
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	//multicast
+	stats->tx_multicast_bytes   = br_stats->tx_multicast_bytes;
+	stats->tx_multicast_packets = br_stats->tx_multicast_packets;
+	stats->rx_multicast_bytes   = br_stats->rx_multicast_bytes;
+	stats->rx_multicast_packets = br_stats->rx_multicast_packets;
+
+	//broadcast
+	stats->tx_broadcast_packets = br_stats->tx_broadcast_packets;
+	stats->rx_broadcast_packets = br_stats->rx_broadcast_packets;
+#endif
+
 	return stats;
 }
 
diff -Naur kernel-3.3-3.0a-ref/net/bridge/br_if.c kernel-current/net/bridge/br_if.c
--- kernel-3.3-3.0a-ref/net/bridge/br_if.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/bridge/br_if.c	2015-06-12 16:27:19.972094064 +0200
@@ -313,6 +313,10 @@
 						     p->dev->features, mask);
 	}
 
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	features |= NETIF_F_EXTSTATS;
+#endif
+
 	return features;
 }
 
diff -Naur kernel-3.3-3.0a-ref/net/bridge/br_input.c kernel-current/net/bridge/br_input.c
--- kernel-3.3-3.0a-ref/net/bridge/br_input.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/bridge/br_input.c	2015-06-12 16:27:19.972094064 +0200
@@ -32,6 +32,11 @@
 	struct net_bridge *br = netdev_priv(brdev);
 	struct br_cpu_netstats *brstats = this_cpu_ptr(br->stats);
 
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	/* Gather general RX statistics */
+	brdev->stats.rx_packets++;
+	brdev->stats.rx_bytes += skb->len;
+#endif
 	u64_stats_update_begin(&brstats->syncp);
 	brstats->rx_packets++;
 	brstats->rx_bytes += skb->len;
@@ -79,7 +84,14 @@
 	dst = NULL;
 
 	if (is_broadcast_ether_addr(dest))
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	{
+		br->dev->stats.rx_broadcast_packets++;
+#endif
 		skb2 = skb;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	}
+#endif
 	else if (is_multicast_ether_addr(dest)) {
 		mdst = br_mdb_get(br, skb);
 		if (mdst || BR_INPUT_SKB_CB_MROUTERS_ONLY(skb)) {
@@ -94,6 +106,10 @@
 			skb2 = skb;
 
 		br->dev->stats.multicast++;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+		br->dev->stats.rx_multicast_bytes += skb2->len;
+		br->dev->stats.rx_multicast_packets++;
+#endif
 	} else if ((dst = __br_fdb_get(br, dest)) && dst->is_local) {
 		skb2 = skb;
 		/* Do not forward the packet since it's local. */
diff -Naur kernel-3.3-3.0a-ref/net/core/dev.c kernel-current/net/core/dev.c
--- kernel-3.3-3.0a-ref/net/core/dev.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/core/dev.c	2015-06-12 16:27:19.972094064 +0200
@@ -5582,6 +5582,9 @@
 	 */
 	dev->hw_features |= NETIF_F_SOFT_FEATURES;
 	dev->features |= NETIF_F_SOFT_FEATURES;
+#if defined(CONFIG_BCM_KF_EXTSTATS)
+	dev->features |= NETIF_F_EXTSTATS;
+#endif	
 	dev->wanted_features = dev->features & dev->hw_features;
 
 	/* Turn on no cache copy if HW is doing checksum */
diff -Naur kernel-3.3-3.0a-ref/net/ipv4/devinet.c kernel-current/net/ipv4/devinet.c
--- kernel-3.3-3.0a-ref/net/ipv4/devinet.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/ipv4/devinet.c	2015-06-12 16:27:19.988102064 +0200
@@ -66,6 +66,7 @@
 
 #include "fib_lookup.h"
 
+#ifndef CONFIG_PROC_SYSCTL_SETTINGS
 static struct ipv4_devconf ipv4_devconf = {
 	.data = {
 		[IPV4_DEVCONF_ACCEPT_REDIRECTS - 1] = 1,
@@ -84,6 +85,60 @@
 		[IPV4_DEVCONF_ACCEPT_SOURCE_ROUTE - 1] = 1,
 	},
 };
+#else
+static struct ipv4_devconf ipv4_devconf = {
+	.data = {
+#ifdef CONFIG_IP_FORWARD
+		[IPV4_DEVCONF_FORWARDING-1] = 1,
+#endif
+
+#ifdef CONFIG_ACCEPT_REDIRECTS
+		[IPV4_DEVCONF_ACCEPT_REDIRECTS - 1] = 1,
+#endif		
+		[IPV4_DEVCONF_SEND_REDIRECTS - 1] = 1,
+		
+#ifdef CONFIG_SECURE_REDIRECTS		
+		[IPV4_DEVCONF_SECURE_REDIRECTS - 1] = 1,
+#endif
+
+		[IPV4_DEVCONF_SHARED_MEDIA - 1] = 1,
+#ifdef CONFIG_RP_FILTER		
+		[IPV4_DEVCONF_RP_FILTER -1] = 1,
+#endif
+		
+#ifdef CONFIG_ACCEPT_SOURCE_ROUTE
+		[IPV4_DEVCONF_ACCEPT_SOURCE_ROUTE - 1] = 1,
+#endif
+	},
+};
+
+static struct ipv4_devconf ipv4_devconf_dflt = {
+	.data = {
+#ifdef CONFIG_IP_FORWARD
+		[IPV4_DEVCONF_FORWARDING-1] = 1,
+#endif
+
+#ifdef CONFIG_ACCEPT_REDIRECTS
+		[IPV4_DEVCONF_ACCEPT_REDIRECTS - 1] = 1,
+#endif		
+		[IPV4_DEVCONF_SEND_REDIRECTS - 1] = 1,
+		
+#ifdef CONFIG_SECURE_REDIRECTS		
+		[IPV4_DEVCONF_SECURE_REDIRECTS - 1] = 1,
+#endif
+
+		[IPV4_DEVCONF_SHARED_MEDIA - 1] = 1,
+#ifdef CONFIG_RP_FILTER		
+		[IPV4_DEVCONF_RP_FILTER -1] = 1,
+#endif
+		
+#ifdef CONFIG_ACCEPT_SOURCE_ROUTE
+		[IPV4_DEVCONF_ACCEPT_SOURCE_ROUTE - 1] = 1,
+#endif
+	},
+};
+
+#endif /* CONFIG_PROC_SYSCTL_SETTINGS */
 
 #define IPV4_DEVCONF_DFLT(net, attr) \
 	IPV4_DEVCONF((*net->ipv4.devconf_dflt), attr)
diff -Naur kernel-3.3-3.0a-ref/net/ipv4/icmp.c kernel-current/net/ipv4/icmp.c
--- kernel-3.3-3.0a-ref/net/ipv4/icmp.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/ipv4/icmp.c	2015-06-12 16:27:19.992104064 +0200
@@ -1164,7 +1164,11 @@
 	}
 
 	/* Control parameters for ECHO replies. */
+#if !defined(CONFIG_PROC_SYSCTL_SETTINGS) || !defined(CONFIG_ICMP_ECHO_IGNORE_ALL)
 	net->ipv4.sysctl_icmp_echo_ignore_all = 0;
+#else
+	net->ipv4.sysctl_icmp_echo_ignore_all = 1;
+#endif
 	net->ipv4.sysctl_icmp_echo_ignore_broadcasts = 1;
 
 	/* Control parameter - ignore bogus broadcast responses? */
diff -Naur kernel-3.3-3.0a-ref/net/ipv4/tcp_input.c kernel-current/net/ipv4/tcp_input.c
--- kernel-3.3-3.0a-ref/net/ipv4/tcp_input.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/ipv4/tcp_input.c	2015-06-12 16:27:19.988102064 +0200
@@ -73,9 +73,17 @@
 #include <asm/unaligned.h>
 #include <net/netdma.h>
 
+#if !defined(CONFIG_PROC_SYSCTL_SETTINGS) || defined(CONFIG_TCP_TIMESTAMPS)
 int sysctl_tcp_timestamps __read_mostly = 1;
+#else
+int sysctl_tcp_timestamps __read_mostly = 0;
+#endif
 int sysctl_tcp_window_scaling __read_mostly = 1;
+#if !defined(CONFIG_PROC_SYSCTL_SETTINGS) || defined(CONFIG_TCP_SACK)
 int sysctl_tcp_sack __read_mostly = 1;
+#else
+int sysctl_tcp_sack __read_mostly = 0;
+#endif
 int sysctl_tcp_fack __read_mostly = 1;
 int sysctl_tcp_reordering __read_mostly = TCP_FASTRETRANS_THRESH;
 EXPORT_SYMBOL(sysctl_tcp_reordering);
diff -Naur kernel-3.3-3.0a-ref/net/ipv6/addrconf.c kernel-current/net/ipv6/addrconf.c
--- kernel-3.3-3.0a-ref/net/ipv6/addrconf.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/net/ipv6/addrconf.c	2015-06-12 16:27:19.988102064 +0200
@@ -169,7 +169,11 @@
 	.hop_limit		= IPV6_DEFAULT_HOPLIMIT,
 	.mtu6			= IPV6_MIN_MTU,
 	.accept_ra		= 1,
+#if !defined(CONFIG_PROC_SYSCTL_SETTINGS) || defined(CONFIG_ACCEPT_REDIRECTS)
 	.accept_redirects	= 1,
+#else
+	.accept_redirects	= 0,
+#endif
 	.autoconf		= 1,
 	.force_mld_version	= 0,
 	.dad_transmits		= 1,
@@ -204,7 +208,11 @@
 	.hop_limit		= IPV6_DEFAULT_HOPLIMIT,
 	.mtu6			= IPV6_MIN_MTU,
 	.accept_ra		= 1,
+#if !defined(CONFIG_PROC_SYSCTL_SETTINGS) || defined(CONFIG_ACCEPT_REDIRECTS)
 	.accept_redirects	= 1,
+#else
+	.accept_redirects	= 0,
+#endif
 	.autoconf		= 1,
 	.dad_transmits		= 1,
 	.rtr_solicits		= MAX_RTR_SOLICITATIONS,
diff -Naur kernel-3.3-3.0a-ref/scripts/gen_initramfs_list.sh kernel-current/scripts/gen_initramfs_list.sh
--- kernel-3.3-3.0a-ref/scripts/gen_initramfs_list.sh	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/scripts/gen_initramfs_list.sh	2015-06-12 16:27:19.956086065 +0200
@@ -11,7 +11,7 @@
 
 # error out on errors
 set -e
-
+all_files=()
 usage() {
 cat << EOF
 Usage:
@@ -97,7 +97,11 @@
 }
 
 list_parse() {
-	[ ! -L "$1" ] && echo "$1 \\" || :
+        if [ ! -f $1 ]; then
+	  [ ! -L "$1" ] && echo "$1 \\" || :
+	else
+	  [ ! -L "$1" ] &&  [[ ${x} != *container*rootfs* ]] && echo "$1 \\" || :
+	fi
 }
 
 # for each file print a line in following format
@@ -112,6 +116,9 @@
 	local uid="$3"
 	local gid="$4"
 	local ftype=$(filetype "${location}")
+	local rootfs_path=`echo ${ROOTFS_PATH}| sed -e "s#//#/#g" ` 
+	local abshardlinks=""
+	local hardlink=""
 	# remap uid/gid to 0 if necessary
 	[ "$root_uid" = "squash" ] && uid=0 || [ "$uid" -eq "$root_uid" ] && uid=0
 	[ "$root_gid" = "squash" ] && gid=0 || [ "$gid" -eq "$root_gid" ] && gid=0
@@ -119,10 +126,40 @@
 
 	[ "${ftype}" = "invalid" ] && return 0
 	[ "${location}" = "${srcdir}" ] && return 0
-
 	case "${ftype}" in
 		"file")
-			str="${ftype} ${name} ${location} ${str}"
+			
+			haslink=`find ${location} -type f -links +1`
+			if [[ $haslink ]]; then
+			    abshardlinks=`find $rootfs_path -xdev -samefile $location`
+			    abshardlinks=`echo ${abshardlinks}| sed -e "s#//#/#g" `  
+			    hardlinks=` echo $abshardlinks | sed -e "s#$rootfs_path#/#g"`
+			    found=0
+                            for hardlink  in ${hardlinks[@]}; do
+			      for i in ${all_files[@]}; do
+			         #echo "test "$i" with "$hardlink
+			         if [ "$i" = "$hardlink" ]; then
+				    found=1
+				    break
+				    #echo "found  "$i
+				 fi
+				 if [ $found -eq 1 ]; then break;fi
+			      done   
+			    done
+			    if [ $found -eq 0 ]; then
+			    # this link is not in our list
+			    # we add it	
+			       #echo "Add "$location
+			       #echo "hl:"$hardlinks		    
+			       rela_name=` echo $location | sed -e "s#$rootfs_path#/#g"` 
+			       all_files=("${all_files[@]}" ${rela_name} )
+                               str="${ftype} ${name} ${location}  ${str} ${hardlinks}"
+			    else
+			       str=""   
+			    fi
+		        else
+			   str="${ftype} ${name} ${location}  ${str}"
+			fi
 			;;
 		"nod")
 			local dev=`LC_ALL=C ls -l "${location}"`
@@ -155,7 +192,7 @@
 	printf "by './' so that it won't be interpreted as an option." >&2
 	printf "\n" >&2
 	usage >&2
-	exit 1
+//	exit 1
 }
 
 list_header() {
@@ -172,7 +209,6 @@
 
 	srcdir=$(echo "$1" | sed -e 's://*:/:g')
 	dirlist=$(find "${srcdir}" -printf "%p %m %U %G\n")
-
 	# If $dirlist is only one line, then the directory is empty
 	if [  "$(echo "${dirlist}" | wc -l)" -gt 1 ]; then
 		${dep_list}print_mtime "$1"
@@ -295,7 +331,8 @@
 			fi
 		fi
 		cpio_tfile="$(mktemp ${TMPDIR:-/tmp}/cpiofile.XXXXXX)"
-		usr/gen_init_cpio $timestamp ${cpio_list} > ${cpio_tfile}
+		sort ${cpio_list} > ${cpio_list}.sorted
+		usr/gen_init_cpio $timestamp ${cpio_list}.sorted > ${cpio_tfile}
 	else
 		cpio_tfile=${cpio_file}
 	fi
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/apparmorfs-24.c kernel-current/security/apparmor/apparmorfs-24.c
--- kernel-3.3-3.0a-ref/security/apparmor/apparmorfs-24.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/security/apparmor/apparmorfs-24.c	2015-06-12 16:27:19.888052067 +0200
@@ -0,0 +1,287 @@
+/*
+ * AppArmor security module
+ *
+ * This file contains AppArmor /sys/kernel/secrutiy/apparmor interface functions
+ *
+ * Copyright (C) 1998-2008 Novell/SUSE
+ * Copyright 2009-2010 Canonical Ltd.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation, version 2 of the
+ * License.
+ *
+ *
+ * This file contain functions providing an interface for <= AppArmor 2.4
+ * compatibility.  It is dependent on CONFIG_SECURITY_APPARMOR_COMPAT_24
+ * being set (see Makefile).
+ */
+
+#include <linux/security.h>
+#include <linux/vmalloc.h>
+#include <linux/module.h>
+#include <linux/seq_file.h>
+#include <linux/uaccess.h>
+#include <linux/namei.h>
+
+#include "include/apparmor.h"
+#include "include/audit.h"
+#include "include/context.h"
+#include "include/policy.h"
+
+
+/* apparmor/matching */
+static ssize_t aa_matching_read(struct file *file, char __user *buf,
+				size_t size, loff_t *ppos)
+{
+	const char matching[] = "pattern=aadfa audit perms=crwxamlk/ "
+	    "user::other";
+
+	return simple_read_from_buffer(buf, size, ppos, matching,
+				       sizeof(matching) - 1);
+}
+
+const struct file_operations aa_fs_matching_fops = {
+	.read = aa_matching_read,
+};
+
+/* apparmor/features */
+static ssize_t aa_features_read(struct file *file, char __user *buf,
+				size_t size, loff_t *ppos)
+{
+	const char features[] = "file=3.1 capability=2.0 network=1.0 "
+	    "change_hat=1.5 change_profile=1.1 " "aanamespaces=1.1 rlimit=1.1";
+
+	return simple_read_from_buffer(buf, size, ppos, features,
+				       sizeof(features) - 1);
+}
+
+const struct file_operations aa_fs_features_fops = {
+	.read = aa_features_read,
+};
+
+/**
+ * __next_namespace - find the next namespace to list
+ * @root: root namespace to stop search at (NOT NULL)
+ * @ns: current ns position (NOT NULL)
+ *
+ * Find the next namespace from @ns under @root and handle all locking needed
+ * while switching current namespace.
+ *
+ * Returns: next namespace or NULL if at last namespace under @root
+ * NOTE: will not unlock root->lock
+ */
+static struct aa_namespace *__next_namespace(struct aa_namespace *root,
+					     struct aa_namespace *ns)
+{
+	struct aa_namespace *parent;
+
+	/* is next namespace a child */
+	if (!list_empty(&ns->sub_ns)) {
+		struct aa_namespace *next;
+		next = list_first_entry(&ns->sub_ns, typeof(*ns), base.list);
+		read_lock(&next->lock);
+		return next;
+	}
+
+	/* check if the next ns is a sibling, parent, gp, .. */
+	parent = ns->parent;
+	while (parent) {
+		read_unlock(&ns->lock);
+		list_for_each_entry_continue(ns, &parent->sub_ns, base.list) {
+			read_lock(&ns->lock);
+			return ns;
+		}
+		if (parent == root)
+			return NULL;
+		ns = parent;
+		parent = parent->parent;
+	}
+
+	return NULL;
+}
+
+/**
+ * __first_profile - find the first profile in a namespace
+ * @root: namespace that is root of profiles being displayed (NOT NULL)
+ * @ns: namespace to start in   (NOT NULL)
+ *
+ * Returns: unrefcounted profile or NULL if no profile
+ */
+static struct aa_profile *__first_profile(struct aa_namespace *root,
+					  struct aa_namespace *ns)
+{
+	for ( ; ns; ns = __next_namespace(root, ns)) {
+		if (!list_empty(&ns->base.profiles))
+			return list_first_entry(&ns->base.profiles,
+						struct aa_profile, base.list);
+	}
+	return NULL;
+}
+
+/**
+ * __next_profile - step to the next profile in a profile tree
+ * @profile: current profile in tree (NOT NULL)
+ *
+ * Perform a depth first taversal on the profile tree in a namespace
+ *
+ * Returns: next profile or NULL if done
+ * Requires: profile->ns.lock to be held
+ */
+static struct aa_profile *__next_profile(struct aa_profile *p)
+{
+	struct aa_profile *parent;
+	struct aa_namespace *ns = p->ns;
+
+	/* is next profile a child */
+	if (!list_empty(&p->base.profiles))
+		return list_first_entry(&p->base.profiles, typeof(*p),
+					base.list);
+
+	/* is next profile a sibling, parent sibling, gp, subling, .. */
+	parent = p->parent;
+	while (parent) {
+		list_for_each_entry_continue(p, &parent->base.profiles,
+					     base.list)
+				return p;
+		p = parent;
+		parent = parent->parent;
+	}
+
+	/* is next another profile in the namespace */
+	list_for_each_entry_continue(p, &ns->base.profiles, base.list)
+		return p;
+
+	return NULL;
+}
+
+/**
+ * next_profile - step to the next profile in where ever it may be
+ * @root: root namespace  (NOT NULL)
+ * @profile: current profile  (NOT NULL)
+ *
+ * Returns: next profile or NULL if there isn't one
+ */
+static struct aa_profile *next_profile(struct aa_namespace *root,
+				       struct aa_profile *profile)
+{
+	struct aa_profile *next = __next_profile(profile);
+	if (next)
+		return next;
+
+	/* finished all profiles in namespace move to next namespace */
+	return __first_profile(root, __next_namespace(root, profile->ns));
+}
+
+/**
+ * p_start - start a depth first traversal of profile tree
+ * @f: seq_file to fill
+ * @pos: current position
+ *
+ * Returns: first profile under current namespace or NULL if none found
+ *
+ * acquires first ns->lock
+ */
+static void *p_start(struct seq_file *f, loff_t *pos)
+	__acquires(root->lock)
+{
+	struct aa_profile *profile = NULL;
+	struct aa_namespace *root = aa_current_profile()->ns;
+	loff_t l = *pos;
+	f->private = aa_get_namespace(root);
+
+
+	/* find the first profile */
+	read_lock(&root->lock);
+	profile = __first_profile(root, root);
+
+	/* skip to position */
+	for (; profile && l > 0; l--)
+		profile = next_profile(root, profile);
+
+	return profile;
+}
+
+/**
+ * p_next - read the next profile entry
+ * @f: seq_file to fill
+ * @p: profile previously returned
+ * @pos: current position
+ *
+ * Returns: next profile after @p or NULL if none
+ *
+ * may acquire/release locks in namespace tree as necessary
+ */
+static void *p_next(struct seq_file *f, void *p, loff_t *pos)
+{
+	struct aa_profile *profile = p;
+	struct aa_namespace *root = f->private;
+	(*pos)++;
+
+	return next_profile(root, profile);
+}
+
+/**
+ * p_stop - stop depth first traversal
+ * @f: seq_file we are filling
+ * @p: the last profile writen
+ *
+ * Release all locking done by p_start/p_next on namespace tree
+ */
+static void p_stop(struct seq_file *f, void *p)
+	__releases(root->lock)
+{
+	struct aa_profile *profile = p;
+	struct aa_namespace *root = f->private, *ns;
+
+	if (profile) {
+		for (ns = profile->ns; ns && ns != root; ns = ns->parent)
+			read_unlock(&ns->lock);
+	}
+	read_unlock(&root->lock);
+	aa_put_namespace(root);
+}
+
+/**
+ * seq_show_profile - show a profile entry
+ * @f: seq_file to file
+ * @p: current position (profile)    (NOT NULL)
+ *
+ * Returns: error on failure
+ */
+static int seq_show_profile(struct seq_file *f, void *p)
+{
+	struct aa_profile *profile = (struct aa_profile *)p;
+	struct aa_namespace *root = f->private;
+
+	if (profile->ns != root)
+		seq_printf(f, ":%s://", aa_ns_name(root, profile->ns));
+	seq_printf(f, "%s (%s)\n", profile->base.hname,
+		   COMPLAIN_MODE(profile) ? "complain" : "enforce");
+
+	return 0;
+}
+
+static const struct seq_operations aa_fs_profiles_op = {
+	.start = p_start,
+	.next = p_next,
+	.stop = p_stop,
+	.show = seq_show_profile,
+};
+
+static int profiles_open(struct inode *inode, struct file *file)
+{
+	return seq_open(file, &aa_fs_profiles_op);
+}
+
+static int profiles_release(struct inode *inode, struct file *file)
+{
+	return seq_release(inode, file);
+}
+
+const struct file_operations aa_fs_profiles_fops = {
+	.open = profiles_open,
+	.read = seq_read,
+	.llseek = seq_lseek,
+	.release = profiles_release,
+};
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/apparmorfs.c kernel-current/security/apparmor/apparmorfs.c
--- kernel-3.3-3.0a-ref/security/apparmor/apparmorfs.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/apparmorfs.c	2015-06-12 16:27:19.888052067 +0200
@@ -187,7 +187,11 @@
 		aafs_remove(".remove");
 		aafs_remove(".replace");
 		aafs_remove(".load");
-
+#ifdef CONFIG_SECURITY_APPARMOR_COMPAT_24
+		aafs_remove("profiles");
+		aafs_remove("matching");
+		aafs_remove("features");
+#endif
 		securityfs_remove(aa_fs_dentry);
 		aa_fs_dentry = NULL;
 	}
@@ -218,7 +222,17 @@
 		aa_fs_dentry = NULL;
 		goto error;
 	}
-
+#ifdef CONFIG_SECURITY_APPARMOR_COMPAT_24
+	error = aafs_create("matching", 0444, &aa_fs_matching_fops);
+	if (error)
+		goto error;
+	error = aafs_create("features", 0444, &aa_fs_features_fops);
+	if (error)
+		goto error;
+#endif
+	error = aafs_create("profiles", 0440, &aa_fs_profiles_fops);
+	if (error)
+		goto error;
 	error = aafs_create(".load", 0640, &aa_fs_profile_load);
 	if (error)
 		goto error;
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/include/apparmorfs.h kernel-current/security/apparmor/include/apparmorfs.h
--- kernel-3.3-3.0a-ref/security/apparmor/include/apparmorfs.h	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/include/apparmorfs.h	2015-06-12 16:27:19.888052067 +0200
@@ -17,4 +17,10 @@
 
 extern void __init aa_destroy_aafs(void);
 
+/*#ifdef CONFIG_SECURITY_APPARMOR_COMPAT_24*/
+extern const struct file_operations aa_fs_matching_fops;
+extern const struct file_operations aa_fs_features_fops;
+extern const struct file_operations aa_fs_profiles_fops;
+/*#endif*/
+
 #endif /* __AA_APPARMORFS_H */
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/include/net.h kernel-current/security/apparmor/include/net.h
--- kernel-3.3-3.0a-ref/security/apparmor/include/net.h	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/security/apparmor/include/net.h	2015-06-12 16:27:19.884050067 +0200
@@ -0,0 +1,40 @@
+/*
+ * AppArmor security module
+ *
+ * This file contains AppArmor network mediation definitions.
+ *
+ * Copyright (C) 1998-2008 Novell/SUSE
+ * Copyright 2009-2010 Canonical Ltd.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation, version 2 of the
+ * License.
+ */
+
+#ifndef __AA_NET_H
+#define __AA_NET_H
+
+#include <net/sock.h>
+
+/* struct aa_net - network confinement data
+ * @allowed: basic network families permissions
+ * @audit_network: which network permissions to force audit
+ * @quiet_network: which network permissions to quiet rejects
+ */
+struct aa_net {
+	u16 allow[AF_MAX];
+	u16 audit[AF_MAX];
+	u16 quiet[AF_MAX];
+};
+
+extern int aa_net_perm(int op, struct aa_profile *profile, u16 family,
+		       int type, int protocol, struct sock *sk);
+extern int aa_revalidate_sk(int op, struct sock *sk);
+
+static inline void aa_free_net_rules(struct aa_net *new)
+{
+	/* NOP */
+}
+
+#endif /* __AA_NET_H */
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/include/policy.h kernel-current/security/apparmor/include/policy.h
--- kernel-3.3-3.0a-ref/security/apparmor/include/policy.h	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/include/policy.h	2015-06-12 16:27:19.884050067 +0200
@@ -27,6 +27,7 @@
 #include "capability.h"
 #include "domain.h"
 #include "file.h"
+#include "net.h"
 #include "resource.h"
 
 extern const char *profile_mode_names[];
@@ -145,6 +146,7 @@
  * @size: the memory consumed by this profiles rules
  * @file: The set of rules governing basic file access and domain transitions
  * @caps: capabilities for the profile
+ * @net: network controls for the profile
  * @rlimits: rlimits for the profile
  *
  * The AppArmor profile contains the basic confinement data.  Each profile
@@ -181,6 +183,7 @@
 
 	struct aa_file_rules file;
 	struct aa_caps caps;
+	struct aa_net net;
 	struct aa_rlimit rlimits;
 };
 
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/Kconfig kernel-current/security/apparmor/Kconfig
--- kernel-3.3-3.0a-ref/security/apparmor/Kconfig	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/Kconfig	2015-06-12 16:27:19.888052067 +0200
@@ -29,3 +29,12 @@
 	  boot.
 
 	  If you are unsure how to answer this question, answer 1.
+
+config SECURITY_APPARMOR_COMPAT_24
+	bool "Enable AppArmor 2.4 compatability"
+	depends on SECURITY_APPARMOR
+	default y
+	help
+	  This option enables compatability with AppArmor 2.4.  It is
+          recommended if compatability with older versions of AppArmor
+          is desired.
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/lsm.c kernel-current/security/apparmor/lsm.c
--- kernel-3.3-3.0a-ref/security/apparmor/lsm.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/lsm.c	2015-06-12 16:27:19.884050067 +0200
@@ -32,6 +32,7 @@
 #include "include/context.h"
 #include "include/file.h"
 #include "include/ipc.h"
+#include "include/net.h"
 #include "include/path.h"
 #include "include/policy.h"
 #include "include/procattr.h"
@@ -620,6 +621,104 @@
 	return error;
 }
 
+static int apparmor_socket_create(int family, int type, int protocol, int kern)
+{
+	struct aa_profile *profile;
+	int error = 0;
+
+	if (kern)
+		return 0;
+
+	profile = __aa_current_profile();
+	if (!unconfined(profile))
+		error = aa_net_perm(OP_CREATE, profile, family, type, protocol,
+				    NULL);
+	return error;
+}
+
+static int apparmor_socket_bind(struct socket *sock,
+				struct sockaddr *address, int addrlen)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_BIND, sk);
+}
+
+static int apparmor_socket_connect(struct socket *sock,
+				   struct sockaddr *address, int addrlen)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_CONNECT, sk);
+}
+
+static int apparmor_socket_listen(struct socket *sock, int backlog)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_LISTEN, sk);
+}
+
+static int apparmor_socket_accept(struct socket *sock, struct socket *newsock)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_ACCEPT, sk);
+}
+
+static int apparmor_socket_sendmsg(struct socket *sock,
+				   struct msghdr *msg, int size)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_SENDMSG, sk);
+}
+
+static int apparmor_socket_recvmsg(struct socket *sock,
+				   struct msghdr *msg, int size, int flags)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_RECVMSG, sk);
+}
+
+static int apparmor_socket_getsockname(struct socket *sock)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_GETSOCKNAME, sk);
+}
+
+static int apparmor_socket_getpeername(struct socket *sock)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_GETPEERNAME, sk);
+}
+
+static int apparmor_socket_getsockopt(struct socket *sock, int level,
+				      int optname)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_GETSOCKOPT, sk);
+}
+
+static int apparmor_socket_setsockopt(struct socket *sock, int level,
+				      int optname)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_SETSOCKOPT, sk);
+}
+
+static int apparmor_socket_shutdown(struct socket *sock, int how)
+{
+	struct sock *sk = sock->sk;
+
+	return aa_revalidate_sk(OP_SOCK_SHUTDOWN, sk);
+}
+
 static struct security_operations apparmor_ops = {
 	.name =				"apparmor",
 
@@ -651,6 +750,19 @@
 	.getprocattr =			apparmor_getprocattr,
 	.setprocattr =			apparmor_setprocattr,
 
+	.socket_create =		apparmor_socket_create,
+	.socket_bind =			apparmor_socket_bind,
+	.socket_connect =		apparmor_socket_connect,
+	.socket_listen =		apparmor_socket_listen,
+	.socket_accept =		apparmor_socket_accept,
+	.socket_sendmsg =		apparmor_socket_sendmsg,
+	.socket_recvmsg =		apparmor_socket_recvmsg,
+	.socket_getsockname =		apparmor_socket_getsockname,
+	.socket_getpeername =		apparmor_socket_getpeername,
+	.socket_getsockopt =		apparmor_socket_getsockopt,
+	.socket_setsockopt =		apparmor_socket_setsockopt,
+	.socket_shutdown =		apparmor_socket_shutdown,
+
 	.cred_alloc_blank =		apparmor_cred_alloc_blank,
 	.cred_free =			apparmor_cred_free,
 	.cred_prepare =			apparmor_cred_prepare,
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/Makefile kernel-current/security/apparmor/Makefile
--- kernel-3.3-3.0a-ref/security/apparmor/Makefile	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/Makefile	2015-06-12 16:27:19.888052067 +0200
@@ -4,9 +4,10 @@
 
 apparmor-y := apparmorfs.o audit.o capability.o context.o ipc.o lib.o match.o \
               path.o domain.o policy.o policy_unpack.o procattr.o lsm.o \
-              resource.o sid.o file.o
+              resource.o sid.o file.o net.o
+apparmor-$(CONFIG_SECURITY_APPARMOR_COMPAT_24) += apparmorfs-24.o
 
-clean-files := capability_names.h rlim_names.h
+clean-files := capability_names.h rlim_names.h af_names.h
 
 
 # Build a lower case string table of capability names
@@ -44,9 +45,24 @@
 	sed -r -n "s/^\# ?define[ \t]+(RLIMIT_[A-Z0-9_]+).*/\1,/p" $< >> $@ ;\
 	echo "};" >> $@
 
+# Build a lower case string table of address family names.
+# Transform lines from
+# #define AF_INET		2	/* Internet IP Protocol 	*/
+# to
+# [2] = "inet",
+quiet_cmd_make-af = GEN     $@
+cmd_make-af = echo "static const char *address_family_names[] = {" > $@ ;\
+	sed $< >> $@ -r -n -e "/AF_MAX/d" -e "/AF_LOCAL/d" -e \
+	  's/^\#define[ \t]+AF_([A-Z0-9_]+)[ \t]+([0-9]+).*/[\2] = "\L\1",/p';\
+	echo "};" >> $@
+
+
 $(obj)/capability.o : $(obj)/capability_names.h
 $(obj)/resource.o : $(obj)/rlim_names.h
+$(obj)/net.o : $(obj)/af_names.h
 $(obj)/capability_names.h : $(srctree)/include/linux/capability.h
 	$(call cmd,make-caps)
 $(obj)/rlim_names.h : $(srctree)/include/asm-generic/resource.h
 	$(call cmd,make-rlim)
+$(obj)/af_names.h : $(srctree)/include/linux/socket.h
+	$(call cmd,make-af)
\ No newline at end of file
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/match.c kernel-current/security/apparmor/match.c
--- kernel-3.3-3.0a-ref/security/apparmor/match.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/match.c	2015-06-12 16:27:19.892054067 +0200
@@ -57,8 +57,17 @@
 	if (bsize < tsize)
 		goto out;
 
+	/* Pad table allocation for next/check by 256 entries to remain
+	 * backwards compatible with old (buggy) tools and remain safe without
+	 * run time checks
+	 */
+	if (th.td_id == YYTD_ID_NXT || th.td_id == YYTD_ID_CHK)
+		tsize += 256 * th.td_flags;
+
 	table = kvmalloc(tsize);
 	if (table) {
+		/* ensure the pad is clear, else there will be errors */
+		memset(table, 0, tsize);
 		*table = th;
 		if (th.td_flags == YYTD_DATA8)
 			UNPACK_ARRAY(table->td_data, blob, th.td_lolen,
@@ -134,11 +143,19 @@
 		goto out;
 
 	if (flags & DFA_FLAG_VERIFY_STATES) {
+		int warning = 0;
 		for (i = 0; i < state_count; i++) {
 			if (DEFAULT_TABLE(dfa)[i] >= state_count)
 				goto out;
 			/* TODO: do check that DEF state recursion terminates */
 			if (BASE_TABLE(dfa)[i] + 255 >= trans_count) {
+				if (warning)
+					continue;
+				printk(KERN_WARNING "AppArmor DFA next/check "
+				       "upper bounds error fixed, upgrade "
+				       "user space tools \n");
+				warning = 1;
+			} else if (BASE_TABLE(dfa)[i] >= trans_count) {
 				printk(KERN_ERR "AppArmor DFA next/check upper "
 				       "bounds error\n");
 				goto out;
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/net.c kernel-current/security/apparmor/net.c
--- kernel-3.3-3.0a-ref/security/apparmor/net.c	1970-01-01 01:00:00.000000000 +0100
+++ kernel-current/security/apparmor/net.c	2015-06-12 16:27:19.884050067 +0200
@@ -0,0 +1,170 @@
+/*
+ * AppArmor security module
+ *
+ * This file contains AppArmor network mediation
+ *
+ * Copyright (C) 1998-2008 Novell/SUSE
+ * Copyright 2009-2010 Canonical Ltd.
+ *
+ * This program is free software; you can redistribute it and/or
+ * modify it under the terms of the GNU General Public License as
+ * published by the Free Software Foundation, version 2 of the
+ * License.
+ */
+
+#include "include/apparmor.h"
+#include "include/audit.h"
+#include "include/context.h"
+#include "include/net.h"
+#include "include/policy.h"
+
+#include "af_names.h"
+
+static const char *sock_type_names[] = {
+	"unknown(0)",
+	"stream",
+	"dgram",
+	"raw",
+	"rdm",
+	"seqpacket",
+	"dccp",
+	"unknown(7)",
+	"unknown(8)",
+	"unknown(9)",
+	"packet",
+};
+
+/* audit callback for net specific fields */
+static void audit_cb(struct audit_buffer *ab, void *va)
+{
+	struct common_audit_data *sa = va;
+
+	audit_log_format(ab, " family=");
+	if (address_family_names[sa->u.net.family]) {
+		audit_log_string(ab, address_family_names[sa->u.net.family]);
+	} else {
+		audit_log_format(ab, " \"unknown(%d)\"", sa->u.net.family);
+	}
+
+	audit_log_format(ab, " sock_type=");
+	if (sock_type_names[sa->aad.net.type]) {
+		audit_log_string(ab, sock_type_names[sa->aad.net.type]);
+	} else {
+		audit_log_format(ab, "\"unknown(%d)\"", sa->aad.net.type);
+	}
+
+	audit_log_format(ab, " protocol=%d", sa->aad.net.protocol);
+}
+
+/**
+ * audit_net - audit network access
+ * @profile: profile being enforced  (NOT NULL)
+ * @op: operation being checked
+ * @family: network family
+ * @type:   network type
+ * @protocol: network protocol
+ * @sk: socket auditing is being applied to
+ * @error: error code for failure else 0
+ *
+ * Returns: %0 or sa->error else other errorcode on failure
+ */
+static int audit_net(struct aa_profile *profile, int op, u16 family, int type,
+		     int protocol, struct sock *sk, int error)
+{
+	int audit_type = AUDIT_APPARMOR_AUTO;
+	struct common_audit_data sa;
+	if (sk) {
+		COMMON_AUDIT_DATA_INIT(&sa, NET);
+	} else {
+		COMMON_AUDIT_DATA_INIT(&sa, NONE);
+	}
+	/* todo fill in socket addr info */
+
+	sa.aad.op = op,
+	sa.u.net.family = family;
+	sa.u.net.sk = sk;
+	sa.aad.net.type = type;
+	sa.aad.net.protocol = protocol;
+	sa.aad.error = error;
+
+	if (likely(!sa.aad.error)) {
+		u16 audit_mask = profile->net.audit[sa.u.net.family];
+		if (likely((AUDIT_MODE(profile) != AUDIT_ALL) &&
+			   !(1 << sa.aad.net.type & audit_mask)))
+			return 0;
+		audit_type = AUDIT_APPARMOR_AUDIT;
+	} else {
+		u16 quiet_mask = profile->net.quiet[sa.u.net.family];
+		u16 kill_mask = 0;
+		u16 denied = (1 << sa.aad.net.type) & ~quiet_mask;
+
+		if (denied & kill_mask)
+			audit_type = AUDIT_APPARMOR_KILL;
+
+		if ((denied & quiet_mask) &&
+		    AUDIT_MODE(profile) != AUDIT_NOQUIET &&
+		    AUDIT_MODE(profile) != AUDIT_ALL)
+			return COMPLAIN_MODE(profile) ? 0 : sa.aad.error;
+	}
+
+	return aa_audit(audit_type, profile, GFP_KERNEL, &sa, audit_cb);
+}
+
+/**
+ * aa_net_perm - very course network access check
+ * @op: operation being checked
+ * @profile: profile being enforced  (NOT NULL)
+ * @family: network family
+ * @type:   network type
+ * @protocol: network protocol
+ *
+ * Returns: %0 else error if permission denied
+ */
+int aa_net_perm(int op, struct aa_profile *profile, u16 family, int type,
+		int protocol, struct sock *sk)
+{
+	u16 family_mask;
+	int error;
+
+	if ((family < 0) || (family >= AF_MAX))
+		return -EINVAL;
+
+	if ((type < 0) || (type >= SOCK_MAX))
+		return -EINVAL;
+
+	/* unix domain and netlink sockets are handled by ipc */
+	if (family == AF_UNIX || family == AF_NETLINK)
+		return 0;
+
+	family_mask = profile->net.allow[family];
+
+	error = (family_mask & (1 << type)) ? 0 : -EACCES;
+
+	return audit_net(profile, op, family, type, protocol, sk, error);
+}
+
+/**
+ * aa_revalidate_sk - Revalidate access to a sock
+ * @op: operation being checked
+ * @sk: sock being revalidated  (NOT NULL)
+ *
+ * Returns: %0 else error if permission denied
+ */
+int aa_revalidate_sk(int op, struct sock *sk)
+{
+	struct aa_profile *profile;
+	int error = 0;
+
+	/* aa_revalidate_sk should not be called from interrupt context
+	 * don't mediate these calls as they are not task related
+	 */
+	if (in_interrupt())
+		return 0;
+
+	profile = __aa_current_profile();
+	if (!unconfined(profile))
+		error = aa_net_perm(op, profile, sk->sk_family, sk->sk_type,
+				    sk->sk_protocol, sk);
+
+	return error;
+}
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/path.c kernel-current/security/apparmor/path.c
--- kernel-3.3-3.0a-ref/security/apparmor/path.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/path.c	2015-06-12 16:27:19.892054067 +0200
@@ -104,9 +104,11 @@
 		*name = buf;
 		goto out;
 	}
-	if (!our_mnt(path->mnt))
+	
+/*	   patch for issue in bind directory that are already mount points
+        if (!our_mnt(path->mnt))
 		connected = 0;
-
+*/	
 ok:
 	/* Handle two cases:
 	 * 1. A deleted dentry && profile is not allowing mediation of deleted
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/policy.c kernel-current/security/apparmor/policy.c
--- kernel-3.3-3.0a-ref/security/apparmor/policy.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/policy.c	2015-06-12 16:27:19.884050067 +0200
@@ -745,6 +745,7 @@
 
 	aa_free_file_rules(&profile->file);
 	aa_free_cap_rules(&profile->caps);
+	aa_free_net_rules(&profile->net);
 	aa_free_rlimit_rules(&profile->rlimits);
 
 	aa_free_sid(profile->sid);
diff -Naur kernel-3.3-3.0a-ref/security/apparmor/policy_unpack.c kernel-current/security/apparmor/policy_unpack.c
--- kernel-3.3-3.0a-ref/security/apparmor/policy_unpack.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/apparmor/policy_unpack.c	2015-06-12 16:27:19.884050067 +0200
@@ -190,6 +190,19 @@
 	return 0;
 }
 
+static bool unpack_u16(struct aa_ext *e, u16 *data, const char *name)
+{
+	if (unpack_nameX(e, AA_U16, name)) {
+		if (!inbounds(e, sizeof(u16)))
+			return 0;
+		if (data)
+			*data = le16_to_cpu(get_unaligned((u16 *) e->pos));
+		e->pos += sizeof(u16);
+		return 1;
+	}
+	return 0;
+}
+
 static bool unpack_u32(struct aa_ext *e, u32 *data, const char *name)
 {
 	if (unpack_nameX(e, AA_U32, name)) {
@@ -468,7 +481,8 @@
 {
 	struct aa_profile *profile = NULL;
 	const char *name = NULL;
-	int error = -EPROTO;
+	size_t size = 0;
+	int i, error = -EPROTO;
 	kernel_cap_t tmpcap;
 	u32 tmp;
 
@@ -559,6 +573,38 @@
 	if (!unpack_rlimits(e, profile))
 		goto fail;
 
+	size = unpack_array(e, "net_allowed_af");
+	if (size) {
+
+		for (i = 0; i < size; i++) {
+			/* discard extraneous rules that this kernel will
+			 * never request
+			 */
+			if (i >= AF_MAX) {
+				u16 tmp;
+				if (!unpack_u16(e, &tmp, NULL) ||
+				    !unpack_u16(e, &tmp, NULL) ||
+				    !unpack_u16(e, &tmp, NULL))
+					goto fail;
+				continue;
+			}
+			if (!unpack_u16(e, &profile->net.allow[i], NULL))
+				goto fail;
+			if (!unpack_u16(e, &profile->net.audit[i], NULL))
+				goto fail;
+			if (!unpack_u16(e, &profile->net.quiet[i], NULL))
+				goto fail;
+		}
+		if (!unpack_nameX(e, AA_ARRAYEND, NULL))
+			goto fail;
+		/*
+		 * allow unix domain and netlink sockets they are handled
+		 * by IPC
+		 */
+	}
+	profile->net.allow[AF_UNIX] = 0xffff;
+	profile->net.allow[AF_NETLINK] = 0xffff;
+
 	/* get file rules */
 	profile->file.dfa = unpack_dfa(e);
 	if (IS_ERR(profile->file.dfa)) {
diff -Naur kernel-3.3-3.0a-ref/security/commoncap.c kernel-current/security/commoncap.c
--- kernel-3.3-3.0a-ref/security/commoncap.c	2013-08-28 01:31:07.000000000 +0200
+++ kernel-current/security/commoncap.c	2015-06-12 16:27:19.932074066 +0200
@@ -270,8 +270,7 @@
  */
 static inline void bprm_clear_caps(struct linux_binprm *bprm)
 {
-	cap_clear(bprm->cred->cap_permitted);
-	bprm->cap_effective = false;
+  return;
 }
 
 /**
@@ -531,8 +530,6 @@
 
 	if (effective)
 		new->cap_effective = new->cap_permitted;
-	else
-		cap_clear(new->cap_effective);
 	bprm->cap_effective = effective;
 
 	/*
