--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.cpp
@@ -51,10 +51,25 @@
 #include <gst/interfaces/streamvolume.h>
 #endif
 
-#if GST_CHECK_VERSION(1, 1, 0) && USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
 #include "TextureMapperGL.h"
 #endif
 
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && PLATFORM(QT)
+#define GL_GLEXT_PROTOTYPES
+#include "OpenGLShims.h"
+#endif
+
+#define EGL_EGLEXT_PROTOTYPES
+#include <gst/egl/egl.h>
+
+struct _EGLDetails {
+    EGLDisplay display;
+    EGLContext context;
+    EGLSurface draw;
+    EGLSurface read;
+};
+
 GST_DEBUG_CATEGORY(webkit_media_player_debug);
 #define GST_CAT_DEFAULT webkit_media_player_debug
 
@@ -99,10 +114,41 @@
     return FALSE;
 }
 
+static void mediaPlayerPrivateVideoPrerollCallback(GstElement* fakesink, GstBuffer* buffer, GstPad* pad, MediaPlayerPrivateGStreamerBase* player)
+{
+    player->updateEGLMemory(buffer);
+}
+
+static void mediaPlayerPrivateVideoBufferCallback(GstElement* fakesink, GstBuffer* buffer, GstPad* pad, MediaPlayerPrivateGStreamerBase* player)
+{
+    player->updateEGLMemory(buffer);
+}
+
+static gboolean mediaPlayerPrivateVideoEventCallback(GstPad* pad, GstEvent* event, MediaPlayerPrivateGStreamerBase* player)
+{
+    switch (GST_EVENT_TYPE (event)) {
+        case GST_EVENT_FLUSH_START:
+            player->queueFlushStart();
+            break;
+        case GST_EVENT_FLUSH_STOP:
+            player->queueFlushStop();
+            break;
+        case GST_EVENT_EOS:
+            player->queueObject(GST_MINI_OBJECT_CAST (gst_event_ref (event)), FALSE);
+            break;
+        default:
+            break;
+    }
+
+    return TRUE;
+}
+
+#if 0
 static void mediaPlayerPrivateRepaintCallback(WebKitVideoSink*, GstBuffer *buffer, MediaPlayerPrivateGStreamerBase* playerPrivate)
 {
     playerPrivate->triggerRepaint(buffer);
 }
+#endif
 
 MediaPlayerPrivateGStreamerBase::MediaPlayerPrivateGStreamerBase(MediaPlayer* player)
     : m_player(player)
@@ -115,6 +161,11 @@
     , m_repaintHandler(0)
     , m_volumeSignalHandler(0)
     , m_muteSignalHandler(0)
+    , m_queueFlushing(false)
+    , m_queueLastObject(NULL)
+    , m_currentEGLMemory(NULL)
+    , m_lastEGLMemory(NULL)
+    , m_egl_details(NULL)
 {
 #if GLIB_CHECK_VERSION(2, 31, 0)
     m_bufferMutex = WTF::fastNew<GMutex>();
@@ -122,11 +173,23 @@
 #else
     m_bufferMutex = g_mutex_new();
 #endif
+
+    m_queue = g_async_queue_new_full((GDestroyNotify) gst_mini_object_unref);
+    m_queueLock = WTF::fastNew<GMutex>();
+    g_mutex_init(m_queueLock);
+    m_queueCond = WTF::fastNew<GCond>();
+    g_cond_init(m_queueCond);
 }
 
 MediaPlayerPrivateGStreamerBase::~MediaPlayerPrivateGStreamerBase()
 {
-    g_signal_handler_disconnect(m_webkitVideoSink.get(), m_repaintHandler);
+    if (m_repaintHandler) {
+        g_signal_handler_disconnect(m_webkitVideoSink.get(), m_repaintHandler);
+        m_repaintHandler = 0;
+    }
+
+    g_signal_handlers_disconnect_by_func(m_webkitVideoSink.get(), reinterpret_cast<gpointer>(mediaPlayerPrivateVideoPrerollCallback), this);
+    g_signal_handlers_disconnect_by_func(m_webkitVideoSink.get(), reinterpret_cast<gpointer>(mediaPlayerPrivateVideoBufferCallback), this);
 
 #if GLIB_CHECK_VERSION(2, 31, 0)
     g_mutex_clear(m_bufferMutex);
@@ -157,10 +220,32 @@
         m_muteSignalHandler = 0;
     }
 
+    if (m_egl_details) {
+        delete m_egl_details;
+        m_egl_details = NULL;
+    }
+
 #if USE(NATIVE_FULLSCREEN_VIDEO)
     if (m_fullscreenVideoController)
         exitFullscreen();
 #endif
+
+    queueFlushStop();
+
+    if (m_queue) {
+        g_async_queue_unref (m_queue);
+    }
+
+    if (m_queueLock) {
+        g_mutex_clear(m_queueLock);
+        WTF::fastDelete(m_queueLock);
+    }
+
+    if (m_queueCond) {
+        g_cond_clear(m_queueCond);
+        WTF::fastDelete(m_queueCond);
+    }
+    LOG_MEDIA_MESSAGE("Player destroyed");
 }
 
 // Returns the size of the video
@@ -320,8 +405,275 @@
     m_muteTimerHandler = g_timeout_add(0, reinterpret_cast<GSourceFunc>(mediaPlayerPrivateMuteChangeTimeoutCallback), this);
 }
 
+static gboolean mediaPlayerPrivateProcessQueueCallback (MediaPlayerPrivateGStreamerBase* player)
+{
+    player->triggerRepaint();
+    return FALSE;
+}
 
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+void MediaPlayerPrivateGStreamerBase::updateEGLMemory (GstBuffer * buffer)
+{
+    g_mutex_lock (m_queueLock);
+    if (m_currentEGLMemory) {
+        gst_egl_image_memory_unref (m_currentEGLMemory);
+        m_currentEGLMemory = NULL;
+    }
+    if (GST_BUFFER_FLAG_IS_SET (buffer, GST_BUFFER_FLAG_PREROLL) || m_queueFlushing) {
+        if (m_lastEGLMemory) {
+            gst_egl_image_memory_unref (m_lastEGLMemory);
+            m_lastEGLMemory = NULL;
+        }
+    } else {
+        GstEGLImageMemory *mem = (GstEGLImageMemory *) GST_BUFFER_DATA (buffer);
+        LOG_MEDIA_MESSAGE("Buffer %" GST_TIME_FORMAT " EGL Image: %p", GST_TIME_ARGS(GST_BUFFER_TIMESTAMP (buffer)), gst_egl_image_memory_get_image (mem));
+        m_currentEGLMemory = gst_egl_image_memory_ref (mem);
+        g_timeout_add_full (G_PRIORITY_HIGH, 0, (GSourceFunc) mediaPlayerPrivateProcessQueueCallback,
+            this, NULL);
+    }
+    g_mutex_unlock (m_queueLock);
+}
+
+gboolean MediaPlayerPrivateGStreamerBase::queueObject (GstMiniObject * obj, gboolean synchronous)
+{
+    gboolean res = TRUE;
+    g_mutex_lock (m_queueLock);
+    if (m_queueFlushing) {
+        gst_mini_object_unref (obj);
+        res = FALSE;
+        goto beach;
+    }
+
+    LOG_MEDIA_MESSAGE("queue object: %p", obj);
+    g_async_queue_push (m_queue, obj);
+
+    g_timeout_add_full (G_PRIORITY_HIGH, 0, (GSourceFunc) mediaPlayerPrivateProcessQueueCallback,
+        this, NULL);
+
+    if (synchronous) {
+        /* Waiting for object to be handled */
+        do {
+            g_cond_wait (m_queueCond, m_queueLock);
+        } while (!m_queueFlushing && m_queueLastObject != obj);
+    }
+
+beach:
+    g_mutex_unlock (m_queueLock);
+    LOG_MEDIA_MESSAGE("queue object: done");
+    return res;
+}
+
+void MediaPlayerPrivateGStreamerBase::dequeueObjects ()
+{
+    GstMiniObject *object = NULL;
+
+    g_mutex_lock (m_queueLock);
+    if (m_queueFlushing) {
+        g_cond_broadcast (m_queueCond);
+    } else if ((object = GST_MINI_OBJECT_CAST (g_async_queue_try_pop (m_queue)))) {
+        if (GST_IS_MESSAGE (object)) {
+            GstMessage *message = GST_MESSAGE_CAST (object);
+            if (gst_structure_has_name (message->structure, "need-egl-pool")) {
+                GstElement *element = GST_ELEMENT (GST_MESSAGE_SRC (message));
+                gint size, width, height;
+
+                gst_message_parse_need_egl_pool (message, &size, &width, &height);
+
+                if (g_object_class_find_property (G_OBJECT_GET_CLASS (element), "pool")) {
+                    GstEGLImageMemoryPool *pool = NULL;
+
+                    if ((pool = createEGLPool (size, width, height))) {
+                        g_object_set (element, "pool", pool, NULL);
+                    }
+                }
+            }
+            gst_message_unref (message);
+        } else if (GST_IS_EVENT (object)) {
+            GstEvent *event = GST_EVENT_CAST (object);
+
+            switch (GST_EVENT_TYPE (event)) {
+                case GST_EVENT_EOS:
+                    if (m_lastEGLMemory) {
+                        gst_egl_image_memory_unref (m_lastEGLMemory);
+                        m_lastEGLMemory = NULL;
+                        object = NULL;
+                    }
+                    break;
+                default:
+                    break;
+            }
+            gst_event_unref (event);
+        }
+    }
+
+    if (object) {
+        m_queueLastObject = object;
+        LOG_MEDIA_MESSAGE("dequeued %p", object);
+        g_cond_broadcast (m_queueCond);
+    }
+    g_mutex_unlock (m_queueLock);
+}
+
+void MediaPlayerPrivateGStreamerBase::queueFlushStart()
+{
+    LOG_MEDIA_MESSAGE("Flush Start");
+    GstMiniObject *object = NULL;
+
+    g_mutex_lock (m_queueLock);
+    m_queueFlushing = true;
+    g_cond_broadcast (m_queueCond);
+    g_mutex_unlock (m_queueLock);
+
+    while ((object = GST_MINI_OBJECT_CAST (g_async_queue_try_pop (m_queue)))) {
+        gst_mini_object_unref (object);
+    }
+
+    g_mutex_lock (m_queueLock);
+    if (m_currentEGLMemory)
+        gst_egl_image_memory_unref (m_currentEGLMemory);
+    m_currentEGLMemory = NULL;
+
+    if (m_lastEGLMemory)
+        gst_egl_image_memory_unref (m_lastEGLMemory);
+    m_lastEGLMemory = NULL;
+
+    m_queueLastObject = NULL;
+    g_mutex_unlock (m_queueLock);
+}
+
+void MediaPlayerPrivateGStreamerBase::queueFlushStop()
+{
+    GstMiniObject *object = NULL;
+
+    g_mutex_lock (m_queueLock);
+    if (m_currentEGLMemory)
+        gst_egl_image_memory_unref (m_currentEGLMemory);
+    m_currentEGLMemory = NULL;
+
+    if (m_lastEGLMemory)
+        gst_egl_image_memory_unref (m_lastEGLMemory);
+    m_lastEGLMemory = NULL;
+
+    while ((object = GST_MINI_OBJECT_CAST (g_async_queue_try_pop (m_queue)))) {
+        gst_mini_object_unref (object);
+    }
+    m_queueLastObject = NULL;
+    m_queueFlushing = false;
+    g_mutex_unlock (m_queueLock);
+    LOG_MEDIA_MESSAGE("Flush Stop");
+}
+
+static void destroy_pool_resources (GstEGLImageMemoryPool * pool, gpointer user_data)
+{
+    gint i, size = gst_egl_image_memory_pool_get_size (pool);
+    EGLClientBuffer client_buffer;
+    EGLImageKHR image;
+    EGLint error;
+
+    /* reset error state */
+    while (glGetError() != GL_NO_ERROR);
+
+    GstEGLDisplay * gst_display = gst_egl_image_memory_pool_get_display (pool);
+    EGLDisplay display = gst_egl_display_get (gst_display);
+    gst_egl_display_unref (gst_display);
+
+    for (i = 0; i < size; i++) {
+        if (gst_egl_image_memory_pool_get_resources (pool, i, &client_buffer,
+                &image)) {
+            GLuint tid = (GLuint) client_buffer;
+            error = EGL_SUCCESS;
+
+            if (image != EGL_NO_IMAGE_KHR) {
+                eglDestroyImageKHR (display, image);
+                if ((error = eglGetError ()) != EGL_SUCCESS) {
+                    LOG_MEDIA_MESSAGE("eglDestroyImageKHR failed %x", error);
+                }
+            }
+
+            if (tid) {
+                error = GL_NO_ERROR;
+                glDeleteTextures (1, &tid);
+                if ((error = glGetError ()) != GL_NO_ERROR) {
+                    LOG_MEDIA_MESSAGE("glDeleteTextures failed %x", error);
+                }
+            }
+            LOG_MEDIA_MESSAGE("destroyed texture %x image %p", tid, image);
+        }
+    }
+}
+GstEGLImageMemoryPool* MediaPlayerPrivateGStreamerBase::createEGLPool(gint size, gint width, gint height)
+{
+    GstEGLImageMemoryPool *pool;
+    gint i;
+    EGLint error;
+    GstEGLDisplay *gst_display;
+
+    if (!width && !height) {
+      width = 320;
+      height = 200;
+    }
+
+    if (!m_egl_details) {
+        m_egl_details = new EGLDetails();
+        m_egl_details->display = eglGetCurrentDisplay();
+        m_egl_details->context = eglGetCurrentContext();
+        m_egl_details->draw = eglGetCurrentSurface(0);
+        m_egl_details->read = eglGetCurrentSurface(1);
+        LOG_MEDIA_MESSAGE("display %p context %p", m_egl_details->display, m_egl_details->context);
+    }
+
+    /* reset error state */
+    while (glGetError() != GL_NO_ERROR);
+
+    gst_display = gst_egl_display_new (m_egl_details->display, NULL, NULL);
+    pool = gst_egl_image_memory_pool_new (size, gst_display, this,
+        destroy_pool_resources);
+    gst_egl_display_unref (gst_display);
+
+    for (i = 0; i < size; i++) {
+        GLuint tid;
+        EGLImageKHR image;
+
+        error = GL_NO_ERROR;
+        glGenTextures (1, &tid);
+        if ((error = glGetError ()) != GL_NO_ERROR) {
+            LOG_MEDIA_MESSAGE("glGenTextures failed %x", error);
+            goto failed;
+        }
+
+        glBindTexture (GL_TEXTURE_2D, tid);
+        glTexImage2D (GL_TEXTURE_2D, 0, GL_RGBA, width, height, 0, GL_RGBA,
+            GL_UNSIGNED_BYTE, NULL);
+        if ((error = glGetError ()) != GL_NO_ERROR) {
+          LOG_MEDIA_MESSAGE("glTexImage2D failed %x", error);
+          goto failed;
+        }
+        /* Create EGL Image */
+        error = EGL_SUCCESS;
+        image = eglCreateImageKHR (m_egl_details->display, m_egl_details->context,
+            EGL_GL_TEXTURE_2D_KHR, (EGLClientBuffer) tid, 0);
+
+        if (image == EGL_NO_IMAGE_KHR) {
+          if ((error = eglGetError ()) != EGL_SUCCESS) {
+            LOG_MEDIA_MESSAGE("eglCreateImageKHR failed %x", error);
+          } else {
+            LOG_MEDIA_MESSAGE("eglCreateImageKHR failed");
+          }
+          goto failed;
+        }
+        LOG_MEDIA_MESSAGE("created texture %x image %p", tid, image);
+        gst_egl_image_memory_pool_set_resources (pool, i, (EGLClientBuffer) tid,
+            image);
+    }
+    return pool;
+
+failed:
+    gst_egl_image_memory_pool_unref (pool);
+    return NULL;
+}
+
+
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
+#if !USE(COORDINATED_GRAPHICS)
 PassRefPtr<BitmapTexture> MediaPlayerPrivateGStreamerBase::updateTexture(TextureMapper* textureMapper)
 {
     g_mutex_lock(m_bufferMutex);
@@ -383,7 +735,38 @@
     g_mutex_unlock(m_bufferMutex);
     return texture;
 }
+#else
+void MediaPlayerPrivateGStreamerBase::updateTexture()
+{
+    GstEGLImageMemory *mem;
+
+    mem = m_currentEGLMemory;
+
+    if (!mem)
+        return;
+
+    GLint texId = static_cast<const BitmapTextureGL*>(m_texture.get())->id();
+
+    GLint ctexId;
+    glGetIntegerv(GL_TEXTURE_BINDING_2D, &ctexId);
+
+    LOG_MEDIA_MESSAGE ("Upload EGL image: %p on texture %d current texture was: %d",
+        gst_egl_image_memory_get_image (mem), texId, ctexId);
+
+    glEnable(GL_TEXTURE_2D);
+    glBindTexture (GL_TEXTURE_2D, texId);
+    glEGLImageTargetTexture2DOES (GL_TEXTURE_2D, gst_egl_image_memory_get_image (mem));
+    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MIN_FILTER, GL_LINEAR);
+    glTexParameterf(GL_TEXTURE_2D, GL_TEXTURE_MAG_FILTER, GL_LINEAR);
+}
 #endif
+#endif
+
+void MediaPlayerPrivateGStreamerBase::triggerRepaint()
+{
+    client()->setPlatformLayerNeedsDisplay();
+    m_player->repaint();
+}
 
 void MediaPlayerPrivateGStreamerBase::triggerRepaint(GstBuffer* buffer)
 {
@@ -410,7 +793,7 @@
 
 void MediaPlayerPrivateGStreamerBase::paint(GraphicsContext* context, const IntRect& rect)
 {
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
     if (client())
         return;
 #endif
@@ -448,7 +831,7 @@
     g_mutex_unlock(m_bufferMutex);
 }
 
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
 void MediaPlayerPrivateGStreamerBase::paintToTextureMapper(TextureMapper* textureMapper, const FloatRect& targetRect, const TransformationMatrix& matrix, float opacity)
 {
     if (textureMapper->accelerationMode() != TextureMapper::OpenGLMode)
@@ -457,9 +840,40 @@
     if (!m_player->visible())
         return;
 
+#if !USE(COORDINATED_GRAPHICS)
     RefPtr<BitmapTexture> texture = updateTexture(textureMapper);
     if (texture)
         textureMapper->drawTexture(*texture.get(), targetRect, matrix, opacity);
+#else
+    IntSize size = naturalSize();
+
+    if (!m_texture) {
+        m_texture = textureMapper->acquireTextureFromPool(size);
+        if (!m_texture) {
+            LOG_MEDIA_MESSAGE("failed acquiring texture");
+        }
+    }
+
+    dequeueObjects();
+
+    if (m_texture) {
+        g_mutex_lock (m_queueLock);
+        updateTexture();
+        TransformationMatrix mmatrix = matrix;
+        mmatrix.setM22(-mmatrix.m22());
+        mmatrix.setM42(targetRect.maxY() + mmatrix.m42());
+        textureMapper->drawTexture(*m_texture.get(), targetRect, mmatrix, opacity);
+        if (m_lastEGLMemory) {
+            gst_egl_image_memory_unref (m_lastEGLMemory);
+            m_lastEGLMemory = NULL;
+        }
+        if (m_currentEGLMemory) {
+            m_lastEGLMemory = m_currentEGLMemory;
+            m_currentEGLMemory = NULL;
+        }
+        g_mutex_unlock (m_queueLock);
+    }
+#endif
 }
 #endif
 
@@ -530,11 +944,19 @@
     m_gstGWorld = GStreamerGWorld::createGWorld(pipeline);
     m_webkitVideoSink = webkitVideoSinkNew(m_gstGWorld.get());
 #else
-    UNUSED_PARAM(pipeline);
-    m_webkitVideoSink = webkitVideoSinkNew();
-#endif
+    m_pipeline = pipeline;
+    m_webkitVideoSink = gst_element_factory_make("fakesink", "vsink");
+    g_object_set (m_webkitVideoSink.get(), "sync", TRUE, "silent", TRUE,
+        "enable-last-buffer", FALSE,
+        "qos", TRUE,
+        "max-lateness", 20 * GST_MSECOND, "signal-handoffs", TRUE, NULL);
+    g_signal_connect (m_webkitVideoSink.get(), "preroll-handoff", G_CALLBACK (mediaPlayerPrivateVideoPrerollCallback), this);
+    g_signal_connect (m_webkitVideoSink.get(), "handoff", G_CALLBACK (mediaPlayerPrivateVideoBufferCallback), this);
 
-    m_repaintHandler = g_signal_connect(m_webkitVideoSink.get(), "repaint-requested", G_CALLBACK(mediaPlayerPrivateRepaintCallback), this);
+    GRefPtr<GstPad> videoSinkPad = adoptGRef(gst_element_get_static_pad(m_webkitVideoSink.get(), "sink"));
+    gst_pad_add_event_probe(videoSinkPad.get(), G_CALLBACK (mediaPlayerPrivateVideoEventCallback), this);
+
+#endif
 
 #if USE(NATIVE_FULLSCREEN_VIDEO)
     // Build a new video sink consisting of a bin containing a tee
@@ -559,7 +981,7 @@
 #endif
 
     GstElement* actualVideoSink = 0;
-    m_fpsSink = gst_element_factory_make("fpsdisplaysink", "sink");
+    m_fpsSink = gst_element_factory_make("disabledfpsdisplaysink", "sink");
     if (m_fpsSink) {
         // The verbose property has been added in -bad 0.10.22. Making
         // this whole code depend on it because we don't want
@@ -597,7 +1019,6 @@
     }
 
     ASSERT(actualVideoSink);
-
 #if USE(NATIVE_FULLSCREEN_VIDEO)
     // Faster elements linking.
     gst_element_link_pads_full(queue, "src", actualVideoSink, "sink", GST_PAD_LINK_CHECK_NOTHING);
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.h
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamerBase.h
@@ -31,7 +31,7 @@
 
 #include <wtf/Forward.h>
 
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
 #include "TextureMapperPlatformLayer.h"
 #endif
 
@@ -41,6 +41,12 @@
 typedef struct _GstStreamVolume GstStreamVolume;
 typedef struct _WebKitVideoSink WebKitVideoSink;
 
+typedef struct _GstMiniObject GstMiniObject;
+
+typedef struct _GstEGLImageMemoryPool GstEGLImageMemoryPool;
+typedef struct _GstEGLImageMemory GstEGLImageMemory;
+typedef struct _EGLDetails EGLDetails;
+
 namespace WebCore {
 
 class FullscreenVideoControllerGStreamer;
@@ -50,7 +56,7 @@
 class GStreamerGWorld;
 
 class MediaPlayerPrivateGStreamerBase : public MediaPlayerPrivateInterface
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
     , public TextureMapperPlatformLayer
 #endif
 {
@@ -103,12 +109,22 @@
     unsigned audioDecodedByteCount() const;
     unsigned videoDecodedByteCount() const;
 
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
     virtual PlatformLayer* platformLayer() const { return const_cast<MediaPlayerPrivateGStreamerBase*>(this); }
     virtual bool supportsAcceleratedRendering() const { return true; }
     virtual void paintToTextureMapper(TextureMapper*, const FloatRect&, const TransformationMatrix&, float);
 #endif
 
+    void updateEGLMemory (GstBuffer * buffer);
+    gboolean queueObject(GstMiniObject * obj, gboolean synchronous);
+    void dequeueObjects();
+    void queueFlushStart();
+    void queueFlushStop();
+    void triggerRepaint();
+    void flushLastEGLMemory();
+    GstEGLImageMemoryPool* createEGLPool(gint size, gint width, gint height);
+    GstElement* pipeline() const { return m_pipeline; }
+
 protected:
     MediaPlayerPrivateGStreamerBase(MediaPlayer*);
     GstElement* createVideoSink(GstElement* pipeline);
@@ -136,9 +152,23 @@
     unsigned long m_volumeSignalHandler;
     unsigned long m_muteSignalHandler;
     mutable IntSize m_videoSize;
-#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL) && !USE(COORDINATED_GRAPHICS)
+#if USE(ACCELERATED_COMPOSITING) && USE(TEXTURE_MAPPER_GL)
+#if !USE(COORDINATED_GRAPHICS)
     PassRefPtr<BitmapTexture> updateTexture(TextureMapper*);
+#else
+    void updateTexture();
+    RefPtr<BitmapTexture> m_texture;
+#endif
 #endif
+    GAsyncQueue *m_queue;
+    GMutex *m_queueLock;
+    GCond *m_queueCond;
+    bool m_queueFlushing;
+    GstMiniObject *m_queueLastObject;
+    GstEGLImageMemory *m_currentEGLMemory;
+    GstEGLImageMemory *m_lastEGLMemory;
+    EGLDetails *m_egl_details;
+    GstElement* m_pipeline;
 };
 }
 
--- a/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
+++ b/Source/WebCore/platform/graphics/gstreamer/MediaPlayerPrivateGStreamer.cpp
@@ -115,6 +115,15 @@
     return FALSE;
 }
 
+static GstBusSyncReply mediaPlayerPrivateSyncMessageCallback (GstBus * bus, GstMessage * message, MediaPlayerPrivateGStreamer* player)
+{
+  if ((GST_MESSAGE_TYPE (message) == GST_MESSAGE_ELEMENT) &&
+      gst_structure_has_name (message->structure, "need-egl-pool")) {
+    player->queueObject (GST_MINI_OBJECT_CAST (gst_message_ref (message)), TRUE);
+  }
+  return GST_BUS_PASS;
+}
+
 #ifdef GST_API_VERSION_1
 static void setAudioStreamPropertiesCallback(GstChildProxy*, GObject* object, gchar*,
     MediaPlayerPrivateGStreamer* player)
@@ -396,6 +405,8 @@
 
 void MediaPlayerPrivateGStreamer::prepareToPlay()
 {
+    dequeueObjects();
+
     m_preload = MediaPlayer::Auto;
     if (m_delayingLoad) {
         m_delayingLoad = false;
@@ -421,6 +432,9 @@
     if (currentState < GST_STATE_PAUSED && pendingState <= GST_STATE_PAUSED)
         return;
 
+    // In case we were waiting for providing a pool dequeue.
+    dequeueObjects();
+
     if (changePipelineState(GST_STATE_PAUSED))
         INFO_MEDIA_MESSAGE("Pause");
 }
@@ -1346,8 +1360,12 @@
 
     if (!m_player->mediaPlayerClient()->mediaPlayerIsLooping()) {
         m_paused = true;
+        LOG_MEDIA_MESSAGE("Setting pipeline to NULL state");
+        queueFlushStart();
         gst_element_set_state(m_playBin.get(), GST_STATE_NULL);
         m_downloadFinished = false;
+        queueFlushStop();
+
     }
 }
 
@@ -1601,10 +1619,11 @@
     setStreamVolumeElement(GST_STREAM_VOLUME(m_playBin.get()));
 
     GRefPtr<GstBus> bus = webkitGstPipelineGetBus(GST_PIPELINE(m_playBin.get()));
+    gst_bus_set_sync_handler(bus.get(), (GstBusSyncHandler) mediaPlayerPrivateSyncMessageCallback, this);
     gst_bus_add_signal_watch(bus.get());
     g_signal_connect(bus.get(), "message", G_CALLBACK(mediaPlayerPrivateMessageCallback), this);
 
-    g_object_set(m_playBin.get(), "mute", m_player->muted(), NULL);
+    g_object_set(m_playBin.get(), "mute", m_player->muted(), "flags", GST_PLAY_FLAG_NATIVE_VIDEO | GST_PLAY_FLAG_SOFT_VOLUME | GST_PLAY_FLAG_AUDIO | GST_PLAY_FLAG_VIDEO, NULL);
 
     g_signal_connect(m_playBin.get(), "notify::source", G_CALLBACK(mediaPlayerPrivateSourceChangedCallback), this);
     g_signal_connect(m_playBin.get(), "video-changed", G_CALLBACK(mediaPlayerPrivateVideoChangedCallback), this);
--- a/Source/WebCore/WebCore.pri
+++ b/Source/WebCore/WebCore.pri
@@ -175,7 +175,7 @@
 
 use?(GSTREAMER) {
     use?(GSTREAMER010) {
-        PKGCONFIG += gstreamer-0.10 gstreamer-app-0.10 gstreamer-base-0.10 gstreamer-interfaces-0.10 gstreamer-pbutils-0.10 gstreamer-plugins-base-0.10 gstreamer-video-0.10
+        PKGCONFIG += gstreamer-0.10 gstreamer-app-0.10 gstreamer-base-0.10 gstreamer-interfaces-0.10 gstreamer-pbutils-0.10 gstreamer-plugins-base-0.10 gstreamer-video-0.10 gstreamer-egl-0.10
     } else {
         DEFINES += GST_API_VERSION=1.0
         DEFINES += GST_API_VERSION_1
--- a/Source/WebKit/qt/WebCoreSupport/ChromeClientQt.cpp
+++ b/Source/WebKit/qt/WebCoreSupport/ChromeClientQt.cpp
@@ -656,7 +656,7 @@ void ChromeClientQt::scheduleCompositing
 ChromeClient::CompositingTriggerFlags ChromeClientQt::allowedCompositingTriggers() const
 {
     if (allowsAcceleratedCompositing())
-        return ThreeDTransformTrigger | CanvasTrigger | AnimationTrigger | AnimatedOpacityTrigger;
+        return ThreeDTransformTrigger | VideoTrigger | CanvasTrigger | AnimationTrigger | AnimatedOpacityTrigger;
 
     return 0;
 }
